{"question": "who is the owner of the mandalay bay in vegas", "answer": ["MGM Resorts International"], "scores": [[0.982421875, 0.9921875, 0.99951171875, 0.99951171875, 1.0, 0.99951171875]], "normalized_score": [0.9955030083656311], "tokens": [["\u2581M", "GM", "\u2581Res", "ort", "s", "\u2581International"]], "entropy": [[0.15673828125, 0.04736328125, 0.005992889404296875, 0.006618499755859375, 0.00036978721618652344, 0.005237579345703125]], "avg_entropy": [0.03705338637034098], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "MGM Resorts International", "score_of_biggest_cluster": 0.9955030083656311, "score_of_first_answer": 0.9955030083656311, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.982421875, "avg_score": 0.9955030083656311, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.006461916514031679, "std_of_first_answer": 0.006461916514031679, "avg_entropy_of_first_answer": 0.03705338637034098, "lex_sim": 1.0}
{"question": "when was the last time the jets won a playoff game", "answer": ["The New York Jets last won a playoff game in the 2010-2011 season."], "scores": [[0.13916015625, 0.63037109375, 0.99755859375, 1.0, 1.0, 0.52587890625, 0.990234375, 0.99951171875, 1.0, 1.0, 1.0, 0.40625, 0.7939453125, 0.9990234375, 1.0, 1.0, 0.99951171875, 0.99951171875, 0.9130859375, 0.9970703125, 1.0, 1.0, 1.0, 0.83154296875, 0.93017578125, 0.064453125, 0.7333984375, 0.9990234375, 0.9892578125, 1.0, 1.0, 1.0, 0.86474609375, 0.9970703125, 0.1187744140625, 1.0, 0.05865478515625, 0.5380859375, 0.3525390625, 0.498046875, 0.99951171875, 0.4208984375, 0.9990234375, 0.998046875, 1.0, 0.888671875, 0.78271484375, 0.98486328125, 0.99951171875, 0.75732421875]], "normalized_score": [0.7169619202613831], "tokens": [["\u2581The", "\u2581New", "\u2581York", "\u2581J", "ets", "\u2581last", "\u2581won", "\u2581a", "\u2581play", "off", "\u2581game", "\u2581in", "\u2581the", "\u2581", "2", "0", "1", "0", "-", "2", "0", "1", "1", "\u2581season", ".", "\u2581They", "\u2581defeated", "\u2581the", "\u2581Indian", "apolis", "\u2581Col", "ts", "\u2581in", "\u2581the", "\u2581A", "FC", "\u2581Championship", "\u2581Game", "\u2581and", "\u2581advanced", "\u2581to", "\u2581Super", "\u2581Bowl", "\u2581X", "L", "V", ",", "\u2581where", "\u2581they", "\u2581lost"]], "entropy": [[1.892578125, 0.9384765625, 0.0203704833984375, 0.001392364501953125, 0.00043892860412597656, 1.2353515625, 0.06072998046875, 0.002681732177734375, 0.0016508102416992188, 0.0007348060607910156, 0.0016469955444335938, 1.037109375, 0.62890625, 0.0113067626953125, 0.00013256072998046875, 5.662441253662109e-06, 0.00612640380859375, 0.00637054443359375, 0.4208984375, 0.02081298828125, 0.0014629364013671875, 0.0002143383026123047, 0.001041412353515625, 0.498291015625, 0.33349609375, 0.66064453125, 0.86376953125, 0.0072479248046875, 0.086181640625, 0.00023698806762695312, 0.0005288124084472656, 9.417533874511719e-06, 0.42626953125, 0.0258331298828125, 0.8203125, 0.0002434253692626953, 0.8203125, 0.7041015625, 1.458984375, 0.98291015625, 0.002864837646484375, 0.70654296875, 0.00728607177734375, 0.01910400390625, 0.0012655258178710938, 0.350830078125, 0.62109375, 0.0958251953125, 0.0035381317138671875, 0.70947265625]], "avg_entropy": [0.3299527275562286], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2010", "score_of_biggest_cluster": 0.7169619202613831, "score_of_first_answer": 0.7169619202613831, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.05865478515625, "avg_score": 0.7169619202613831, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.28123764278232843, "std_of_first_answer": 0.28123764278232843, "avg_entropy_of_first_answer": 0.3299527275562286, "lex_sim": 1.0}
{"question": "when did the song here comes the boom come out", "answer": ["September 20th, 2010"], "scores": [[0.00228118896484375, 0.9912109375, 0.44140625, 0.288818359375, 0.03851318359375, 0.81396484375, 1.0, 0.99658203125, 1.0, 0.93896484375, 0.308349609375]], "normalized_score": [0.3107297420501709], "tokens": [["\u2581September", "\u2581", "2", "0", "th", ",", "\u2581", "2", "0", "1", "0"]], "entropy": [[2.193359375, 0.060211181640625, 1.3466796875, 2.205078125, 0.8505859375, 0.54833984375, 0.0014314651489257812, 0.02362060546875, 2.4259090423583984e-05, 0.265869140625, 1.91796875]], "avg_entropy": [0.8557425791567023], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "May 2002", "score_of_biggest_cluster": 0.3107297420501709, "score_of_first_answer": 0.3107297420501709, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.00228118896484375, "avg_score": 0.3107297420501709, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3891925134226127, "std_of_first_answer": 0.3891925134226127, "avg_entropy_of_first_answer": 0.8557425791567023, "lex_sim": 1.0}
{"question": "how many gold medals won by india in 2018 commonwealth games", "answer": ["27 #MyStory: I Kissed Him, And Everything Changed Forever"], "scores": [[0.66162109375, 0.8974609375, 0.70703125, 3.5762786865234375e-07, 8.71419906616211e-05, 0.0005865097045898438, 0.003414154052734375, 0.0606689453125, 7.18235969543457e-05, 0.022003173828125, 0.9970703125, 0.017822265625, 0.1390380859375, 0.2137451171875, 0.041412353515625, 0.91162109375, 1.0, 0.01047515869140625, 0.99951171875]], "normalized_score": [0.025485634803771973], "tokens": [["\u2581", "2", "7", "\u2581#", "My", "Story", ":", "\u2581I", "\u2581K", "iss", "ed", "\u2581Him", ",", "\u2581And", "\u2581Everything", "\u2581Ch", "anged", "\u2581Fore", "ver"]], "entropy": [[0.7685546875, 0.385009765625, 0.74755859375, 0.54150390625, 5.703125, 4.796875, 3.033203125, 5.453125, 3.810546875, 0.316162109375, 0.0321044921875, 2.09765625, 3.3125, 2.54296875, 2.8671875, 0.54150390625, 0.000957489013671875, 2.52734375, 0.00589752197265625]], "avg_entropy": [2.078093880101254], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "26", "score_of_biggest_cluster": 0.025485634803771973, "score_of_first_answer": 0.025485634803771973, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 3.5762786865234375e-07, "avg_score": 0.025485634803771973, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41596602020354007, "std_of_first_answer": 0.41596602020354007, "avg_entropy_of_first_answer": 2.078093880101254, "lex_sim": 1.0}
{"question": "how many episodes are there in ordeal by innocence", "answer": ["3"], "scores": [[0.9765625, 0.92724609375]], "normalized_score": [0.9515848755836487], "tokens": [["\u2581", "3"]], "entropy": [[0.183837890625, 0.350830078125]], "avg_entropy": [0.267333984375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "three part", "score_of_biggest_cluster": 0.9515848755836487, "score_of_first_answer": 0.9515848755836487, "max_score_of_first_answer": 0.9765625, "min_score_of_first_answer": 0.92724609375, "avg_score": 0.9515848755836487, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.024658203125, "std_of_first_answer": 0.024658203125, "avg_entropy_of_first_answer": 0.267333984375, "lex_sim": 1.0}
{"question": "when did the first fleet arive in australia", "answer": ["January 26, 1788 #NYCC: Marvel TV Announces \u2018Agents of S.H.I.E.L.D."], "scores": [[0.305908203125, 0.994140625, 0.9775390625, 0.9990234375, 0.91796875, 0.998046875, 1.0, 1.0, 1.0, 1.0, 1.7881393432617188e-07, 0.0037384033203125, 0.0010519027709960938, 8.749961853027344e-05, 0.0013761520385742188, 0.0003638267517089844, 0.0001857280731201172, 0.0193328857421875, 0.771484375, 0.8828125, 0.0091552734375, 0.034576416015625, 0.99951171875, 0.99560546875, 0.5908203125, 0.81201171875, 0.99951171875, 1.0, 1.0, 0.99951171875, 1.0, 1.0, 1.0, 0.99951171875, 1.0, 0.06378173828125, 0.10992431640625, 0.99951171875, 0.99560546875, 0.91796875, 0.037322998046875]], "normalized_score": [0.1314479559659958], "tokens": [["\u2581January", "\u2581", "2", "6", ",", "\u2581", "1", "7", "8", "8", "\u2581#", "N", "Y", "CC", ":", "\u2581Marvel", "\u2581TV", "\u2581Ann", "oun", "ces", "\u2581\u2018", "Ag", "ents", "\u2581of", "\u2581S", ".", "H", ".", "I", ".", "E", ".", "L", ".", "D", ".:", "\u2581S", "ling", "shot", "\u2019", "\u2581Series"]], "entropy": [[0.830078125, 0.03985595703125, 0.10821533203125, 0.008941650390625, 0.306884765625, 0.0160064697265625, 0.0003154277801513672, 0.0005402565002441406, 0.000518798828125, 0.001407623291015625, 0.943359375, 4.16015625, 3.712890625, 1.734375, 3.1796875, 5.2421875, 4.16796875, 3.6015625, 0.78759765625, 0.405517578125, 3.57421875, 2.869140625, 0.005710601806640625, 0.0305938720703125, 1.056640625, 0.490234375, 0.003284454345703125, 0.0011272430419921875, 0.00110626220703125, 0.00482940673828125, 0.001556396484375, 0.0018787384033203125, 0.001476287841796875, 0.00305938720703125, 0.00031280517578125, 0.76318359375, 1.8984375, 0.00638580322265625, 0.034210205078125, 0.310791015625, 2.17578125]], "avg_entropy": [1.0361469838677384], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "18 January 1788", "score_of_biggest_cluster": 0.1314479559659958, "score_of_first_answer": 0.1314479559659958, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.1314479559659958, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44309104422690665, "std_of_first_answer": 0.44309104422690665, "avg_entropy_of_first_answer": 1.0361469838677384, "lex_sim": 1.0}
{"question": "who sang i dreamed a dream in les miserables", "answer": ["Eponine (played by Samantha Barks) #FundingFriday: February 24"], "scores": [[0.0064697265625, 0.98876953125, 1.0, 0.098876953125, 0.44580078125, 0.99951171875, 0.99951171875, 0.99755859375, 0.9892578125, 1.0, 0.99951171875, 0.99072265625, 0.7177734375, 1.5497207641601562e-06, 0.0180816650390625, 0.00013387203216552734, 0.57861328125, 0.235107421875, 0.97607421875, 0.9912109375, 0.0020618438720703125, 7.569789886474609e-06, 0.87060546875, 0.59716796875, 0.08331298828125]], "normalized_score": [0.09834881126880646], "tokens": [["\u2581E", "pon", "ine", "\u2581(", "play", "ed", "\u2581by", "\u2581Sam", "anth", "a", "\u2581B", "arks", ")", "\u2581#", "F", "und", "ing", "F", "rid", "ay", ":", "\u2581February", "\u2581", "2", "4"]], "entropy": [[1.3935546875, 0.1124267578125, 0.00020837783813476562, 2.794921875, 1.447265625, 0.005035400390625, 0.0039520263671875, 0.0265045166015625, 0.05999755859375, 2.1457672119140625e-05, 0.00565338134765625, 0.05609130859375, 0.63037109375, 0.90185546875, 4.05859375, 3.55859375, 2.45703125, 3.68359375, 0.2080078125, 0.051727294921875, 2.4765625, 4.1171875, 0.71728515625, 1.21484375, 1.72265625]], "avg_entropy": [1.2681576919555664], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Rose Laurens", "score_of_biggest_cluster": 0.09834881126880646, "score_of_first_answer": 0.09834881126880646, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.5497207641601562e-06, "avg_score": 0.09834881126880646, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42851738224640157, "std_of_first_answer": 0.42851738224640157, "avg_entropy_of_first_answer": 1.2681576919555664, "lex_sim": 1.0}
{"question": "when is the last time the us lost the olympics", "answer": ["The last time the United States did not win the most gold medals at the Olympics was in 1996."], "scores": [[0.349365234375, 0.057037353515625, 0.99755859375, 0.99755859375, 0.8447265625, 0.99951171875, 0.7236328125, 0.9990234375, 0.9736328125, 0.11016845703125, 0.213623046875, 0.31982421875, 1.0, 1.0, 0.95849609375, 0.990234375, 0.3427734375, 0.99853515625, 0.81640625, 0.90673828125, 0.77978515625, 1.0, 0.89501953125, 0.84912109375, 0.498046875, 1.8477439880371094e-06, 2.396106719970703e-05, 9.179115295410156e-06, 0.0017633438110351562, 0.3564453125, 0.9970703125, 0.005908966064453125, 0.09222412109375, 0.040618896484375, 0.89599609375, 0.0038299560546875, 0.15478515625, 0.982421875, 0.64599609375, 0.99951171875, 0.77685546875, 0.092041015625, 0.010498046875]], "normalized_score": [0.1530933976173401], "tokens": [["\u2581The", "\u2581last", "\u2581time", "\u2581the", "\u2581United", "\u2581States", "\u2581did", "\u2581not", "\u2581win", "\u2581the", "\u2581most", "\u2581gold", "\u2581med", "als", "\u2581at", "\u2581the", "\u2581Olympics", "\u2581was", "\u2581in", "\u2581", "1", "9", "9", "6", ".", "\u2581#", "Black", "On", "C", "amp", "us", ":", "\u2581The", "\u2581History", "\u2581of", "\u2581the", "\u2581African", "\u2581American", "\u2581Exper", "ience", "\u2581at", "\u2581U", "MD"]], "entropy": [[1.84375, 0.46728515625, 0.0225372314453125, 0.0194854736328125, 0.5107421875, 0.004512786865234375, 0.923828125, 0.0081787109375, 0.17724609375, 0.734375, 1.40625, 0.9736328125, 0.00223541259765625, 0.0013399124145507812, 0.1805419921875, 0.056976318359375, 1.1435546875, 0.01219940185546875, 0.63330078125, 0.340087890625, 0.52685546875, 9.417533874511719e-05, 0.414306640625, 0.454833984375, 1.3828125, 1.0751953125, 4.34375, 0.4345703125, 1.9921875, 2.953125, 0.0272064208984375, 2.14453125, 5.65625, 6.39453125, 0.5703125, 0.66357421875, 4.625, 0.1217041015625, 1.4541015625, 0.006099700927734375, 0.87890625, 3.642578125, 2.345703125]], "avg_entropy": [1.1993090551952983], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2018 Pyeongchang", "score_of_biggest_cluster": 0.1530933976173401, "score_of_first_answer": 0.1530933976173401, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.8477439880371094e-06, "avg_score": 0.1530933976173401, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40716844877076436, "std_of_first_answer": 0.40716844877076436, "avg_entropy_of_first_answer": 1.1993090551952983, "lex_sim": 1.0}
{"question": "when were the first general elections held in independent india", "answer": ["August 21, 1947 [Following is an official Bureau of Military Personnel News Release.]"], "scores": [[0.058868408203125, 0.99560546875, 0.9560546875, 0.0238494873046875, 0.9228515625, 0.9921875, 0.99951171875, 1.0, 0.9951171875, 1.0, 4.315376281738281e-05, 0.00038552284240722656, 0.053863525390625, 0.004734039306640625, 0.0003819465637207031, 0.018768310546875, 0.0022449493408203125, 5.364418029785156e-07, 0.955078125, 0.0021209716796875, 0.09832763671875, 1.0, 0.0010223388671875, 0.94482421875, 0.1328125]], "normalized_score": [0.03649727255105972], "tokens": [["\u2581August", "\u2581", "2", "1", ",", "\u2581", "1", "9", "4", "7", "\u2581[", "F", "ollow", "ing", "\u2581is", "\u2581an", "\u2581official", "\u2581Bureau", "\u2581of", "\u2581Military", "\u2581Person", "nel", "\u2581News", "\u2581Release", ".]"]], "entropy": [[0.427490234375, 0.03173828125, 0.21044921875, 1.6513671875, 0.378662109375, 0.050811767578125, 0.005828857421875, 2.9265880584716797e-05, 0.03448486328125, 0.00254058837890625, 0.98974609375, 1.466796875, 4.08984375, 0.240478515625, 1.078125, 1.2568359375, 2.859375, 3.875, 0.36376953125, 1.533203125, 0.93017578125, 0.0006499290466308594, 4.5546875, 0.407958984375, 3.15625]], "avg_entropy": [1.183851935863495], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1951\u201352", "score_of_biggest_cluster": 0.03649727255105972, "score_of_first_answer": 0.03649727255105972, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.364418029785156e-07, "avg_score": 0.03649727255105972, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4728431955222209, "std_of_first_answer": 0.4728431955222209, "avg_entropy_of_first_answer": 1.183851935863495, "lex_sim": 1.0}
{"question": "who is the longest railway station in india", "answer": ["Kharagpur Railway Station ##### Table of Contents"], "scores": [[0.063720703125, 0.970703125, 0.99755859375, 0.998046875, 0.314453125, 0.99609375, 0.0, 4.112720489501953e-06, 0.0836181640625, 0.68994140625, 1.0]], "normalized_score": [0.0], "tokens": [["\u2581K", "har", "ag", "pur", "\u2581Railway", "\u2581Station", "\u2581#####", "\u2581Table", "\u2581of", "\u2581Cont", "ents"]], "entropy": [[3.65234375, 0.1973876953125, 0.022491455078125, 0.0179443359375, 1.12109375, 0.0269317626953125, 1.4931640625, 4.23828125, 5.73828125, 1.8974609375, 0.0006647109985351562]], "avg_entropy": [1.6732768145474521], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Gorakhpur Junction", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43830380003590513, "std_of_first_answer": 0.43830380003590513, "avg_entropy_of_first_answer": 1.6732768145474521, "lex_sim": 1.0}
{"question": "who hung the lanterns in the old north church", "answer": ["Paul Revere #InvestLocal: 5 local startups to support this holiday season"], "scores": [[0.466064453125, 0.99951171875, 0.9990234375, 8.344650268554688e-07, 0.0008797645568847656, 0.0005221366882324219, 0.0010671615600585938, 0.0001556873321533203, 0.02044677734375, 0.042724609375, 0.0011682510375976562, 0.00347900390625, 0.95068359375, 0.587890625, 0.06005859375, 0.234619140625, 0.07928466796875, 0.99951171875, 0.99560546875]], "normalized_score": [0.022840704768896103], "tokens": [["\u2581Paul", "\u2581Re", "vere", "\u2581#", "In", "vest", "Local", ":", "\u2581", "5", "\u2581local", "\u2581start", "ups", "\u2581to", "\u2581support", "\u2581this", "\u2581hol", "iday", "\u2581season"]], "entropy": [[1.2841796875, 0.0035152435302734375, 0.00942230224609375, 1.0380859375, 5.33203125, 4.08203125, 0.8447265625, 1.9423828125, 5.53515625, 2.337890625, 4.3671875, 1.857421875, 0.209228515625, 1.9423828125, 1.5546875, 2.10546875, 2.52734375, 0.004688262939453125, 0.036285400390625]], "avg_entropy": [1.948111383538497], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Robert Newman", "score_of_biggest_cluster": 0.022840704768896103, "score_of_first_answer": 0.022840704768896103, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 8.344650268554688e-07, "avg_score": 0.022840704768896103, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41905309345920105, "std_of_first_answer": 0.41905309345920105, "avg_entropy_of_first_answer": 1.948111383538497, "lex_sim": 1.0}
{"question": "who plays joker in batman the dark knight", "answer": ["Heath Ledger (posthumously) #152861 - 11/25/05 10:28 AM Re: Satanism and the Church of Satan [Re: Lil"], "scores": [[0.99853515625, 1.0, 0.99755859375, 1.0, 0.00408172607421875, 0.91943359375, 0.99951171875, 0.99365234375, 0.978515625, 2.205371856689453e-06, 0.013336181640625, 0.01383209228515625, 0.06634521484375, 0.11187744140625, 0.1241455078125, 0.074462890625, 0.0001932382583618164, 0.158447265625, 0.25, 0.0684814453125, 0.3837890625, 0.372314453125, 0.08966064453125, 0.9921875, 0.0245819091796875, 0.0205078125, 0.09027099609375, 0.5029296875, 0.279052734375, 0.99267578125, 0.1890869140625, 0.1507568359375, 0.0897216796875, 0.00032138824462890625, 0.474365234375, 0.0011892318725585938, 0.17919921875, 0.2064208984375, 0.11541748046875, 0.292236328125, 0.0282745361328125, 0.97998046875, 0.92626953125, 0.99951171875, 0.65576171875, 0.99755859375, 0.99853515625, 0.0010280609130859375]], "normalized_score": [0.10813508182764053], "tokens": [["\u2581He", "ath", "\u2581Led", "ger", "\u2581(", "post", "hum", "ously", ")", "\u2581#", "1", "5", "2", "8", "6", "1", "\u2581-", "\u2581", "1", "1", "/", "2", "5", "/", "0", "5", "\u2581", "1", "0", ":", "2", "8", "\u2581AM", "\u2581Re", ":", "\u2581Sat", "an", "ism", "\u2581and", "\u2581the", "\u2581Church", "\u2581of", "\u2581Sat", "an", "\u2581[", "Re", ":", "\u2581Lil"]], "entropy": [[0.01473236083984375, 0.0024871826171875, 0.0207977294921875, 9.936094284057617e-05, 0.39208984375, 0.513671875, 0.006458282470703125, 0.038360595703125, 0.138427734375, 0.484619140625, 2.4921875, 2.7890625, 3.01171875, 2.630859375, 2.431640625, 2.41015625, 2.556640625, 5.38671875, 1.6845703125, 2.486328125, 2.818359375, 1.6171875, 2.26953125, 0.065185546875, 0.78369140625, 0.74755859375, 2.140625, 1.7939453125, 1.5341796875, 0.07061767578125, 1.794921875, 2.29296875, 1.9189453125, 2.759765625, 2.265625, 4.5234375, 3.12890625, 3.240234375, 3.3984375, 4.515625, 3.8203125, 0.139404296875, 0.441650390625, 0.00592041015625, 1.798828125, 0.0286865234375, 0.015777587890625, 5.76953125]], "avg_entropy": [1.7748226361970108], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ledger", "score_of_biggest_cluster": 0.10813508182764053, "score_of_first_answer": 0.10813508182764053, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.205371856689453e-06, "avg_score": 0.10813508182764053, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4094880312087439, "std_of_first_answer": 0.4094880312087439, "avg_entropy_of_first_answer": 1.7748226361970108, "lex_sim": 1.0}
{"question": "who has the highest paid contract in the nba", "answer": ["Stephen Curry"], "scores": [[0.46875, 0.99951171875, 1.0]], "normalized_score": [0.776681661605835], "tokens": [["\u2581Stephen", "\u2581Cur", "ry"]], "entropy": [[1.568359375, 0.0028018951416015625, 0.00024771690368652344]], "avg_entropy": [0.5238029956817627], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Stephen Curry", "score_of_biggest_cluster": 0.776681661605835, "score_of_first_answer": 0.776681661605835, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.46875, "avg_score": 0.776681661605835, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.2503186420476095, "std_of_first_answer": 0.2503186420476095, "avg_entropy_of_first_answer": 0.5238029956817627, "lex_sim": 1.0}
{"question": "which country has the most coastline in the world", "answer": ["Canada"], "scores": [[0.974609375]], "normalized_score": [0.974609375], "tokens": [["\u2581Canada"]], "entropy": [[0.187255859375]], "avg_entropy": [0.187255859375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Canada", "score_of_biggest_cluster": 0.974609375, "score_of_first_answer": 0.974609375, "max_score_of_first_answer": 0.974609375, "min_score_of_first_answer": 0.974609375, "avg_score": 0.974609375, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.0, "std_of_first_answer": 0.0, "avg_entropy_of_first_answer": 0.187255859375, "lex_sim": 1.0}
{"question": "royal society for the protection of birds number of members", "answer": ["I'm sorry, I do not have the specific number of members for the Royal Society for the Protection of Birds."], "scores": [[0.46826171875, 0.5009765625, 0.9990234375, 0.95947265625, 0.990234375, 0.87109375, 0.3642578125, 0.99951171875, 0.9765625, 0.259765625, 0.1785888671875, 0.445068359375, 0.99267578125, 0.994140625, 0.78369140625, 0.982421875, 0.9677734375, 0.99951171875, 0.99951171875, 0.99853515625, 0.9990234375, 0.99951171875, 0.99951171875, 0.99951171875, 1.0, 0.93115234375, 0.203125, 0.99609375, 0.0657958984375, 0.371826171875, 0.466064453125, 0.01006317138671875, 0.7998046875, 0.9990234375, 0.62451171875, 0.39501953125, 0.469482421875, 1.0, 1.0, 0.479736328125, 0.943359375, 0.90869140625, 1.0, 0.70849609375, 0.269775390625, 0.194091796875, 0.0860595703125, 0.95654296875, 0.06561279296875, 0.5283203125]], "normalized_score": [0.5484740734100342], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581I", "\u2581do", "\u2581not", "\u2581have", "\u2581the", "\u2581specific", "\u2581number", "\u2581of", "\u2581members", "\u2581for", "\u2581the", "\u2581Royal", "\u2581Society", "\u2581for", "\u2581the", "\u2581Prote", "ction", "\u2581of", "\u2581Bird", "s", ".", "\u2581However", ",", "\u2581they", "\u2581have", "\u2581a", "\u2581vast", "\u2581network", "\u2581of", "\u2581members", ",", "\u2581supp", "or", "ters", ",", "\u2581and", "\u2581volunte", "ers", "\u2581who", "\u2581help", "\u2581to", "\u2581support", "\u2581their", "\u2581mission", "\u2581to"]], "entropy": [[2.365234375, 1.5419921875, 0.006847381591796875, 0.2042236328125, 0.065185546875, 0.5244140625, 1.3154296875, 0.005153656005859375, 0.114501953125, 1.6044921875, 1.5322265625, 0.88671875, 0.05108642578125, 0.04376220703125, 0.6796875, 0.1185302734375, 0.170654296875, 0.005950927734375, 0.00424957275390625, 0.01201629638671875, 0.006732940673828125, 0.004150390625, 0.0040740966796875, 0.006565093994140625, 0.0010929107666015625, 0.363525390625, 1.9609375, 0.030731201171875, 1.7861328125, 0.7626953125, 1.599609375, 0.79541015625, 0.76171875, 0.00897216796875, 0.99169921875, 0.7529296875, 0.857421875, 0.00045943260192871094, 0.0006580352783203125, 0.7041015625, 0.2371826171875, 0.4580078125, 0.0011816024780273438, 1.2490234375, 1.0283203125, 1.39453125, 1.60546875, 0.2208251953125, 0.9560546875, 1.1748046875]], "avg_entropy": [0.6195475149154663], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "more than a million", "score_of_biggest_cluster": 0.5484740734100342, "score_of_first_answer": 0.5484740734100342, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.01006317138671875, "avg_score": 0.5484740734100342, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3357672090704845, "std_of_first_answer": 0.3357672090704845, "avg_entropy_of_first_answer": 0.6195475149154663, "lex_sim": 1.0}
{"question": "when did the astros change from the national league to the american league", "answer": ["In 2013, the Houston Astros moved from the National League to the American League."], "scores": [[0.07659912109375, 0.9873046875, 0.99951171875, 1.0, 0.99951171875, 0.99755859375, 0.94189453125, 0.86865234375, 0.9794921875, 1.0, 1.0, 0.72265625, 0.99560546875, 1.0, 0.99755859375, 1.0, 0.98291015625, 0.99951171875, 1.0, 0.99951171875, 0.398193359375, 1.430511474609375e-06, 0.216064453125, 1.1920928955078125e-07, 0.962890625, 0.0009360313415527344, 0.91796875, 0.00011640787124633789]], "normalized_score": [0.16084277629852295], "tokens": [["\u2581In", "\u2581", "2", "0", "1", "3", ",", "\u2581the", "\u2581Houston", "\u2581Ast", "ros", "\u2581moved", "\u2581from", "\u2581the", "\u2581National", "\u2581League", "\u2581to", "\u2581the", "\u2581American", "\u2581League", ".", "\u2581#", "A", "fr", "ican", "Develop", "ment", "\u2581Bank"]], "entropy": [[1.72265625, 0.08740234375, 0.0030040740966796875, 2.2172927856445312e-05, 0.002716064453125, 0.0170135498046875, 0.319091796875, 0.51806640625, 0.1016845703125, 0.001537322998046875, 0.001544952392578125, 1.068359375, 0.030120849609375, 0.00179290771484375, 0.0186920166015625, 0.0019464492797851562, 0.09747314453125, 0.004596710205078125, 0.0005636215209960938, 0.00272369384765625, 1.33984375, 0.80078125, 3.373046875, 0.0802001953125, 0.2744140625, 2.82421875, 0.39599609375, 2.36328125]], "avg_entropy": [0.5518853749547686], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2013", "score_of_biggest_cluster": 0.16084277629852295, "score_of_first_answer": 0.16084277629852295, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.16084277629852295, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.38757501245386167, "std_of_first_answer": 0.38757501245386167, "avg_entropy_of_first_answer": 0.5518853749547686, "lex_sim": 1.0}
{"question": "what river is associated with the city of rome", "answer": ["Tiber Online ExclusivesNews"], "scores": [[0.8466796875, 1.0, 0.0, 0.00018203258514404297, 0.151611328125, 0.00019407272338867188, 5.364418029785156e-07]], "normalized_score": [0.0], "tokens": [["\u2581T", "iber", "\u2581Online", "\u2581Ex", "clus", "ives", "News"]], "entropy": [[0.580078125, 0.0008306503295898438, 1.1103515625, 0.7099609375, 1.2099609375, 0.0028839111328125, 1.0048828125]], "avg_entropy": [0.6598498480660575], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The Tiber", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40868868215732, "std_of_first_answer": 0.40868868215732, "avg_entropy_of_first_answer": 0.6598498480660575, "lex_sim": 1.0}
{"question": "when did the nest 3rd generation come out", "answer": ["There is no product called the \"Nest 3rd Generation.\""], "scores": [[0.01079559326171875, 0.420166015625, 0.9833984375, 0.032684326171875, 0.71533203125, 0.05853271484375, 0.9619140625, 0.7890625, 1.0, 0.99853515625, 1.0, 1.0, 0.58447265625, 0.62060546875, 0.479736328125, 0.9990234375, 0.8623046875, 0.92236328125, 0.9736328125, 0.7275390625, 0.9296875, 0.52392578125, 0.1356201171875, 0.89892578125, 0.95263671875, 0.56103515625, 0.99951171875, 0.99853515625]], "normalized_score": [0.5246757864952087], "tokens": [["\u2581There", "\u2581is", "\u2581no", "\u2581product", "\u2581called", "\u2581the", "\u2581\"", "N", "est", "\u2581", "3", "rd", "\u2581Generation", ".\"", "\u2581Can", "\u2581you", "\u2581please", "\u2581provide", "\u2581more", "\u2581context", "\u2581or", "\u2581clarify", "\u2581what", "\u2581you", "\u2581are", "\u2581referring", "\u2581to", "?"]], "entropy": [[2.35546875, 1.54296875, 0.1046142578125, 2.08203125, 0.77392578125, 0.60009765625, 0.1993408203125, 0.806640625, 0.0002589225769042969, 0.01236724853515625, 3.0934810638427734e-05, 0.0008444786071777344, 0.685546875, 0.8896484375, 1.4765625, 0.01061248779296875, 0.43017578125, 0.34423828125, 0.156005859375, 0.67578125, 0.341064453125, 1.2412109375, 0.75390625, 0.362548828125, 0.23291015625, 0.7412109375, 0.006069183349609375, 0.0122222900390625]], "avg_entropy": [0.6013679994004113], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "September 1, 2015", "score_of_biggest_cluster": 0.5246757864952087, "score_of_first_answer": 0.5246757864952087, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.01079559326171875, "avg_score": 0.5246757864952087, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.32341455772837313, "std_of_first_answer": 0.32341455772837313, "avg_entropy_of_first_answer": 0.6013679994004113, "lex_sim": 1.0}
{"question": "in which year was led zepplin refused entry into singapore because the band members had long hair", "answer": ["1972 ### Why We Sleep: Unlocking the Power of Sleep and Dreams"], "scores": [[0.90966796875, 0.99951171875, 1.0, 0.939453125, 0.96826171875, 0.0, 0.0008168220520019531, 0.0001970529556274414, 0.0011835098266601562, 0.83935546875, 0.27978515625, 0.0565185546875, 0.73828125, 0.97021484375, 0.98193359375, 0.9853515625, 0.99609375, 0.99853515625, 1.0, 0.96142578125, 1.0, 0.9990234375]], "normalized_score": [0.0], "tokens": [["\u2581", "1", "9", "7", "2", "\u2581###", "\u2581Why", "\u2581We", "\u2581S", "leep", ":", "\u2581Un", "lock", "ing", "\u2581the", "\u2581Power", "\u2581of", "\u2581S", "leep", "\u2581and", "\u2581Dream", "s"]], "entropy": [[0.552734375, 0.006748199462890625, 0.0009145736694335938, 0.229736328125, 0.1649169921875, 0.64990234375, 4.80078125, 2.76953125, 3.822265625, 0.927734375, 2.427734375, 3.517578125, 0.94189453125, 0.16357421875, 0.1414794921875, 0.10076904296875, 0.0325927734375, 0.0151214599609375, 0.0002796649932861328, 0.2939453125, 0.0015192031860351562, 0.01032257080078125]], "avg_entropy": [0.9805489128286188], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1972", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4083001247061002, "std_of_first_answer": 0.4083001247061002, "avg_entropy_of_first_answer": 0.9805489128286188, "lex_sim": 1.0}
{"question": "where is the hotel used in the movie the shining", "answer": ["The Stanley Hotel in Estes Park, Colorado, USA."], "scores": [[0.720703125, 0.884765625, 0.99853515625, 0.60595703125, 0.32373046875, 1.0, 0.9990234375, 0.9990234375, 0.99951171875, 0.419921875, 0.71826171875, 0.642578125, 2.980232238769531e-07, 0.0013532638549804688, 6.258487701416016e-06, 0.9384765625, 0.00013148784637451172, 0.01629638671875, 0.548828125, 0.002025604248046875, 0.0030364990234375]], "normalized_score": [0.04966335743665695], "tokens": [["\u2581The", "\u2581Stanley", "\u2581Hotel", "\u2581in", "\u2581Est", "es", "\u2581Park", ",", "\u2581Colorado", ",", "\u2581USA", ".", "\u2581#", "F", "ant", "asy", "\u2581(", "1", "9", "9", ")"]], "entropy": [[1.1181640625, 0.57421875, 0.01134490966796875, 1.1904296875, 0.64111328125, 4.166364669799805e-05, 0.0075531005859375, 0.007114410400390625, 0.004009246826171875, 1.4296875, 0.7119140625, 1.009765625, 0.294189453125, 2.685546875, 0.317626953125, 0.28271484375, 1.134765625, 5.1953125, 2.056640625, 0.056915283203125, 0.69482421875]], "avg_entropy": [0.924947270325252], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The Stanley Hotel", "score_of_biggest_cluster": 0.04966335743665695, "score_of_first_answer": 0.04966335743665695, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.04966335743665695, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40688502758082, "std_of_first_answer": 0.40688502758082, "avg_entropy_of_first_answer": 0.924947270325252, "lex_sim": 1.0}
{"question": "when was the term prime minister first used", "answer": ["16th century England #929 in Fiction & Literature, Military Fiction"], "scores": [[0.576171875, 0.99951171875, 0.1943359375, 0.98974609375, 0.99658203125, 0.28955078125, 5.960464477539063e-08, 0.003391265869140625, 0.061859130859375, 0.061553955078125, 1.3530254364013672e-05, 0.0006613731384277344, 0.04608154296875, 0.197021484375, 0.71142578125, 1.0, 0.03057861328125, 0.0005536079406738281, 0.01338958740234375, 1.0]], "normalized_score": [0.029882241040468216], "tokens": [["\u2581", "1", "6", "th", "\u2581century", "\u2581England", "\u2581#", "9", "2", "9", "\u2581in", "\u2581F", "iction", "\u2581&", "\u2581Liter", "ature", ",", "\u2581Military", "\u2581F", "iction"]], "entropy": [[1.55078125, 0.00469207763671875, 0.82373046875, 0.07806396484375, 0.0294952392578125, 1.4296875, 1.0966796875, 4.9375, 2.91796875, 2.837890625, 2.759765625, 4.58203125, 5.546875, 3.203125, 1.5712890625, 0.00034499168395996094, 2.982421875, 2.994140625, 2.443359375, 0.0009341239929199219]], "avg_entropy": [2.0895388245582582], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1624", "score_of_biggest_cluster": 0.029882241040468216, "score_of_first_answer": 0.029882241040468216, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.029882241040468216, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41285591259477866, "std_of_first_answer": 0.41285591259477866, "avg_entropy_of_first_answer": 2.0895388245582582, "lex_sim": 1.0}
{"question": "where was the witch of blackbird pond published", "answer": ["Scholastic Corporation  48."], "scores": [[0.5458984375, 1.0, 1.0, 0.9140625, 1.6689300537109375e-06, 4.0531158447265625e-06, 0.0129547119140625, 0.003993988037109375, 1.6629695892333984e-05, 0.6328125, 0.440673828125, 0.028350830078125, 0.21630859375, 0.0020427703857421875, 0.35693359375, 0.53271484375, 0.000720977783203125, 0.470703125, 0.25341796875, 0.18994140625, 0.1827392578125, 0.1328125]], "normalized_score": [0.031239742413163185], "tokens": [["\u2581Sch", "ol", "astic", "\u2581Corporation", "\u2581\u2581", "4", "8", ".", "\u2581Chapter", "\u2581", "1", ":", "\u2581The", "\u2581Man", "\u2581in", "\u2581Black", "................", "................", "........", "...", "\u2581", "1"]], "entropy": [[2.283203125, 0.0008792877197265625, 0.0018911361694335938, 0.433837890625, 0.7626953125, 0.0701904296875, 2.234375, 1.984375, 4.3515625, 2.31640625, 1.8310546875, 2.7421875, 4.78125, 6.26171875, 2.6953125, 0.90673828125, 2.216796875, 1.3984375, 1.916015625, 1.6728515625, 2.8515625, 1.7421875]], "avg_entropy": [2.06616041877053], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "United States", "score_of_biggest_cluster": 0.031239742413163185, "score_of_first_answer": 0.031239742413163185, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.6689300537109375e-06, "avg_score": 0.031239742413163185, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3292683501074445, "std_of_first_answer": 0.3292683501074445, "avg_entropy_of_first_answer": 2.06616041877053, "lex_sim": 1.0}
{"question": "who has the most gold gloves at shortstop", "answer": ["Ozzie Smith with 13 Gold Gloves."], "scores": [[0.93505859375, 0.96435546875, 1.0, 1.0, 0.080078125, 0.9990234375, 1.0, 0.99951171875, 0.615234375, 0.99853515625, 0.8740234375, 0.47900390625, 0.0, 0.0003914833068847656, 0.0272064208984375, 0.05950927734375, 0.44189453125, 0.99365234375, 0.35009765625, 1.0, 0.2431640625, 0.277587890625, 0.81298828125, 0.2406005859375, 0.9931640625, 0.99755859375, 0.958984375, 0.334716796875, 0.6513671875, 1.0, 0.99462890625, 0.126953125, 0.99951171875, 0.99853515625, 0.9921875, 0.389892578125, 0.890625, 0.107177734375, 0.2247314453125, 0.99853515625, 0.99853515625, 0.12493896484375, 0.7353515625, 0.06744384765625, 1.0, 0.8623046875, 0.51416015625, 0.990234375]], "normalized_score": [0.0], "tokens": [["\u2581O", "z", "zie", "\u2581Smith", "\u2581with", "\u2581", "1", "3", "\u2581Gold", "\u2581Glo", "ves", ".", "\u2581Proof", "reading", "\u2581is", "\u2581the", "\u2581process", "\u2581of", "\u2581review", "ing", "\u2581written", "\u2581work", "\u2581to", "\u2581identify", "\u2581and", "\u2581correct", "\u2581errors", "\u2581in", "\u2581sp", "elling", ",", "\u2581pun", "ctu", "ation", ",", "\u2581and", "\u2581grammar", ",", "\u2581as", "\u2581well", "\u2581as", "\u2581improve", "\u2581the", "\u2581clar", "ity", "\u2581and", "\u2581flow", "\u2581of"]], "entropy": [[0.378173828125, 0.1546630859375, 0.000537872314453125, 0.0007715225219726562, 1.474609375, 0.0088043212890625, 0.0002999305725097656, 0.0027599334716796875, 1.1748046875, 0.01192474365234375, 0.380126953125, 1.2578125, 0.17626953125, 1.1435546875, 2.576171875, 2.98046875, 2.923828125, 0.056396484375, 1.7490234375, 0.0006651878356933594, 1.765625, 0.8779296875, 0.6748046875, 1.6201171875, 0.043060302734375, 0.0208740234375, 0.2353515625, 1.19921875, 0.68896484375, 0.0002613067626953125, 0.038970947265625, 0.42724609375, 0.0025997161865234375, 0.0138702392578125, 0.052978515625, 0.9501953125, 0.56787109375, 0.515625, 2.115234375, 0.0134735107421875, 0.01152801513671875, 2.30078125, 1.037109375, 1.0859375, 5.888938903808594e-05, 0.51953125, 1.84765625, 0.067626953125]], "avg_entropy": [0.7322118431329727], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ozzie Smith", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.37772551396281834, "std_of_first_answer": 0.37772551396281834, "avg_entropy_of_first_answer": 0.7322118431329727, "lex_sim": 1.0}
{"question": "when did the legal drinking age changed to 21", "answer": ["1984 ### What is the CRC standard?"], "scores": [[0.8291015625, 0.99951171875, 1.0, 1.0, 0.9990234375, 0.0, 0.0008459091186523438, 0.335693359375, 0.630859375, 0.0004801750183105469, 0.0723876953125, 0.00018715858459472656, 0.464111328125]], "normalized_score": [0.0], "tokens": [["\u2581", "1", "9", "8", "4", "\u2581###", "\u2581What", "\u2581is", "\u2581the", "\u2581C", "RC", "\u2581standard", "?"]], "entropy": [[0.65625, 0.00574493408203125, 0.0015048980712890625, 0.0009579658508300781, 0.00830841064453125, 1.0576171875, 3.552734375, 3.546875, 1.6044921875, 4.58984375, 4.11328125, 2.068359375, 1.9775390625]], "avg_entropy": [1.7833467997037447], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "By mid-1988", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.423486189666966, "std_of_first_answer": 0.423486189666966, "avg_entropy_of_first_answer": 1.7833467997037447, "lex_sim": 1.0}
{"question": "who plays genie in ferris bueller's day off", "answer": ["Alan Ruck #108 \"The Power of Vulnerability\" - Bren\u00e9 Brown"], "scores": [[0.52392578125, 0.99951171875, 1.0, 4.172325134277344e-07, 0.0357666015625, 0.06890869140625, 0.047943115234375, 0.0003581047058105469, 0.058319091796875, 0.001903533935546875, 0.8828125, 0.0012006759643554688, 0.281494140625, 0.99658203125, 0.99755859375, 0.76171875, 0.02777099609375, 0.04620361328125, 0.77978515625, 0.98974609375, 0.998046875]], "normalized_score": [0.06709299236536026], "tokens": [["\u2581Alan", "\u2581R", "uck", "\u2581#", "1", "0", "8", "\u2581\"", "The", "\u2581Power", "\u2581of", "\u2581V", "ul", "ner", "ability", "\"", "\u2581-", "\u2581B", "ren", "\u00e9", "\u2581Brown"]], "entropy": [[1.447265625, 0.0078125, 0.0001926422119140625, 0.57470703125, 5.05078125, 3.552734375, 3.283203125, 2.916015625, 5.08984375, 6.078125, 0.673828125, 2.64453125, 2.556640625, 0.0286407470703125, 0.01934814453125, 1.3515625, 3.0390625, 5.30078125, 0.61181640625, 0.0904541015625, 0.018402099609375]], "avg_entropy": [2.111226127261207], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Jennifer Grey", "score_of_biggest_cluster": 0.06709299236536026, "score_of_first_answer": 0.06709299236536026, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.06709299236536026, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4365347106898115, "std_of_first_answer": 0.4365347106898115, "avg_entropy_of_first_answer": 2.111226127261207, "lex_sim": 1.0}
{"question": "where was the tv show friday night lights filmed", "answer": ["Austin, Texas and surrounding areas"], "scores": [[0.1396484375, 0.9736328125, 0.9453125, 0.043060302734375, 0.78662109375, 0.9677734375]], "normalized_score": [0.40188688039779663], "tokens": [["\u2581Austin", ",", "\u2581Texas", "\u2581and", "\u2581surrounding", "\u2581areas"]], "entropy": [[1.314453125, 0.1356201171875, 0.2210693359375, 1.3837890625, 1.1669921875, 0.1953125]], "avg_entropy": [0.7362060546875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Austin", "score_of_biggest_cluster": 0.40188688039779663, "score_of_first_answer": 0.40188688039779663, "max_score_of_first_answer": 0.9736328125, "min_score_of_first_answer": 0.043060302734375, "avg_score": 0.40188688039779663, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.39583361609583717, "std_of_first_answer": 0.39583361609583717, "avg_entropy_of_first_answer": 0.7362060546875, "lex_sim": 1.0}
{"question": "where does porter fly out of in toronto", "answer": ["Billy Bishop Toronto City Airport"], "scores": [[0.97216796875, 0.9990234375, 0.974609375, 0.99951171875, 0.9990234375]], "normalized_score": [0.9887858033180237], "tokens": [["\u2581Billy", "\u2581Bishop", "\u2581Toronto", "\u2581City", "\u2581Airport"]], "entropy": [[0.174072265625, 0.00655364990234375, 0.141845703125, 0.003570556640625, 0.01004791259765625]], "avg_entropy": [0.067218017578125], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Billy Bishop Toronto City Airport", "score_of_biggest_cluster": 0.9887858033180237, "score_of_first_answer": 0.9887858033180237, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.97216796875, "avg_score": 0.9887858033180237, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.012662969618558945, "std_of_first_answer": 0.012662969618558945, "avg_entropy_of_first_answer": 0.067218017578125, "lex_sim": 1.0}
{"question": "when did the isle of wight become an island", "answer": ["The Isle of Wight has been an island since the last Ice Age when the sea levels rose and cut it off from the mainland."], "scores": [[0.372314453125, 0.97998046875, 1.0, 1.0, 1.0, 1.0, 0.81201171875, 0.72607421875, 0.998046875, 0.9990234375, 0.90380859375, 0.919921875, 0.7822265625, 0.59228515625, 0.99365234375, 0.1756591796875, 0.1900634765625, 0.81494140625, 0.43017578125, 0.986328125, 0.71142578125, 0.2939453125, 0.81982421875, 1.0, 1.0, 0.9501953125, 0.95263671875, 1.0, 0.9892578125, 2.2649765014648438e-06, 0.0013294219970703125, 0.5693359375, 0.016082763671875, 3.5822391510009766e-05, 0.87158203125, 0.00020682811737060547, 0.10284423828125, 1.8417835235595703e-05, 0.05841064453125, 0.00716400146484375, 0.0158843994140625, 0.697265625, 0.00925445556640625, 0.0085296630859375, 0.030731201171875, 0.986328125]], "normalized_score": [0.14009682834148407], "tokens": [["\u2581The", "\u2581Is", "le", "\u2581of", "\u2581W", "ight", "\u2581has", "\u2581been", "\u2581an", "\u2581island", "\u2581since", "\u2581the", "\u2581last", "\u2581Ice", "\u2581Age", "\u2581when", "\u2581the", "\u2581sea", "\u2581levels", "\u2581rose", "\u2581and", "\u2581cut", "\u2581it", "\u2581off", "\u2581from", "\u2581the", "\u2581main", "land", ".", "\u2581#", "R", "ock", "y", "Gen", "ius", ":", "\u2581The", "\u2581M", "aking", "\u2581Of", "\u2581Rock", "y", "\u2581IV", "\u2581\u2013", "\u2581Document", "ary"]], "entropy": [[2.33984375, 0.1429443359375, 0.00013136863708496094, 0.0021038055419921875, 0.0012159347534179688, 0.00019788742065429688, 0.74755859375, 0.92236328125, 0.0167236328125, 0.006641387939453125, 0.322509765625, 0.47119140625, 0.76220703125, 0.71044921875, 0.0418701171875, 1.099609375, 0.55712890625, 0.78466796875, 0.6845703125, 0.0928955078125, 0.951171875, 0.91748046875, 0.55078125, 0.00017786026000976562, 0.0005135536193847656, 0.2000732421875, 0.24072265625, 0.0008029937744140625, 0.08001708984375, 0.72216796875, 4.18359375, 2.783203125, 3.130859375, 1.9013671875, 0.625, 2.302734375, 4.765625, 0.78857421875, 2.51953125, 0.11822509765625, 3.150390625, 1.8076171875, 3.693359375, 3.4453125, 5.0234375, 0.11395263671875]], "avg_entropy": [1.167902516282123], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "During the last Ice Age", "score_of_biggest_cluster": 0.14009682834148407, "score_of_first_answer": 0.14009682834148407, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.2649765014648438e-06, "avg_score": 0.14009682834148407, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.41221513197864607, "std_of_first_answer": 0.41221513197864607, "avg_entropy_of_first_answer": 1.167902516282123, "lex_sim": 1.0}
{"question": "baga beach is in north or south goa", "answer": ["Baga beach is located in North Goa."], "scores": [[0.457763671875, 1.0, 0.2998046875, 0.99951171875, 0.57470703125, 0.9990234375, 0.83984375, 1.0, 1.0, 0.8076171875, 4.172325134277344e-07, 1.9788742065429688e-05, 0.9951171875, 0.0007543563842773438, 0.00017321109771728516, 0.002887725830078125, 0.0006608963012695312, 0.0165252685546875, 0.86279296875, 0.96044921875, 0.97021484375, 1.0, 0.1884765625, 0.98828125, 1.0, 0.049041748046875, 1.0, 0.005695343017578125, 0.15771484375, 0.0382080078125, 0.98583984375, 0.587890625, 0.196044921875, 0.1175537109375, 0.420654296875, 0.99609375, 0.5380859375, 1.0, 0.0224761962890625, 0.638671875, 0.9443359375, 0.0214080810546875, 0.5078125, 0.81591796875, 0.9873046875]], "normalized_score": [0.13056452572345734], "tokens": [["\u2581B", "aga", "\u2581beach", "\u2581is", "\u2581located", "\u2581in", "\u2581North", "\u2581Go", "a", ".", "\u2581#", "Throw", "back", "V", "iral", ":", "\u2581Sh", "il", "pa", "\u2581Sh", "et", "ty", "\u2581K", "und", "ra", "\u2019", "s", "\u2581Fun", "ny", "\u2581Re", "action", "\u2581To", "\u2581Her", "\u2581Son", "\u2581Via", "an", "\u2019", "s", "\u2581H", "air", "cut", "\u2581W", "ins", "\u2581The", "\u2581Internet"]], "entropy": [[1.2958984375, 0.00014972686767578125, 0.6318359375, 0.0060272216796875, 0.7099609375, 0.0080413818359375, 0.66015625, 0.00164031982421875, 0.0002503395080566406, 0.64599609375, 0.285400390625, 3.41015625, 0.0316162109375, 2.2578125, 0.40625, 2.517578125, 4.73828125, 2.396484375, 0.59033203125, 0.340087890625, 0.1500244140625, 2.7418136596679688e-05, 3.80859375, 0.09246826171875, 0.000415802001953125, 3.8671875, 0.00043654441833496094, 5.41796875, 2.982421875, 3.94140625, 0.09820556640625, 1.71875, 3.744140625, 3.841796875, 1.603515625, 0.03521728515625, 2.41015625, 0.001537322998046875, 4.80859375, 1.0146484375, 0.397705078125, 2.216796875, 1.2548828125, 0.7646484375, 0.09576416015625]], "avg_entropy": [1.4489170074462892], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "North Goa", "score_of_biggest_cluster": 0.13056452572345734, "score_of_first_answer": 0.13056452572345734, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.13056452572345734, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.41547263223347797, "std_of_first_answer": 0.41547263223347797, "avg_entropy_of_first_answer": 1.4489170074462892, "lex_sim": 1.0}
{"question": "who invented the first home video security system", "answer": ["Edward Hendrie is credited with inventing the first home video security system in 1969."], "scores": [[0.006206512451171875, 0.013275146484375, 0.1473388671875, 0.0034046173095703125, 0.5791015625, 1.0, 0.87548828125, 0.890625, 1.0, 0.99658203125, 0.99169921875, 0.86669921875, 0.95751953125, 0.99609375, 0.99951171875, 0.5126953125, 0.74560546875, 1.0, 1.0, 0.990234375, 0.99560546875, 0.8251953125, 5.960464477539063e-08, 5.036592483520508e-05]], "normalized_score": [0.14895237982273102], "tokens": [["\u2581Edward", "\u2581Hend", "rie", "\u2581is", "\u2581cred", "ited", "\u2581with", "\u2581invent", "ing", "\u2581the", "\u2581first", "\u2581home", "\u2581video", "\u2581security", "\u2581system", "\u2581in", "\u2581", "1", "9", "6", "9", ".", "\u2581###", "\u2581Question"]], "entropy": [[4.16015625, 4.47265625, 1.3720703125, 0.8525390625, 1.3759765625, 0.0004622936248779297, 0.41455078125, 0.481689453125, 0.0011816024780273438, 0.0279693603515625, 0.055267333984375, 0.53076171875, 0.1861572265625, 0.030364990234375, 0.006496429443359375, 1.1259765625, 0.5751953125, 5.882978439331055e-05, 2.1219253540039062e-05, 0.0640869140625, 0.0323486328125, 0.70458984375, 0.6396484375, 5.33203125]], "avg_entropy": [0.9350940262277921], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "her husband Albert Brown", "score_of_biggest_cluster": 0.14895237982273102, "score_of_first_answer": 0.14895237982273102, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.14895237982273102, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3993423658489138, "std_of_first_answer": 0.3993423658489138, "avg_entropy_of_first_answer": 0.9350940262277921, "lex_sim": 1.0}
{"question": "when was the first time the internet was used", "answer": ["November 22, 1969"], "scores": [[0.0008816719055175781, 0.99560546875, 0.97216796875, 0.9912109375, 0.97998046875, 0.99853515625, 1.0, 1.0, 0.99853515625, 0.99951171875]], "normalized_score": [0.491703599691391], "tokens": [["\u2581November", "\u2581", "2", "2", ",", "\u2581", "1", "9", "6", "9"]], "entropy": [[1.8525390625, 0.03192138671875, 0.130615234375, 0.060546875, 0.11676025390625, 0.01058197021484375, 0.0020008087158203125, 2.9206275939941406e-05, 0.0124969482421875, 0.0034198760986328125]], "avg_entropy": [0.22209116220474243], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1969", "score_of_biggest_cluster": 0.491703599691391, "score_of_first_answer": 0.491703599691391, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0008816719055175781, "avg_score": 0.491703599691391, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.297723949829884, "std_of_first_answer": 0.297723949829884, "avg_entropy_of_first_answer": 0.22209116220474243, "lex_sim": 1.0}
{"question": "when were the words under god added to the pledge", "answer": ["1954 #885 The Dust 15:36"], "scores": [[0.91650390625, 1.0, 1.0, 1.0, 0.99951171875, 5.960464477539063e-08, 0.0013570785522460938, 0.02532958984375, 0.09521484375, 0.00017750263214111328, 3.0338764190673828e-05, 0.00012105703353881836, 0.0012731552124023438, 0.138916015625, 0.0231170654296875, 0.07647705078125, 0.1236572265625, 0.10906982421875]], "normalized_score": [0.014109766110777855], "tokens": [["\u2581", "1", "9", "5", "4", "\u2581#", "8", "8", "5", "\u2581The", "\u2581D", "ust", "\u2581", "1", "5", ":", "3", "6"]], "entropy": [[0.46484375, 0.00011593103408813477, 0.0005130767822265625, 0.0001678466796875, 0.0051422119140625, 0.9287109375, 4.875, 2.044921875, 2.728515625, 2.814453125, 2.251953125, 3.5, 0.63818359375, 1.87890625, 2.45703125, 3.7734375, 2.005859375, 2.681640625]], "avg_entropy": [1.8360775609811146], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "on Flag Day in 1954", "score_of_biggest_cluster": 0.014109766110777855, "score_of_first_answer": 0.014109766110777855, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.014109766110777855, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4225877177111368, "std_of_first_answer": 0.4225877177111368, "avg_entropy_of_first_answer": 1.8360775609811146, "lex_sim": 1.0}
{"question": "who was the first indian to be appointed as a judge in the international court of justice", "answer": ["Dr. Bhupinder Nandra."], "scores": [[0.0088348388671875, 0.9970703125, 0.045562744140625, 0.646484375, 0.93896484375, 0.490966796875, 0.439697265625, 0.324951171875, 1.1920928955078125e-07, 0.002819061279296875, 0.006103515625, 0.0197906494140625, 0.224609375, 0.78125, 0.0001862049102783203, 0.0011959075927734375, 0.61474609375, 0.0242919921875, 0.0025577545166015625, 0.1279296875, 0.11517333984375, 0.001621246337890625, 0.0152740478515625, 0.82763671875, 0.2196044921875, 0.9755859375, 0.08026123046875, 0.8466796875, 0.9990234375]], "normalized_score": [0.04762726277112961], "tokens": [["\u2581Dr", ".", "\u2581Bh", "up", "inder", "\u2581N", "andra", ".", "\u2581#", "M", "aking", "It", "H", "appen", ":", "\u2581Me", "et", "\u2581The", "\u2581Women", "\u2581Of", "\u2581The", "\u2581\u201c", "Year", "\u2581Of", "\u2581Return", "\u201d", "\u2581In", "iti", "ative"]], "entropy": [[3.16015625, 0.029937744140625, 3.212890625, 0.86767578125, 0.286865234375, 1.3154296875, 1.0791015625, 1.1982421875, 0.328857421875, 4.1875, 4.234375, 1.76953125, 2.712890625, 0.79296875, 1.17578125, 5.359375, 2.3828125, 3.244140625, 2.68359375, 3.5703125, 4.625, 5.2265625, 4.48046875, 0.5888671875, 1.345703125, 0.148193359375, 3.28515625, 0.55078125, 0.009368896484375]], "avg_entropy": [2.2018116918103448], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Sir Benegal Narsing Rau", "score_of_biggest_cluster": 0.04762726277112961, "score_of_first_answer": 0.04762726277112961, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.04762726277112961, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3720568823157648, "std_of_first_answer": 0.3720568823157648, "avg_entropy_of_first_answer": 2.2018116918103448, "lex_sim": 1.0}
{"question": "who sings good night on the beatles white album", "answer": ["Ringo Starr"], "scores": [[0.82958984375, 1.0, 0.99951171875, 1.0]], "normalized_score": [0.9542514681816101], "tokens": [["\u2581Ring", "o", "\u2581St", "arr"]], "entropy": [[0.888671875, 0.00019979476928710938, 0.005916595458984375, 0.00015544891357421875]], "avg_entropy": [0.22373592853546143], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ringo Starr", "score_of_biggest_cluster": 0.9542514681816101, "score_of_first_answer": 0.9542514681816101, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.82958984375, "avg_score": 0.9542514681816101, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.0737195543711829, "std_of_first_answer": 0.0737195543711829, "avg_entropy_of_first_answer": 0.22373592853546143, "lex_sim": 1.0}
{"question": "what states do not allow daylight savings time", "answer": ["Hawaii, Arizona, and Oregon #17: Nosferatu (1922) with special guest The Nerdwriter"], "scores": [[0.3251953125, 1.0, 0.496826171875, 0.736328125, 0.82470703125, 0.984375, 0.5693359375, 5.960464477539063e-08, 0.01045989990234375, 0.0256195068359375, 0.005214691162109375, 0.0009131431579589844, 1.6808509826660156e-05, 0.0028018951416015625, 0.99462890625, 0.09649658203125, 0.953125, 0.9990234375, 0.98095703125, 0.9990234375, 0.83984375, 0.001979827880859375, 0.0003879070281982422, 0.61962890625, 0.007381439208984375, 0.056610107421875, 0.062103271484375, 0.919921875]], "normalized_score": [0.04860107600688934], "tokens": [["\u2581Hawai", "i", ",", "\u2581Arizona", ",", "\u2581and", "\u2581Oregon", "\u2581#", "1", "7", ":", "\u2581N", "os", "fer", "atu", "\u2581(", "1", "9", "2", "2", ")", "\u2581with", "\u2581special", "\u2581guest", "\u2581The", "\u2581N", "erd", "writer"]], "entropy": [[0.701171875, 0.00020551681518554688, 0.73388671875, 0.75048828125, 0.56640625, 0.1259765625, 2.265625, 1.5126953125, 5.375, 3.40234375, 2.994140625, 4.90625, 1.0595703125, 5.125, 0.0465087890625, 3.205078125, 0.410400390625, 0.00798797607421875, 0.1053466796875, 0.0098876953125, 0.7685546875, 3.16015625, 1.7294921875, 1.798828125, 4.734375, 5.19921875, 0.98876953125, 0.62353515625]], "avg_entropy": [1.8681035552706038], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Navajo", "score_of_biggest_cluster": 0.04860107600688934, "score_of_first_answer": 0.04860107600688934, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.04860107600688934, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42615534019282925, "std_of_first_answer": 0.42615534019282925, "avg_entropy_of_first_answer": 1.8681035552706038, "lex_sim": 1.0}
{"question": "who sings he thinks he'll keep her", "answer": ["Tove Lo"], "scores": [[0.1676025390625, 0.009002685546875, 0.99658203125]], "normalized_score": [0.1145658791065216], "tokens": [["\u2581T", "ove", "\u2581Lo"]], "entropy": [[3.1015625, 1.4375, 0.0243377685546875]], "avg_entropy": [1.5211334228515625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Mary Chapin Carpenter", "score_of_biggest_cluster": 0.1145658791065216, "score_of_first_answer": 0.1145658791065216, "max_score_of_first_answer": 0.99658203125, "min_score_of_first_answer": 0.009002685546875, "avg_score": 0.1145658791065216, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4330350096267603, "std_of_first_answer": 0.4330350096267603, "avg_entropy_of_first_answer": 1.5211334228515625, "lex_sim": 1.0}
{"question": "which was the first village of karnataka which declared independence", "answer": ["Nandi village"], "scores": [[0.05694580078125, 0.6689453125, 0.640625, 0.1326904296875]], "normalized_score": [0.23854699730873108], "tokens": [["\u2581N", "and", "i", "\u2581village"]], "entropy": [[3.404296875, 2.158203125, 1.5888671875, 3.810546875]], "avg_entropy": [2.740478515625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Hyderabad", "score_of_biggest_cluster": 0.23854699730873108, "score_of_first_answer": 0.23854699730873108, "max_score_of_first_answer": 0.6689453125, "min_score_of_first_answer": 0.05694580078125, "avg_score": 0.23854699730873108, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2814394834941946, "std_of_first_answer": 0.2814394834941946, "avg_entropy_of_first_answer": 2.740478515625, "lex_sim": 1.0}
{"question": "who plays charles on have and have nots", "answer": ["John Schneider"], "scores": [[0.6630859375, 0.98828125, 0.99951171875]], "normalized_score": [0.8684525489807129], "tokens": [["\u2581John", "\u2581Schne", "ider"]], "entropy": [[1.8310546875, 0.1187744140625, 0.004505157470703125]], "avg_entropy": [0.6514447530110677], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Nick Sager", "score_of_biggest_cluster": 0.8684525489807129, "score_of_first_answer": 0.8684525489807129, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.6630859375, "avg_score": 0.8684525489807129, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.15601296989886956, "std_of_first_answer": 0.15601296989886956, "avg_entropy_of_first_answer": 0.6514447530110677, "lex_sim": 1.0}
{"question": "who expanded the palace of versailles to its present size", "answer": ["King Louis XIV of France #96 in Nonfiction, Social & Cultural Studies, Education, College Finances"], "scores": [[0.07958984375, 0.9990234375, 0.99560546875, 0.38525390625, 1.0, 1.7881393432617188e-07, 0.005764007568359375, 0.053192138671875, 0.00021958351135253906, 7.569789886474609e-06, 0.201416015625, 0.8916015625, 0.01451873779296875, 0.00018990039825439453, 0.03985595703125, 0.4287109375, 0.982421875, 0.2139892578125, 0.0011730194091796875, 0.29345703125, 0.007701873779296875, 2.7179718017578125e-05, 0.001209259033203125]], "normalized_score": [0.01438827533274889], "tokens": [["\u2581King", "\u2581Louis", "\u2581XIV", "\u2581of", "\u2581France", "\u2581#", "9", "6", "\u2581in", "\u2581Non", "f", "iction", ",", "\u2581Social", "\u2581&", "\u2581Cultural", "\u2581Studies", ",", "\u2581Education", ",", "\u2581College", "\u2581Fin", "ances"]], "entropy": [[0.3671875, 0.0077362060546875, 0.032470703125, 1.248046875, 0.0004940032958984375, 1.279296875, 4.93359375, 3.23828125, 2.58984375, 4.80078125, 1.845703125, 0.360595703125, 2.490234375, 1.4462890625, 1.8564453125, 2.0234375, 0.145263671875, 3.17578125, 3.533203125, 2.16015625, 4.60546875, 2.240234375, 0.0859375]], "avg_entropy": [1.933325311411982], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Louis XIV", "score_of_biggest_cluster": 0.01438827533274889, "score_of_first_answer": 0.01438827533274889, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.01438827533274889, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38301604301247993, "std_of_first_answer": 0.38301604301247993, "avg_entropy_of_first_answer": 1.933325311411982, "lex_sim": 1.0}
{"question": "who is the first indian who got oscar for lifetime achievement", "answer": ["Satyajit Ray #CBR5 Book 70: \"Ink and Bone\" by Rachel Caine"], "scores": [[0.9208984375, 0.9990234375, 1.0, 1.0, 0.99951171875, 1.3709068298339844e-06, 0.0095672607421875, 0.002567291259765625, 0.0004436969757080078, 0.0005521774291992188, 0.4970703125, 0.0501708984375, 0.049591064453125, 0.2164306640625, 0.17822265625, 0.00334930419921875, 0.003177642822265625, 0.005481719970703125, 0.74169921875, 0.99755859375, 0.91650390625, 0.95751953125, 0.433349609375, 1.0, 0.99951171875, 0.99951171875]], "normalized_score": [0.07514501363039017], "tokens": [["\u2581S", "aty", "aj", "it", "\u2581Ray", "\u2581#", "C", "BR", "5", "\u2581Book", "\u2581", "7", "0", ":", "\u2581\"", "In", "k", "\u2581and", "\u2581B", "one", "\"", "\u2581by", "\u2581Rach", "el", "\u2581Ca", "ine"]], "entropy": [[0.57421875, 0.008026123046875, 2.384185791015625e-05, 4.601478576660156e-05, 0.0035305023193359375, 0.96044921875, 5.08203125, 3.37890625, 0.9658203125, 3.865234375, 1.8056640625, 1.986328125, 2.994140625, 2.77734375, 2.3359375, 1.671875, 3.283203125, 1.7099609375, 1.4599609375, 0.02520751953125, 0.40478515625, 0.238525390625, 1.396484375, 0.00033211708068847656, 0.007724761962890625, 0.0037078857421875]], "avg_entropy": [1.4207487656519964], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Mehboob Khan", "score_of_biggest_cluster": 0.07514501363039017, "score_of_first_answer": 0.07514501363039017, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.3709068298339844e-06, "avg_score": 0.07514501363039017, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44644375253908236, "std_of_first_answer": 0.44644375253908236, "avg_entropy_of_first_answer": 1.4207487656519964, "lex_sim": 1.0}
{"question": "what is cain and abel software used for", "answer": ["Cain and Abel is a password recovery tool, not a software used for anything else."], "scores": [[0.515625, 0.9970703125, 0.99169921875, 0.99951171875, 1.0, 0.99560546875, 0.99169921875, 0.8837890625, 0.9541015625, 0.9345703125, 0.01058197021484375, 0.28759765625, 0.75, 0.9853515625, 0.72314453125, 0.9892578125, 0.55908203125, 0.93310546875, 0.978515625, 0.0643310546875, 0.734375, 0.1722412109375, 0.99267578125, 0.397705078125, 0.81640625, 0.374267578125, 0.1007080078125, 1.0, 0.1932373046875, 0.1756591796875, 1.0, 0.1744384765625, 0.0919189453125, 0.84765625, 0.409423828125, 0.98388671875, 0.389892578125, 0.55224609375, 0.0025730133056640625, 0.1749267578125, 0.7353515625, 0.9912109375, 0.99560546875, 0.71240234375, 0.99853515625, 0.978515625, 0.287109375, 0.45947265625, 0.45654296875, 0.09228515625]], "normalized_score": [0.44079041481018066], "tokens": [["\u2581C", "ain", "\u2581and", "\u2581Ab", "el", "\u2581is", "\u2581a", "\u2581password", "\u2581recovery", "\u2581tool", ",", "\u2581not", "\u2581a", "\u2581software", "\u2581used", "\u2581for", "\u2581anything", "\u2581else", ".", "\u2581It", "\u2581is", "\u2581designed", "\u2581to", "\u2581recover", "\u2581passwords", "\u2581by", "\u2581crack", "ing", "\u2581or", "\u2581br", "ute", "\u2581forcing", "\u2581the", "\u2581password", "\u2581hash", "es", "\u2581stored", "\u2581in", "\u2581binary", "\u2581large", "\u2581objects", "\u2581(", "B", "LOB", "s", ")", "\u2581of", "\u2581a", "\u2581Windows", "\u2581S"]], "entropy": [[2.59765625, 0.0274505615234375, 0.05548095703125, 0.003467559814453125, 5.6862831115722656e-05, 0.0384521484375, 0.06915283203125, 0.6494140625, 0.24169921875, 0.296630859375, 1.01171875, 2.40625, 0.7919921875, 0.1099853515625, 0.89794921875, 0.0736083984375, 1.3837890625, 0.35888671875, 0.1339111328125, 0.59765625, 0.92626953125, 1.48828125, 0.049560546875, 1.2109375, 0.70166015625, 1.3720703125, 2.42578125, 9.715557098388672e-05, 1.091796875, 0.92041015625, 0.00030541419982910156, 0.71240234375, 1.3623046875, 0.6455078125, 1.5810546875, 0.10723876953125, 1.447265625, 0.9228515625, 1.3564453125, 2.07421875, 0.5966796875, 0.074462890625, 0.037261962890625, 0.70263671875, 0.01263427734375, 0.1131591796875, 2.0703125, 1.744140625, 1.962890625, 2.646484375]], "avg_entropy": [0.8420466184616089], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "password recovery", "score_of_biggest_cluster": 0.44079041481018066, "score_of_first_answer": 0.44079041481018066, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0025730133056640625, "avg_score": 0.44079041481018066, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.3532537225752343, "std_of_first_answer": 0.3532537225752343, "avg_entropy_of_first_answer": 0.8420466184616089, "lex_sim": 1.0}
{"question": "who made the first spanish landing on the mainland of north america", "answer": ["Juan Ponce de Le\u00f3n #HockeySticks"], "scores": [[0.8642578125, 0.97412109375, 1.0, 0.9912109375, 0.6806640625, 5.960464477539063e-08, 0.0105133056640625, 1.0371208190917969e-05, 0.0287322998046875, 0.0238189697265625]], "normalized_score": [0.017388002946972847], "tokens": [["\u2581Juan", "\u2581P", "once", "\u2581de", "\u2581Le\u00f3n", "\u2581#", "H", "ockey", "St", "icks"]], "entropy": [[0.521484375, 0.141845703125, 0.0017290115356445312, 0.050811767578125, 0.76416015625, 0.84716796875, 5.8828125, 2.091796875, 3.91015625, 0.188232421875]], "avg_entropy": [1.440019702911377], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1535", "score_of_biggest_cluster": 0.017388002946972847, "score_of_first_answer": 0.017388002946972847, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.017388002946972847, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4529487658068446, "std_of_first_answer": 0.4529487658068446, "avg_entropy_of_first_answer": 1.440019702911377, "lex_sim": 1.0}
{"question": "where does jack ryan live in patriot games", "answer": ["Cape Anne, Massachusetts"], "scores": [[0.0035533905029296875, 0.242919921875, 0.68115234375, 0.99169921875]], "normalized_score": [0.15539340674877167], "tokens": [["\u2581Cape", "\u2581Anne", ",", "\u2581Massachusetts"]], "entropy": [[2.84375, 1.4853515625, 0.8876953125, 0.070556640625]], "avg_entropy": [1.32183837890625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Baltimore, Maryland", "score_of_biggest_cluster": 0.15539340674877167, "score_of_first_answer": 0.15539340674877167, "max_score_of_first_answer": 0.99169921875, "min_score_of_first_answer": 0.0035533905029296875, "avg_score": 0.15539340674877167, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38259200758183837, "std_of_first_answer": 0.38259200758183837, "avg_entropy_of_first_answer": 1.32183837890625, "lex_sim": 1.0}
{"question": "who sings why does it hurt when i pee", "answer": ["Taylor Swift #BookReview: The Witches of New York by Ami McKay"], "scores": [[0.0242919921875, 0.97412109375, 6.556510925292969e-07, 6.616115570068359e-06, 0.005779266357421875, 0.70654296875, 0.0254364013671875, 0.1041259765625, 0.0040283203125, 0.1904296875, 0.08282470703125, 0.35498046875, 0.382568359375, 0.99853515625, 0.76904296875, 0.99755859375, 0.99853515625, 0.986328125, 1.0]], "normalized_score": [0.06054103747010231], "tokens": [["\u2581Taylor", "\u2581Swift", "\u2581#", "Book", "Re", "view", ":", "\u2581The", "\u2581W", "itch", "es", "\u2581of", "\u2581New", "\u2581York", "\u2581by", "\u2581Am", "i", "\u2581McK", "ay"]], "entropy": [[4.48828125, 0.1748046875, 0.97509765625, 4.8125, 4.1796875, 0.7744140625, 2.2421875, 3.61328125, 5.46875, 3.302734375, 2.021484375, 2.109375, 2.048828125, 0.0163726806640625, 0.94482421875, 0.024566650390625, 0.0166473388671875, 0.09490966796875, 0.0007653236389160156]], "avg_entropy": [1.9636585085015548], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Frank Zappa", "score_of_biggest_cluster": 0.06054103747010231, "score_of_first_answer": 0.06054103747010231, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 6.556510925292969e-07, "avg_score": 0.06054103747010231, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42500726735125294, "std_of_first_answer": 0.42500726735125294, "avg_entropy_of_first_answer": 1.9636585085015548, "lex_sim": 1.0}
{"question": "who does luke skywalker fall in love with", "answer": ["Leia Organa"], "scores": [[0.244384765625, 0.9970703125, 0.98974609375, 1.0, 1.0]], "normalized_score": [0.7524276375770569], "tokens": [["\u2581Le", "ia", "\u2581Or", "g", "ana"]], "entropy": [[1.5283203125, 0.0218353271484375, 0.0770263671875, 1.3828277587890625e-05, 0.0001672506332397461]], "avg_entropy": [0.32547261714935305], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Mara Jade", "score_of_biggest_cluster": 0.7524276375770569, "score_of_first_answer": 0.7524276375770569, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.244384765625, "avg_score": 0.7524276375770569, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3009510858782679, "std_of_first_answer": 0.3009510858782679, "avg_entropy_of_first_answer": 0.32547261714935305, "lex_sim": 1.0}
{"question": "who is the most losing team in nfl history", "answer": ["There are several teams that have a high number of losing seasons, but the worst team in terms of wins and losses in NFL history is the Detroit Lions, who have not won a championship since the league was founded in 1920,"], "scores": [[0.0200653076171875, 0.56396484375, 0.59423828125, 0.9130859375, 0.48779296875, 0.8154296875, 0.1761474609375, 0.3681640625, 0.93701171875, 1.0, 0.09765625, 0.9638671875, 0.712890625, 0.68359375, 0.73828125, 0.0296783447265625, 0.410888671875, 0.97802734375, 0.10015869140625, 1.0, 0.10723876953125, 0.99072265625, 0.99951171875, 0.401611328125, 0.9892578125, 0.99951171875, 0.99951171875, 0.9765625, 0.26220703125, 1.0, 1.0, 0.404296875, 0.7080078125, 0.85400390625, 0.70654296875, 0.283935546875, 0.99951171875, 0.8798828125, 0.98974609375, 0.47802734375, 0.1295166015625, 0.273193359375, 0.9853515625, 0.99462890625, 0.99951171875, 1.0, 1.0, 0.99755859375, 0.99951171875, 0.1531982421875]], "normalized_score": [0.5210773348808289], "tokens": [["\u2581There", "\u2581are", "\u2581several", "\u2581teams", "\u2581that", "\u2581have", "\u2581a", "\u2581high", "\u2581number", "\u2581of", "\u2581losing", "\u2581seasons", ",", "\u2581but", "\u2581the", "\u2581worst", "\u2581team", "\u2581in", "\u2581terms", "\u2581of", "\u2581wins", "\u2581and", "\u2581losses", "\u2581in", "\u2581NFL", "\u2581history", "\u2581is", "\u2581the", "\u2581Detroit", "\u2581L", "ions", ",", "\u2581who", "\u2581have", "\u2581not", "\u2581won", "\u2581a", "\u2581championship", "\u2581since", "\u2581the", "\u2581league", "\u2581was", "\u2581founded", "\u2581in", "\u2581", "1", "9", "2", "0", ","]], "entropy": [[1.47265625, 1.0732421875, 1.251953125, 0.357421875, 1.1025390625, 0.611328125, 1.8681640625, 1.703125, 0.307861328125, 0.000843048095703125, 0.447509765625, 0.1680908203125, 0.9150390625, 1.0, 0.9443359375, 2.27734375, 1.41796875, 0.1375732421875, 0.37451171875, 0.0010175704956054688, 1.322265625, 0.06573486328125, 0.005931854248046875, 1.1513671875, 0.0634765625, 0.005908966064453125, 0.005619049072265625, 0.15625, 2.369140625, 0.0004208087921142578, 0.0003361701965332031, 1.228515625, 0.6953125, 0.6796875, 1.1240234375, 0.81689453125, 0.0039520263671875, 0.55224609375, 0.06915283203125, 1.107421875, 1.828125, 0.77783203125, 0.08843994140625, 0.039276123046875, 0.0032901763916015625, 3.331899642944336e-05, 1.0132789611816406e-06, 0.0169219970703125, 0.0045166015625, 1.068359375]], "avg_entropy": [0.6536595678329468], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Arizona Cardinals", "score_of_biggest_cluster": 0.5210773348808289, "score_of_first_answer": 0.5210773348808289, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0200653076171875, "avg_score": 0.5210773348808289, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.34336088967938544, "std_of_first_answer": 0.34336088967938544, "avg_entropy_of_first_answer": 0.6536595678329468, "lex_sim": 1.0}
{"question": "who produced the movie i can only imagine", "answer": ["Andrew and Jon Erwin."], "scores": [[0.224365234375, 0.697265625, 0.99267578125, 0.99462890625, 1.0, 0.1590576171875, 0.0, 5.364418029785156e-07, 0.0217742919921875, 0.6806640625, 0.00615692138671875, 0.90185546875, 0.9873046875, 0.023651123046875, 0.41259765625, 0.008392333984375, 0.002620697021484375, 0.97802734375, 0.0011968612670898438, 0.99951171875, 0.253662109375, 0.88525390625, 0.0207977294921875, 0.59423828125, 0.5927734375, 0.72216796875, 0.99951171875, 1.0, 0.99951171875, 0.99658203125, 0.12457275390625, 0.0006566047668457031, 0.76025390625, 0.045166015625, 0.282958984375, 0.99951171875, 1.0, 0.99267578125, 0.99609375, 0.405029296875, 0.98291015625, 0.026031494140625, 0.98486328125, 0.003997802734375, 1.0, 0.921875, 0.2222900390625, 0.98828125]], "normalized_score": [0.0], "tokens": [["\u2581Andrew", "\u2581and", "\u2581Jon", "\u2581Er", "win", ".", "\u2581#####", "\u2581What", "\u2581do", "\u2581you", "\u2581get", "\u2581when", "\u2581you", "\u2581combine", "\u2581a", "\u2581w", "ann", "abe", "\u2581pir", "ate", ",", "\u2581a", "\u2581pl", "astic", "\u2581p", "ink", "\u2581fl", "aming", "o", ",", "\u2581a", "\u2581ha", "unted", "\u2581M", "ardi", "\u2581Gr", "as", "\u2581mask", ",", "\u2581and", "\u2581a", "\u2581taste", "\u2581for", "\u2581champ", "agne", "?", "\u2581You", "\u2581get"]], "entropy": [[3.59765625, 1.6708984375, 0.06280517578125, 0.041168212890625, 0.0011186599731445312, 1.201171875, 0.423095703125, 0.73486328125, 3.0234375, 1.693359375, 2.162109375, 0.55078125, 0.11187744140625, 1.0341796875, 2.9453125, 6.00390625, 2.142578125, 0.1282958984375, 4.5703125, 0.00640106201171875, 1.55078125, 0.81396484375, 5.24609375, 1.279296875, 2.400390625, 1.0537109375, 0.005306243896484375, 0.0014324188232421875, 0.004302978515625, 0.0259246826171875, 0.4482421875, 1.96875, 1.1005859375, 4.46484375, 1.3212890625, 0.005634307861328125, 0.00035643577575683594, 0.052764892578125, 0.0280609130859375, 0.8408203125, 0.130859375, 4.38671875, 0.09478759765625, 3.61328125, 0.0009202957153320312, 0.302490234375, 3.23828125, 0.08892822265625]], "avg_entropy": [1.3869614154100418], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Pete Shilaimon", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42184535828281466, "std_of_first_answer": 0.42184535828281466, "avg_entropy_of_first_answer": 1.3869614154100418, "lex_sim": 1.0}
{"question": "who wrote the book my country my life", "answer": ["James Clavell"], "scores": [[0.035247802734375, 0.088134765625, 0.72265625, 0.9990234375]], "normalized_score": [0.217618927359581], "tokens": [["\u2581James", "\u2581C", "lav", "ell"]], "entropy": [[4.4765625, 4.328125, 0.869140625, 0.008575439453125]], "avg_entropy": [2.4206008911132812], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "L. K. Advani", "score_of_biggest_cluster": 0.217618927359581, "score_of_first_answer": 0.217618927359581, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 0.035247802734375, "avg_score": 0.217618927359581, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41177249387511683, "std_of_first_answer": 0.41177249387511683, "avg_entropy_of_first_answer": 2.4206008911132812, "lex_sim": 1.0}
{"question": "when did the the regulatory reform (fire safety) order 2005 first come into effect", "answer": ["October 1, 2006 #1 Song October 31, 2019 - November 6, 2019"], "scores": [[0.034912109375, 0.99609375, 0.99658203125, 0.89599609375, 0.99658203125, 1.0, 1.0, 1.0, 1.0, 1.1920928955078125e-07, 0.019805908203125, 9.47713851928711e-06, 0.00025081634521484375, 0.98291015625, 0.005191802978515625, 0.420166015625, 0.8173828125, 0.9921875, 0.80029296875, 0.99951171875, 0.015960693359375, 0.398681640625, 0.04046630859375, 0.2498779296875, 0.9951171875, 0.87548828125, 0.9931640625, 0.998046875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875]], "normalized_score": [0.15540637075901031], "tokens": [["\u2581October", "\u2581", "1", ",", "\u2581", "2", "0", "0", "6", "\u2581#", "1", "\u2581Song", "\u2581October", "\u2581", "3", "1", ",", "\u2581", "2", "0", "1", "9", "\u2581-", "\u2581November", "\u2581", "6", ",", "\u2581", "2", "0", "1", "9"]], "entropy": [[1.9755859375, 0.0283203125, 0.02685546875, 0.3818359375, 0.0253753662109375, 1.9371509552001953e-05, -0.0, 4.273653030395508e-05, 0.0015878677368164062, 1.0234375, 5.5546875, 3.091796875, 2.818359375, 0.1400146484375, 0.234619140625, 1.3349609375, 0.86279296875, 0.085693359375, 0.50341796875, 0.006622314453125, 0.1177978515625, 1.95703125, 2.76953125, 4.36328125, 0.054229736328125, 0.54638671875, 0.05694580078125, 0.02001953125, 0.002719879150390625, 0.00409698486328125, 0.00522613525390625, 0.0032978057861328125]], "avg_entropy": [0.8748934306204319], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1 October 2006", "score_of_biggest_cluster": 0.15540637075901031, "score_of_first_answer": 0.15540637075901031, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.15540637075901031, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4220639113794345, "std_of_first_answer": 0.4220639113794345, "avg_entropy_of_first_answer": 0.8748934306204319, "lex_sim": 1.0}
{"question": "who played the virgin in conan the destroyer", "answer": ["Olivia d'Abo #MondayMotivation: How a Mentorship Program Can Help Your Career Soar"], "scores": [[0.2362060546875, 1.0, 0.83349609375, 0.99560546875, 0.9921875, 1.0, 2.384185791015625e-07, 0.00846099853515625, 0.03302001953125, 0.98193359375, 0.331787109375, 0.931640625, 0.99951171875, 0.998046875, 0.00220489501953125, 0.00780487060546875, 0.0106048583984375, 0.004245758056640625, 0.56787109375, 0.927734375, 0.092529296875, 0.810546875, 0.59814453125, 0.53662109375, 0.1453857421875, 0.6875, 0.007068634033203125, 0.99609375]], "normalized_score": [0.12215375900268555], "tokens": [["\u2581Oliv", "ia", "\u2581d", "'", "A", "bo", "\u2581#", "M", "ond", "ay", "M", "ot", "iv", "ation", ":", "\u2581How", "\u2581a", "\u2581M", "ent", "or", "ship", "\u2581Program", "\u2581Can", "\u2581Help", "\u2581Your", "\u2581Career", "\u2581So", "ar"]], "entropy": [[2.88671875, 1.7821788787841797e-05, 0.48388671875, 0.03564453125, 0.04901123046875, 3.796815872192383e-05, 0.67724609375, 5.75, 4.57421875, 0.122802734375, 2.3203125, 0.465087890625, 0.007266998291015625, 0.016021728515625, 1.89453125, 4.47265625, 2.1640625, 5.421875, 2.11328125, 0.32421875, 1.94921875, 1.083984375, 1.873046875, 2.0703125, 1.947265625, 1.044921875, 2.810546875, 0.0290069580078125]], "avg_entropy": [1.663828662463597], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Olivia d'Abo", "score_of_biggest_cluster": 0.12215375900268555, "score_of_first_answer": 0.12215375900268555, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.12215375900268555, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41789332535177015, "std_of_first_answer": 0.41789332535177015, "avg_entropy_of_first_answer": 1.663828662463597, "lex_sim": 1.0}
{"question": "list all the planet of the ape movies", "answer": ["1. Planet of the Apes (1968)"], "scores": [[0.86376953125, 0.99951171875, 0.9736328125, 0.96435546875, 1.0, 1.0, 0.99951171875, 1.0, 0.97802734375, 1.0, 1.0, 1.0, 0.998046875, 0.99951171875]], "normalized_score": [0.9833471179008484], "tokens": [["\u2581", "1", ".", "\u2581Planet", "\u2581of", "\u2581the", "\u2581A", "pes", "\u2581(", "1", "9", "6", "8", ")"]], "entropy": [[0.685546875, 0.004734039306640625, 0.1446533203125, 0.2313232421875, 0.0003752708435058594, 0.0010318756103515625, 0.0036525726318359375, 0.00010925531387329102, 0.11376953125, 0.0012006759643554688, -0.0, 0.00013566017150878906, 0.01485443115234375, 0.004425048828125]], "avg_entropy": [0.08612941418375288], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Planet of the Apes", "score_of_biggest_cluster": 0.9833471179008484, "score_of_first_answer": 0.9833471179008484, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.86376953125, "avg_score": 0.9833471179008484, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.03529424249459816, "std_of_first_answer": 0.03529424249459816, "avg_entropy_of_first_answer": 0.08612941418375288, "lex_sim": 1.0}
{"question": "what is the name for the ch3coo- ion", "answer": ["Acetate ion #GivingTuesday is a global day of giving that harnesses the collective power of individuals, communities, and organizations to encourage philanthropy and to celebrate generosity worldwide."], "scores": [[0.2210693359375, 0.96875, 0.99267578125, 0.89013671875, 5.960464477539063e-08, 0.0003101825714111328, 0.0009503364562988281, 0.92138671875, 0.99755859375, 0.9970703125, 0.01177215576171875, 0.84912109375, 0.79345703125, 0.91943359375, 0.99853515625, 0.99755859375, 0.037139892578125, 0.1866455078125, 1.0, 0.99951171875, 0.9951171875, 0.90478515625, 1.0, 0.9970703125, 0.9765625, 0.99658203125, 0.994140625, 0.98486328125, 0.61669921875, 0.99755859375, 0.9990234375, 0.9833984375, 0.9677734375, 1.0, 0.82470703125, 0.99951171875, 1.0, 0.99462890625, 0.8916015625, 0.984375, 0.99755859375, 0.99658203125, 0.99951171875, 1.0, 0.99755859375, 1.0, 0.95361328125, 0.01617431640625]], "normalized_score": [0.36388763785362244], "tokens": [["\u2581Ac", "et", "ate", "\u2581ion", "\u2581#", "G", "iving", "T", "ues", "day", "\u2581is", "\u2581a", "\u2581global", "\u2581day", "\u2581of", "\u2581giving", "\u2581that", "\u2581har", "ness", "es", "\u2581the", "\u2581collect", "ive", "\u2581power", "\u2581of", "\u2581individuals", ",", "\u2581communities", ",", "\u2581and", "\u2581organizations", "\u2581to", "\u2581encou", "rage", "\u2581phil", "anth", "ropy", "\u2581and", "\u2581to", "\u2581celebr", "ate", "\u2581gener", "os", "ity", "\u2581world", "wide", ".", "\u2581Every"]], "entropy": [[1.7822265625, 0.1466064453125, 0.0487060546875, 0.439697265625, 1.150390625, 2.32421875, 2.853515625, 0.62646484375, 0.0242156982421875, 0.0291900634765625, 1.76171875, 0.8779296875, 1.099609375, 0.375732421875, 0.0137481689453125, 0.0223236083984375, 0.9931640625, 2.171875, 3.7610530853271484e-05, 0.005992889404296875, 0.0316162109375, 0.357666015625, 0.00035071372985839844, 0.02337646484375, 0.11932373046875, 0.027374267578125, 0.0430908203125, 0.1031494140625, 0.71533203125, 0.0225830078125, 0.00846099853515625, 0.1119384765625, 0.2261962890625, 0.0007338523864746094, 0.62890625, 0.0051727294921875, 0.0020751953125, 0.04052734375, 0.3935546875, 0.11529541015625, 0.0184173583984375, 0.0298614501953125, 0.003467559814453125, 0.0004553794860839844, 0.021484375, 0.0010957717895507812, 0.321044921875, 2.15234375]], "avg_entropy": [0.46400537466009456], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "polyatomic anion", "score_of_biggest_cluster": 0.36388763785362244, "score_of_first_answer": 0.36388763785362244, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.36388763785362244, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.344250397560103, "std_of_first_answer": 0.344250397560103, "avg_entropy_of_first_answer": 0.46400537466009456, "lex_sim": 1.0}
{"question": "philadelphia is known as the city of what", "answer": ["Brotherly Love Chapter Twelve: The Ripple Effect"], "scores": [[0.8779296875, 1.0, 1.0, 0.63623046875, 0.0, 7.522106170654297e-05, 0.312744140625, 0.048492431640625, 0.1978759765625, 0.0033779144287109375, 0.006378173828125, 0.9404296875, 0.92529296875]], "normalized_score": [0.0], "tokens": [["\u2581Bro", "ther", "ly", "\u2581Love", "\u2581Chapter", "\u2581Tw", "elve", ":", "\u2581The", "\u2581R", "ipp", "le", "\u2581Effect"]], "entropy": [[0.436767578125, 1.7642974853515625e-05, 5.2928924560546875e-05, 0.66650390625, 0.72021484375, 1.578125, 0.82080078125, 3.060546875, 4.61328125, 5.9296875, 2.513671875, 0.29248046875, 0.5068359375]], "avg_entropy": [1.6260758913480318], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "City of Brotherly Love", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4236559693055033, "std_of_first_answer": 0.4236559693055033, "avg_entropy_of_first_answer": 1.6260758913480318, "lex_sim": 1.0}
{"question": "ranjit sagar dam has builded over which river", "answer": ["Yamuna River"], "scores": [[0.1268310546875, 0.99853515625, 0.344482421875]], "normalized_score": [0.3520345687866211], "tokens": [["\u2581Yam", "una", "\u2581River"]], "entropy": [[3.556640625, 0.01093292236328125, 1.3916015625]], "avg_entropy": [1.653058369954427], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ravi River", "score_of_biggest_cluster": 0.3520345687866211, "score_of_first_answer": 0.3520345687866211, "max_score_of_first_answer": 0.99853515625, "min_score_of_first_answer": 0.1268310546875, "avg_score": 0.3520345687866211, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37043894948544004, "std_of_first_answer": 0.37043894948544004, "avg_entropy_of_first_answer": 1.653058369954427, "lex_sim": 1.0}
{"question": "who acts as the chairman of the election commission", "answer": ["Ashok Lavasa (as of 2021)"], "scores": [[0.06927490234375, 0.98779296875, 0.99658203125, 0.30517578125, 1.0, 0.113037109375, 0.6767578125, 0.8662109375, 0.489013671875, 0.998046875, 0.99853515625, 0.998046875, 0.99609375, 0.919921875]], "normalized_score": [0.5896791219711304], "tokens": [["\u2581Ash", "ok", "\u2581L", "avas", "a", "\u2581(", "as", "\u2581of", "\u2581", "2", "0", "2", "1", ")"]], "entropy": [[2.90234375, 0.089599609375, 0.035125732421875, 0.669921875, 0.0019359588623046875, 1.3759765625, 1.5068359375, 0.485107421875, 1.1845703125, 0.01557159423828125, 0.0147705078125, 0.01531219482421875, 0.02850341796875, 0.37255859375]], "avg_entropy": [0.6212952477591378], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The Chief Election Commissioner", "score_of_biggest_cluster": 0.5896791219711304, "score_of_first_answer": 0.5896791219711304, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.06927490234375, "avg_score": 0.5896791219711304, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3388579501720551, "std_of_first_answer": 0.3388579501720551, "avg_entropy_of_first_answer": 0.6212952477591378, "lex_sim": 1.0}
{"question": "who was the first baseball player to be featured on a postage stamp", "answer": ["Ty Cobb"], "scores": [[0.10931396484375, 0.998046875, 1.0]], "normalized_score": [0.4778323471546173], "tokens": [["\u2581Ty", "\u2581C", "obb"]], "entropy": [[1.25, 0.0139312744140625, 0.00013303756713867188]], "avg_entropy": [0.4213547706604004], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Jackie Robinson", "score_of_biggest_cluster": 0.4778323471546173, "score_of_first_answer": 0.4778323471546173, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.10931396484375, "avg_score": 0.4778323471546173, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41941382554364864, "std_of_first_answer": 0.41941382554364864, "avg_entropy_of_first_answer": 0.4213547706604004, "lex_sim": 1.0}
{"question": "what is the main religion in british columbia", "answer": ["Christianity #101."], "scores": [[0.947265625, 1.0, 1.1920928955078125e-07, 0.0654296875, 0.021087646484375, 0.06597900390625, 0.00226593017578125, 0.0022754669189453125, 3.74913215637207e-05, 0.138916015625, 0.048736572265625, 0.0009474754333496094, 0.224853515625, 0.83154296875, 0.9609375, 1.0, 1.0]], "normalized_score": [0.02709786221385002], "tokens": [["\u2581Christian", "ity", "\u2581#", "1", "0", "1", ".", "\u2581In", "nov", "ative", "\u2581Technology", "\u2581at", "\u2581Your", "\u2581F", "ing", "ert", "ips"]], "entropy": [[0.34814453125, 0.0015354156494140625, 1.0859375, 5.5546875, 2.287109375, 2.931640625, 2.720703125, 3.455078125, 2.568359375, 1.0224609375, 5.79296875, 3.302734375, 3.490234375, 0.71337890625, 0.1947021484375, 0.0011310577392578125, 0.0018243789672851562]], "avg_entropy": [2.0866253235760857], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Protestant", "score_of_biggest_cluster": 0.02709786221385002, "score_of_first_answer": 0.02709786221385002, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.02709786221385002, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43731609560729395, "std_of_first_answer": 0.43731609560729395, "avg_entropy_of_first_answer": 2.0866253235760857, "lex_sim": 1.0}
{"question": "where is union station in washington dc located", "answer": ["It is located in Washington, D.C. #42 \u2013 The Most Popular Podcast Topic of 2019"], "scores": [[0.2464599609375, 0.90283203125, 0.9794921875, 0.6865234375, 0.65576171875, 0.174560546875, 0.9599609375, 0.99951171875, 0.99951171875, 0.65576171875, 5.364418029785156e-07, 0.002170562744140625, 0.0823974609375, 5.91278076171875e-05, 0.0228118896484375, 0.00047326087951660156, 0.09857177734375, 7.68899917602539e-06, 0.99609375, 0.0007033348083496094, 0.18408203125, 0.187744140625, 0.791015625, 0.9892578125, 0.9970703125, 0.056427001953125, 0.54931640625]], "normalized_score": [0.05728219076991081], "tokens": [["\u2581It", "\u2581is", "\u2581located", "\u2581in", "\u2581Washington", ",", "\u2581D", ".", "C", ".", "\u2581#", "4", "2", "\u2581\u2013", "\u2581The", "\u2581Most", "\u2581Popular", "\u2581Pod", "cast", "\u2581Top", "ic", "\u2581of", "\u2581", "2", "0", "1", "9"]], "entropy": [[1.7080078125, 0.35009765625, 0.126220703125, 0.78564453125, 1.1171875, 0.5009765625, 0.1695556640625, 0.004901885986328125, 0.0028972625732421875, 0.88330078125, 1.8681640625, 4.0546875, 3.37109375, 1.861328125, 1.9951171875, 5.30859375, 3.31640625, 4.109375, 0.0408935546875, 0.576171875, 0.50634765625, 3.005859375, 0.7783203125, 0.06805419921875, 0.02435302734375, 0.298095703125, 1.4580078125]], "avg_entropy": [1.4181355370415583], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "50 Massachusetts Avenue NE", "score_of_biggest_cluster": 0.05728219076991081, "score_of_first_answer": 0.05728219076991081, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 5.364418029785156e-07, "avg_score": 0.05728219076991081, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41136853749523783, "std_of_first_answer": 0.41136853749523783, "avg_entropy_of_first_answer": 1.4181355370415583, "lex_sim": 1.0}
{"question": "who was the person who escaped from alcatraz", "answer": ["Frank Lee"], "scores": [[0.09619140625, 0.64599609375]], "normalized_score": [0.2492775022983551], "tokens": [["\u2581Frank", "\u2581Lee"]], "entropy": [[3.126953125, 0.95849609375]], "avg_entropy": [2.042724609375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Clarence Anglin", "score_of_biggest_cluster": 0.2492775022983551, "score_of_first_answer": 0.2492775022983551, "max_score_of_first_answer": 0.64599609375, "min_score_of_first_answer": 0.09619140625, "avg_score": 0.2492775022983551, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.27490234375, "std_of_first_answer": 0.27490234375, "avg_entropy_of_first_answer": 2.042724609375, "lex_sim": 1.0}
{"question": "what is the minimum number of parties required to enter into a deed", "answer": ["Two #RealtyNewsRoundup: Govt Mulls Tough Action Against Delinquent Builders"], "scores": [[0.42431640625, 3.933906555175781e-06, 0.00016772747039794922, 0.021514892578125, 0.00882720947265625, 0.00027823448181152344, 0.1805419921875, 0.759765625, 0.0008025169372558594, 0.0013341903686523438, 0.5830078125, 0.99609375, 0.01395416259765625, 0.8955078125, 0.87060546875, 0.005390167236328125, 0.1842041015625, 0.054931640625, 0.94091796875, 1.0, 0.0655517578125, 0.373291015625, 0.99951171875, 0.434814453125, 0.9990234375]], "normalized_score": [0.05187603831291199], "tokens": [["\u2581Two", "\u2581#", "Re", "alty", "News", "R", "ound", "up", ":", "\u2581G", "ov", "t", "\u2581M", "ull", "s", "\u2581T", "ough", "\u2581Action", "\u2581Again", "st", "\u2581Del", "in", "quent", "\u2581Build", "ers"]], "entropy": [[1.83984375, 1.6005859375, 3.953125, 2.728515625, 2.751953125, 1.5517578125, 2.1875, 0.5986328125, 0.99951171875, 3.556640625, 1.34375, 0.03790283203125, 4.23828125, 0.449951171875, 0.38818359375, 4.2578125, 2.072265625, 1.671875, 0.377685546875, 0.0016164779663085938, 2.953125, 0.8251953125, 0.0040130615234375, 2.212890625, 0.008819580078125]], "avg_entropy": [1.704457359313965], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "two parties", "score_of_biggest_cluster": 0.05187603831291199, "score_of_first_answer": 0.05187603831291199, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 3.933906555175781e-06, "avg_score": 0.05187603831291199, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4040707070460727, "std_of_first_answer": 0.4040707070460727, "avg_entropy_of_first_answer": 1.704457359313965, "lex_sim": 1.0}
{"question": "different ways to spell corey for a boy", "answer": ["Cory, Corey \u00cdsland och F\u00e4r\u00f6arna, Finland, Sverige, Norge"], "scores": [[0.18798828125, 0.9951171875, 0.978515625, 0.09521484375, 0.99853515625, 0.0, 0.039459228515625, 0.60595703125, 1.996755599975586e-05, 0.0031681060791015625, 0.01058197021484375, 0.89453125, 0.62548828125, 0.1585693359375, 0.0007376670837402344, 0.9091796875, 0.0950927734375, 0.69482421875, 0.72216796875, 0.99853515625]], "normalized_score": [0.0], "tokens": [["\u2581C", "ory", ",", "\u2581Core", "y", "\u2581\u00cd", "s", "land", "\u2581och", "\u2581F", "\u00e4r", "\u00f6", "arna", ",", "\u2581Finland", ",", "\u2581Sverige", ",", "\u2581N", "orge"]], "entropy": [[2.05859375, 0.040313720703125, 0.1265869140625, 0.88720703125, 0.01287078857421875, 1.1455078125, 4.87890625, 2.134765625, 2.45703125, 4.9296875, 3.06640625, 0.55029296875, 2.033203125, 4.0234375, 5.2421875, 0.68798828125, 1.96875, 1.5556640625, 1.3818359375, 0.009857177734375]], "avg_entropy": [1.959554672241211], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Coire", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.99853515625, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4092287747979609, "std_of_first_answer": 0.4092287747979609, "avg_entropy_of_first_answer": 1.959554672241211, "lex_sim": 1.0}
{"question": "animals that are active at dawn and dusk", "answer": ["nocturnal animals #1 Postby Baby Hercules \u00bb Wed Sep 12, 2007 2:42 pm"], "scores": [[0.27197265625, 1.0, 1.0, 1.0, 0.912109375, 1.7881393432617188e-07, 0.0318603515625, 3.635883331298828e-06, 4.76837158203125e-07, 6.413459777832031e-05, 8.499622344970703e-05, 0.94775390625, 0.381591796875, 0.1015625, 0.101318359375, 0.99853515625, 0.3603515625, 0.1689453125, 0.9990234375, 0.99658203125, 0.9990234375, 1.0, 0.010162353515625, 0.9677734375, 0.99853515625, 0.07275390625, 0.99755859375, 0.166259765625, 0.1031494140625, 0.45263671875]], "normalized_score": [0.055042069405317307], "tokens": [["\u2581no", "ct", "urn", "al", "\u2581animals", "\u2581#", "1", "\u2581Post", "by", "\u2581Baby", "\u2581Her", "cules", "\u2581\u00bb", "\u2581Wed", "\u2581Sep", "\u2581", "1", "2", ",", "\u2581", "2", "0", "0", "7", "\u2581", "2", ":", "4", "2", "\u2581pm"]], "entropy": [[2.548828125, 0.0016946792602539062, 0.0003662109375, 0.00045180320739746094, 0.447265625, 1.5400390625, 5.25390625, 2.8046875, 0.92626953125, 6.453125, 4.03125, 0.335205078125, 2.5625, 2.27734375, 2.5078125, 0.01371002197265625, 1.185546875, 2.0078125, 0.00937652587890625, 0.032867431640625, 0.0075225830078125, 5.078315734863281e-05, 0.06060791015625, 0.1461181640625, 0.019317626953125, 1.94140625, 0.0214691162109375, 1.791015625, 2.298828125, 0.7021484375]], "avg_entropy": [1.3976181030273438], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Crepuscular", "score_of_biggest_cluster": 0.055042069405317307, "score_of_first_answer": 0.055042069405317307, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.055042069405317307, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4379410944996838, "std_of_first_answer": 0.4379410944996838, "avg_entropy_of_first_answer": 1.3976181030273438, "lex_sim": 1.0}
{"question": "who plays the coach in old spice commercial", "answer": ["Terry Crews #EvictionWatch: Johannesburg woman and her grandchildren protest against eviction"], "scores": [[0.394287109375, 0.998046875, 1.0, 1.0, 8.344650268554688e-07, 0.0016164779663085938, 0.00017833709716796875, 0.0005297660827636719, 0.0001481771469116211, 0.0026912689208984375, 4.0531158447265625e-06, 0.96533203125, 0.0014314651489257812, 0.00579071044921875, 0.72216796875, 0.01026153564453125, 0.08258056640625, 0.0008740425109863281, 0.108642578125, 0.2587890625, 0.99365234375]], "normalized_score": [0.011142238043248653], "tokens": [["\u2581Terry", "\u2581C", "rew", "s", "\u2581#", "E", "v", "iction", "Watch", ":", "\u2581Johannes", "burg", "\u2581woman", "\u2581and", "\u2581her", "\u2581grand", "children", "\u2581protest", "\u2581against", "\u2581ev", "iction"]], "entropy": [[1.4326171875, 0.0186004638671875, 0.0002536773681640625, 0.0004444122314453125, 0.77783203125, 4.29296875, 0.55615234375, 2.88671875, 3.869140625, 2.25390625, 5.30859375, 0.322998046875, 4.5, 4.99609375, 1.7099609375, 3.951171875, 1.5068359375, 4.0546875, 2.44921875, 3.173828125, 0.039794921875]], "avg_entropy": [2.290562765938895], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Isaiah Amir Mustafa", "score_of_biggest_cluster": 0.011142238043248653, "score_of_first_answer": 0.011142238043248653, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 8.344650268554688e-07, "avg_score": 0.011142238043248653, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41615718430535864, "std_of_first_answer": 0.41615718430535864, "avg_entropy_of_first_answer": 2.290562765938895, "lex_sim": 1.0}
{"question": "where can you find dna in the body", "answer": ["DNA is found in the chromosomes of all living cells, including the body's cells."], "scores": [[0.0267181396484375, 0.90478515625, 0.90234375, 0.990234375, 0.94140625, 0.01410675048828125, 0.99951171875, 1.0, 1.0, 0.82177734375, 0.74951171875, 0.91552734375, 0.982421875, 0.546875, 0.9208984375, 0.178955078125, 0.05023193359375, 0.94677734375, 1.0, 0.97998046875, 0.96533203125]], "normalized_score": [0.5072088241577148], "tokens": [["\u2581DNA", "\u2581is", "\u2581found", "\u2581in", "\u2581the", "\u2581chrom", "os", "om", "es", "\u2581of", "\u2581all", "\u2581living", "\u2581cells", ",", "\u2581including", "\u2581the", "\u2581body", "'", "s", "\u2581cells", "."]], "entropy": [[1.78515625, 0.337890625, 0.42822265625, 0.06524658203125, 0.323486328125, 1.1845703125, 0.0059051513671875, 0.0008845329284667969, 0.00018930435180664062, 0.71435546875, 0.95703125, 0.39697265625, 0.08984375, 0.86962890625, 0.390625, 1.0693359375, 0.392333984375, 0.26318359375, 1.3649463653564453e-05, 0.1571044921875, 0.193115234375]], "avg_entropy": [0.45833788883118404], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "chromosomes in a cell", "score_of_biggest_cluster": 0.5072088241577148, "score_of_first_answer": 0.5072088241577148, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.01410675048828125, "avg_score": 0.5072088241577148, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.34958269370938877, "std_of_first_answer": 0.34958269370938877, "avg_entropy_of_first_answer": 0.45833788883118404, "lex_sim": 1.0}
{"question": "where does the lincoln highway begin and end", "answer": ["The Lincoln Highway begins in New York City and ends in San Francisco."], "scores": [[0.56591796875, 0.99267578125, 0.99951171875, 0.67578125, 0.99853515625, 0.10333251953125, 0.998046875, 0.99951171875, 0.78857421875, 0.9814453125, 0.99853515625, 0.99951171875, 0.99951171875, 0.66552734375, 0.06781005859375, 0.282958984375, 0.1798095703125, 0.7158203125, 0.433837890625, 0.99462890625, 0.51220703125, 0.5810546875, 0.9990234375, 1.0, 0.9931640625, 0.0242767333984375, 0.266845703125, 0.9013671875, 0.99169921875, 0.9892578125, 0.99951171875, 0.98291015625, 3.2782554626464844e-06, 0.0008807182312011719, 0.0002894401550292969, 0.0032558441162109375, 0.78369140625, 0.260986328125, 0.044097900390625, 0.001056671142578125, 0.97509765625, 0.002071380615234375, 0.01094818115234375, 0.0019140243530273438, 0.0882568359375, 0.00287628173828125, 0.005340576171875, 0.24365234375]], "normalized_score": [0.14064587652683258], "tokens": [["\u2581The", "\u2581Lincoln", "\u2581Highway", "\u2581begins", "\u2581in", "\u2581New", "\u2581York", "\u2581City", "\u2581and", "\u2581ends", "\u2581in", "\u2581San", "\u2581Francisco", ".", "\u2581It", "\u2581is", "\u2581a", "\u2581historic", "\u2581highway", "\u2581that", "\u2581was", "\u2581one", "\u2581of", "\u2581the", "\u2581first", "\u2581road", "\u2581routes", "\u2581across", "\u2581the", "\u2581United", "\u2581States", ".", "\u2581#", "K", "h", "any", "i", "M", "bau", "'", "s", "\u2581ex", ",", "\u2581J", "ade", "\u2581'", "e", "M"]], "entropy": [[2.17578125, 0.0625, 0.004276275634765625, 1.2099609375, 0.01161956787109375, 1.927734375, 0.0175933837890625, 0.0029239654541015625, 0.5322265625, 0.121337890625, 0.01184844970703125, 0.0032196044921875, 0.0029010772705078125, 0.6904296875, 0.59326171875, 0.7119140625, 1.87890625, 1.33203125, 1.75, 0.0435791015625, 1.634765625, 1.208984375, 0.006439208984375, 0.0014886856079101562, 0.0408935546875, 0.6181640625, 1.10546875, 0.501953125, 0.049774169921875, 0.06640625, 0.00360870361328125, 0.100341796875, 0.25048828125, 3.03125, 0.286865234375, 3.91015625, 1.01171875, 3.259765625, 1.9150390625, 1.30078125, 0.2232666015625, 5.6640625, 1.8583984375, 4.1875, 4.015625, 4.34375, 4.69921875, 3.275390625]], "avg_entropy": [1.2844918767611186], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Lincoln Park in San Francisco", "score_of_biggest_cluster": 0.14064587652683258, "score_of_first_answer": 0.14064587652683258, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 3.2782554626464844e-06, "avg_score": 0.14064587652683258, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4206402578066531, "std_of_first_answer": 0.4206402578066531, "avg_entropy_of_first_answer": 1.2844918767611186, "lex_sim": 1.0}
{"question": "what was the name of atom bomb dropped by usa on hiroshima", "answer": ["Little Boy #5867918, By OzzyIsBack The future of online music distribution"], "scores": [[0.919921875, 0.9990234375, 2.384185791015625e-07, 0.00836181640625, 0.02679443359375, 0.06500244140625, 0.0007443428039550781, 0.10626220703125, 0.0175628662109375, 0.0307464599609375, 0.0022983551025390625, 2.1636486053466797e-05, 3.916025161743164e-05, 0.00015044212341308594, 0.0029449462890625, 0.00023996829986572266, 0.1376953125, 8.666515350341797e-05, 7.987022399902344e-06, 0.1131591796875, 0.0013294219970703125, 0.00235748291015625, 0.0260162353515625]], "normalized_score": [0.0028310304041951895], "tokens": [["\u2581Little", "\u2581Boy", "\u2581#", "5", "8", "6", "7", "9", "1", "8", ",", "\u2581By", "\u2581O", "z", "zy", "Is", "Back", "\u2581The", "\u2581future", "\u2581of", "\u2581online", "\u2581music", "\u2581distribution"]], "entropy": [[0.3017578125, 0.0093841552734375, 0.60595703125, 2.7109375, 2.673828125, 2.68359375, 1.052734375, 2.806640625, 2.001953125, 2.54296875, 2.7734375, 3.96875, 2.482421875, 1.4169921875, 1.0302734375, 3.7890625, 3.623046875, 2.609375, 6.0546875, 5.109375, 5.20703125, 5.37109375, 4.609375]], "avg_entropy": [2.8449859619140625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Little Boy", "score_of_biggest_cluster": 0.0028310304041951895, "score_of_first_answer": 0.0028310304041951895, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.0028310304041951895, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.26629906085708954, "std_of_first_answer": 0.26629906085708954, "avg_entropy_of_first_answer": 2.8449859619140625, "lex_sim": 1.0}
{"question": "who played raquel in only fools and horses", "answer": ["June Whitfield"], "scores": [[0.023834228515625, 0.55859375, 1.0]], "normalized_score": [0.2370094656944275], "tokens": [["\u2581June", "\u2581Whit", "field"]], "entropy": [[4.3828125, 0.79931640625, 0.001049041748046875]], "avg_entropy": [1.7277259826660156], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Tessa Peake-Jones", "score_of_biggest_cluster": 0.2370094656944275, "score_of_first_answer": 0.2370094656944275, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.023834228515625, "avg_score": 0.2370094656944275, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39912499250442907, "std_of_first_answer": 0.39912499250442907, "avg_entropy_of_first_answer": 1.7277259826660156, "lex_sim": 1.0}
{"question": "where does what in the sam hill come from", "answer": ["\"What in the Sam Hill\" is an exclamation that originated in the United States in the late 19th century."], "scores": [[0.35302734375, 0.97265625, 0.97119140625, 0.94140625, 0.74658203125, 0.99853515625, 0.87646484375, 0.97607421875, 0.5322265625, 0.44775390625, 0.99609375, 0.99072265625, 0.111572265625, 0.490966796875, 0.9072265625, 0.72119140625, 0.99365234375, 0.876953125, 1.0, 0.93408203125, 1.0, 0.7822265625, 0.99951171875, 1.0, 0.56982421875, 1.0, 0.87548828125, 0.9189453125, 0.020050048828125, 0.9990234375, 0.99853515625, 1.0, 0.85009765625, 0.9794921875, 0.20654296875, 1.0, 1.0, 0.9853515625, 0.99853515625, 0.99365234375, 0.138916015625, 1.0, 0.8408203125, 0.410888671875, 0.61328125, 0.86376953125, 0.38720703125, 0.0394287109375, 0.7412109375, 0.90478515625]], "normalized_score": [0.6496649384498596], "tokens": [["\u2581\"", "What", "\u2581in", "\u2581the", "\u2581Sam", "\u2581Hill", "\"", "\u2581is", "\u2581an", "\u2581ex", "clam", "ation", "\u2581that", "\u2581origin", "ated", "\u2581in", "\u2581the", "\u2581United", "\u2581States", "\u2581in", "\u2581the", "\u2581late", "\u2581", "1", "9", "th", "\u2581century", ".", "\u2581\"", "Sam", "\u2581Hill", "\"", "\u2581was", "\u2581a", "\u2581eu", "ph", "em", "ism", "\u2581for", "\u2581\"", "dam", "n", "\"", "\u2581and", "\u2581the", "\u2581phrase", "\u2581was", "\u2581originally", "\u2581\"", "What"]], "entropy": [[2.271484375, 0.168701171875, 0.1324462890625, 0.282958984375, 0.58984375, 0.01306915283203125, 0.41015625, 0.154052734375, 0.77001953125, 1.361328125, 0.027099609375, 0.05377197265625, 1.4453125, 1.7578125, 0.308837890625, 0.72021484375, 0.0458984375, 0.58154296875, 0.0019168853759765625, 0.346923828125, 0.0007567405700683594, 0.70849609375, 0.004055023193359375, 1.823902130126953e-05, 0.68359375, 0.0006690025329589844, 0.409423828125, 0.365234375, 0.441650390625, 0.00754547119140625, 0.01212310791015625, 0.00024318695068359375, 0.62744140625, 0.14599609375, 3.251953125, 0.0002541542053222656, 0.0008802413940429688, 0.07586669921875, 0.01141357421875, 0.04815673828125, 1.55078125, 0.0006265640258789062, 0.501953125, 0.740234375, 0.87451171875, 0.52001953125, 1.451171875, 1.4853515625, 0.90966796875, 0.322998046875]], "avg_entropy": [0.5319295811653137], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "simple bowdlerization", "score_of_biggest_cluster": 0.6496649384498596, "score_of_first_answer": 0.6496649384498596, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.020050048828125, "avg_score": 0.6496649384498596, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2921025082250914, "std_of_first_answer": 0.2921025082250914, "avg_entropy_of_first_answer": 0.5319295811653137, "lex_sim": 1.0}
{"question": "who won the mvp for the national league", "answer": ["Matt Carpenter ### Giving an opportunity to learn and practice"], "scores": [[0.0024318695068359375, 0.7197265625, 0.99951171875, 1.0, 0.0, 0.0010623931884765625, 0.004726409912109375, 0.0830078125, 0.0005736351013183594, 0.52392578125, 0.045562744140625, 0.11981201171875, 0.0159454345703125]], "normalized_score": [0.0], "tokens": [["\u2581Matt", "\u2581Car", "p", "enter", "\u2581###", "\u2581G", "iving", "\u2581an", "\u2581opportunity", "\u2581to", "\u2581learn", "\u2581and", "\u2581practice"]], "entropy": [[2.853515625, 0.92138671875, 0.005054473876953125, 0.0003814697265625, 0.828125, 3.439453125, 2.18359375, 3.59375, 2.349609375, 0.81884765625, 5.00390625, 3.0703125, 3.306640625]], "avg_entropy": [2.1826597360464244], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Stanton, Giancarlo", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.378665235741438, "std_of_first_answer": 0.378665235741438, "avg_entropy_of_first_answer": 2.1826597360464244, "lex_sim": 1.0}
{"question": "what type of snake is kaa in jungle book", "answer": ["Indian Python #BookReview The Other Side of Us by Lauren Doyle"], "scores": [[0.7529296875, 0.44091796875, 1.2516975402832031e-06, 2.8192996978759766e-05, 0.0242767333984375, 0.2529296875, 0.0015153884887695312, 8.702278137207031e-05, 0.56396484375, 0.755859375, 0.001567840576171875, 0.830078125, 0.167724609375, 0.5869140625, 0.9482421875, 0.99169921875]], "normalized_score": [0.030232934281229973], "tokens": [["\u2581Indian", "\u2581Python", "\u2581#", "Book", "Re", "view", "\u2581The", "\u2581Other", "\u2581Side", "\u2581of", "\u2581Us", "\u2581by", "\u2581La", "uren", "\u2581Do", "yle"]], "entropy": [[0.8251953125, 1.15234375, 0.94873046875, 3.435546875, 3.638671875, 0.6806640625, 1.947265625, 0.450439453125, 2.125, 0.828125, 2.099609375, 0.9248046875, 2.775390625, 1.94140625, 0.43017578125, 0.0638427734375]], "avg_entropy": [1.5167007446289062], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Indian rock python", "score_of_biggest_cluster": 0.030232934281229973, "score_of_first_answer": 0.030232934281229973, "max_score_of_first_answer": 0.99169921875, "min_score_of_first_answer": 1.2516975402832031e-06, "avg_score": 0.030232934281229973, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.3677734786865184, "std_of_first_answer": 0.3677734786865184, "avg_entropy_of_first_answer": 1.5167007446289062, "lex_sim": 1.0}
{"question": "who picks the chief justice of the illinois supreme court", "answer": ["the Illinois Supreme Court Chief Justice Selection Committee"], "scores": [[0.1749267578125, 0.33935546875, 0.96826171875, 0.99951171875, 0.0241851806640625, 0.99462890625, 0.2459716796875, 0.67626953125]], "normalized_score": [0.35090407729148865], "tokens": [["\u2581the", "\u2581Illinois", "\u2581Supreme", "\u2581Court", "\u2581Chief", "\u2581Justice", "\u2581Selection", "\u2581Committee"]], "entropy": [[1.529296875, 1.5751953125, 0.202392578125, 0.0028667449951171875, 2.45703125, 0.040740966796875, 1.7587890625, 1.55078125]], "avg_entropy": [1.139636754989624], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the court", "score_of_biggest_cluster": 0.35090407729148865, "score_of_first_answer": 0.35090407729148865, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.0241851806640625, "avg_score": 0.35090407729148865, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3782428525805668, "std_of_first_answer": 0.3782428525805668, "avg_entropy_of_first_answer": 1.139636754989624, "lex_sim": 1.0}
{"question": "what domain has more individuals than all other domains combined do", "answer": ["the domain archea"], "scores": [[0.06591796875, 0.006256103515625, 0.0654296875, 0.00360870361328125, 0.87451171875]], "normalized_score": [0.03855137526988983], "tokens": [["\u2581the", "\u2581domain", "\u2581ar", "che", "a"]], "entropy": [[3.095703125, 1.19921875, 0.97607421875, 0.354248046875, 0.56640625]], "avg_entropy": [1.238330078125], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the com TLD", "score_of_biggest_cluster": 0.03855137526988983, "score_of_first_answer": 0.03855137526988983, "max_score_of_first_answer": 0.87451171875, "min_score_of_first_answer": 0.00360870361328125, "avg_score": 0.03855137526988983, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.33678183073979284, "std_of_first_answer": 0.33678183073979284, "avg_entropy_of_first_answer": 1.238330078125, "lex_sim": 1.0}
{"question": "when did the song push it come out", "answer": ["1998"], "scores": [[0.77978515625, 0.58837890625, 0.99951171875, 0.492431640625, 0.74072265625]], "normalized_score": [0.6993334889411926], "tokens": [["\u2581", "1", "9", "9", "8"]], "entropy": [[1.2255859375, 0.681640625, 0.005279541015625, 0.95654296875, 1.0078125]], "avg_entropy": [0.775372314453125], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "March 8, 1987", "score_of_biggest_cluster": 0.6993334889411926, "score_of_first_answer": 0.6993334889411926, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.492431640625, "avg_score": 0.6993334889411926, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.17392057210756204, "std_of_first_answer": 0.17392057210756204, "avg_entropy_of_first_answer": 0.775372314453125, "lex_sim": 1.0}
{"question": "when does part 5 of jojo take place", "answer": ["\"JoJo's Bizarre Adventure: Golden Wind\" also known as \"JoJo's Bizarre Adventure Part 5,\" takes place in the 1990s."], "scores": [[0.00433349609375, 0.9541015625, 0.65283203125, 0.99951171875, 1.0, 1.0, 0.998046875, 0.99951171875, 1.0, 0.99951171875, 0.78759765625, 0.98486328125, 1.0, 0.9697265625, 0.004180908203125, 0.99951171875, 0.99951171875, 0.4287109375, 0.84375, 0.89404296875, 0.95556640625, 1.0, 0.98876953125, 0.99755859375, 1.0, 1.0, 1.0, 0.67724609375, 1.0, 1.0, 0.0831298828125, 0.72607421875, 1.0, 0.9736328125, 0.7958984375, 0.443115234375, 0.97119140625, 1.0, 0.76171875, 1.0, 0.982421875, 0.63671875, 2.3245811462402344e-06, 0.0012950897216796875, 0.0634765625, 0.0750732421875, 0.0024356842041015625, 7.343292236328125e-05]], "normalized_score": [0.2961535155773163], "tokens": [["\u2581\"", "Jo", "Jo", "'", "s", "\u2581B", "izar", "re", "\u2581Advent", "ure", ":", "\u2581Golden", "\u2581Wind", "\"", "\u2581also", "\u2581known", "\u2581as", "\u2581\"", "Jo", "Jo", "'", "s", "\u2581B", "izar", "re", "\u2581Advent", "ure", "\u2581Part", "\u2581", "5", ",\"", "\u2581takes", "\u2581place", "\u2581in", "\u2581the", "\u2581", "1", "9", "9", "0", "s", ".", "\u2581#", "3", "0", "4", ":", "\u2581Be"]], "entropy": [[3.04296875, 0.302734375, 0.888671875, 0.0037364959716796875, 1.1324882507324219e-06, 0.002437591552734375, 0.0134429931640625, 0.00601959228515625, 0.0014772415161132812, 0.0038204193115234375, 0.7119140625, 0.10064697265625, 0.0004489421844482422, 0.173095703125, 1.9375, 0.0062408447265625, 0.007205963134765625, 1.080078125, 0.50537109375, 0.414306640625, 0.22705078125, 3.737211227416992e-05, 0.09088134765625, 0.0169677734375, 0.0005097389221191406, 0.0010995864868164062, 0.0005598068237304688, 0.958984375, 0.0022449493408203125, 0.00028514862060546875, 0.49169921875, 0.63671875, 0.0025615692138671875, 0.1729736328125, 0.66796875, 1.2626953125, 0.1385498046875, 0.002086639404296875, 0.59765625, 0.0005435943603515625, 0.0899658203125, 0.97900390625, 0.5302734375, 2.80078125, 3.333984375, 3.2421875, 2.693359375, 4.45703125]], "avg_entropy": [0.6791829193631808], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The manga begins in 2001", "score_of_biggest_cluster": 0.2961535155773163, "score_of_first_answer": 0.2961535155773163, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.3245811462402344e-06, "avg_score": 0.2961535155773163, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37160399872279765, "std_of_first_answer": 0.37160399872279765, "avg_entropy_of_first_answer": 0.6791829193631808, "lex_sim": 1.0}
{"question": "who wins america's next top model cycle 20", "answer": ["I am not aware of the results of the specific cycle you have mentioned."], "scores": [[0.92431640625, 0.309814453125, 0.8046875, 0.2568359375, 0.998046875, 0.89306640625, 0.1492919921875, 0.97900390625, 0.0390625, 0.01253509521484375, 0.89453125, 0.53466796875, 0.0094146728515625, 0.9384765625, 0.5322265625, 0.35791015625, 0.80908203125, 0.8662109375, 0.309326171875, 0.99951171875, 0.7646484375, 0.83447265625, 1.0, 1.0, 1.0, 0.99951171875, 0.5400390625, 5.960464477539063e-08, 4.76837158203125e-07, 0.2666015625, 0.98095703125]], "normalized_score": [0.1710497885942459], "tokens": [["\u2581I", "\u2581am", "\u2581not", "\u2581aware", "\u2581of", "\u2581the", "\u2581results", "\u2581of", "\u2581the", "\u2581specific", "\u2581cycle", "\u2581you", "\u2581have", "\u2581mentioned", ".", "\u2581My", "\u2581knowledge", "\u2581cut", "-", "off", "\u2581is", "\u2581", "2", "0", "2", "1", ".", "\u2581###", "\u2581Ex", "plan", "ation"]], "entropy": [[0.6416015625, 1.2099609375, 0.72998046875, 0.9326171875, 0.0198822021484375, 0.56982421875, 1.583984375, 0.13232421875, 0.625, 1.7763671875, 0.47607421875, 0.81884765625, 0.87890625, 0.343994140625, 1.0458984375, 2.13671875, 0.5498046875, 0.48681640625, 1.03125, 0.0053558349609375, 0.62255859375, 0.71630859375, 0.00045609474182128906, 0.0010251998901367188, 0.0018606185913085938, 0.004505157470703125, 1.0712890625, 1.1572265625, 5.57421875, 2.09375, 0.10919189453125]], "avg_entropy": [0.8821806215470837], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Jourdan Miller", "score_of_biggest_cluster": 0.1710497885942459, "score_of_first_answer": 0.1710497885942459, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.1710497885942459, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37124401546137703, "std_of_first_answer": 0.37124401546137703, "avg_entropy_of_first_answer": 0.8821806215470837, "lex_sim": 1.0}
{"question": "when was the minimum wage established in the united states", "answer": ["1938"], "scores": [[0.939453125, 0.99951171875, 1.0, 1.0, 0.99951171875]], "normalized_score": [0.987393319606781], "tokens": [["\u2581", "1", "9", "3", "8"]], "entropy": [[0.359375, 0.0031070709228515625, 0.00077056884765625, 0.0005459785461425781, 0.00337982177734375]], "avg_entropy": [0.07343568801879882], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1938", "score_of_biggest_cluster": 0.987393319606781, "score_of_first_answer": 0.987393319606781, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.939453125, "avg_score": 0.987393319606781, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.024122082153332235, "std_of_first_answer": 0.024122082153332235, "avg_entropy_of_first_answer": 0.07343568801879882, "lex_sim": 1.0}
{"question": "a player that can shoot pass or dribble is considered to be", "answer": ["a versatile player #44956 - 08/14/18 02:42 PM Re: The Handmaid's Tale [Re: NW Ponderer]"], "scores": [[0.237060546875, 0.8095703125, 1.0, 0.970703125, 1.1920928955078125e-07, 0.00753021240234375, 0.044097900390625, 0.01224517822265625, 0.10089111328125, 0.036712646484375, 0.0004935264587402344, 0.1011962890625, 0.0615234375, 0.0172271728515625, 0.44384765625, 0.334228515625, 0.093994140625, 0.93359375, 0.0021953582763671875, 0.166748046875, 0.1253662109375, 0.325927734375, 0.09814453125, 0.998046875, 0.1671142578125, 0.09979248046875, 0.10137939453125, 0.00011307001113891602, 0.47314453125, 0.01381683349609375, 3.349781036376953e-05, 0.007755279541015625, 0.986328125, 0.9716796875, 1.0, 0.9853515625, 0.9951171875, 0.396728515625, 0.88232421875, 0.9990234375, 0.003009796142578125, 0.0002567768096923828, 0.0009889602661132812, 0.84130859375, 0.96435546875, 0.9658203125]], "normalized_score": [0.06164101883769035], "tokens": [["\u2581a", "\u2581vers", "atile", "\u2581player", "\u2581#", "4", "4", "9", "5", "6", "\u2581-", "\u2581", "0", "8", "/", "1", "4", "/", "1", "8", "\u2581", "0", "2", ":", "4", "2", "\u2581PM", "\u2581Re", ":", "\u2581The", "\u2581Hand", "ma", "id", "'", "s", "\u2581T", "ale", "\u2581[", "Re", ":", "\u2581N", "W", "\u2581P", "onder", "er", "]"]], "entropy": [[1.2880859375, 0.9970703125, 0.0014009475708007812, 0.192626953125, 1.1884765625, 5.61328125, 3.81640625, 3.578125, 2.583984375, 2.001953125, 2.7890625, 6.0078125, 2.14453125, 1.0576171875, 1.3427734375, 1.1357421875, 2.1328125, 0.3251953125, 0.0341796875, 1.2568359375, 1.2568359375, 1.2109375, 2.322265625, 0.0200042724609375, 1.791015625, 2.306640625, 1.7802734375, 2.0390625, 1.7705078125, 5.18359375, 4.48046875, 2.041015625, 0.0819091796875, 0.1605224609375, 0.002513885498046875, 0.1339111328125, 0.040802001953125, 2.76171875, 0.9794921875, 0.01007843017578125, 4.91015625, 5.05078125, 2.40234375, 1.0791015625, 0.20556640625, 0.29443359375]], "avg_entropy": [1.8218244677004607], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Triple threat", "score_of_biggest_cluster": 0.06164101883769035, "score_of_first_answer": 0.06164101883769035, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.06164101883769035, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4120895968256222, "std_of_first_answer": 0.4120895968256222, "avg_entropy_of_first_answer": 1.8218244677004607, "lex_sim": 1.0}
{"question": "what is the term of an official in the house of representatives", "answer": ["Two years"], "scores": [[0.21484375, 0.99560546875]], "normalized_score": [0.46249282360076904], "tokens": [["\u2581Two", "\u2581years"]], "entropy": [[1.736328125, 0.0340576171875]], "avg_entropy": [0.88519287109375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "two-year", "score_of_biggest_cluster": 0.46249282360076904, "score_of_first_answer": 0.46249282360076904, "max_score_of_first_answer": 0.99560546875, "min_score_of_first_answer": 0.21484375, "avg_score": 0.46249282360076904, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.390380859375, "std_of_first_answer": 0.390380859375, "avg_entropy_of_first_answer": 0.88519287109375, "lex_sim": 1.0}
{"question": "who plays ivo on once upon a time", "answer": ["Oliver Rice"], "scores": [[0.0015239715576171875, 0.73779296875, 0.8291015625]], "normalized_score": [0.09768766909837723], "tokens": [["\u2581Oliver", "\u2581R", "ice"]], "entropy": [[2.228515625, 1.7802734375, 1.3427734375]], "avg_entropy": [1.7838541666666667], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Dan Payne", "score_of_biggest_cluster": 0.09768766909837723, "score_of_first_answer": 0.09768766909837723, "max_score_of_first_answer": 0.8291015625, "min_score_of_first_answer": 0.0015239715576171875, "avg_score": 0.09768766909837723, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3704822629656404, "std_of_first_answer": 0.3704822629656404, "avg_entropy_of_first_answer": 1.7838541666666667, "lex_sim": 1.0}
{"question": "who did the central powers defeat on the eastern front before concentrating back on france", "answer": ["Russian Empire"], "scores": [[0.016937255859375, 0.9912109375]], "normalized_score": [0.12957005202770233], "tokens": [["\u2581Russian", "\u2581Empire"]], "entropy": [[2.533203125, 0.07659912109375]], "avg_entropy": [1.304901123046875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the Russian army", "score_of_biggest_cluster": 0.12957005202770233, "score_of_first_answer": 0.12957005202770233, "max_score_of_first_answer": 0.9912109375, "min_score_of_first_answer": 0.016937255859375, "avg_score": 0.12957005202770233, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4871368408203125, "std_of_first_answer": 0.4871368408203125, "avg_entropy_of_first_answer": 1.304901123046875, "lex_sim": 1.0}
{"question": "who played violet in a series of unfortunate events netflix", "answer": ["Emily Browning"], "scores": [[0.01497650146484375, 0.98876953125, 0.93359375, 1.0]], "normalized_score": [0.34289872646331787], "tokens": [["\u2581Em", "ily", "\u2581Brow", "ning"]], "entropy": [[0.1297607421875, 0.0682373046875, 0.273681640625, 0.0010128021240234375]], "avg_entropy": [0.11817312240600586], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Malina Weissman", "score_of_biggest_cluster": 0.34289872646331787, "score_of_first_answer": 0.34289872646331787, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.01497650146484375, "avg_score": 0.34289872646331787, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4160815790754598, "std_of_first_answer": 0.4160815790754598, "avg_entropy_of_first_answer": 0.11817312240600586, "lex_sim": 1.0}
{"question": "in what part of the digestive tube do you expect the initial digestion of starch", "answer": ["Mouth #81 Post by chijohna \u00bb Wed Apr 04, 2018 5:08 pm"], "scores": [[0.177001953125, 0.91552734375, 5.304813385009766e-06, 0.0006570816040039062, 0.01544189453125, 1.1920928955078125e-06, 0.01123809814453125, 0.0024261474609375, 0.0004420280456542969, 0.479736328125, 0.0297088623046875, 0.016021728515625, 0.1484375, 0.10882568359375, 1.0, 0.9990234375, 0.446533203125, 0.17138671875, 0.9990234375, 0.9755859375, 0.9990234375, 1.0, 0.99951171875, 0.9921875, 0.9951171875, 0.079833984375, 0.99951171875, 0.1497802734375, 0.1064453125, 0.47998046875]], "normalized_score": [0.06980574131011963], "tokens": [["\u2581M", "outh", "\u2581#", "8", "1", "\u2581Post", "\u2581by", "\u2581ch", "ij", "oh", "na", "\u2581\u00bb", "\u2581Wed", "\u2581A", "pr", "\u2581", "0", "4", ",", "\u2581", "2", "0", "1", "8", "\u2581", "5", ":", "0", "8", "\u2581pm"]], "entropy": [[1.8505859375, 0.41650390625, 1.525390625, 3.697265625, 3.05859375, 2.984375, 3.205078125, 5.26171875, 4.82421875, 2.267578125, 3.763671875, 4.27734375, 2.19921875, 2.447265625, 0.00016236305236816406, 0.00823211669921875, 0.99658203125, 1.7353515625, 0.0099334716796875, 0.133544921875, 0.0089111328125, 9.036064147949219e-05, 0.004116058349609375, 0.04779052734375, 0.035858154296875, 1.9794921875, 0.003467559814453125, 1.7890625, 2.30078125, 0.70068359375]], "avg_entropy": [1.717762279510498], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the mouth", "score_of_biggest_cluster": 0.06980574131011963, "score_of_first_answer": 0.06980574131011963, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-06, "avg_score": 0.06980574131011963, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.43428345348885883, "std_of_first_answer": 0.43428345348885883, "avg_entropy_of_first_answer": 1.717762279510498, "lex_sim": 1.0}
{"question": "when is chinese new year and what year is it", "answer": ["Chinese New Year usually falls on the first day of the lunar calendar."], "scores": [[0.92236328125, 0.99951171875, 0.9990234375, 0.01424407958984375, 0.912109375, 0.150146484375, 0.82177734375, 0.0222930908203125, 0.9833984375, 1.0, 0.99853515625, 0.5009765625, 1.0, 0.99853515625, 0.19921875, 0.5283203125, 0.55322265625, 0.0141143798828125, 0.19140625, 0.9990234375, 0.998046875, 0.94677734375, 1.0, 1.0, 0.9990234375, 0.41845703125, 0.0950927734375, 0.92578125, 0.42919921875, 0.99951171875, 0.99462890625, 0.00079345703125, 0.0655517578125, 1.1920928955078125e-07, 0.0009918212890625, 0.36669921875, 0.010284423828125, 0.001544952392578125, 0.004795074462890625, 0.59423828125]], "normalized_score": [0.15475140511989594], "tokens": [["\u2581Chinese", "\u2581New", "\u2581Year", "\u2581usually", "\u2581falls", "\u2581on", "\u2581the", "\u2581first", "\u2581day", "\u2581of", "\u2581the", "\u2581lun", "ar", "\u2581calendar", ".", "\u2581The", "\u2581year", "\u2581for", "\u2581Chinese", "\u2581New", "\u2581Year", "\u2581", "2", "0", "2", "3", "\u2581starts", "\u2581on", "\u2581January", "\u2581", "2", "9", ".", "\u2581###", "\u2581What", "\u2581is", "\u2581a", "\u2581data", "\u2581logger", "?"]], "entropy": [[0.421875, 0.005962371826171875, 0.0076751708984375, 1.6474609375, 0.398193359375, 0.68701171875, 0.63916015625, 0.21435546875, 0.119873046875, 0.0017910003662109375, 0.01195526123046875, 1.2939453125, 0.0004887580871582031, 0.01490020751953125, 1.2001953125, 1.533203125, 1.142578125, 0.96337890625, 1.0830078125, 0.01103973388671875, 0.01430511474609375, 0.25244140625, 0.00021135807037353516, 0.0004363059997558594, 0.00794219970703125, 1.09375, 0.87451171875, 0.2763671875, 0.9716796875, 0.0033779144287109375, 0.037872314453125, 0.8662109375, 0.8525390625, 1.205078125, 5.8671875, 2.275390625, 1.4189453125, 6.03515625, 4.54296875, 1.767578125]], "avg_entropy": [0.9940500169992447], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the year of the Dog", "score_of_biggest_cluster": 0.15475140511989594, "score_of_first_answer": 0.15475140511989594, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.15475140511989594, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4186313333855766, "std_of_first_answer": 0.4186313333855766, "avg_entropy_of_first_answer": 0.9940500169992447, "lex_sim": 1.0}
{"question": "what is bermuda competing in the winter olympics", "answer": ["Bermuda does not compete in the Winter Olympics as it is not a participating country."], "scores": [[0.389404296875, 1.0, 0.99951171875, 0.267822265625, 0.99951171875, 0.87646484375, 1.0, 0.9990234375, 0.99853515625, 0.8974609375, 0.9951171875, 0.5595703125, 0.919921875, 0.96826171875, 0.1710205078125, 0.9599609375, 0.0911865234375, 0.82421875, 0.65283203125, 0.84521484375, 0.335205078125, 1.0, 1.0, 0.2425537109375, 0.405517578125, 1.0, 1.0, 0.9970703125, 0.9853515625, 0.98681640625, 0.9912109375, 0.0, 0.0002338886260986328, 0.0022220611572265625, 0.0010900497436523438, 0.06195068359375, 0.8154296875, 0.99853515625, 1.0, 1.0, 0.99951171875, 0.0006527900695800781]], "normalized_score": [0.0], "tokens": [["\u2581B", "erm", "uda", "\u2581does", "\u2581not", "\u2581comp", "ete", "\u2581in", "\u2581the", "\u2581Winter", "\u2581Olympics", "\u2581as", "\u2581it", "\u2581is", "\u2581not", "\u2581a", "\u2581particip", "ating", "\u2581country", ".", "\u2581B", "erm", "uda", "\u2581only", "\u2581particip", "ates", "\u2581in", "\u2581the", "\u2581Summer", "\u2581Olympics", ".", "\u2581##", "\u2581The", "\u2581S", "cy", "lla", "\u2581and", "\u2581Ch", "ary", "b", "dis", "\u2581Problem"]], "entropy": [[1.2578125, 4.500150680541992e-05, 0.00534820556640625, 1.251953125, 0.003955841064453125, 0.52197265625, 2.5510787963867188e-05, 0.00867462158203125, 0.0135650634765625, 0.33154296875, 0.0325927734375, 1.0751953125, 0.345947265625, 0.1546630859375, 0.71728515625, 0.269287109375, 1.7060546875, 0.46484375, 0.802734375, 0.53955078125, 1.75390625, 0.00033164024353027344, 0.002288818359375, 1.7373046875, 0.79541015625, 0.0013723373413085938, 0.0021457672119140625, 0.0244293212890625, 0.09698486328125, 0.073974609375, 0.06805419921875, 0.42578125, 6.4453125, 4.76953125, 2.8046875, 0.99560546875, 1.15234375, 0.0145263671875, 0.001495361328125, 0.00019812583923339844, 0.003997802734375, 2.466796875]], "avg_entropy": [0.789036397423063], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Cross-country skiing", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3849500485196493, "std_of_first_answer": 0.3849500485196493, "avg_entropy_of_first_answer": 0.789036397423063, "lex_sim": 1.0}
{"question": "how and why were serial novels a phenomenon in the nineteenth century", "answer": ["Serial novels became popular in the 19th century due to the rise of mass publishing and increased literacy rates."], "scores": [[0.99365234375, 0.97802734375, 1.0, 0.22607421875, 0.4453125, 0.97802734375, 0.9990234375, 0.8876953125, 1.0, 1.0, 1.0, 1.0, 0.63134765625, 0.99951171875, 0.3779296875, 0.41943359375, 0.9970703125, 0.71484375, 0.038360595703125, 0.9365234375, 0.02569580078125, 0.9873046875, 1.0, 0.9375, 0.80517578125, 0.06695556640625, 0.97998046875, 1.0, 0.9765625, 0.58984375, 0.99853515625, 0.7607421875, 0.99951171875, 0.7919921875, 0.69140625, 1.0, 1.0, 0.25, 0.5029296875, 0.90625, 0.35791015625, 0.9990234375, 0.0075225830078125, 0.64892578125, 1.0, 0.765625, 1.0, 0.09893798828125, 0.60009765625, 0.998046875]], "normalized_score": [0.5694028735160828], "tokens": [["\u2581Serial", "\u2581nov", "els", "\u2581became", "\u2581popular", "\u2581in", "\u2581the", "\u2581", "1", "9", "th", "\u2581century", "\u2581due", "\u2581to", "\u2581the", "\u2581rise", "\u2581of", "\u2581mass", "\u2581publishing", "\u2581and", "\u2581increased", "\u2581liter", "acy", "\u2581rates", ".", "\u2581These", "\u2581nov", "els", "\u2581were", "\u2581published", "\u2581in", "\u2581install", "ments", "\u2581in", "\u2581mag", "az", "ines", ",", "\u2581which", "\u2581allowed", "\u2581authors", "\u2581to", "\u2581create", "\u2581cl", "iff", "hang", "ers", "\u2581that", "\u2581kept", "\u2581readers"]], "entropy": [[0.05328369140625, 0.122314453125, 2.6106834411621094e-05, 1.013671875, 0.6923828125, 0.10882568359375, 0.0085906982421875, 0.3583984375, 6.973743438720703e-06, 0.0013837814331054688, 0.001598358154296875, 0.0018301010131835938, 0.91845703125, 0.00598907470703125, 1.6474609375, 2.146484375, 0.020965576171875, 1.2958984375, 1.580078125, 0.295166015625, 1.541015625, 0.09246826171875, 3.349781036376953e-05, 0.294921875, 0.5693359375, 1.447265625, 0.131103515625, 1.1324882507324219e-06, 0.127197265625, 1.62109375, 0.0159454345703125, 1.0390625, 0.002490997314453125, 0.54052734375, 0.765625, 2.1457672119140625e-06, 9.357929229736328e-06, 0.98681640625, 1.41015625, 0.428955078125, 1.1142578125, 0.00821685791015625, 1.61328125, 1.4609375, 0.00021195411682128906, 0.61865234375, 9.167194366455078e-05, 0.6767578125, 1.2451171875, 0.016754150390625]], "avg_entropy": [0.5608223617076874], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "improved economics of distribution", "score_of_biggest_cluster": 0.5694028735160828, "score_of_first_answer": 0.5694028735160828, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0075225830078125, "avg_score": 0.5694028735160828, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.32224452588702635, "std_of_first_answer": 0.32224452588702635, "avg_entropy_of_first_answer": 0.5608223617076874, "lex_sim": 1.0}
{"question": "who is the coach for the ottawa senators", "answer": ["D.J."], "scores": [[0.8857421875, 0.99853515625, 0.89111328125, 0.9931640625, 0.99755859375]], "normalized_score": [0.9517274498939514], "tokens": [["\u2581D", ".", "J", ".", "\u2581Smith"]], "entropy": [[0.6572265625, 0.0159454345703125, 0.35986328125, 0.048553466796875, 0.021392822265625]], "avg_entropy": [0.2205963134765625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Guy Boucher", "score_of_biggest_cluster": 0.9517274498939514, "score_of_first_answer": 0.9517274498939514, "max_score_of_first_answer": 0.99853515625, "min_score_of_first_answer": 0.8857421875, "avg_score": 0.9517274498939514, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.05296300986366201, "std_of_first_answer": 0.05296300986366201, "avg_entropy_of_first_answer": 0.2205963134765625, "lex_sim": 1.0}
{"question": "when was the biltmore house opened to the public", "answer": ["1895"], "scores": [[0.9013671875, 0.99951171875, 0.87744140625, 1.0, 0.9990234375]], "normalized_score": [0.9538864493370056], "tokens": [["\u2581", "1", "8", "9", "5"]], "entropy": [[0.56787109375, 0.00301361083984375, 0.373291015625, 0.0018215179443359375, 0.010345458984375]], "avg_entropy": [0.19126853942871094], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "March 1930", "score_of_biggest_cluster": 0.9538864493370056, "score_of_first_answer": 0.9538864493370056, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.87744140625, "avg_score": 0.9538864493370056, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.05447030670690354, "std_of_first_answer": 0.05447030670690354, "avg_entropy_of_first_answer": 0.19126853942871094, "lex_sim": 1.0}
{"question": "who is rose in the fall season 2", "answer": ["It appears that you are referring to a television show called \"The Fall,\" but you haven't specified which character you are asking about."], "scores": [[0.014923095703125, 0.007175445556640625, 0.73193359375, 0.60107421875, 0.73681640625, 0.7587890625, 0.99853515625, 0.6220703125, 0.23876953125, 0.9423828125, 0.14697265625, 0.96240234375, 0.63427734375, 0.533203125, 0.280517578125, 0.5654296875, 0.134765625, 0.08453369140625, 0.99560546875, 1.0, 0.8291015625, 0.88671875, 0.07843017578125, 0.491943359375, 0.79833984375, 0.76123046875, 0.9990234375, 0.99755859375, 0.62158203125, 0.99853515625, 0.8583984375, 0.0440673828125, 0.86328125, 0.9658203125, 0.9267578125, 0.8212890625, 0.349365234375, 0.9951171875, 0.64111328125, 1.3113021850585938e-06, 0.007709503173828125, 1.2576580047607422e-05, 0.55859375, 0.533203125, 0.384521484375, 0.77392578125, 0.94677734375, 0.923828125]], "normalized_score": [0.2641751170158386], "tokens": [["\u2581It", "\u2581appears", "\u2581that", "\u2581you", "\u2581are", "\u2581referring", "\u2581to", "\u2581a", "\u2581television", "\u2581show", "\u2581called", "\u2581\"", "The", "\u2581Fall", ",\"", "\u2581but", "\u2581you", "\u2581haven", "'", "t", "\u2581specified", "\u2581which", "\u2581character", "\u2581you", "\u2581are", "\u2581asking", "\u2581about", ".", "\u2581Could", "\u2581you", "\u2581please", "\u2581specify", "\u2581which", "\u2581character", "\u2581you", "\u2581are", "\u2581asking", "\u2581about", "?", "\u2581#", "1", "\u2581New", "\u2581York", "\u2581Times", "\u2581best", "s", "elling", "\u2581author"]], "entropy": [[4.98046875, 1.71484375, 0.880859375, 1.1728515625, 1.00390625, 0.90380859375, 0.00997161865234375, 0.97119140625, 1.5185546875, 0.2431640625, 1.5673828125, 0.2149658203125, 1.30078125, 2.22265625, 1.484375, 1.2744140625, 1.8134765625, 0.89111328125, 0.0333251953125, 3.1828880310058594e-05, 0.52734375, 0.39501953125, 0.431884765625, 1.548828125, 0.55712890625, 0.6181640625, 0.00687408447265625, 0.0229949951171875, 1.1748046875, 0.01319122314453125, 0.461669921875, 0.81982421875, 0.57373046875, 0.1688232421875, 0.33935546875, 0.65576171875, 1.275390625, 0.037078857421875, 1.2080078125, 0.481201171875, 5.36328125, 3.103515625, 3.125, 1.9765625, 1.126953125, 0.63037109375, 0.220947265625, 0.49365234375]], "avg_entropy": [1.0741563116510708], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Valene Kane", "score_of_biggest_cluster": 0.2641751170158386, "score_of_first_answer": 0.2641751170158386, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.3113021850585938e-06, "avg_score": 0.2641751170158386, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3445830485803605, "std_of_first_answer": 0.3445830485803605, "avg_entropy_of_first_answer": 1.0741563116510708, "lex_sim": 1.0}
{"question": "which country is the last member of saarc", "answer": ["Maldives #LoveMyNewCamera: How the Samsung NX500 Is Changing the Face of Photography for Me"], "scores": [[0.208251953125, 1.0, 1.0, 1.7881393432617188e-07, 0.0014467239379882812, 0.363525390625, 0.0115509033203125, 0.000732421875, 0.0006527900695800781, 8.7738037109375e-05, 0.001323699951171875, 0.0017042160034179688, 0.0107269287109375, 0.568359375, 0.10430908203125, 0.95458984375, 0.86962890625, 0.9921875, 0.970703125, 0.003932952880859375, 0.3720703125, 0.998046875, 0.587890625, 0.004123687744140625, 0.98974609375, 0.654296875, 0.99951171875, 0.023651123046875, 0.08984375]], "normalized_score": [0.040849197655916214], "tokens": [["\u2581M", "ald", "ives", "\u2581#", "L", "ove", "My", "New", "Camera", ":", "\u2581How", "\u2581the", "\u2581S", "amsung", "\u2581N", "X", "5", "0", "0", "\u2581Is", "\u2581Ch", "anging", "\u2581the", "\u2581Face", "\u2581of", "\u2581Phot", "ography", "\u2581for", "\u2581Me"]], "entropy": [[2.208984375, 0.0005383491516113281, 0.00015473365783691406, 1.0625, 4.55859375, 2.072265625, 2.970703125, 1.7392578125, 3.419921875, 1.83203125, 5.04296875, 2.873046875, 4.8359375, 2.353515625, 0.7177734375, 0.277099609375, 0.5341796875, 0.0589599609375, 0.25244140625, 3.248046875, 2.287109375, 0.016937255859375, 0.955078125, 0.82080078125, 0.070556640625, 1.7978515625, 0.005100250244140625, 2.734375, 3.77734375]], "avg_entropy": [1.8111749435293263], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Afghanistan", "score_of_biggest_cluster": 0.040849197655916214, "score_of_first_answer": 0.040849197655916214, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.040849197655916214, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.423936986284496, "std_of_first_answer": 0.423936986284496, "avg_entropy_of_first_answer": 1.8111749435293263, "lex_sim": 1.0}
{"question": "who is the owner of reading football club", "answer": ["Mr John Madejski #52BooksWeek 9: The Road to Little Dribbling by Bill Bryson"], "scores": [[0.7021484375, 0.177490234375, 0.8408203125, 0.99951171875, 1.0, 5.7220458984375e-06, 0.004131317138671875, 0.06982421875, 4.172325134277344e-06, 0.876953125, 2.181529998779297e-05, 0.0145416259765625, 0.0290985107421875, 0.017333984375, 0.113037109375, 0.003978729248046875, 0.7880859375, 0.002582550048828125, 0.99951171875, 0.99951171875, 0.9970703125, 0.4833984375, 0.98876953125, 1.0, 1.0]], "normalized_score": [0.05569048970937729], "tokens": [["\u2581Mr", "\u2581John", "\u2581Made", "j", "ski", "\u2581#", "5", "2", "Book", "s", "Week", "\u2581", "9", ":", "\u2581The", "\u2581Road", "\u2581to", "\u2581Little", "\u2581D", "rib", "bling", "\u2581by", "\u2581Bill", "\u2581Bry", "son"]], "entropy": [[1.61328125, 1.15234375, 0.96337890625, 0.004146575927734375, 0.0019073486328125, 1.03125, 5.4921875, 2.814453125, 2.921875, 0.81982421875, 2.6796875, 2.162109375, 2.21484375, 2.251953125, 4.79296875, 5.47265625, 1.22265625, 0.896484375, 0.00481414794921875, 0.0047149658203125, 0.0232696533203125, 1.55078125, 0.10467529296875, 0.0013933181762695312, 0.001476287841796875]], "avg_entropy": [1.6079652786254883], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Xiu Li Dai", "score_of_biggest_cluster": 0.05569048970937729, "score_of_first_answer": 0.05569048970937729, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-06, "avg_score": 0.05569048970937729, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4462845568827749, "std_of_first_answer": 0.4462845568827749, "avg_entropy_of_first_answer": 1.6079652786254883, "lex_sim": 1.0}
{"question": "who's the guy in call me maybe", "answer": ["Carly Rae Jepsen, the singer of the song \"Call Me Maybe,\" does not mention a guy in the song's lyrics."], "scores": [[0.89208984375, 1.0, 0.9990234375, 1.0, 1.0, 0.99853515625, 1.0, 0.002941131591796875, 0.28271484375, 0.64306640625, 0.8291015625, 0.9833984375, 0.98681640625, 0.69091796875, 0.99951171875, 0.9970703125, 0.9990234375, 0.1776123046875, 0.630859375, 1.0, 0.0362548828125, 0.81591796875, 0.253173828125, 1.0, 0.99658203125, 0.99951171875, 0.5849609375, 0.048828125, 1.0, 0.99951171875, 1.0, 0.97314453125, 2.384185791015625e-07, 0.0152587890625, 0.00014078617095947266, 0.0009226799011230469, 0.000530242919921875, 0.1546630859375]], "normalized_score": [0.18750843405723572], "tokens": [["\u2581Car", "ly", "\u2581R", "ae", "\u2581Je", "ps", "en", ",", "\u2581the", "\u2581singer", "\u2581of", "\u2581the", "\u2581song", "\u2581\"", "Call", "\u2581Me", "\u2581Maybe", ",\"", "\u2581does", "\u2581not", "\u2581mention", "\u2581a", "\u2581gu", "y", "\u2581in", "\u2581the", "\u2581song", "'", "s", "\u2581lyr", "ics", ".", "\u2581#", "S", "ab", "ika", "\u2581She", "ikh"]], "entropy": [[0.88134765625, 0.001827239990234375, 0.00801849365234375, 9.548664093017578e-05, 0.0020961761474609375, 0.0125579833984375, 0.0002040863037109375, 0.728515625, 3.03515625, 1.068359375, 0.77978515625, 0.097412109375, 0.0809326171875, 1.1044921875, 0.0026912689208984375, 0.0208892822265625, 0.00798797607421875, 1.3466796875, 0.9638671875, 0.0003757476806640625, 1.1904296875, 0.6298828125, 0.78271484375, 4.8160552978515625e-05, 0.028717041015625, 0.00489044189453125, 0.6806640625, 0.36474609375, 0.00026106834411621094, 0.004241943359375, 7.724761962890625e-05, 0.1488037109375, 1.0654296875, 4.421875, 1.685546875, 3.03515625, 4.2890625, 2.82421875]], "avg_entropy": [0.8236857307584662], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Holden Nowell", "score_of_biggest_cluster": 0.18750843405723572, "score_of_first_answer": 0.18750843405723572, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.18750843405723572, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4107743888272079, "std_of_first_answer": 0.4107743888272079, "avg_entropy_of_first_answer": 0.8236857307584662, "lex_sim": 1.0}
{"question": "when was rosencrantz and guildenstern are dead written", "answer": ["1964"], "scores": [[0.9501953125, 1.0, 1.0, 0.99951171875, 0.55712890625]], "normalized_score": [0.8804633617401123], "tokens": [["\u2581", "1", "9", "6", "4"]], "entropy": [[0.329833984375, 0.0007915496826171875, 0.00012069940567016602, 0.004459381103515625, 0.97509765625]], "avg_entropy": [0.2620606541633606], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1966", "score_of_biggest_cluster": 0.8804633617401123, "score_of_first_answer": 0.8804633617401123, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.55712890625, "avg_score": 0.8804633617401123, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.17318971822055274, "std_of_first_answer": 0.17318971822055274, "avg_entropy_of_first_answer": 0.2620606541633606, "lex_sim": 1.0}
{"question": "who become ceo of wipro company in 2016", "answer": ["Abidali Neemuchwala \\r\\nShe has a Bachelor of Arts in Communications and a Master of Arts in English from California State University, Fullerton."], "scores": [[0.99755859375, 0.828125, 0.9638671875, 0.87646484375, 0.97216796875, 1.0, 0.95361328125, 0.99658203125, 2.384185791015625e-07, 9.995698928833008e-05, 0.2431640625, 0.98974609375, 1.2934207916259766e-05, 0.0152435302734375, 0.0187530517578125, 0.11505126953125, 0.970703125, 0.250244140625, 0.08575439453125, 0.4755859375, 0.002025604248046875, 0.68212890625, 0.33349609375, 0.63134765625, 0.76953125, 0.80517578125, 0.028228759765625, 0.994140625, 0.01219940185546875, 0.388671875, 0.0005521774291992188, 0.9990234375, 0.9990234375, 0.8681640625, 0.01410675048828125, 0.998046875, 0.763671875, 0.00011831521987915039, 0.392333984375, 0.99658203125, 0.94873046875, 0.94482421875, 0.9326171875, 0.998046875, 0.0002834796905517578, 0.0110321044921875, 0.39111328125, 0.99951171875]], "normalized_score": [0.10984691977500916], "tokens": [["\u2581Ab", "id", "ali", "\u2581Ne", "em", "uch", "w", "ala", "\u2581\\", "r", "\\", "n", "She", "\u2581has", "\u2581a", "\u2581Bach", "elor", "\u2581of", "\u2581Arts", "\u2581in", "\u2581Communic", "ations", "\u2581and", "\u2581a", "\u2581Master", "\u2581of", "\u2581Arts", "\u2581in", "\u2581English", "\u2581from", "\u2581California", "\u2581State", "\u2581University", ",", "\u2581Full", "erton", ".", "\",\"", "url", "\":\"", "https", "://", "www", ".", "h", "uff", "post", "."]], "entropy": [[0.02044677734375, 0.87109375, 0.1966552734375, 0.3837890625, 0.180419921875, 0.0020542144775390625, 0.3310546875, 0.028228759765625, 0.9775390625, 0.73046875, 1.068359375, 0.082763671875, 3.556640625, 3.111328125, 2.302734375, 4.49609375, 0.136962890625, 1.0302734375, 1.77734375, 1.3798828125, 2.12109375, 0.62939453125, 1.2255859375, 1.9326171875, 0.80712890625, 0.6484375, 0.7578125, 0.048004150390625, 2.955078125, 1.330078125, 2.787109375, 0.00969696044921875, 0.0086212158203125, 0.54833984375, 1.5, 0.01385498046875, 0.9462890625, 2.0390625, 3.646484375, 0.02587890625, 0.269775390625, 0.2166748046875, 0.37744140625, 0.0205230712890625, 2.42578125, 3.734375, 0.701171875, 0.0034999847412109375]], "avg_entropy": [1.1332071622212727], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Abid Ali Neemuchwala", "score_of_biggest_cluster": 0.10984691977500916, "score_of_first_answer": 0.10984691977500916, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.10984691977500916, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4172152168930302, "std_of_first_answer": 0.4172152168930302, "avg_entropy_of_first_answer": 1.1332071622212727, "lex_sim": 1.0}
{"question": "who sings the song you'll never find another love like mine", "answer": ["Lou Rawls"], "scores": [[0.99560546875, 0.966796875, 0.99951171875]], "normalized_score": [0.9871962070465088], "tokens": [["\u2581Lou", "\u2581Raw", "ls"]], "entropy": [[0.04541015625, 0.20556640625, 0.00693511962890625]], "avg_entropy": [0.08597056070963542], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Lou Rawls", "score_of_biggest_cluster": 0.9871962070465088, "score_of_first_answer": 0.9871962070465088, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.966796875, "avg_score": 0.9871962070465088, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.014588636614776405, "std_of_first_answer": 0.014588636614776405, "avg_entropy_of_first_answer": 0.08597056070963542, "lex_sim": 1.0}
{"question": "who owns the rights to rocky and bullwinkle", "answer": ["Jay Ward Productions, Inc."], "scores": [[0.242431640625, 0.9990234375, 0.9365234375, 1.0, 0.2218017578125, 0.7841796875, 0.94775390625]], "normalized_score": [0.6253289580345154], "tokens": [["\u2581Jay", "\u2581Ward", "\u2581Produ", "ctions", ",", "\u2581Inc", "."]], "entropy": [[2.59765625, 0.01221466064453125, 0.32373046875, 2.866983413696289e-05, 1.7685546875, 1.2822265625, 0.287109375]], "avg_entropy": [0.8959315248898098], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Universal Pictures", "score_of_biggest_cluster": 0.6253289580345154, "score_of_first_answer": 0.6253289580345154, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.2218017578125, "avg_score": 0.6253289580345154, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3238603633860752, "std_of_first_answer": 0.3238603633860752, "avg_entropy_of_first_answer": 0.8959315248898098, "lex_sim": 1.0}
{"question": "who played junior on in the heat of the night", "answer": ["Carroll O'Connor #India \u2013 No Right to Privacy \u2013 Magsaysay Awardee Shoma Sen"], "scores": [[0.64892578125, 0.986328125, 0.9990234375, 0.99609375, 0.99951171875, 1.0, 6.556510925292969e-07, 0.0007777214050292969, 0.0098114013671875, 0.00025653839111328125, 0.00054931640625, 6.973743438720703e-06, 0.06494140625, 0.1019287109375, 0.99951171875, 0.04315185546875, 0.00562286376953125, 0.0006136894226074219, 0.94384765625, 1.0, 0.007411956787109375, 0.9921875, 0.998046875, 0.853515625, 0.0162506103515625, 0.008941650390625, 0.880859375]], "normalized_score": [0.037084031850099564], "tokens": [["\u2581Car", "roll", "\u2581O", "'", "Con", "nor", "\u2581#", "Ind", "ia", "\u2581\u2013", "\u2581No", "\u2581Right", "\u2581to", "\u2581Priv", "acy", "\u2581\u2013", "\u2581M", "ags", "ays", "ay", "\u2581A", "war", "de", "e", "\u2581Sh", "oma", "\u2581Sen"]], "entropy": [[1.6240234375, 0.08062744140625, 0.01312255859375, 0.031890869140625, 0.005184173583984375, 0.0010232925415039062, 0.81787109375, 5.5, 2.064453125, 3.8125, 5.8125, 5.6171875, 1.1552734375, 4.1875, 0.005962371826171875, 3.33203125, 5.34375, 4.29296875, 0.224365234375, 1.901388168334961e-05, 2.5, 0.07318115234375, 0.0174560546875, 0.42138671875, 4.56640625, 1.912109375, 0.6787109375]], "avg_entropy": [2.0033890384214894], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Christian LeBlanc", "score_of_biggest_cluster": 0.037084031850099564, "score_of_first_answer": 0.037084031850099564, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 6.556510925292969e-07, "avg_score": 0.037084031850099564, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4688067193058728, "std_of_first_answer": 0.4688067193058728, "avg_entropy_of_first_answer": 2.0033890384214894, "lex_sim": 1.0}
{"question": "if a piece of music is perceived to have changed key then we say the piece has", "answer": ["modulated."], "scores": [[0.8330078125, 0.99755859375, 0.1812744140625, 0.0, 0.98681640625, 5.424022674560547e-06, 0.00046896934509277344, 0.0141448974609375, 0.81640625, 0.99951171875, 0.81787109375, 0.9990234375]], "normalized_score": [0.0], "tokens": [["\u2581mod", "ulated", ".", "\u2581Tags", ":", "\u2581ML", "\u2581|", "\u2581Art", "ific", "ial", "\u2581Int", "elligence"]], "entropy": [[0.64404296875, 0.0196380615234375, 1.029296875, 0.217529296875, 0.1265869140625, 2.283203125, 3.107421875, 4.46484375, 0.84033203125, 0.00388336181640625, 0.765625, 0.01087188720703125]], "avg_entropy": [1.1261062622070312], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "transposed", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4422971620422312, "std_of_first_answer": 0.4422971620422312, "avg_entropy_of_first_answer": 1.1261062622070312, "lex_sim": 1.0}
{"question": "where are unipolar neurons found in spinal cord", "answer": ["Gray matter of the spinal cord #26 \u2013 The World\u2019s Largest Snowmobile: 50 Years of Arctic Cat"], "scores": [[0.022857666015625, 0.6123046875, 0.185791015625, 0.90283203125, 0.8427734375, 1.0, 0.99951171875, 0.0, 0.00742340087890625, 0.0246734619140625, 9.179115295410156e-05, 0.01230621337890625, 0.00034427642822265625, 0.164306640625, 1.0, 0.07537841796875, 0.998046875, 1.0, 0.000579833984375, 0.0029582977294921875, 0.1878662109375, 0.0192108154296875, 0.061279296875, 0.346435546875, 0.02911376953125, 0.9765625, 0.33642578125, 0.994140625, 0.98486328125]], "normalized_score": [0.0], "tokens": [["\u2581Gray", "\u2581matter", "\u2581of", "\u2581the", "\u2581sp", "inal", "\u2581cord", "\u2581#", "2", "6", "\u2581\u2013", "\u2581The", "\u2581World", "\u2019", "s", "\u2581L", "arg", "est", "\u2581Snow", "mobile", ":", "\u2581", "5", "0", "\u2581Years", "\u2581of", "\u2581Ar", "ctic", "\u2581Cat"]], "entropy": [[3.33984375, 1.5146484375, 1.306640625, 0.36083984375, 0.603515625, 0.00024580955505371094, 0.0059814453125, 1.16796875, 5.171875, 3.365234375, 3.333984375, 3.5078125, 4.921875, 2.650390625, 0.0017080307006835938, 3.845703125, 0.017333984375, 0.002193450927734375, 4.05859375, 1.42578125, 2.3046875, 3.27734375, 1.9501953125, 3.169921875, 2.515625, 0.118408203125, 2.466796875, 0.0469970703125, 0.10711669921875]], "avg_entropy": [1.9503193805957664], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the distal dorsal root", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4298229017956364, "std_of_first_answer": 0.4298229017956364, "avg_entropy_of_first_answer": 1.9503193805957664, "lex_sim": 1.0}
{"question": "how many countries are a part of opec", "answer": ["13"], "scores": [[0.98046875, 0.99951171875, 0.708984375]], "normalized_score": [0.8856989145278931], "tokens": [["\u2581", "1", "3"]], "entropy": [[0.15625, 0.00522613525390625, 0.767578125]], "avg_entropy": [0.30968475341796875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "14", "score_of_biggest_cluster": 0.8856989145278931, "score_of_first_answer": 0.8856989145278931, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.708984375, "avg_score": 0.8856989145278931, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.1326953645654356, "std_of_first_answer": 0.1326953645654356, "avg_entropy_of_first_answer": 0.30968475341796875, "lex_sim": 1.0}
{"question": "who is responsible for introducing the principle of uniformitarianism", "answer": ["James Hutton"], "scores": [[0.96875, 1.0, 1.0]], "normalized_score": [0.9894729256629944], "tokens": [["\u2581James", "\u2581H", "utton"]], "entropy": [[0.1455078125, 0.0005540847778320312, 0.0007572174072265625]], "avg_entropy": [0.04893970489501953], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "James Hutton", "score_of_biggest_cluster": 0.9894729256629944, "score_of_first_answer": 0.9894729256629944, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.96875, "avg_score": 0.9894729256629944, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.01473139127471974, "std_of_first_answer": 0.01473139127471974, "avg_entropy_of_first_answer": 0.04893970489501953, "lex_sim": 1.0}
{"question": "what is the symbol for christmas in brazil", "answer": ["star"], "scores": [[0.38232421875]], "normalized_score": [0.38232421875], "tokens": [["\u2581star"]], "entropy": [[2.0703125]], "avg_entropy": [2.0703125], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Nativity scene", "score_of_biggest_cluster": 0.38232421875, "score_of_first_answer": 0.38232421875, "max_score_of_first_answer": 0.38232421875, "min_score_of_first_answer": 0.38232421875, "avg_score": 0.38232421875, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.0, "std_of_first_answer": 0.0, "avg_entropy_of_first_answer": 2.0703125, "lex_sim": 1.0}
{"question": "what are the five compulsory prayers in islam", "answer": ["Fajr, Zuhr, Asr, Maghrib, and Isha."], "scores": [[0.26416015625, 0.93310546875, 0.994140625, 0.81298828125, 0.138671875, 0.9951171875, 0.9990234375, 0.9375, 1.0, 1.0, 0.9990234375, 0.99951171875, 0.99951171875, 0.904296875, 0.352783203125, 0.99609375, 0.99853515625, 0.59228515625, 4.887580871582031e-06, 0.003955841064453125, 0.03460693359375, 0.055694580078125, 0.0111236572265625, 0.0003814697265625, 4.76837158203125e-07, 0.83154296875, 0.0181732177734375, 0.92333984375, 0.9462890625, 0.01531219482421875, 0.9970703125, 0.99951171875]], "normalized_score": [0.1320681869983673], "tokens": [["\u2581F", "aj", "r", ",", "\u2581Zu", "hr", ",", "\u2581As", "r", ",", "\u2581Mag", "h", "rib", ",", "\u2581and", "\u2581I", "sha", ".", "\u2581#", "1", "6", "2", ":", "\u2581H", "inds", "ight", "\u2581", "2", "0", "/", "2", "0"]], "entropy": [[2.49609375, 0.269775390625, 0.037567138671875, 0.55322265625, 1.0458984375, 0.033935546875, 0.00811767578125, 0.290771484375, 0.0005488395690917969, 0.00165557861328125, 0.0083160400390625, 0.006046295166015625, 0.00396728515625, 0.31884765625, 0.697265625, 0.0286865234375, 0.0104522705078125, 1.0615234375, 0.396728515625, 1.3056640625, 3.1015625, 3.12109375, 3.123046875, 4.8359375, 1.5185546875, 0.96826171875, 1.978515625, 0.420166015625, 0.33154296875, 0.13623046875, 0.0259246826171875, 0.0034046173095703125]], "avg_entropy": [0.8793539255857468], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Asr", "score_of_biggest_cluster": 0.1320681869983673, "score_of_first_answer": 0.1320681869983673, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.76837158203125e-07, "avg_score": 0.1320681869983673, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43294507360337275, "std_of_first_answer": 0.43294507360337275, "avg_entropy_of_first_answer": 0.8793539255857468, "lex_sim": 1.0}
{"question": "who plays alec ramsay in the black stallion", "answer": ["Mickey Rooney"], "scores": [[0.96337890625, 0.8603515625, 1.0, 1.0]], "normalized_score": [0.9541535377502441], "tokens": [["\u2581Mic", "key", "\u2581Ro", "oney"]], "entropy": [[0.25146484375, 0.75634765625, 0.00254058837890625, 0.00048828125]], "avg_entropy": [0.25271034240722656], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Kelly Reno", "score_of_biggest_cluster": 0.9541535377502441, "score_of_first_answer": 0.9541535377502441, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.8603515625, "avg_score": 0.9541535377502441, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.057173100519090296, "std_of_first_answer": 0.057173100519090296, "avg_entropy_of_first_answer": 0.25271034240722656, "lex_sim": 1.0}
{"question": "who has access to the presidential daily briefing", "answer": ["The President, Vice President, Secretary of Defense, Secretary of State, and National Security Advisor have access to the presidential daily briefing."], "scores": [[0.599609375, 0.98974609375, 0.34814453125, 0.86474609375, 0.9873046875, 0.98486328125, 0.51708984375, 0.99853515625, 0.0887451171875, 1.0, 0.9931640625, 0.8212890625, 0.9970703125, 0.92041015625, 0.99560546875, 0.62451171875, 0.07586669921875, 0.99951171875, 0.99951171875, 0.888671875, 0.1871337890625, 0.99365234375, 0.94091796875, 0.998046875, 0.01470947265625, 1.0, 0.99951171875, 1.0, 0.99853515625, 0.9453125, 1.1324882507324219e-06, 0.001743316650390625, 0.1102294921875, 0.07086181640625, 2.7179718017578125e-05, 9.5367431640625e-07, 0.01155853271484375, 0.0003185272216796875, 0.0310516357421875, 0.359130859375, 0.04339599609375, 0.38427734375, 0.24169921875, 0.7646484375, 0.7177734375, 0.11456298828125]], "normalized_score": [0.144837886095047], "tokens": [["\u2581The", "\u2581President", ",", "\u2581Vice", "\u2581President", ",", "\u2581Secretary", "\u2581of", "\u2581Def", "ense", ",", "\u2581Secretary", "\u2581of", "\u2581State", ",", "\u2581and", "\u2581National", "\u2581Security", "\u2581Ad", "visor", "\u2581have", "\u2581access", "\u2581to", "\u2581the", "\u2581president", "ial", "\u2581daily", "\u2581brief", "ing", ".", "\u2581#", "0", "1", "9", "\u2581\u2013", "\u2581Building", "\u2581an", "\u2581Author", "ity", "\u2581Site", "\u2581in", "\u2581", "2", "0", "2", "0"]], "entropy": [[1.5556640625, 0.069091796875, 1.23046875, 0.479736328125, 0.07025146484375, 0.08343505859375, 1.3291015625, 0.0118560791015625, 0.30615234375, 5.704164505004883e-05, 0.045562744140625, 0.73779296875, 0.0200653076171875, 0.300048828125, 0.0286102294921875, 1.3623046875, 1.9912109375, 0.006633758544921875, 0.00494384765625, 0.349365234375, 1.3330078125, 0.050994873046875, 0.239990234375, 0.016143798828125, 0.0889892578125, 0.0006351470947265625, 0.0035839080810546875, 0.0004570484161376953, 0.01361083984375, 0.2958984375, 0.5791015625, 4.2265625, 2.634765625, 2.69140625, 2.4453125, 4.30078125, 3.8359375, 0.685546875, 0.49609375, 1.900390625, 3.05078125, 1.787109375, 1.623046875, 0.97802734375, 0.7373046875, 1.27734375]], "avg_entropy": [0.9842429588670316], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "National Security Advisor", "score_of_biggest_cluster": 0.144837886095047, "score_of_first_answer": 0.144837886095047, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 9.5367431640625e-07, "avg_score": 0.144837886095047, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4158588563127775, "std_of_first_answer": 0.4158588563127775, "avg_entropy_of_first_answer": 0.9842429588670316, "lex_sim": 1.0}
{"question": "india participated olympic hockey for the first time", "answer": ["1928 Summer Olympics"], "scores": [[0.76708984375, 0.998046875, 0.99951171875, 0.99951171875, 0.998046875, 0.83984375, 1.0]], "normalized_score": [0.9384636878967285], "tokens": [["\u2581", "1", "9", "2", "8", "\u2581Summer", "\u2581Olympics"]], "entropy": [[1.3173828125, 0.0153045654296875, 0.00473785400390625, 0.0029087066650390625, 0.015838623046875, 0.75830078125, 0.002422332763671875]], "avg_entropy": [0.30241366795131136], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1927", "score_of_biggest_cluster": 0.9384636878967285, "score_of_first_answer": 0.9384636878967285, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.76708984375, "avg_score": 0.9384636878967285, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.09046064879129108, "std_of_first_answer": 0.09046064879129108, "avg_entropy_of_first_answer": 0.30241366795131136, "lex_sim": 1.0}
{"question": "who did johnny manziel play college football for", "answer": ["Texas A&M University #FarmersTrend September 24, 2019 Agricultural Tractor Rentals Puts More Equipment to Work2019-09-24T1"], "scores": [[0.99560546875, 0.99951171875, 0.99853515625, 0.99951171875, 0.6826171875, 1.1920928955078125e-07, 0.000438690185546875, 0.00788116455078125, 0.489013671875, 0.0012989044189453125, 0.003509521484375, 1.5497207641601562e-06, 0.958984375, 0.763671875, 0.0208740234375, 0.8916015625, 0.9775390625, 0.9951171875, 1.0, 0.51953125, 0.8076171875, 0.00021564960479736328, 0.0887451171875, 0.049407958984375, 0.0020809173583984375, 0.033172607421875, 0.038360595703125, 0.8720703125, 0.002384185791015625, 0.0008878707885742188, 0.032012939453125, 0.00797271728515625, 0.998046875, 0.998046875, 0.006122589111328125, 0.70458984375, 2.7358531951904297e-05, 0.9287109375, 0.83056640625, 0.99609375, 0.96875, 0.94140625, 0.9951171875, 0.9521484375, 0.96923828125, 0.814453125, 0.63671875, 0.7333984375]], "normalized_score": [0.07237669080495834], "tokens": [["\u2581Texas", "\u2581A", "&", "M", "\u2581University", "\u2581#", "F", "arm", "ers", "Tr", "end", "\u2581September", "\u2581", "2", "4", ",", "\u2581", "2", "0", "1", "9", "\u2581Agricult", "ural", "\u2581T", "ractor", "\u2581R", "ent", "als", "\u2581P", "uts", "\u2581More", "\u2581Equ", "ip", "ment", "\u2581to", "\u2581Work", "2", "0", "1", "9", "-", "0", "9", "-", "2", "4", "T", "1"]], "entropy": [[0.0357666015625, 0.0058441162109375, 0.013275146484375, 0.00304412841796875, 0.99072265625, 0.98486328125, 1.4931640625, 3.765625, 1.8193359375, 3.056640625, 0.0948486328125, 1.0361328125, 0.32861328125, 0.904296875, 0.9189453125, 0.54296875, 0.160400390625, 0.036224365234375, 0.002140045166015625, 0.693359375, 0.80224609375, 1.6552734375, 0.3076171875, 4.39453125, 1.927734375, 4.6015625, 2.041015625, 0.50146484375, 3.689453125, 2.578125, 3.107421875, 3.5, 0.016815185546875, 0.014495849609375, 1.748046875, 1.5244140625, 3.9296875, 0.48974609375, 0.60302734375, 0.03228759765625, 0.260986328125, 0.2298583984375, 0.040557861328125, 0.3291015625, 0.1739501953125, 0.80517578125, 1.0546875, 0.76953125]], "avg_entropy": [1.2086463769276936], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Texas A&M", "score_of_biggest_cluster": 0.07237669080495834, "score_of_first_answer": 0.07237669080495834, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.07237669080495834, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.43680437177501447, "std_of_first_answer": 0.43680437177501447, "avg_entropy_of_first_answer": 1.2086463769276936, "lex_sim": 1.0}
{"question": "most runs ever scored in a mlb inning", "answer": ["In 1897, the New York Giants and the Brooklyn Dodgers combined for 46 runs in one inning."], "scores": [[0.0146484375, 0.4775390625, 0.99853515625, 0.95166015625, 0.61962890625, 0.9990234375, 0.99462890625, 0.94921875, 0.05059814453125, 1.0, 0.99560546875, 1.0, 0.188232421875, 0.60009765625, 0.2880859375, 1.0, 0.46728515625, 1.0, 1.0, 0.822265625, 0.5859375, 0.9921875, 0.07659912109375, 0.196533203125, 1.0, 0.9921875, 0.64306640625, 0.99853515625, 1.0, 0.7412109375]], "normalized_score": [0.5413728356361389], "tokens": [["\u2581In", "\u2581", "1", "8", "9", "7", ",", "\u2581the", "\u2581New", "\u2581York", "\u2581Gi", "ants", "\u2581and", "\u2581the", "\u2581Brook", "lyn", "\u2581D", "od", "gers", "\u2581combined", "\u2581for", "\u2581", "4", "6", "\u2581runs", "\u2581in", "\u2581one", "\u2581in", "ning", "."]], "entropy": [[0.87890625, 1.544921875, 0.010284423828125, 0.193603515625, 1.0263671875, 0.011505126953125, 0.04351806640625, 0.3369140625, 2.572265625, 0.0022945404052734375, 0.032928466796875, 0.0002682209014892578, 0.54248046875, 1.328125, 1.2666015625, 0.00023806095123291016, 0.86083984375, 0.0004322528839111328, 0.0016393661499023438, 0.701171875, 0.70703125, 0.054931640625, 1.763671875, 1.888671875, 0.0026035308837890625, 0.056182861328125, 1.033203125, 0.01259613037109375, 6.0617923736572266e-05, 0.90283203125]], "avg_entropy": [0.5925696909427642], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "18", "score_of_biggest_cluster": 0.5413728356361389, "score_of_first_answer": 0.5413728356361389, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0146484375, "avg_score": 0.5413728356361389, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3402129454250468, "std_of_first_answer": 0.3402129454250468, "avg_entropy_of_first_answer": 0.5925696909427642, "lex_sim": 1.0}
{"question": "who founded amazon where is the headquarters of amazon", "answer": ["Amazon was founded by Jeff Bezos and the headquarters of Amazon is located in Seattle, Washington, United States."], "scores": [[0.386962890625, 0.74560546875, 0.99951171875, 0.99951171875, 1.0, 0.99853515625, 1.0, 0.46240234375, 0.83203125, 0.88330078125, 0.724609375, 0.9931640625, 0.94482421875, 0.7333984375, 0.99951171875, 0.99951171875, 0.99755859375, 0.9912109375, 0.6103515625, 0.3017578125, 1.0, 0.9716796875]], "normalized_score": [0.8056856393814087], "tokens": [["\u2581Amazon", "\u2581was", "\u2581founded", "\u2581by", "\u2581Jeff", "\u2581Bez", "os", "\u2581and", "\u2581the", "\u2581headquarters", "\u2581of", "\u2581Amazon", "\u2581is", "\u2581located", "\u2581in", "\u2581Seattle", ",", "\u2581Washington", ",", "\u2581United", "\u2581States", "."]], "entropy": [[0.82861328125, 0.7294921875, 0.0036334991455078125, 0.0032062530517578125, 0.001811981201171875, 0.01284027099609375, 0.0011758804321289062, 1.306640625, 0.62451171875, 0.38623046875, 0.7392578125, 0.04461669921875, 0.215087890625, 0.58984375, 0.005756378173828125, 0.006320953369140625, 0.02020263671875, 0.058013916015625, 0.73828125, 0.66162109375, 0.00128173828125, 0.1468505859375]], "avg_entropy": [0.32387685775756836], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Seattle, Washington", "score_of_biggest_cluster": 0.8056856393814087, "score_of_first_answer": 0.8056856393814087, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.3017578125, "avg_score": 0.8056856393814087, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2162243162395686, "std_of_first_answer": 0.2162243162395686, "avg_entropy_of_first_answer": 0.32387685775756836, "lex_sim": 1.0}
{"question": "avatar the last airbender season 3 episode 12", "answer": ["\"The Day the Earth Shook\" ##"], "scores": [[0.42822265625, 0.9931640625, 0.2327880859375, 0.4990234375, 0.65869140625, 0.1134033203125, 0.9619140625, 0.56201171875, 0.0]], "normalized_score": [0.0], "tokens": [["\u2581\"", "The", "\u2581Day", "\u2581the", "\u2581Earth", "\u2581Sho", "ok", "\"", "\u2581##"]], "entropy": [[1.1240234375, 0.05401611328125, 2.3203125, 1.1884765625, 1.328125, 1.275390625, 0.197265625, 1.4306640625, 0.70068359375]], "avg_entropy": [1.0687730577256944], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The Western Air Temple", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.9931640625, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.32682469370171563, "std_of_first_answer": 0.32682469370171563, "avg_entropy_of_first_answer": 1.0687730577256944, "lex_sim": 1.0}
{"question": "when was the last easter fell on april 1", "answer": ["1956"], "scores": [[0.88134765625, 0.97705078125, 0.97900390625, 0.03509521484375, 0.8974609375]], "normalized_score": [0.4839744567871094], "tokens": [["\u2581", "1", "9", "5", "6"]], "entropy": [[0.658203125, 0.11175537109375, 0.1124267578125, 1.3564453125, 0.489990234375]], "avg_entropy": [0.54576416015625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2018", "score_of_biggest_cluster": 0.4839744567871094, "score_of_first_answer": 0.4839744567871094, "max_score_of_first_answer": 0.97900390625, "min_score_of_first_answer": 0.03509521484375, "avg_score": 0.4839744567871094, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.36166309315736944, "std_of_first_answer": 0.36166309315736944, "avg_entropy_of_first_answer": 0.54576416015625, "lex_sim": 1.0}
{"question": "when was the titanic started to be built", "answer": ["The construction of Titanic began in 1909 and was completed by 1912."], "scores": [[0.1636962890625, 0.79638671875, 0.98095703125, 0.316162109375, 1.0, 1.0, 0.87060546875, 0.204345703125, 0.99755859375, 1.0, 1.0, 0.99853515625, 1.0, 0.6552734375, 0.6025390625, 0.6640625, 0.00017392635345458984, 0.97216796875, 1.0, 1.0, 1.0, 0.96533203125, 0.96826171875, 3.337860107421875e-06, 0.00450897216796875, 0.002964019775390625, 0.001476287841796875, 0.052734375, 0.001651763916015625, 0.0128021240234375, 0.00013649463653564453, 0.010284423828125, 0.97900390625, 0.095947265625, 0.005695343017578125, 0.49951171875, 0.12396240234375, 0.37841796875, 0.0091705322265625, 0.716796875, 0.814453125, 0.99853515625, 0.58203125, 0.018280029296875, 0.99560546875, 0.26513671875, 0.99951171875]], "normalized_score": [0.1326046586036682], "tokens": [["\u2581The", "\u2581construction", "\u2581of", "\u2581T", "itan", "ic", "\u2581began", "\u2581in", "\u2581", "1", "9", "0", "9", "\u2581and", "\u2581was", "\u2581completed", "\u2581by", "\u2581", "1", "9", "1", "2", ".", "\u2581#", "S", "at", "Sp", "anks", "\u2581-", "\u2581T", "ender", "\u2581Mer", "cies", "\u2581-", "\u2581New", "\u2581Release", "!", "\u2581#", "western", "\u2581#", "rom", "ance", "\u2581#", "kind", "le", "un", "limited"]], "entropy": [[1.771484375, 0.7880859375, 0.11004638671875, 1.02734375, 0.0007538795471191406, 0.00030112266540527344, 0.4189453125, 0.50732421875, 0.0228424072265625, 0.00118255615234375, 0.00018906593322753906, 0.012603759765625, 0.0003993511199951172, 1.0234375, 0.78466796875, 0.7314453125, 0.004425048828125, 0.16845703125, 0.001148223876953125, 9.435415267944336e-05, 0.0006399154663085938, 0.153564453125, 0.17919921875, 0.82470703125, 1.82421875, 1.14453125, 3.802734375, 2.73828125, 2.01171875, 5.875, 0.9228515625, 4.1953125, 0.10736083984375, 2.828125, 4.30859375, 2.576171875, 2.55078125, 3.181640625, 3.486328125, 0.875, 0.833984375, 0.014251708984375, 1.9677734375, 2.763671875, 0.0374755859375, 2.59375, 0.004863739013671875]], "avg_entropy": [1.2591001873320722], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "31 March 1909", "score_of_biggest_cluster": 0.1326046586036682, "score_of_first_answer": 0.1326046586036682, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 3.337860107421875e-06, "avg_score": 0.1326046586036682, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.42365924862866006, "std_of_first_answer": 0.42365924862866006, "avg_entropy_of_first_answer": 1.2591001873320722, "lex_sim": 1.0}
{"question": "who was kat slater's sisters in eastenders", "answer": ["Bianca Butcher-Miller #OTD in 1939 \u2013 The United States President Franklin D. Roosevelt, in a radio address to the nation, asks Congress to declare war on Japan in response to the"], "scores": [[0.0217742919921875, 1.0, 0.250244140625, 0.9990234375, 0.00464630126953125, 0.10748291015625, 0.357177734375, 7.849931716918945e-05, 1.7404556274414062e-05, 0.0205841064453125, 0.00016880035400390625, 0.159423828125, 0.338623046875, 0.96484375, 0.01041412353515625, 0.05206298828125, 0.00972747802734375, 0.07183837890625, 0.0087890625, 0.216796875, 0.00017464160919189453, 0.6201171875, 0.97412109375, 0.91845703125, 0.984375, 1.0, 1.0, 1.0, 0.004695892333984375, 0.306884765625, 0.81640625, 0.303466796875, 0.399658203125, 0.67626953125, 0.9990234375, 0.935546875, 0.9873046875, 0.18994140625, 0.73974609375, 0.99072265625, 0.96484375, 0.96728515625, 0.8349609375, 0.39990234375, 0.06402587890625, 0.86181640625, 0.9990234375, 0.84912109375]], "normalized_score": [0.13642917573451996], "tokens": [["\u2581Bian", "ca", "\u2581But", "cher", "-", "M", "iller", "\u2581#", "OT", "D", "\u2581in", "\u2581", "1", "9", "3", "9", "\u2581\u2013", "\u2581The", "\u2581United", "\u2581States", "\u2581President", "\u2581Franklin", "\u2581D", ".", "\u2581Ro", "ose", "vel", "t", ",", "\u2581in", "\u2581a", "\u2581radio", "\u2581address", "\u2581to", "\u2581the", "\u2581nation", ",", "\u2581asks", "\u2581Congress", "\u2581to", "\u2581declare", "\u2581war", "\u2581on", "\u2581Japan", "\u2581in", "\u2581response", "\u2581to", "\u2581the"]], "entropy": [[3.63671875, 0.00038051605224609375, 0.7314453125, 0.01001739501953125, 1.1884765625, 2.912109375, 1.779296875, 1.4091796875, 1.03515625, 3.568359375, 3.06640625, 2.1171875, 0.97314453125, 0.242431640625, 0.701171875, 2.076171875, 3.060546875, 5.34375, 4.0625, 0.5478515625, 4.98046875, 1.3291015625, 0.155517578125, 0.313720703125, 0.10870361328125, 0.0021495819091796875, 0.00022149085998535156, 0.00038909912109375, 3.70703125, 2.802734375, 0.64599609375, 2.8203125, 0.8203125, 0.74560546875, 0.0132904052734375, 0.329833984375, 0.112060546875, 2.642578125, 1.08203125, 0.059722900390625, 0.28759765625, 0.1651611328125, 0.5859375, 1.162109375, 2.216796875, 0.55517578125, 0.008056640625, 0.56689453125]], "avg_entropy": [1.3892044474681218], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Zoe", "score_of_biggest_cluster": 0.13642917573451996, "score_of_first_answer": 0.13642917573451996, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7404556274414062e-05, "avg_score": 0.13642917573451996, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41232455942684537, "std_of_first_answer": 0.41232455942684537, "avg_entropy_of_first_answer": 1.3892044474681218, "lex_sim": 1.0}
{"question": "who will take the throne after the queen dies", "answer": ["The monarch after Queen Elizabeth II will be her eldest son, Prince Charles."], "scores": [[0.392822265625, 0.01114654541015625, 0.1458740234375, 0.873046875, 0.99951171875, 0.9990234375, 0.1937255859375, 0.98681640625, 0.72216796875, 0.78564453125, 1.0, 0.9873046875, 0.970703125, 0.958984375, 1.0, 0.58056640625, 5.364418029785156e-07, 0.00047588348388671875, 0.013763427734375, 0.0012798309326171875, 0.0032596588134765625, 0.0021038055419921875, 3.2901763916015625e-05, 4.571676254272461e-05, 0.038177490234375, 0.0019426345825195312, 0.034698486328125, 0.5927734375, 0.90869140625, 0.0009694099426269531, 0.919921875, 0.0005693435668945312, 0.01041412353515625, 0.0021457672119140625, 0.77880859375, 9.816884994506836e-05, 0.982421875, 0.5068359375, 0.09051513671875, 0.2239990234375]], "normalized_score": [0.0404081791639328], "tokens": [["\u2581The", "\u2581monarch", "\u2581after", "\u2581Queen", "\u2581Elizabeth", "\u2581II", "\u2581will", "\u2581be", "\u2581her", "\u2581el", "dest", "\u2581son", ",", "\u2581Prince", "\u2581Charles", ".", "\u2581#", "M", "H", "Y", "AL", "ive", "\u2581Final", "ist", ",", "\u2581J", "ov", "ana", "\u2581R", "aki", "\u0107", "\u2581\u2013", "\u2581\"", "Cre", "ating", "\u2581Sp", "aces", "\u2581for", "\u2581Hope", "\""]], "entropy": [[2.33984375, 2.900390625, 1.8798828125, 0.390869140625, 0.004558563232421875, 0.0098724365234375, 1.3916015625, 0.07659912109375, 1.0908203125, 0.65185546875, 0.0014934539794921875, 0.073974609375, 0.141357421875, 0.1785888671875, 0.00026798248291015625, 0.7314453125, 0.9853515625, 1.830078125, 4.70703125, 2.3984375, 2.345703125, 1.7861328125, 0.689453125, 0.84716796875, 3.201171875, 5.52734375, 5.12890625, 1.5, 0.67578125, 0.94140625, 0.452392578125, 2.31640625, 5.73828125, 4.59375, 0.9365234375, 3.04296875, 0.138916015625, 1.8662109375, 4.00390625, 1.9423828125]], "avg_entropy": [1.7364781141281127], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Charles, Prince of Wales", "score_of_biggest_cluster": 0.0404081791639328, "score_of_first_answer": 0.0404081791639328, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.364418029785156e-07, "avg_score": 0.0404081791639328, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4237362402072097, "std_of_first_answer": 0.4237362402072097, "avg_entropy_of_first_answer": 1.7364781141281127, "lex_sim": 1.0}
{"question": "what are the spices in chinese 5 spice powder", "answer": ["star anise, cloves, cinnamon, Sichuan pepper, and fennel seeds #FergusonOctober: The National Strike that Almost Wasn\u2019t"], "scores": [[0.70263671875, 0.9990234375, 1.0, 0.998046875, 0.6328125, 0.9990234375, 0.99951171875, 0.88232421875, 0.99609375, 1.0, 0.99951171875, 0.99951171875, 0.79833984375, 0.98974609375, 1.0, 0.9990234375, 1.0, 0.73095703125, 0.99560546875, 0.9697265625, 1.0, 1.0, 0.62255859375, 1.0, 4.172325134277344e-07, 0.0104217529296875, 2.2649765014648438e-05, 0.93408203125, 0.462158203125, 3.516674041748047e-05, 0.6513671875, 0.002925872802734375, 0.044342041015625, 0.00048732757568359375, 0.0004420280456542969, 0.9794921875, 0.020355224609375, 0.007541656494140625, 0.998046875, 0.7333984375, 0.10662841796875, 0.286865234375, 1.0]], "normalized_score": [0.15423397719860077], "tokens": [["\u2581star", "\u2581an", "ise", ",", "\u2581clo", "ves", ",", "\u2581c", "inn", "am", "on", ",", "\u2581S", "ich", "uan", "\u2581pe", "pper", ",", "\u2581and", "\u2581f", "enn", "el", "\u2581se", "eds", "\u2581#", "F", "erg", "us", "on", "Oct", "ober", ":", "\u2581The", "\u2581National", "\u2581St", "rike", "\u2581that", "\u2581Al", "most", "\u2581Was", "n", "\u2019", "t"]], "entropy": [[1.3779296875, 0.0084075927734375, 0.00022459030151367188, 0.0183258056640625, 0.787109375, 0.0083770751953125, 0.0036869049072265625, 0.482421875, 0.0264129638671875, 0.00016987323760986328, 0.00566864013671875, 0.006389617919921875, 0.8388671875, 0.0567626953125, 1.1682510375976562e-05, 0.0100860595703125, 0.0013027191162109375, 0.77880859375, 0.03411865234375, 0.1939697265625, 0.00024259090423583984, 0.00018644332885742188, 1.1376953125, 0.0003211498260498047, 1.13671875, 4.7890625, 1.345703125, 0.491943359375, 3.06640625, 3.15234375, 1.365234375, 1.7919921875, 5.234375, 5.60546875, 2.693359375, 0.14453125, 3.029296875, 3.27734375, 0.0169830322265625, 1.0673828125, 2.283203125, 0.84130859375, 0.002685546875]], "avg_entropy": [1.09564742376638], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Sichuan pepper", "score_of_biggest_cluster": 0.15423397719860077, "score_of_first_answer": 0.15423397719860077, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.15423397719860077, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41097188432663645, "std_of_first_answer": 0.41097188432663645, "avg_entropy_of_first_answer": 1.09564742376638, "lex_sim": 1.0}
{"question": "what do you call initials that stand for something", "answer": ["abbreviation"], "scores": [[0.06317138671875, 0.2568359375]], "normalized_score": [0.12737615406513214], "tokens": [["\u2581abbre", "viation"]], "entropy": [[1.1884765625, 0.5703125]], "avg_entropy": [0.87939453125], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "acronym", "score_of_biggest_cluster": 0.12737615406513214, "score_of_first_answer": 0.12737615406513214, "max_score_of_first_answer": 0.2568359375, "min_score_of_first_answer": 0.06317138671875, "avg_score": 0.12737615406513214, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.096832275390625, "std_of_first_answer": 0.096832275390625, "avg_entropy_of_first_answer": 0.87939453125, "lex_sim": 1.0}
{"question": "who plays emma in air bud world pup", "answer": ["Kylie Morgan"], "scores": [[0.1639404296875, 0.046142578125, 0.99951171875, 0.0025959014892578125]], "normalized_score": [0.06656040996313095], "tokens": [["\u2581K", "yl", "ie", "\u2581Morgan"]], "entropy": [[4.31640625, 1.6005859375, 0.004024505615234375, 3.48046875]], "avg_entropy": [2.3503713607788086], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Brittany Paige Bouck", "score_of_biggest_cluster": 0.06656040996313095, "score_of_first_answer": 0.06656040996313095, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.0025959014892578125, "avg_score": 0.06656040996313095, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40641250194264944, "std_of_first_answer": 0.40641250194264944, "avg_entropy_of_first_answer": 2.3503713607788086, "lex_sim": 1.0}
{"question": "what is the enrollment at university of miami", "answer": ["I do not have real-time data."], "scores": [[0.740234375, 0.251220703125, 0.99951171875, 0.96728515625, 0.0288543701171875, 0.98388671875, 0.99951171875, 0.494873046875, 0.338623046875, 0.58349609375, 0.75830078125, 0.58544921875, 0.51904296875, 0.98974609375, 0.394775390625, 0.7705078125, 0.27587890625, 0.580078125, 0.998046875, 1.0, 0.83056640625, 0.9833984375]], "normalized_score": [0.5715148448944092], "tokens": [["\u2581I", "\u2581do", "\u2581not", "\u2581have", "\u2581real", "-", "time", "\u2581data", ".", "\u2581Please", "\u2581check", "\u2581the", "\u2581official", "\u2581website", "\u2581for", "\u2581the", "\u2581latest", "\u2581en", "roll", "ment", "\u2581figures", "."]], "entropy": [[1.4208984375, 1.4912109375, 0.002689361572265625, 0.1470947265625, 1.0439453125, 0.08514404296875, 0.0030975341796875, 1.0556640625, 1.736328125, 1.7412109375, 1.048828125, 1.25, 1.416015625, 0.0714111328125, 1.109375, 0.94140625, 0.8447265625, 0.88916015625, 0.0157012939453125, 0.0005707740783691406, 0.67578125, 0.10595703125]], "avg_entropy": [0.777100758119063], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "16,801", "score_of_biggest_cluster": 0.5715148448944092, "score_of_first_answer": 0.5715148448944092, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0288543701171875, "avg_score": 0.5715148448944092, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.29139975977353577, "std_of_first_answer": 0.29139975977353577, "avg_entropy_of_first_answer": 0.777100758119063, "lex_sim": 1.0}
{"question": "who plays harley quinn in the lego batman movie", "answer": ["Harley Quinn is not in the Lego Batman Movie."], "scores": [[0.202880859375, 0.9951171875, 0.99853515625, 1.0, 0.79248046875, 0.9375, 0.4912109375, 0.82763671875, 0.96044921875, 1.0, 0.99951171875, 1.0, 0.55419921875, 0.87744140625, 6.198883056640625e-06, 0.0006322860717773438, 0.99267578125, 0.01300048828125, 0.00023233890533447266, 0.056060791015625, 0.0129547119140625, 0.0024433135986328125, 0.02197265625, 0.64794921875, 0.99951171875, 0.8115234375, 0.0101318359375, 0.41748046875, 0.99755859375, 1.0, 0.10638427734375, 0.91259765625, 0.0142364501953125, 0.406005859375, 0.006473541259765625, 0.9990234375, 0.99658203125, 0.9990234375, 0.71630859375]], "normalized_score": [0.15917997062206268], "tokens": [["\u2581Har", "ley", "\u2581Qu", "inn", "\u2581is", "\u2581not", "\u2581in", "\u2581the", "\u2581L", "ego", "\u2581Bat", "man", "\u2581Movie", ".", "\u2581#", "TB", "T", ":", "\u2581Remember", "ing", "\u2581The", "\u2581Classic", "\u2581", "9", "0", "s", "\u2581Nick", "el", "ode", "on", "\u2581Game", "\u2581Show", ",", "\u2581\"", "Fig", "ure", "\u2581It", "\u2581Out", "\""]], "entropy": [[1.9033203125, 0.03375244140625, 0.0172576904296875, 0.0010995864868164062, 1.10546875, 0.314453125, 1.169921875, 0.52783203125, 0.2266845703125, 8.821487426757812e-06, 0.0043487548828125, 0.0001461505889892578, 0.69140625, 0.5283203125, 1.5419921875, 4.99609375, 0.058441162109375, 3.201171875, 3.09375, 2.822265625, 3.337890625, 4.1953125, 3.3828125, 1.1630859375, 0.006595611572265625, 0.61767578125, 1.771484375, 1.78125, 0.01983642578125, 0.0009546279907226562, 1.4833984375, 0.306884765625, 1.890625, 1.798828125, 0.300537109375, 0.0095977783203125, 0.0278472900390625, 0.00844573974609375, 1.0283203125]], "avg_entropy": [1.1633107234270146], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Jenny Slate", "score_of_biggest_cluster": 0.15917997062206268, "score_of_first_answer": 0.15917997062206268, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 6.198883056640625e-06, "avg_score": 0.15917997062206268, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42077285140053333, "std_of_first_answer": 0.42077285140053333, "avg_entropy_of_first_answer": 1.1633107234270146, "lex_sim": 1.0}
{"question": "where does the ohio river and the mississippi river meet", "answer": ["Cairo, Illinois #ShoppingSpreeGiveaway: Win $500 in Cash & Prizes from ShopSense"], "scores": [[0.63671875, 1.0, 0.98779296875, 0.9921875, 1.1920928955078125e-07, 0.00405120849609375, 0.0003178119659423828, 0.032867431640625, 0.0016279220581054688, 0.990234375, 0.01424407958984375, 0.0015316009521484375, 0.9853515625, 0.0008726119995117188, 0.1109619140625, 0.152099609375, 0.266845703125, 0.9853515625, 0.89208984375, 0.023834228515625, 0.1641845703125, 0.951171875, 0.01068878173828125, 0.031982421875, 0.9931640625, 0.99951171875, 0.03265380859375, 0.062225341796875, 0.9619140625, 0.0233306884765625, 0.012054443359375]], "normalized_score": [0.05286305397748947], "tokens": [["\u2581C", "airo", ",", "\u2581Illinois", "\u2581#", "S", "ho", "pping", "Sp", "ree", "G", "ive", "away", ":", "\u2581Win", "\u2581$", "5", "0", "0", "\u2581in", "\u2581C", "ash", "\u2581&", "\u2581P", "riz", "es", "\u2581from", "\u2581Sh", "op", "S", "ense"]], "entropy": [[1.6796875, 0.0007109642028808594, 0.08038330078125, 0.047088623046875, 0.98828125, 5.6875, 3.12109375, 3.47265625, 2.064453125, 0.08392333984375, 2.330078125, 0.356201171875, 0.11761474609375, 1.9072265625, 5.0625, 2.7890625, 1.3447265625, 0.0958251953125, 0.64599609375, 3.328125, 3.29296875, 0.25927734375, 2.197265625, 3.0859375, 0.059722900390625, 0.002758026123046875, 2.240234375, 4.37109375, 0.280517578125, 2.947265625, 2.150390625]], "avg_entropy": [1.8093731018804735], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Cairo, Illinois", "score_of_biggest_cluster": 0.05286305397748947, "score_of_first_answer": 0.05286305397748947, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.05286305397748947, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4451810882658719, "std_of_first_answer": 0.4451810882658719, "avg_entropy_of_first_answer": 1.8093731018804735, "lex_sim": 1.0}
{"question": "where do peaches come from in the us", "answer": ["Georgia is the largest peach-producing state in the United States."], "scores": [[0.603515625, 0.08447265625, 0.98291015625, 0.892578125, 0.3955078125, 1.0, 0.9599609375, 0.99951171875, 1.0, 1.0, 0.9755859375, 1.0, 0.498291015625, 0.99951171875, 0.69091796875, 1.4901161193847656e-06, 0.00278472900390625, 0.002376556396484375, 0.00029540061950683594, 0.0002493858337402344, 0.05853271484375, 0.5, 0.00018477439880371094, 0.533203125, 0.99609375, 0.88037109375, 0.06695556640625, 0.273193359375]], "normalized_score": [0.10234685242176056], "tokens": [["\u2581Georgia", "\u2581is", "\u2581the", "\u2581largest", "\u2581pe", "ach", "-", "produ", "cing", "\u2581state", "\u2581in", "\u2581the", "\u2581United", "\u2581States", ".", "\u2581#", "1", "\u2581The", "\u2581W", "inner", "\u2581of", "\u2581the", "\u2581Amazon", "\u2581G", "ift", "\u2581Card", "\u2581Is", "..."]], "entropy": [[1.6376953125, 1.65234375, 0.10833740234375, 0.4384765625, 0.79248046875, 0.0001976490020751953, 0.184326171875, 0.0029621124267578125, 0.0004413127899169922, 0.0011301040649414062, 0.135009765625, 0.0012989044189453125, 0.9921875, 0.0041656494140625, 0.86865234375, 1.568359375, 2.607421875, 3.81640625, 4.4296875, 3.046875, 3.064453125, 2.771484375, 4.55078125, 2.28125, 0.0416259765625, 0.5634765625, 1.4775390625, 2.9296875]], "avg_entropy": [1.4274554593222482], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "other states", "score_of_biggest_cluster": 0.10234685242176056, "score_of_first_answer": 0.10234685242176056, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.4901161193847656e-06, "avg_score": 0.10234685242176056, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41425559410993473, "std_of_first_answer": 0.41425559410993473, "avg_entropy_of_first_answer": 1.4274554593222482, "lex_sim": 1.0}
{"question": "how are leaders of the two parties in congress chosen", "answer": ["The leaders of the two parties in Congress are chosen through a process of internal party elections or leadership elections."], "scores": [[0.525390625, 0.6923828125, 0.9990234375, 0.9775390625, 0.86083984375, 0.7529296875, 0.99755859375, 0.91650390625, 0.57080078125, 0.85986328125, 0.56494140625, 0.84912109375, 0.9091796875, 0.3447265625, 0.69775390625, 0.95361328125, 0.90234375, 0.52294921875, 0.06256103515625, 0.86376953125, 0.59326171875, 0.06475830078125, 1.0, 0.99609375, 0.79248046875, 0.25244140625, 0.03741455078125, 0.29736328125, 1.0, 0.9296875, 0.85498046875, 0.9755859375, 0.9365234375, 0.99951171875, 0.06512451171875, 0.95263671875, 0.83642578125, 0.875, 1.0, 0.99560546875, 0.99853515625, 0.9990234375, 1.0, 0.1676025390625, 0.890625, 0.07330322265625, 0.322509765625, 0.9951171875, 0.208984375, 0.3974609375]], "normalized_score": [0.5579855442047119], "tokens": [["\u2581The", "\u2581leaders", "\u2581of", "\u2581the", "\u2581two", "\u2581parties", "\u2581in", "\u2581Congress", "\u2581are", "\u2581chosen", "\u2581through", "\u2581a", "\u2581process", "\u2581of", "\u2581internal", "\u2581party", "\u2581elections", "\u2581or", "\u2581leadership", "\u2581elections", ".", "\u2581Typ", "ically", ",", "\u2581the", "\u2581party", "\u2581c", "auc", "uses", "\u2581in", "\u2581each", "\u2581chamber", "\u2581of", "\u2581Congress", "\u2581(", "the", "\u2581House", "\u2581of", "\u2581Representatives", "\u2581and", "\u2581the", "\u2581Senate", ")", "\u2581select", "\u2581their", "\u2581respective", "\u2581party", "\u2581leaders", ".", "\u2581The"]], "entropy": [[1.921875, 0.97216796875, 0.01000213623046875, 0.11578369140625, 0.5478515625, 0.77099609375, 0.018218994140625, 0.343505859375, 0.79931640625, 0.483154296875, 0.70263671875, 0.576171875, 0.459716796875, 1.7265625, 1.1904296875, 0.2734375, 0.457275390625, 1.2119140625, 2.19140625, 0.58740234375, 1.318359375, 1.6708984375, 8.893013000488281e-05, 0.0302886962890625, 0.9169921875, 1.541015625, 1.0400390625, 0.60888671875, 0.001434326171875, 0.36328125, 0.44921875, 0.1197509765625, 0.34375, 0.003940582275390625, 1.8701171875, 0.2783203125, 0.6318359375, 0.384765625, 0.002147674560546875, 0.0306396484375, 0.01091766357421875, 0.00865936279296875, 0.0020847320556640625, 1.677734375, 0.429931640625, 1.021484375, 0.6669921875, 0.0355224609375, 1.185546875, 1.4599609375]], "avg_entropy": [0.6692886209487915], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Senate Republican Conference", "score_of_biggest_cluster": 0.5579855442047119, "score_of_first_answer": 0.5579855442047119, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.03741455078125, "avg_score": 0.5579855442047119, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3227726422087368, "std_of_first_answer": 0.3227726422087368, "avg_entropy_of_first_answer": 0.6692886209487915, "lex_sim": 1.0}
{"question": "what was the biggest tank in world war 2", "answer": ["T-35"], "scores": [[0.1199951171875, 0.75048828125, 0.9853515625, 0.78271484375]], "normalized_score": [0.5133642554283142], "tokens": [["\u2581T", "-", "3", "5"]], "entropy": [[1.880859375, 0.57958984375, 0.09295654296875, 0.52587890625]], "avg_entropy": [0.7698211669921875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Panzerkampfwagen VIII Maus", "score_of_biggest_cluster": 0.5133642554283142, "score_of_first_answer": 0.5133642554283142, "max_score_of_first_answer": 0.9853515625, "min_score_of_first_answer": 0.1199951171875, "avg_score": 0.5133642554283142, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3243090535415594, "std_of_first_answer": 0.3243090535415594, "avg_entropy_of_first_answer": 0.7698211669921875, "lex_sim": 1.0}
{"question": "who is known as the super fast boy in the series the icredible", "answer": ["Invincible"], "scores": [[0.014892578125, 0.14501953125, 0.99853515625]], "normalized_score": [0.12919723987579346], "tokens": [["\u2581Inv", "inci", "ble"]], "entropy": [[4.8203125, 0.46826171875, 0.01464080810546875]], "avg_entropy": [1.7677383422851562], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Dashiell Robert Parr / Dash", "score_of_biggest_cluster": 0.12919723987579346, "score_of_first_answer": 0.12919723987579346, "max_score_of_first_answer": 0.99853515625, "min_score_of_first_answer": 0.014892578125, "avg_score": 0.12919723987579346, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43626886047089164, "std_of_first_answer": 0.43626886047089164, "avg_entropy_of_first_answer": 1.7677383422851562, "lex_sim": 1.0}
{"question": "when was the first hunger games book published", "answer": ["September 14, 2008"], "scores": [[0.11676025390625, 0.9970703125, 0.9970703125, 0.85302734375, 0.93505859375, 0.9990234375, 1.0, 1.0, 0.99951171875, 0.99951171875]], "normalized_score": [0.7880793809890747], "tokens": [["\u2581September", "\u2581", "1", "4", ",", "\u2581", "2", "0", "0", "8"]], "entropy": [[0.763671875, 0.0234527587890625, 0.0203704833984375, 0.487060546875, 0.25341796875, 0.0084991455078125, 0.001438140869140625, 7.987022399902344e-06, 0.00467681884765625, 0.00275421142578125]], "avg_entropy": [0.15653499364852905], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "September 14, 2008", "score_of_biggest_cluster": 0.7880793809890747, "score_of_first_answer": 0.7880793809890747, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.11676025390625, "avg_score": 0.7880793809890747, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.2615905055369055, "std_of_first_answer": 0.2615905055369055, "avg_entropy_of_first_answer": 0.15653499364852905, "lex_sim": 1.0}
{"question": "who sang the song one of these nights", "answer": ["The Eagles"], "scores": [[0.46484375, 0.97998046875, 1.0, 1.0]], "normalized_score": [0.8215445280075073], "tokens": [["\u2581The", "\u2581E", "ag", "les"]], "entropy": [[1.6328125, 0.17626953125, 0.00133514404296875, 0.0011882781982421875]], "avg_entropy": [0.45290136337280273], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "American rock band Eagles", "score_of_biggest_cluster": 0.8215445280075073, "score_of_first_answer": 0.8215445280075073, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.46484375, "avg_score": 0.8215445280075073, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.22898578368748967, "std_of_first_answer": 0.22898578368748967, "avg_entropy_of_first_answer": 0.45290136337280273, "lex_sim": 1.0}
{"question": "who plays the characters in yo gabba gabba", "answer": ["DJ Lance Rock #699 Cockroach Milkshake"], "scores": [[0.22900390625, 0.99951171875, 1.0, 0.9951171875, 2.980232238769531e-07, 0.0023212432861328125, 0.2142333984375, 0.050506591796875, 5.65648078918457e-05, 0.0006413459777832031, 0.173583984375, 1.0, 0.00016391277313232422, 0.0010995864868164062, 0.2303466796875, 1.0]], "normalized_score": [0.019523954018950462], "tokens": [["\u2581DJ", "\u2581L", "ance", "\u2581Rock", "\u2581#", "6", "9", "9", "\u2581C", "ock", "ro", "ach", "\u2581Mil", "k", "sh", "ake"]], "entropy": [[3.498046875, 0.00534820556640625, 0.00036072731018066406, 0.041259765625, 1.35546875, 2.966796875, 3.248046875, 3.03125, 2.615234375, 3.576171875, 3.65234375, 0.0015163421630859375, 2.54296875, 0.05865478515625, 2.525390625, 0.0007076263427734375]], "avg_entropy": [1.819972887635231], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "DJ Lance Rock", "score_of_biggest_cluster": 0.019523954018950462, "score_of_first_answer": 0.019523954018950462, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.019523954018950462, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4330315639572056, "std_of_first_answer": 0.4330315639572056, "avg_entropy_of_first_answer": 1.819972887635231, "lex_sim": 1.0}
{"question": "when did the first ice age come out", "answer": ["The first Ice Age came out in 2002."], "scores": [[0.253662109375, 0.9248046875, 0.94873046875, 0.998046875, 0.150146484375, 0.9990234375, 0.7890625, 0.99267578125, 0.859375, 1.0, 0.99853515625, 0.9990234375, 0.93603515625, 1.1920928955078125e-06, 0.0006470680236816406, 0.033355712890625, 0.00070953369140625, 1.6629695892333984e-05, 0.5458984375, 0.978515625, 0.1583251953125, 0.040771484375, 0.5888671875, 0.00901031494140625, 0.7001953125, 0.07037353515625, 0.95166015625]], "normalized_score": [0.1064847782254219], "tokens": [["\u2581The", "\u2581first", "\u2581Ice", "\u2581Age", "\u2581came", "\u2581out", "\u2581in", "\u2581", "2", "0", "0", "2", ".", "\u2581#", "8", "6", "\u2581in", "\u2581Non", "f", "iction", ",", "\u2581History", ",", "\u2581Military", ",", "\u2581Str", "ategy"]], "entropy": [[1.51953125, 0.416748046875, 0.299072265625, 0.0140228271484375, 2.17578125, 0.010589599609375, 0.529296875, 0.0528564453125, 0.40673828125, 0.000347137451171875, 0.011260986328125, 0.00783538818359375, 0.290283203125, 0.449951171875, 4.25, 3.798828125, 2.330078125, 2.904296875, 0.8642578125, 0.11968994140625, 2.052734375, 1.8896484375, 1.6455078125, 3.68359375, 1.4931640625, 3.177734375, 0.19384765625]], "avg_entropy": [1.2810257805718317], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2002", "score_of_biggest_cluster": 0.1064847782254219, "score_of_first_answer": 0.1064847782254219, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-06, "avg_score": 0.1064847782254219, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4230555133438354, "std_of_first_answer": 0.4230555133438354, "avg_entropy_of_first_answer": 1.2810257805718317, "lex_sim": 1.0}
{"question": "what is in a pat o brien hurricane", "answer": ["dark rum, light rum, vodka, triple sec, lime juice and simple syrup"], "scores": [[0.048583984375, 0.99755859375, 0.9951171875, 0.9619140625, 1.0, 1.0, 0.251708984375, 0.99951171875, 1.0, 0.9990234375, 0.0843505859375, 1.0, 0.994140625, 0.84033203125, 0.99072265625, 0.98681640625, 1.0, 0.12548828125, 0.53271484375, 1.0, 1.0]], "normalized_score": [0.626131534576416], "tokens": [["\u2581dark", "\u2581rum", ",", "\u2581light", "\u2581rum", ",", "\u2581v", "od", "ka", ",", "\u2581triple", "\u2581sec", ",", "\u2581l", "ime", "\u2581ju", "ice", "\u2581and", "\u2581simple", "\u2581sy", "rup"]], "entropy": [[1.7509765625, 0.0266265869140625, 0.036346435546875, 0.291015625, 0.001850128173828125, 0.0007076263427734375, 3.44140625, 0.002960205078125, 2.1755695343017578e-05, 0.01107025146484375, 2.876953125, 0.0023899078369140625, 0.04058837890625, 0.71875, 0.05718994140625, 0.091796875, 0.0015134811401367188, 0.487548828125, 2.1796875, 0.0010852813720703125, 0.00013899803161621094]], "avg_entropy": [0.5724106544540042], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "fruit juice", "score_of_biggest_cluster": 0.626131534576416, "score_of_first_answer": 0.626131534576416, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.048583984375, "avg_score": 0.626131534576416, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.34345109986874384, "std_of_first_answer": 0.34345109986874384, "avg_entropy_of_first_answer": 0.5724106544540042, "lex_sim": 1.0}
{"question": "how many episodes in game if thrones season 7", "answer": ["7 One of the key aspects of your life that you need to be aware of is the presence of other people."], "scores": [[0.9189453125, 0.994140625, 1.1920928955078125e-07, 0.0027599334716796875, 0.7724609375, 0.0004754066467285156, 0.0158843994140625, 0.8583984375, 0.002185821533203125, 0.01042938232421875, 0.11712646484375, 0.298583984375, 0.2490234375, 0.9833984375, 0.04229736328125, 0.239501953125, 0.98046875, 0.8125, 0.2509765625, 0.0439453125, 0.9853515625, 0.019500732421875, 0.6787109375, 0.3173828125, 0.43212890625, 0.00333404541015625, 0.26611328125, 0.17138671875, 0.8857421875, 0.023345947265625, 0.8486328125, 0.371337890625, 0.468017578125, 0.0289306640625, 1.0, 1.0, 0.51416015625, 0.1109619140625, 0.444580078125, 0.99755859375, 0.005809783935546875, 0.9833984375, 0.01128387451171875, 0.8037109375, 0.0016345977783203125, 0.998046875, 0.432373046875, 0.235107421875]], "normalized_score": [0.11078453063964844], "tokens": [["\u2581", "7", "\u2581One", "\u2581of", "\u2581the", "\u2581key", "\u2581aspects", "\u2581of", "\u2581your", "\u2581life", "\u2581that", "\u2581you", "\u2581need", "\u2581to", "\u2581be", "\u2581aware", "\u2581of", "\u2581is", "\u2581the", "\u2581presence", "\u2581of", "\u2581other", "\u2581people", ".", "\u2581You", "\u2581should", "\u2581be", "\u2581open", "\u2581to", "\u2581other", "\u2581people", "\u2581and", "\u2581their", "\u2581pers", "pect", "ives", ",", "\u2581as", "\u2581well", "\u2581as", "\u2581act", "ively", "\u2581engaged", "\u2581in", "\u2581sh", "aping", "\u2581your", "\u2581own"]], "entropy": [[0.336181640625, 0.0386962890625, 0.88671875, 2.49609375, 1.3271484375, 3.037109375, 4.4453125, 0.62255859375, 4.54296875, 5.2578125, 2.259765625, 3.626953125, 2.650390625, 0.1229248046875, 3.146484375, 3.955078125, 0.1279296875, 1.1240234375, 1.453125, 4.421875, 0.108154296875, 4.890625, 2.025390625, 1.705078125, 2.91796875, 1.755859375, 3.087890625, 2.865234375, 0.473388671875, 2.947265625, 0.779296875, 1.6181640625, 2.556640625, 2.0625, 0.0006265640258789062, 0.00012171268463134766, 1.375, 1.94921875, 1.5986328125, 0.0212860107421875, 2.845703125, 0.12371826171875, 2.40234375, 0.6025390625, 3.3125, 0.0183868408203125, 1.537109375, 2.1875]], "avg_entropy": [1.9509852851430576], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "7", "score_of_biggest_cluster": 0.11078453063964844, "score_of_first_answer": 0.11078453063964844, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.11078453063964844, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38674487304097616, "std_of_first_answer": 0.38674487304097616, "avg_entropy_of_first_answer": 1.9509852851430576, "lex_sim": 1.0}
{"question": "when did avatar the last airbender first air", "answer": ["March 2, 2005"], "scores": [[0.051788330078125, 0.9990234375, 0.99658203125, 0.36865234375, 0.99658203125, 1.0, 1.0, 0.99951171875, 0.99951171875]], "normalized_score": [0.6435146927833557], "tokens": [["\u2581March", "\u2581", "2", ",", "\u2581", "2", "0", "0", "5"]], "entropy": [[0.671875, 0.00772857666015625, 0.0288238525390625, 0.990234375, 0.024078369140625, 0.0002453327178955078, -0.0, 0.0032100677490234375, 0.003330230712890625]], "avg_entropy": [0.19216953383551705], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "February 2005", "score_of_biggest_cluster": 0.6435146927833557, "score_of_first_answer": 0.6435146927833557, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.051788330078125, "avg_score": 0.6435146927833557, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3362230238341235, "std_of_first_answer": 0.3362230238341235, "avg_entropy_of_first_answer": 0.19216953383551705, "lex_sim": 1.0}
{"question": "who sang the song brother let me be your shelter", "answer": ["Whitney Houston \\ \u02c8w\u028ct\u0259r \\"], "scores": [[0.203125, 1.0, 0.99560546875, 1.6689300537109375e-06, 3.814697265625e-06, 0.0009927749633789062, 0.1903076171875, 3.927946090698242e-05, 0.00017833709716796875, 8.338689804077148e-05, 4.70280647277832e-05, 3.170967102050781e-05]], "normalized_score": [0.0008787034312263131], "tokens": [["\u2581Whit", "ney", "\u2581Houston", "\u2581\\", "\u2581", "\u02c8", "w", "\u028c", "t", "\u0259", "r", "\u2581\\"]], "entropy": [[4.375, 0.00010097026824951172, 0.0343017578125, 0.78759765625, 0.498046875, 1.3818359375, 1.3916015625, 0.041290283203125, 0.1337890625, 0.12127685546875, 0.1827392578125, 2.322265625]], "avg_entropy": [0.9391538202762604], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Needtobreathe", "score_of_biggest_cluster": 0.0008787034312263131, "score_of_first_answer": 0.0008787034312263131, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.6689300537109375e-06, "avg_score": 0.0008787034312263131, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.36429543239359474, "std_of_first_answer": 0.36429543239359474, "avg_entropy_of_first_answer": 0.9391538202762604, "lex_sim": 1.0}
{"question": "a political leader during the roman empire was called", "answer": ["Imperator ### What is the useability of this prompt?"], "scores": [[0.069580078125, 1.0, 0.0, 0.0019969940185546875, 0.478515625, 0.471923828125, 0.00025010108947753906, 0.0003972053527832031, 0.5380859375, 0.2080078125, 0.035247802734375, 0.492919921875]], "normalized_score": [0.0], "tokens": [["\u2581Imper", "ator", "\u2581###", "\u2581What", "\u2581is", "\u2581the", "\u2581use", "ability", "\u2581of", "\u2581this", "\u2581prompt", "?"]], "entropy": [[1.4521484375, 0.002532958984375, 1.224609375, 3.958984375, 3.005859375, 2.19140625, 3.484375, 0.48193359375, 1.7900390625, 3.49609375, 4.0390625, 2.58203125]], "avg_entropy": [2.3090896606445312], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "emperors", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.30655904480053625, "std_of_first_answer": 0.30655904480053625, "avg_entropy_of_first_answer": 2.3090896606445312, "lex_sim": 1.0}
{"question": "when did seat belts become law in ontario", "answer": ["October 19, 1976 #166: Sharpen Your Concentration with Cognitive Training \u2013 Part 2 by Dr. Brent Everson: Dr. Brent Everson"], "scores": [[0.004734039306640625, 0.99609375, 0.61572265625, 0.51904296875, 0.68359375, 0.9970703125, 1.0, 1.0, 0.99267578125, 0.97314453125, 5.960464477539063e-08, 0.024993896484375, 0.0177154541015625, 0.07171630859375, 0.0037708282470703125, 5.4717063903808594e-05, 0.007801055908203125, 0.55322265625, 0.10107421875, 0.0008645057678222656, 0.1383056640625, 0.9990234375, 0.99951171875, 0.01076507568359375, 0.0074462890625, 0.05389404296875, 0.8798828125, 0.475341796875, 0.01334381103515625, 0.002475738525390625, 0.8134765625, 0.384521484375, 0.0034961700439453125, 0.0305938720703125, 0.916015625, 0.004856109619140625, 0.11993408203125, 0.0016803741455078125, 0.0035114288330078125, 0.99853515625, 0.030975341796875, 0.01374053955078125, 0.970703125, 0.5390625, 0.998046875, 0.9560546875, 0.998046875, 1.0]], "normalized_score": [0.06954667717218399], "tokens": [["\u2581October", "\u2581", "1", "9", ",", "\u2581", "1", "9", "7", "6", "\u2581#", "1", "6", "6", ":", "\u2581Sh", "ar", "pen", "\u2581Your", "\u2581Con", "cent", "r", "ation", "\u2581with", "\u2581C", "ogn", "itive", "\u2581Training", "\u2581\u2013", "\u2581Part", "\u2581", "2", "\u2581by", "\u2581Dr", ".", "\u2581Br", "ent", "\u2581E", "vers", "on", ":", "\u2581Dr", ".", "\u2581Br", "ent", "\u2581E", "vers", "on"]], "entropy": [[1.251953125, 0.0267791748046875, 1.3173828125, 1.0810546875, 0.7919921875, 0.0228271484375, 0.0006279945373535156, 2.0265579223632812e-06, 0.050323486328125, 0.1416015625, 1.06640625, 4.51171875, 2.326171875, 3.001953125, 3.1171875, 4.40625, 4.578125, 2.25390625, 1.7353515625, 3.26171875, 0.8955078125, 0.00888824462890625, 0.004791259765625, 3.140625, 4.87109375, 2.166015625, 0.564453125, 2.62890625, 3.302734375, 5.37109375, 0.9921875, 1.330078125, 3.30078125, 4.83984375, 0.728515625, 4.71875, 2.689453125, 3.810546875, 2.138671875, 0.0139617919921875, 3.068359375, 3.8046875, 0.1834716796875, 0.85302734375, 0.0188140869140625, 0.361083984375, 0.020477294921875, 0.0022220611572265625]], "avg_entropy": [1.8910911604762077], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "January 1, 1976", "score_of_biggest_cluster": 0.06954667717218399, "score_of_first_answer": 0.06954667717218399, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.06954667717218399, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4343261125944294, "std_of_first_answer": 0.4343261125944294, "avg_entropy_of_first_answer": 1.8910911604762077, "lex_sim": 1.0}
{"question": "what is the largest man made lake in the us", "answer": ["Lake Mead #BookReview :: The Lost Love of Lieutenant Lynch by @LaviniaKatsarelis #RLFblog #Romance"], "scores": [[0.9755859375, 0.98779296875, 0.99951171875, 1.4901161193847656e-06, 2.2351741790771484e-05, 0.0013256072998046875, 0.298095703125, 3.4928321838378906e-05, 0.23388671875, 0.0028553009033203125, 5.7637691497802734e-05, 0.278076171875, 0.00626373291015625, 0.031707763671875, 0.77734375, 0.389404296875, 0.94287109375, 0.0232391357421875, 0.009002685546875, 0.70166015625, 0.99658203125, 0.6162109375, 0.0251922607421875, 0.11614990234375, 0.97607421875, 0.5947265625, 0.006244659423828125, 0.96630859375, 0.99658203125, 0.787109375, 0.08740234375, 0.99462890625, 0.66455078125]], "normalized_score": [0.05742816627025604], "tokens": [["\u2581Lake", "\u2581M", "ead", "\u2581#", "Book", "Re", "view", "\u2581::", "\u2581The", "\u2581Lost", "\u2581Love", "\u2581of", "\u2581Lieutenant", "\u2581Lyn", "ch", "\u2581by", "\u2581@", "L", "av", "in", "ia", "K", "ats", "arel", "is", "\u2581#", "RL", "F", "blog", "\u2581#", "R", "om", "ance"]], "entropy": [[0.171875, 0.085693359375, 0.003376007080078125, 0.72998046875, 3.12109375, 4.8984375, 0.677734375, 2.638671875, 4.16796875, 5.4453125, 1.4814453125, 1.494140625, 3.779296875, 3.77734375, 0.7236328125, 1.9150390625, 0.412841796875, 5.0546875, 4.05859375, 1.533203125, 0.033477783203125, 2.220703125, 4.30078125, 2.97265625, 0.1326904296875, 1.8779296875, 2.916015625, 0.28662109375, 0.03521728515625, 0.70556640625, 1.8466796875, 0.038238525390625, 0.83740234375]], "avg_entropy": [1.9507378086899265], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Lake Oahe", "score_of_biggest_cluster": 0.05742816627025604, "score_of_first_answer": 0.05742816627025604, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 1.4901161193847656e-06, "avg_score": 0.05742816627025604, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41214400190700407, "std_of_first_answer": 0.41214400190700407, "avg_entropy_of_first_answer": 1.9507378086899265, "lex_sim": 1.0}
{"question": "jharkhand which festival is associated with cattle worship", "answer": ["None, there is no information available about any such festival associated with cattle worship in Jharkhand."], "scores": [[0.008209228515625, 0.2498779296875, 0.16845703125, 0.7451171875, 0.982421875, 0.00804901123046875, 0.2734375, 0.256103515625, 0.1490478515625, 0.0256500244140625, 0.99365234375, 0.60791015625, 0.9990234375, 0.9951171875, 0.99951171875, 0.99755859375, 0.97802734375, 1.0, 1.0, 1.0, 0.9501953125, 5.364418029785156e-07, 0.000690460205078125, 0.00029349327087402344, 0.0023670196533203125, 0.203125, 0.0010156631469726562, 0.7841796875, 0.97021484375, 0.0159759521484375, 0.002994537353515625, 0.2193603515625, 0.9970703125, 0.00136566162109375, 0.0193634033203125, 0.0035991668701171875, 0.09820556640625, 0.99267578125, 0.044342041015625, 0.6162109375, 1.0, 0.007236480712890625, 6.079673767089844e-06, 0.93701171875, 0.0736083984375, 0.09490966796875, 0.04498291015625, 0.98779296875]], "normalized_score": [0.07363110780715942], "tokens": [["\u2581None", ",", "\u2581there", "\u2581is", "\u2581no", "\u2581information", "\u2581available", "\u2581about", "\u2581any", "\u2581such", "\u2581festival", "\u2581associated", "\u2581with", "\u2581cattle", "\u2581worship", "\u2581in", "\u2581J", "h", "ark", "hand", ".", "\u2581#", "P", "itch", "W", "ars", "\u2581M", "ent", "or", "\u2581Pick", "\u2581Re", "ve", "al", "\u2581\u2013", "\u2581A", ".", "E", ".", "\u2581S", "aw", "an", "\u2581is", "\u2581TE", "AM", "\u2581R", "ED", "\u2581ment", "or"]], "entropy": [[4.1875, 2.193359375, 1.80078125, 0.7626953125, 0.112060546875, 2.162109375, 1.9365234375, 1.603515625, 2.111328125, 0.8798828125, 0.046112060546875, 1.044921875, 0.0067138671875, 0.03485107421875, 0.0049591064453125, 0.0205535888671875, 0.10797119140625, 0.0009374618530273438, 0.001155853271484375, 0.0013017654418945312, 0.28662109375, 0.40478515625, 4.0, 4.7265625, 4.04296875, 2.59765625, 1.6904296875, 0.57861328125, 0.1416015625, 2.958984375, 2.767578125, 1.6376953125, 0.0220794677734375, 2.951171875, 5.55078125, 4.7109375, 2.955078125, 0.0810546875, 3.19140625, 1.01953125, 0.0002911090850830078, 3.259765625, 2.986328125, 0.33154296875, 4.05078125, 1.5810546875, 3.19140625, 0.08233642578125]], "avg_entropy": [1.6837140967448552], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Sohrai", "score_of_biggest_cluster": 0.07363110780715942, "score_of_first_answer": 0.07363110780715942, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.364418029785156e-07, "avg_score": 0.07363110780715942, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4383953324131383, "std_of_first_answer": 0.4383953324131383, "avg_entropy_of_first_answer": 1.6837140967448552, "lex_sim": 1.0}
{"question": "what theater number was the aurora shooting in", "answer": ["Theater 9 #NewRelease #OutNow #Suspense #Romance - Ricochet (Tribulation of the Lost #2) by S.M."], "scores": [[0.67236328125, 0.99755859375, 0.98486328125, 1.6391277313232422e-05, 8.887052536010742e-05, 0.0005431175231933594, 0.065673828125, 0.0001556873321533203, 0.146240234375, 0.3759765625, 0.00830078125, 0.00653839111328125, 0.52197265625, 0.93017578125, 0.53369140625, 0.0030460357666015625, 0.41357421875, 0.625, 0.01068878173828125, 1.0132789611816406e-06, 0.3359375, 0.99755859375, 0.080810546875, 0.0005331039428710938, 0.031005859375, 0.14794921875, 0.0031223297119140625, 0.290771484375, 0.07342529296875, 0.1014404296875, 0.274658203125, 0.94580078125, 0.199462890625, 0.0069580078125, 0.880859375, 0.115234375, 0.9921875, 0.0016460418701171875, 0.59912109375]], "normalized_score": [0.040646910667419434], "tokens": [["\u2581Theater", "\u2581", "9", "\u2581#", "New", "Release", "\u2581#", "Out", "Now", "\u2581#", "S", "us", "p", "ense", "\u2581#", "R", "om", "ance", "\u2581-", "\u2581Rico", "ch", "et", "\u2581(", "T", "rib", "ulation", "\u2581of", "\u2581the", "\u2581Lost", "\u2581#", "2", ")", "\u2581by", "\u2581S", ".", "M", ".", "\u2581Sh", "ade"]], "entropy": [[1.435546875, 0.020843505859375, 0.080078125, 0.90185546875, 3.62109375, 3.8828125, 2.09765625, 4.3984375, 3.595703125, 2.21484375, 4.21484375, 2.986328125, 1.126953125, 0.428955078125, 2.041015625, 3.04296875, 2.716796875, 0.859375, 1.7841796875, 5.94140625, 2.72265625, 0.0196533203125, 3.064453125, 0.7314453125, 4.51171875, 1.96875, 3.7421875, 2.990234375, 3.828125, 3.16796875, 1.8828125, 0.377685546875, 3.580078125, 4.1015625, 0.9150390625, 2.966796875, 0.08514404296875, 4.65234375, 2.39453125]], "avg_entropy": [2.4383302346254005], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "9", "score_of_biggest_cluster": 0.040646910667419434, "score_of_first_answer": 0.040646910667419434, "max_score_of_first_answer": 0.99755859375, "min_score_of_first_answer": 1.0132789611816406e-06, "avg_score": 0.040646910667419434, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.35884267297443617, "std_of_first_answer": 0.35884267297443617, "avg_entropy_of_first_answer": 2.4383302346254005, "lex_sim": 1.0}
{"question": "where was the first sonic drive in located", "answer": ["Salt Lake City, Utah"], "scores": [[0.028533935546875, 0.99951171875, 0.99853515625, 0.94091796875, 0.98388671875, 1.0]], "normalized_score": [0.545550525188446], "tokens": [["\u2581Salt", "\u2581Lake", "\u2581City", ",", "\u2581Ut", "ah"]], "entropy": [[4.875, 0.006450653076171875, 0.0139007568359375, 0.281005859375, 0.09759521484375, 0.002063751220703125]], "avg_entropy": [0.8793360392252604], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Woodward, Oklahoma", "score_of_biggest_cluster": 0.545550525188446, "score_of_first_answer": 0.545550525188446, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.028533935546875, "avg_score": 0.545550525188446, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3568925205159504, "std_of_first_answer": 0.3568925205159504, "avg_entropy_of_first_answer": 0.8793360392252604, "lex_sim": 1.0}
{"question": "who won the marathon in new york city", "answer": ["Lawrence Cherono"], "scores": [[0.002086639404296875, 0.9990234375, 0.99951171875]], "normalized_score": [0.1277233362197876], "tokens": [["\u2581Lawrence", "\u2581Cher", "ono"]], "entropy": [[1.677734375, 0.01146697998046875, 0.003643035888671875]], "avg_entropy": [0.5642814636230469], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Geoffrey Kamworor", "score_of_biggest_cluster": 0.1277233362197876, "score_of_first_answer": 0.1277233362197876, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.002086639404296875, "avg_score": 0.1277233362197876, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.47007564482558123, "std_of_first_answer": 0.47007564482558123, "avg_entropy_of_first_answer": 0.5642814636230469, "lex_sim": 1.0}
{"question": "through what process has the colorado river created the grand canyon in the usa", "answer": ["erosion from water and wind over millions of years"], "scores": [[0.75439453125, 1.0, 1.0, 0.18017578125, 0.11517333984375, 0.96142578125, 0.96044921875, 0.2998046875, 0.83203125, 0.99951171875, 0.9990234375]], "normalized_score": [0.5995875597000122], "tokens": [["\u2581er", "os", "ion", "\u2581from", "\u2581water", "\u2581and", "\u2581wind", "\u2581over", "\u2581millions", "\u2581of", "\u2581years"]], "entropy": [[1.2138671875, 0.00039124488830566406, 0.00072479248046875, 1.3837890625, 0.51025390625, 0.21337890625, 0.2159423828125, 1.6572265625, 0.64208984375, 0.00537872314453125, 0.008270263671875]], "avg_entropy": [0.53193753415888], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "erosion", "score_of_biggest_cluster": 0.5995875597000122, "score_of_first_answer": 0.5995875597000122, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.11517333984375, "avg_score": 0.5995875597000122, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.34023998779004316, "std_of_first_answer": 0.34023998779004316, "avg_entropy_of_first_answer": 0.53193753415888, "lex_sim": 1.0}
{"question": "when was half life 2 episode 2 released", "answer": ["October 31, 2007"], "scores": [[0.09014892578125, 0.99560546875, 0.1695556640625, 0.84765625, 0.93310546875, 0.998046875, 1.0, 1.0, 0.99951171875, 0.9990234375]], "normalized_score": [0.6425434947013855], "tokens": [["\u2581October", "\u2581", "3", "1", ",", "\u2581", "2", "0", "0", "7"]], "entropy": [[1.794921875, 0.032562255859375, 0.50927734375, 0.4306640625, 0.279296875, 0.0162811279296875, 0.00020623207092285156, 1.0132789611816406e-06, 0.0037841796875, 0.00836944580078125]], "avg_entropy": [0.30753644108772277], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "in 2007", "score_of_biggest_cluster": 0.6425434947013855, "score_of_first_answer": 0.6425434947013855, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.09014892578125, "avg_score": 0.6425434947013855, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3403130153011943, "std_of_first_answer": 0.3403130153011943, "avg_entropy_of_first_answer": 0.30753644108772277, "lex_sim": 1.0}
{"question": "who did puerto rico belong to before the u.s", "answer": ["Spain #MythsAndLegends: The Ancient Greek Creation Myth"], "scores": [[0.97802734375, 2.980232238769531e-07, 0.006191253662109375, 0.40625, 0.00106048583984375, 0.06365966796875, 0.255859375, 0.99658203125, 0.0010480880737304688, 0.0797119140625, 7.319450378417969e-05, 0.689453125, 0.0386962890625, 0.002880096435546875, 0.97021484375, 0.90869140625, 1.0]], "normalized_score": [0.02844584546983242], "tokens": [["\u2581Spain", "\u2581#", "M", "yth", "s", "And", "Leg", "ends", ":", "\u2581The", "\u2581An", "cient", "\u2581Greek", "\u2581Cre", "ation", "\u2581M", "yth"]], "entropy": [[0.1605224609375, 1.2158203125, 5.59765625, 3.306640625, 2.037109375, 3.896484375, 1.58203125, 0.0289306640625, 1.7900390625, 2.6171875, 3.896484375, 1.51953125, 4.21875, 3.78125, 0.17431640625, 0.448974609375, 0.0002903938293457031]], "avg_entropy": [2.1336481711443733], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ta\u00edno", "score_of_biggest_cluster": 0.02844584546983242, "score_of_first_answer": 0.02844584546983242, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.02844584546983242, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4219245034187508, "std_of_first_answer": 0.4219245034187508, "avg_entropy_of_first_answer": 2.1336481711443733, "lex_sim": 1.0}
{"question": "where did the first persian gulf war take place", "answer": ["The Persian Gulf War, also known as the Gulf War, was a conflict that took place in Iraq and Kuwait from 1990 to 1991."], "scores": [[0.041351318359375, 0.2169189453125, 1.0, 1.0, 1.0, 0.07080078125, 0.568359375, 0.99951171875, 1.0, 1.0, 0.99755859375, 1.0, 1.0, 1.0, 0.9248046875, 0.09869384765625, 0.86767578125, 0.9892578125, 0.90380859375, 0.9912109375, 1.0, 0.239990234375, 0.681640625, 1.0, 0.98681640625, 0.99658203125, 1.0, 0.99951171875, 0.97216796875, 0.9931640625, 0.9990234375, 1.0, 1.0, 0.99951171875, 0.9970703125, 0.9990234375, 1.0, 1.0, 1.0, 1.0, 0.994140625, 9.119510650634766e-06, 0.03436279296875, 0.06414794921875, 0.0751953125, 0.10638427734375, 4.649162292480469e-06]], "normalized_score": [0.3656175136566162], "tokens": [["\u2581The", "\u2581Pers", "ian", "\u2581G", "ulf", "\u2581War", ",", "\u2581also", "\u2581known", "\u2581as", "\u2581the", "\u2581G", "ulf", "\u2581War", ",", "\u2581was", "\u2581a", "\u2581conflict", "\u2581that", "\u2581took", "\u2581place", "\u2581in", "\u2581Ira", "q", "\u2581and", "\u2581K", "uw", "ait", "\u2581from", "\u2581", "1", "9", "9", "0", "\u2581to", "\u2581", "1", "9", "9", "1", ".", "\u2581#", "1", "1", "9", "5", "\u2581\u2013"]], "entropy": [[0.5302734375, 1.1845703125, 0.0008068084716796875, 0.00093841552734375, 0.00010961294174194336, 1.91015625, 0.884765625, 0.006137847900390625, 0.002201080322265625, 0.0003650188446044922, 0.0175323486328125, 0.0009245872497558594, 8.165836334228516e-05, 5.650520324707031e-05, 0.288330078125, 0.52294921875, 0.61376953125, 0.074951171875, 0.437744140625, 0.05413818359375, 0.0021152496337890625, 0.84716796875, 0.97509765625, 0.0005440711975097656, 0.08282470703125, 0.025360107421875, 0.0005469322204589844, 0.005207061767578125, 0.174072265625, 0.049285888671875, 0.00661468505859375, 0.00036978721618652344, 0.00012481212615966797, 0.003696441650390625, 0.020782470703125, 0.01018524169921875, 0.00021600723266601562, 0.00029659271240234375, 0.000675201416015625, 0.0022907257080078125, 0.0423583984375, 0.89794921875, 4.83984375, 2.576171875, 2.767578125, 2.66015625, 2.521484375]], "avg_entropy": [0.5328471850841603], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Israel", "score_of_biggest_cluster": 0.3656175136566162, "score_of_first_answer": 0.3656175136566162, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.649162292480469e-06, "avg_score": 0.3656175136566162, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3832726888286599, "std_of_first_answer": 0.3832726888286599, "avg_entropy_of_first_answer": 0.5328471850841603, "lex_sim": 1.0}
{"question": "who sings i wanna rock'n'roll all night", "answer": ["Def Leppard #MotivationMonday: The Power of Choice"], "scores": [[0.189208984375, 0.99951171875, 0.99951171875, 1.0, 4.410743713378906e-06, 0.0010442733764648438, 0.07769775390625, 0.0034122467041015625, 0.84521484375, 0.5205078125, 0.99560546875, 0.99853515625, 0.000823974609375, 0.0262908935546875, 0.1505126953125, 0.986328125, 0.0011434555053710938, 0.96533203125]], "normalized_score": [0.06435389071702957], "tokens": [["\u2581Def", "\u2581Le", "pp", "ard", "\u2581#", "M", "ot", "iv", "ation", "M", "ond", "ay", ":", "\u2581The", "\u2581Power", "\u2581of", "\u2581Cho", "ice"]], "entropy": [[1.130859375, 0.006206512451171875, 0.004436492919921875, 0.0004858970642089844, 0.859375, 5.04296875, 3.9296875, 0.1787109375, 0.6123046875, 1.9736328125, 0.038360595703125, 0.0124053955078125, 1.3671875, 4.0625, 3.96484375, 0.08477783203125, 2.94140625, 0.1640625]], "avg_entropy": [1.4652339882320828], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Kiss", "score_of_biggest_cluster": 0.06435389071702957, "score_of_first_answer": 0.06435389071702957, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.410743713378906e-06, "avg_score": 0.06435389071702957, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.45201434043920097, "std_of_first_answer": 0.45201434043920097, "avg_entropy_of_first_answer": 1.4652339882320828, "lex_sim": 1.0}
{"question": "last world series that didn't go 7 games", "answer": ["2017 World Series (Houston Astros defeated the Los Angeles Dodgers in a four-game sweep)."], "scores": [[0.8916015625, 0.89453125, 1.0, 0.94287109375, 0.3017578125, 0.814453125, 1.0, 0.2286376953125, 0.9404296875, 1.0, 1.0, 1.0, 1.0, 0.63427734375, 0.98583984375, 0.9912109375, 0.99951171875, 1.0, 1.0, 1.0, 0.9970703125, 0.406494140625, 0.325927734375, 0.99462890625, 1.0, 0.99951171875, 1.0, 0.1844482421875, 1.3113021850585938e-06, 0.0002562999725341797, 0.99560546875, 0.00817108154296875, 0.99951171875, 0.99755859375, 0.000762939453125, 0.1048583984375, 1.0192394256591797e-05, 0.0023899078369140625, 0.1046142578125, 0.489501953125, 1.0, 0.74267578125, 0.65380859375, 0.79296875, 0.1380615234375, 0.99951171875, 0.98828125, 0.035858154296875]], "normalized_score": [0.23135019838809967], "tokens": [["\u2581", "2", "0", "1", "7", "\u2581World", "\u2581Series", "\u2581(", "H", "ou", "ston", "\u2581Ast", "ros", "\u2581defeated", "\u2581the", "\u2581Los", "\u2581Angeles", "\u2581D", "od", "gers", "\u2581in", "\u2581a", "\u2581four", "-", "game", "\u2581swe", "ep", ").", "\u2581#", "Throw", "back", "Th", "urs", "day", ":", "\u2581The", "\u2581Best", "\u2581Com", "edy", "\u2581Mov", "ies", "\u2581of", "\u2581the", "\u2581", "8", "0", "s", "\u2581and"]], "entropy": [[0.5673828125, 0.338134765625, 0.00152587890625, 0.253173828125, 1.552734375, 0.7451171875, 0.0021572113037109375, 1.5986328125, 0.348876953125, 1.0728836059570312e-06, 0.00057220458984375, 0.00016379356384277344, 8.934736251831055e-05, 0.98291015625, 0.07537841796875, 0.05523681640625, 0.00522613525390625, 0.0016050338745117188, 1.4126300811767578e-05, 1.8298625946044922e-05, 0.021087646484375, 0.81884765625, 1.521484375, 0.034271240234375, 0.0014324188232421875, 0.005573272705078125, 5.4955482482910156e-05, 0.6259765625, 0.26953125, 3.83984375, 0.032012939453125, 1.833984375, 0.0058746337890625, 0.021942138671875, 1.5498046875, 3.3046875, 1.1474609375, 2.744140625, 0.748046875, 1.69140625, 0.00013637542724609375, 1.2265625, 0.91552734375, 0.787109375, 1.0537109375, 0.002902984619140625, 0.07305908203125, 2.625]], "avg_entropy": [0.6964671649038792], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2015", "score_of_biggest_cluster": 0.23135019838809967, "score_of_first_answer": 0.23135019838809967, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.3113021850585938e-06, "avg_score": 0.23135019838809967, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39648913485893017, "std_of_first_answer": 0.39648913485893017, "avg_entropy_of_first_answer": 0.6964671649038792, "lex_sim": 1.0}
{"question": "where does the name loyola university come from", "answer": ["It is named after Ignatius of Loyola, the founder of the Society of Jesus (the Jesuits)."], "scores": [[0.019073486328125, 0.390625, 0.99951171875, 0.99755859375, 0.71923828125, 1.0, 1.0, 0.99365234375, 1.0, 1.0, 1.0, 0.9619140625, 0.96240234375, 0.99853515625, 1.0, 1.0, 0.982421875, 1.0, 1.0, 0.84912109375, 0.38818359375, 1.0, 0.9970703125, 0.978515625, 3.5762786865234375e-07, 0.01078033447265625, 0.06585693359375, 0.001232147216796875, 0.26904296875, 0.2978515625, 0.028839111328125, 0.09857177734375, 0.0004324913024902344, 0.0926513671875, 0.1373291015625, 0.347900390625, 0.984375]], "normalized_score": [0.21524561941623688], "tokens": [["\u2581It", "\u2581is", "\u2581named", "\u2581after", "\u2581Ign", "ati", "us", "\u2581of", "\u2581Lo", "y", "ola", ",", "\u2581the", "\u2581founder", "\u2581of", "\u2581the", "\u2581Society", "\u2581of", "\u2581Jesus", "\u2581(", "the", "\u2581Jes", "uits", ").", "\u2581#", "2", "8", "-", "3", "0", ":", "\u2581The", "\u2581In", "cred", "ible", "\u2581H", "ulk"]], "entropy": [[1.794921875, 1.2216796875, 0.00527191162109375, 0.017303466796875, 1.0458984375, 0.00010126829147338867, 0.00017631053924560547, 0.04071044921875, 0.0004355907440185547, 8.165836334228516e-06, 0.0014810562133789062, 0.201416015625, 0.2030029296875, 0.01421356201171875, 0.0004506111145019531, 0.0007162094116210938, 0.09381103515625, 0.00015783309936523438, 0.0006289482116699219, 0.5283203125, 0.81884765625, 0.001285552978515625, 0.019775390625, 0.11962890625, 0.58642578125, 4.6953125, 2.6171875, 2.916015625, 3.46875, 1.9619140625, 2.3125, 5.09765625, 4.81640625, 3.291015625, 0.46484375, 3.130859375, 0.1009521484375]], "avg_entropy": [1.1240562716045894], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "St. Ignatius of Loyola", "score_of_biggest_cluster": 0.21524561941623688, "score_of_first_answer": 0.21524561941623688, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 3.5762786865234375e-07, "avg_score": 0.21524561941623688, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.42120255952929275, "std_of_first_answer": 0.42120255952929275, "avg_entropy_of_first_answer": 1.1240562716045894, "lex_sim": 1.0}
{"question": "when did clifford the big red dog first air on tv", "answer": ["September 16, 2000"], "scores": [[0.4970703125, 0.99853515625, 0.343994140625, 0.0168914794921875, 0.9375, 0.99853515625, 0.94482421875, 1.0, 0.99853515625, 0.998046875]], "normalized_score": [0.5501992702484131], "tokens": [["\u2581September", "\u2581", "1", "6", ",", "\u2581", "2", "0", "0", "0"]], "entropy": [[0.95751953125, 0.01165771484375, 1.1787109375, 1.6328125, 0.2489013671875, 0.010528564453125, 0.213623046875, 0.00012886524200439453, 0.0104827880859375, 0.0169677734375]], "avg_entropy": [0.4281333088874817], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "September 4, 2000", "score_of_biggest_cluster": 0.5501992702484131, "score_of_first_answer": 0.5501992702484131, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0168914794921875, "avg_score": 0.5501992702484131, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3381181740701182, "std_of_first_answer": 0.3381181740701182, "avg_entropy_of_first_answer": 0.4281333088874817, "lex_sim": 1.0}
{"question": "when is the last time the jaguars won a playoff game", "answer": ["2007"], "scores": [[0.267333984375, 0.97900390625, 0.99951171875, 0.99365234375, 0.99658203125]], "normalized_score": [0.7632640600204468], "tokens": [["\u2581", "2", "0", "0", "7"]], "entropy": [[1.8115234375, 0.10406494140625, 0.007526397705078125, 0.0382080078125, 0.024261474609375]], "avg_entropy": [0.39711685180664064], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2017", "score_of_biggest_cluster": 0.7632640600204468, "score_of_first_answer": 0.7632640600204468, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.267333984375, "avg_score": 0.7632640600204468, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2900272415783454, "std_of_first_answer": 0.2900272415783454, "avg_entropy_of_first_answer": 0.39711685180664064, "lex_sim": 1.0}
{"question": "where is the battle of britain flight based", "answer": ["RAF BBMF ##### SIMONE DAVIDSON"], "scores": [[0.043975830078125, 1.0, 0.0009908676147460938, 0.99951171875, 1.0, 0.0, 0.0002601146697998047, 0.0183868408203125, 0.004856109619140625, 0.0033588409423828125, 0.043914794921875, 0.289306640625, 0.2109375]], "normalized_score": [0.0], "tokens": [["\u2581R", "AF", "\u2581BB", "M", "F", "\u2581#####", "\u2581S", "IM", "ONE", "\u2581D", "AV", "ID", "SON"]], "entropy": [[1.1064453125, 0.0012664794921875, 1.421875, 0.0038356781005859375, 3.129243850708008e-05, 2.072265625, 1.7998046875, 3.927734375, 2.67578125, 3.533203125, 3.671875, 1.8642578125, 2.48046875]], "avg_entropy": [1.8891418759639447], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "RAF Coningsby in Lincolnshire", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40439196984805015, "std_of_first_answer": 0.40439196984805015, "avg_entropy_of_first_answer": 1.8891418759639447, "lex_sim": 1.0}
{"question": "who was the oldest man elected president of usa", "answer": ["Ronald Reagan."], "scores": [[0.26513671875, 1.0, 0.9970703125, 0.99951171875, 0.047637939453125, 0.65869140625, 0.99609375, 0.83544921875, 0.2489013671875, 0.87646484375, 0.99951171875, 0.99951171875, 1.0, 0.91259765625, 0.99267578125, 1.0, 1.0, 1.0, 0.998046875, 1.0, 0.87158203125, 8.940696716308594e-07, 0.00333404541015625, 0.6240234375, 4.202127456665039e-05, 0.95263671875, 0.0014009475708007812, 0.02081298828125, 0.09173583984375, 0.005031585693359375, 0.7607421875, 0.8701171875, 0.396484375, 0.78076171875, 0.98681640625, 0.99365234375]], "normalized_score": [0.2070365697145462], "tokens": [["\u2581Ron", "ald", "\u2581Re", "agan", ".", "\u2581He", "\u2581was", "\u2581elected", "\u2581President", "\u2581of", "\u2581the", "\u2581United", "\u2581States", "\u2581at", "\u2581the", "\u2581age", "\u2581of", "\u2581", "6", "9", ".", "\u2581#", "L", "ead", "You", "ng", ":", "\u2581How", "\u2581to", "\u2581develop", "\u2581leadership", "\u2581skills", "\u2581at", "\u2581a", "\u2581young", "\u2581age"]], "entropy": [[1.921875, 0.0006771087646484375, 0.0229034423828125, 0.003154754638671875, 1.439453125, 0.9052734375, 0.0304107666015625, 0.556640625, 1.5439453125, 0.427001953125, 0.0027828216552734375, 0.00640106201171875, 0.0021305084228515625, 0.355224609375, 0.04547119140625, 0.0002357959747314453, 0.0022716522216796875, 0.0020389556884765625, 0.0151824951171875, 0.0001735687255859375, 0.5732421875, 0.25732421875, 3.7734375, 1.373046875, 0.56591796875, 0.346923828125, 1.4677734375, 5.3984375, 2.794921875, 3.611328125, 1.17578125, 0.7626953125, 2.072265625, 0.67724609375, 0.090576171875, 0.04010009765625]], "avg_entropy": [0.8962296181254916], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ronald Reagan", "score_of_biggest_cluster": 0.2070365697145462, "score_of_first_answer": 0.2070365697145462, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 8.940696716308594e-07, "avg_score": 0.2070365697145462, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.39832832226187065, "std_of_first_answer": 0.39832832226187065, "avg_entropy_of_first_answer": 0.8962296181254916, "lex_sim": 1.0}
{"question": "where does a girl wear an engagement ring", "answer": ["On the ring finger of her left hand, following traditional customs."], "scores": [[0.7109375, 0.39892578125, 0.55126953125, 1.0, 0.99658203125, 0.779296875, 0.99658203125, 0.9990234375, 0.16552734375, 0.0015020370483398438, 0.7509765625, 0.498046875, 0.61669921875, 0.734375, 3.5762786865234375e-07, 8.422136306762695e-05, 0.99365234375, 0.281494140625, 0.99951171875, 0.99951171875, 0.004238128662109375, 0.12255859375, 5.9664249420166016e-05, 0.0002655982971191406, 0.0059967041015625, 0.99267578125, 0.177734375]], "normalized_score": [0.07465069741010666], "tokens": [["\u2581On", "\u2581the", "\u2581ring", "\u2581finger", "\u2581of", "\u2581her", "\u2581left", "\u2581hand", ",", "\u2581following", "\u2581traditional", "\u2581custom", "s", ".", "\u2581#", "Throw", "back", "Th", "urs", "day", ":", "\u2581The", "\u2581Great", "\u2581T", "urt", "le", "\u2581Race"]], "entropy": [[0.82373046875, 0.68994140625, 1.1484375, 0.00151824951171875, 0.02734375, 0.53515625, 0.023651123046875, 0.00824737548828125, 1.28125, 2.84765625, 1.0322265625, 1.3896484375, 0.861328125, 0.75830078125, 1.048828125, 3.77734375, 0.040252685546875, 2.009765625, 0.003238677978515625, 0.0038509368896484375, 1.5361328125, 3.955078125, 1.72265625, 1.349609375, 2.16015625, 0.047576904296875, 2.78515625]], "avg_entropy": [1.180299335055881], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "left hand ring finger", "score_of_biggest_cluster": 0.07465069741010666, "score_of_first_answer": 0.07465069741010666, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 3.5762786865234375e-07, "avg_score": 0.07465069741010666, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.40302274282436334, "std_of_first_answer": 0.40302274282436334, "avg_entropy_of_first_answer": 1.180299335055881, "lex_sim": 1.0}
{"question": "when was the worlds first laptop computer introduced in the market and by whom", "answer": ["The first laptop computer, the Epson HX-80, was introduced in 1982."], "scores": [[0.34423828125, 0.78515625, 0.958984375, 0.9931640625, 0.250244140625, 0.8564453125, 0.3486328125, 0.92236328125, 0.908203125, 1.0, 1.0, 0.456298828125, 0.990234375, 0.99609375, 0.99951171875, 0.98974609375, 0.986328125, 0.9521484375, 1.0, 1.0, 1.0, 0.08074951171875, 0.207763671875]], "normalized_score": [0.6735967397689819], "tokens": [["\u2581The", "\u2581first", "\u2581laptop", "\u2581computer", ",", "\u2581the", "\u2581E", "pson", "\u2581H", "X", "-", "8", "0", ",", "\u2581was", "\u2581introduced", "\u2581in", "\u2581", "1", "9", "8", "2", "."]], "entropy": [[1.287109375, 0.931640625, 0.23779296875, 0.050140380859375, 0.58837890625, 0.59423828125, 1.81640625, 0.61962890625, 0.5595703125, 0.0007839202880859375, 0.0023365020751953125, 0.70361328125, 0.06329345703125, 0.029266357421875, 0.0078125, 0.0767822265625, 0.08673095703125, 0.251708984375, 4.798173904418945e-05, 3.0875205993652344e-05, 0.0002434253692626953, 1.298828125, 0.64111328125]], "avg_entropy": [0.42815208175907965], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "September 1980", "score_of_biggest_cluster": 0.6735967397689819, "score_of_first_answer": 0.6735967397689819, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.08074951171875, "avg_score": 0.6735967397689819, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.30891111626487266, "std_of_first_answer": 0.30891111626487266, "avg_entropy_of_first_answer": 0.42815208175907965, "lex_sim": 1.0}
{"question": "sending money home to the native country is an example of", "answer": ["remittance."], "scores": [[0.80078125, 0.99853515625, 0.71240234375, 0.1988525390625, 4.172325134277344e-07, 0.1368408203125, 1.1920928955078125e-06, 0.98779296875, 0.91748046875, 0.406982421875, 0.9326171875, 0.90087890625, 0.91796875, 0.00022482872009277344, 0.96923828125, 0.9736328125, 0.1219482421875, 0.99169921875, 0.179443359375, 0.406982421875, 0.9970703125, 0.982421875, 0.978515625, 0.5556640625, 0.9990234375, 0.97998046875, 0.99951171875, 0.953125, 0.1141357421875, 1.0, 1.0, 0.943359375, 0.79638671875, 0.77099609375, 0.90673828125, 0.8876953125, 0.84375, 0.99951171875, 0.0258941650390625, 0.99951171875, 0.8447265625, 0.9814453125, 0.99072265625, 0.97412109375, 0.93017578125, 0.07470703125, 0.57861328125, 0.74072265625]], "normalized_score": [0.2978527545928955], "tokens": [["\u2581rem", "itt", "ance", ".", "\u2581#", "1", "\u2581New", "\u2581York", "\u2581Times", "\u2581best", "s", "elling", "\u2581author", "\u2581Sand", "ra", "\u2581Brown", "\u2581del", "ivers", "\u2581a", "\u2581heart", "-", "p", "ounding", "\u2581story", "\u2581of", "\u2581susp", "ense", "\u2581and", "\u2581bet", "ray", "al", "\u2581as", "\u2581a", "\u2581woman", "\u2581is", "\u2581drawn", "\u2581into", "\u2581a", "\u2581game", "\u2581of", "\u2581cat", "\u2581and", "\u2581mouse", "\u2581with", "\u2581a", "\u2581man", "\u2581she", "\u2581doesn"]], "entropy": [[0.5595703125, 0.0119171142578125, 0.6005859375, 1.1015625, 0.134521484375, 3.359375, 2.412109375, 0.1214599609375, 0.5107421875, 0.92578125, 0.283203125, 0.331298828125, 0.525390625, 3.25390625, 0.191650390625, 0.2392578125, 4.0234375, 0.049163818359375, 0.7802734375, 1.8984375, 0.0260162353515625, 0.116943359375, 0.11492919921875, 0.994140625, 0.00875091552734375, 0.154296875, 0.0026226043701171875, 0.277587890625, 3.39453125, 0.0003104209899902344, 0.001415252685546875, 0.2724609375, 0.65966796875, 0.77099609375, 0.59423828125, 0.50439453125, 0.46435546875, 0.002994537353515625, 1.7060546875, 0.005035400390625, 1.0126953125, 0.1002197265625, 0.056427001953125, 0.1446533203125, 0.26220703125, 3.736328125, 1.591796875, 1.2802734375]], "avg_entropy": [0.8243747452894846], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "international capital flows", "score_of_biggest_cluster": 0.2978527545928955, "score_of_first_answer": 0.2978527545928955, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.2978527545928955, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3548127552412766, "std_of_first_answer": 0.3548127552412766, "avg_entropy_of_first_answer": 0.8243747452894846, "lex_sim": 1.0}
{"question": "what happens to water that infiltrates the soil if it is not absorbed by the roots of plants", "answer": ["It can become groundwater or become part of surface runoff."], "scores": [[0.6923828125, 0.262451171875, 0.47607421875, 0.845703125, 0.978515625, 0.4755859375, 0.004772186279296875, 0.7001953125, 1.0, 0.374267578125, 0.6943359375, 0.99560546875, 0.82666015625, 1.2516975402832031e-06, 0.5361328125, 0.073486328125, 0.030609130859375, 0.322998046875, 0.0088958740234375, 0.83349609375, 0.0007243156433105469, 0.8955078125, 0.119140625, 0.9921875, 0.0869140625, 0.00014412403106689453, 0.034576416015625, 0.71728515625, 0.04547119140625, 0.82080078125, 0.86328125, 0.0021610260009765625, 0.276123046875, 1.0, 0.02313232421875, 0.32568359375, 0.0008673667907714844, 0.50244140625, 0.0117340087890625, 0.198486328125, 0.279541015625, 0.96142578125, 0.93115234375]], "normalized_score": [0.11671853065490723], "tokens": [["\u2581It", "\u2581can", "\u2581become", "\u2581ground", "water", "\u2581or", "\u2581become", "\u2581part", "\u2581of", "\u2581surface", "\u2581run", "off", ".", "\u2581Note", ":", "\u2581The", "\u2581information", "\u2581provided", "\u2581in", "\u2581this", "\u2581post", "\u2581is", "\u2581based", "\u2581on", "\u2581my", "\u2581personal", "\u2581experience", "\u2581and", "\u2581may", "\u2581not", "\u2581be", "\u2581a", "\u2581compreh", "ensive", "\u2581guide", "\u2581to", "\u2581working", "\u2581with", "\u2581children", "\u2581who", "\u2581st", "utter", "."]], "entropy": [[0.94921875, 2.0703125, 1.12890625, 0.487060546875, 0.1048583984375, 1.353515625, 2.662109375, 1.0361328125, 0.0014219284057617188, 1.2197265625, 0.634765625, 0.0299530029296875, 0.82861328125, 0.2978515625, 0.8837890625, 2.771484375, 3.73046875, 2.1484375, 1.21484375, 0.79345703125, 1.712890625, 0.650390625, 2.455078125, 0.054534912109375, 2.544921875, 1.615234375, 1.7939453125, 1.0146484375, 2.29296875, 0.671875, 0.65625, 1.6259765625, 2.599609375, 0.0009717941284179688, 2.203125, 1.271484375, 3.259765625, 1.619140625, 4.87890625, 2.2421875, 1.5751953125, 0.1668701171875, 0.419921875]], "avg_entropy": [1.4342516078505405], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "runoff", "score_of_biggest_cluster": 0.11671853065490723, "score_of_first_answer": 0.11671853065490723, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.2516975402832031e-06, "avg_score": 0.11671853065490723, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3751356291986745, "std_of_first_answer": 0.3751356291986745, "avg_entropy_of_first_answer": 1.4342516078505405, "lex_sim": 1.0}
{"question": "where does the grapes of wrath take place", "answer": ["The Grapes of Wrath takes place in the American Great Plains during the Great Depression."], "scores": [[0.309814453125, 0.125244140625, 1.0, 1.0, 0.99951171875, 0.998046875, 1.0, 1.0, 0.88916015625, 0.99951171875, 0.97705078125, 0.75537109375, 0.29150390625, 0.1451416015625, 0.9892578125, 1.0, 0.274169921875, 0.99951171875, 0.85791015625, 1.0, 1.0, 0.505859375, 1.6689300537109375e-06, 0.0013875961303710938, 0.002811431884765625, 0.02978515625, 0.043487548828125, 0.00013887882232666016, 0.00687408447265625, 0.00913238525390625, 0.11090087890625, 0.00855255126953125, 0.05645751953125, 0.9990234375, 0.2086181640625]], "normalized_score": [0.1302376091480255], "tokens": [["\u2581The", "\u2581G", "rap", "es", "\u2581of", "\u2581W", "r", "ath", "\u2581takes", "\u2581place", "\u2581in", "\u2581the", "\u2581American", "\u2581Great", "\u2581Pla", "ins", "\u2581during", "\u2581the", "\u2581Great", "\u2581De", "pression", ".", "\u2581#", "N", "Y", "F", "W", "\u2581\u2013", "\u2581M", "AG", "DA", "\u2581B", "UT", "RY", "MO"]], "entropy": [[1.6171875, 1.5927734375, 0.0002536773681640625, 2.0265579223632812e-06, 0.0032100677490234375, 0.01451873779296875, 0.0007781982421875, 0.0001461505889892578, 0.5205078125, 0.003021240234375, 0.124755859375, 0.62451171875, 1.517578125, 2.158203125, 0.06048583984375, 0.00014901161193847656, 1.5927734375, 0.00498199462890625, 0.52685546875, 0.0006127357482910156, 3.445148468017578e-05, 1.17578125, 1.2119140625, 4.234375, 3.21484375, 2.896484375, 3.1484375, 1.736328125, 5.52734375, 4.40625, 1.1103515625, 1.478515625, 2.595703125, 0.00885772705078125, 1.4375]], "avg_entropy": [1.2727436133793422], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Oklahoma", "score_of_biggest_cluster": 0.1302376091480255, "score_of_first_answer": 0.1302376091480255, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.6689300537109375e-06, "avg_score": 0.1302376091480255, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.43928527839012455, "std_of_first_answer": 0.43928527839012455, "avg_entropy_of_first_answer": 1.2727436133793422, "lex_sim": 1.0}
{"question": "when did amnesia the dark descent come out", "answer": ["September 8, 2010 #1097 : Lecture d'Andy Hertzfeld- What was the Apple I?"], "scores": [[0.00875091552734375, 0.99755859375, 0.9580078125, 0.931640625, 0.99853515625, 1.0, 1.0, 1.0, 1.0, 2.384185791015625e-07, 0.0161590576171875, 0.2177734375, 0.0287628173828125, 0.06341552734375, 5.364418029785156e-06, 0.0014505386352539062, 0.0003254413604736328, 0.3662109375, 0.0002562999725341797, 0.95263671875, 0.0012388229370117188, 0.012420654296875, 0.00962066650390625, 0.1116943359375, 0.9951171875, 0.955078125, 0.0009245872497558594, 0.00043654441833496094, 0.2232666015625, 0.8232421875, 0.0161590576171875, 0.317138671875, 0.1263427734375]], "normalized_score": [0.035876013338565826], "tokens": [["\u2581September", "\u2581", "8", ",", "\u2581", "2", "0", "1", "0", "\u2581#", "1", "0", "9", "7", "\u2581:", "\u2581L", "ect", "ure", "\u2581d", "'", "And", "y", "\u2581H", "ert", "z", "feld", "-", "\u2581What", "\u2581was", "\u2581the", "\u2581Apple", "\u2581I", "?"]], "entropy": [[0.5087890625, 0.019683837890625, 0.2132568359375, 0.267333984375, 0.0106048583984375, 0.00010061264038085938, 1.0132789611816406e-06, 0.0005702972412109375, 0.0013322830200195312, 1.0361328125, 5.8984375, 3.294921875, 3.306640625, 2.947265625, 2.744140625, 6.32421875, 4.52734375, 2.38671875, 2.990234375, 0.31298828125, 2.400390625, 2.375, 4.30078125, 3.357421875, 0.046234130859375, 0.218505859375, 2.8515625, 5.671875, 2.802734375, 0.85888671875, 4.59765625, 2.119140625, 2.595703125]], "avg_entropy": [2.1511093360005002], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "8 September 2010", "score_of_biggest_cluster": 0.035876013338565826, "score_of_first_answer": 0.035876013338565826, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.035876013338565826, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44053124560004203, "std_of_first_answer": 0.44053124560004203, "avg_entropy_of_first_answer": 2.1511093360005002, "lex_sim": 1.0}
{"question": "what is the rank of india in economic growth", "answer": ["India's rank in economic growth is currently 6th in the world."], "scores": [[0.208251953125, 0.08917236328125, 1.0, 0.6220703125, 0.96142578125, 0.94189453125, 0.9970703125, 0.24072265625, 0.0972900390625, 0.5400390625, 0.73681640625, 0.99658203125, 0.72705078125, 0.9990234375, 0.99951171875, 0.8916015625, 8.940696716308594e-07, 0.002777099609375, 0.01003265380859375, 0.006992340087890625, 0.01291656494140625, 0.0009207725524902344, 0.0016689300537109375, 0.003055572509765625, 0.214599609375, 0.396484375, 0.9814453125, 0.896484375, 0.058868408203125, 0.8076171875]], "normalized_score": [0.10290003567934036], "tokens": [["\u2581India", "'", "s", "\u2581rank", "\u2581in", "\u2581economic", "\u2581growth", "\u2581is", "\u2581currently", "\u2581", "6", "th", "\u2581in", "\u2581the", "\u2581world", ".", "\u2581#", "5", "9", ":", "\u2581The", "\u2581Big", "\u2581E", "cho", "\u2581(", "2", "0", "1", "1", ")"]], "entropy": [[2.017578125, 0.7275390625, 3.3020973205566406e-05, 1.0615234375, 0.237548828125, 0.288818359375, 0.0200347900390625, 1.095703125, 1.9287109375, 1.5380859375, 0.69189453125, 0.0296173095703125, 0.95751953125, 0.00887298583984375, 0.004390716552734375, 0.491455078125, 0.97412109375, 2.439453125, 3.494140625, 2.57421875, 4.703125, 5.00390625, 2.83984375, 3.15234375, 2.978515625, 3.6015625, 0.15576171875, 0.37109375, 1.2685546875, 1.0205078125]], "avg_entropy": [1.5225491404533387], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "12 / 225", "score_of_biggest_cluster": 0.10290003567934036, "score_of_first_answer": 0.10290003567934036, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 8.940696716308594e-07, "avg_score": 0.10290003567934036, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4136492681831996, "std_of_first_answer": 0.4136492681831996, "avg_entropy_of_first_answer": 1.5225491404533387, "lex_sim": 1.0}
{"question": "who played bubba in the heat of the night", "answer": ["Gail Fisher #96 - The Hour of the Time"], "scores": [[0.0264739990234375, 0.2607421875, 0.26416015625, 0.9990234375, 7.748603820800781e-07, 0.0006756782531738281, 0.0408935546875, 0.00021147727966308594, 0.035797119140625, 0.00585174560546875, 0.02520751953125, 0.1417236328125, 0.96826171875, 0.0003695487976074219]], "normalized_score": [0.012474092654883862], "tokens": [["\u2581G", "ail", "\u2581Fish", "er", "\u2581#", "9", "6", "\u2581-", "\u2581The", "\u2581H", "our", "\u2581of", "\u2581the", "\u2581Time"]], "entropy": [[2.951171875, 1.6630859375, 0.9697265625, 0.00899505615234375, 0.9296875, 1.5732421875, 2.990234375, 1.939453125, 5.0546875, 4.78515625, 2.880859375, 1.6298828125, 0.2491455078125, 2.486328125]], "avg_entropy": [2.1508325849260603], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Carlos Alan Autry Jr.", "score_of_biggest_cluster": 0.012474092654883862, "score_of_first_answer": 0.012474092654883862, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 7.748603820800781e-07, "avg_score": 0.012474092654883862, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.33273028575411584, "std_of_first_answer": 0.33273028575411584, "avg_entropy_of_first_answer": 2.1508325849260603, "lex_sim": 1.0}
{"question": "what episode does goku give up against cell", "answer": ["Episode 23 #235: The Enduring Appeal of Sherlock Holmes"], "scores": [[0.28271484375, 1.0, 0.99853515625, 0.67529296875, 0.34716796875, 2.7418136596679688e-06, 0.3896484375, 0.045928955078125, 0.019866943359375, 0.01152801513671875, 0.062408447265625, 0.01000213623046875, 8.344650268554688e-07, 6.735324859619141e-06, 0.97509765625, 0.9951171875, 0.93359375, 1.1920928955078125e-07, 0.97412109375, 0.9892578125, 1.0]], "normalized_score": [0.0252122413367033], "tokens": [["\u2581E", "pisode", "\u2581", "2", "3", "\u2581#", "2", "3", "5", ":", "\u2581The", "\u2581End", "uring", "\u2581App", "e", "al", "\u2581of", "\u2581Sher", "lock", "\u2581Hol", "mes"]], "entropy": [[1.3701171875, 0.0004143714904785156, 0.01140594482421875, 0.9169921875, 1.755859375, 1.7890625, 1.7080078125, 0.94189453125, 1.6474609375, 1.3876953125, 0.97802734375, 3.7421875, 0.091796875, 1.5712890625, 0.1724853515625, 0.03546142578125, 0.384033203125, 1.4296875, 0.1617431640625, 0.08551025390625, 0.0002181529998779297]], "avg_entropy": [0.9610166663215274], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "165", "score_of_biggest_cluster": 0.0252122413367033, "score_of_first_answer": 0.0252122413367033, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.0252122413367033, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43981755556553326, "std_of_first_answer": 0.43981755556553326, "avg_entropy_of_first_answer": 0.9610166663215274, "lex_sim": 1.0}
{"question": "where did the ancestors of the domestic goat originate", "answer": ["Domestic goats originated from the wild goats found in Southwest Asia and Eastern North Africa."], "scores": [[0.009796142578125, 1.0, 0.97265625, 0.98876953125, 0.495849609375, 0.95654296875, 0.472412109375, 0.80859375, 0.94287109375, 0.998046875, 0.640625, 0.1473388671875, 0.99755859375, 0.208984375, 0.93359375, 0.9833984375, 0.7392578125, 0.90625, 0.0701904296875, 0.9951171875, 0.89794921875, 0.0, 1.6868114471435547e-05, 0.08856201171875, 0.0079345703125, 0.433837890625, 0.01032257080078125, 0.1619873046875, 0.89990234375, 0.99951171875, 0.0300750732421875]], "normalized_score": [0.0], "tokens": [["\u2581Dom", "estic", "\u2581go", "ats", "\u2581origin", "ated", "\u2581from", "\u2581the", "\u2581wild", "\u2581go", "ats", "\u2581found", "\u2581in", "\u2581South", "west", "\u2581Asia", "\u2581and", "\u2581Eastern", "\u2581North", "\u2581Africa", ".", "\u2581#####", "\u2581D", "AN", "'", "S", "\u2581J", "OUR", "N", "AL", "\u2581#####"]], "entropy": [[2.599609375, 0.00138092041015625, 0.137939453125, 0.060546875, 1.419921875, 0.180908203125, 0.69482421875, 1.0703125, 0.35205078125, 0.0201873779296875, 0.65283203125, 0.603515625, 0.0209808349609375, 1.962890625, 0.29150390625, 0.08782958984375, 0.7705078125, 0.4921875, 0.292724609375, 0.034423828125, 0.439697265625, 1.03515625, 1.12109375, 2.09765625, 4.2421875, 0.6904296875, 3.298828125, 1.8447265625, 0.33349609375, 0.00701904296875, 2.6875]], "avg_entropy": [0.9530602732012349], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Iran", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4071757606972818, "std_of_first_answer": 0.4071757606972818, "avg_entropy_of_first_answer": 0.9530602732012349, "lex_sim": 1.0}
{"question": "who played the original wonder woman on tv", "answer": ["Lynda Carter"], "scores": [[0.8544921875, 1.0, 1.0, 1.0]], "normalized_score": [0.9614506959915161], "tokens": [["\u2581Ly", "nd", "a", "\u2581Carter"]], "entropy": [[0.7021484375, 6.860494613647461e-05, 1.8477439880371094e-05, 0.0010194778442382812]], "avg_entropy": [0.17581374943256378], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Lynda Carter", "score_of_biggest_cluster": 0.9614506959915161, "score_of_first_answer": 0.9614506959915161, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.8544921875, "avg_score": 0.9614506959915161, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.06300673103705144, "std_of_first_answer": 0.06300673103705144, "avg_entropy_of_first_answer": 0.17581374943256378, "lex_sim": 1.0}
{"question": "how many episodes are in chicago fire season 4", "answer": ["23 ### What is the **Fermi Paradox**?"], "scores": [[0.9921875, 0.998046875, 0.7265625, 0.0, 0.0019817352294921875, 0.351318359375, 0.673828125, 0.0011920928955078125, 0.0013628005981445312, 0.02490234375, 0.84765625, 0.8701171875, 1.0, 1.0, 0.982421875, 0.87548828125]], "normalized_score": [0.0], "tokens": [["\u2581", "2", "3", "\u2581###", "\u2581What", "\u2581is", "\u2581the", "\u2581**", "F", "erm", "i", "\u2581Par", "ado", "x", "**", "?"]], "entropy": [[0.05810546875, 0.0158538818359375, 0.6416015625, 0.82275390625, 5.3046875, 3.6171875, 1.638671875, 4.44921875, 5.203125, 3.921875, 0.4462890625, 0.57666015625, 0.0002675056457519531, 6.580352783203125e-05, 0.11663818359375, 0.6572265625]], "avg_entropy": [1.7168892323970795], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "23", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42081044209979707, "std_of_first_answer": 0.42081044209979707, "avg_entropy_of_first_answer": 1.7168892323970795, "lex_sim": 1.0}
{"question": "what was the name of darth vader star destroyer", "answer": ["Executor ### What are the best ways to stay healthy during pregnancy?"], "scores": [[0.2440185546875, 0.9951171875, 0.0, 0.0012073516845703125, 0.058990478515625, 0.433349609375, 0.030548095703125, 0.0181121826171875, 0.947265625, 0.006793975830078125, 0.12127685546875, 0.9990234375, 0.2274169921875, 0.270263671875, 0.99951171875, 0.99853515625, 0.93408203125]], "normalized_score": [0.0], "tokens": [["\u2581Exec", "utor", "\u2581###", "\u2581What", "\u2581are", "\u2581the", "\u2581best", "\u2581ways", "\u2581to", "\u2581stay", "\u2581health", "y", "\u2581during", "\u2581pre", "gn", "ancy", "?"]], "entropy": [[2.548828125, 0.0364990234375, 0.4453125, 5.03125, 2.775390625, 2.404296875, 5.4921875, 6.16796875, 0.331298828125, 4.35546875, 2.33203125, 0.00907135009765625, 2.1484375, 2.28125, 0.00262451171875, 0.01207733154296875, 0.451171875]], "avg_entropy": [2.166186164407169], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Devastator", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42172906578209146, "std_of_first_answer": 0.42172906578209146, "avg_entropy_of_first_answer": 2.166186164407169, "lex_sim": 1.0}
{"question": "what is the ethnic background of the shib sibs", "answer": ["The Shib Sibs are of Japanese descent."], "scores": [[0.293212890625, 0.9873046875, 0.9853515625, 0.919921875, 1.0, 0.7998046875, 0.82080078125, 0.38330078125, 0.67626953125, 0.98291015625, 1.6689300537109375e-06, 8.237361907958984e-05, 4.929304122924805e-05, 0.00336456298828125, 0.04193115234375, 5.614757537841797e-05, 0.2430419921875, 0.08868408203125, 0.99609375, 0.0137481689453125, 0.01091766357421875, 0.8515625, 0.70556640625, 0.1575927734375, 0.00848388671875, 0.919921875, 0.1514892578125, 0.99951171875, 0.98046875, 0.97509765625, 0.986328125, 0.703125, 0.05413818359375, 0.64599609375, 0.5703125, 0.00203704833984375, 0.161865234375, 0.650390625, 0.955078125, 0.9990234375, 0.0015439987182617188, 0.216064453125]], "normalized_score": [0.09937018156051636], "tokens": [["\u2581The", "\u2581Sh", "ib", "\u2581Sib", "s", "\u2581are", "\u2581of", "\u2581Japanese", "\u2581descent", ".", "\u2581#", "W", "ATCH", ":", "\u2581#", "Ind", "ia", "\u2019", "s", "\u2581first", "\u2581trans", "gender", "\u2581band", ",", "\u2581\u201c", "The", "\u2581", "6", "-", "Pack", "\u2581Band", "\u201d,", "\u2581perform", "\u2581at", "\u2581#", "IG", "L", "F", "2", "0", "1", "6"]], "entropy": [[2.6796875, 0.09552001953125, 0.080322265625, 0.2861328125, 0.00042176246643066406, 0.619140625, 0.8466796875, 0.83056640625, 1.052734375, 0.10308837890625, 0.822265625, 1.876953125, 0.1114501953125, 2.232421875, 3.20703125, 3.66796875, 1.423828125, 3.326171875, 0.035430908203125, 1.2509765625, 2.265625, 0.9111328125, 1.359375, 3.845703125, 1.529296875, 0.4140625, 1.103515625, 0.0026836395263671875, 0.1126708984375, 0.12225341796875, 0.0914306640625, 0.85693359375, 3.884765625, 1.552734375, 1.72265625, 3.138671875, 3.142578125, 1.4833984375, 0.323974609375, 0.009521484375, 0.0389404296875, 1.302734375]], "avg_entropy": [1.2800821633565993], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Japanese", "score_of_biggest_cluster": 0.09937018156051636, "score_of_first_answer": 0.09937018156051636, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.6689300537109375e-06, "avg_score": 0.09937018156051636, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.40904892449293323, "std_of_first_answer": 0.40904892449293323, "avg_entropy_of_first_answer": 1.2800821633565993, "lex_sim": 1.0}
{"question": "how do you say evil eye in greek", "answer": ["\"evil eye\""], "scores": [[0.607421875, 0.2783203125, 0.99853515625, 0.998046875, 0.9990234375]], "normalized_score": [0.7002047896385193], "tokens": [["\u2581\"", "ev", "il", "\u2581eye", "\""]], "entropy": [[0.98828125, 3.919921875, 0.0163726806640625, 0.0203704833984375, 0.00989532470703125]], "avg_entropy": [0.9909683227539062], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "matiasma", "score_of_biggest_cluster": 0.7002047896385193, "score_of_first_answer": 0.7002047896385193, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 0.2783203125, "avg_score": 0.7002047896385193, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.29143419719790387, "std_of_first_answer": 0.29143419719790387, "avg_entropy_of_first_answer": 0.9909683227539062, "lex_sim": 1.0}
{"question": "who sings will you still love me when i'm not young and beautiful", "answer": ["Loretta Lynn"], "scores": [[0.1298828125, 0.5830078125, 1.0, 0.99853515625]], "normalized_score": [0.5243814587593079], "tokens": [["\u2581Lor", "etta", "\u2581Lyn", "n"]], "entropy": [[2.78515625, 0.73828125, 0.00281524658203125, 0.01178741455078125]], "avg_entropy": [0.8845100402832031], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Lana Del Rey", "score_of_biggest_cluster": 0.5243814587593079, "score_of_first_answer": 0.5243814587593079, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.1298828125, "avg_score": 0.5243814587593079, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.35912486368927593, "std_of_first_answer": 0.35912486368927593, "avg_entropy_of_first_answer": 0.8845100402832031, "lex_sim": 1.0}
{"question": "what are the first and second major religions in france", "answer": ["Christianity and Irreligion #117 4909A 50 Street NW, Calgary, Alberta, T3A 0M5"], "scores": [[0.833984375, 1.0, 0.8271484375, 0.384521484375, 0.99951171875, 0.99951171875, 0.9970703125, 2.384185791015625e-07, 0.09002685546875, 0.0184173583984375, 0.062744140625, 0.0005307197570800781, 0.035858154296875, 0.066650390625, 0.0218505859375, 0.0177764892578125, 2.944469451904297e-05, 0.06109619140625, 0.061187744140625, 0.144775390625, 2.6226043701171875e-06, 0.1561279296875, 0.884765625, 0.240234375, 0.76953125, 1.0, 1.0, 0.96044921875, 0.304443359375, 0.9990234375, 0.787109375, 0.68212890625, 0.128173828125, 0.97998046875, 0.98388671875, 0.445068359375, 0.1600341796875, 0.09423828125]], "normalized_score": [0.09215442836284637], "tokens": [["\u2581Christian", "ity", "\u2581and", "\u2581Ir", "rel", "ig", "ion", "\u2581#", "1", "1", "7", "\u2581", "4", "9", "0", "9", "A", "\u2581", "5", "0", "\u2581Street", "\u2581N", "W", ",", "\u2581Cal", "g", "ary", ",", "\u2581Al", "berta", ",", "\u2581T", "3", "A", "\u2581", "0", "M", "5"]], "entropy": [[0.62744140625, 0.0001652240753173828, 0.53271484375, 0.89306640625, 0.0029888153076171875, 0.002742767333984375, 0.019317626953125, 1.3359375, 3.9375, 3.158203125, 3.029296875, 2.736328125, 3.328125, 2.80859375, 2.54296875, 3.123046875, 2.861328125, 3.798828125, 2.259765625, 3.111328125, 2.99609375, 3.095703125, 0.82958984375, 1.85546875, 1.0576171875, 0.0022678375244140625, 0.0008578300476074219, 0.261474609375, 1.189453125, 0.0089263916015625, 0.845703125, 0.732421875, 0.9794921875, 0.1387939453125, 0.1356201171875, 1.3603515625, 2.650390625, 1.9970703125]], "avg_entropy": [1.585446928676806], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Islam", "score_of_biggest_cluster": 0.09215442836284637, "score_of_first_answer": 0.09215442836284637, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.09215442836284637, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.414102056536525, "std_of_first_answer": 0.414102056536525, "avg_entropy_of_first_answer": 1.585446928676806, "lex_sim": 1.0}
{"question": "who was the girl in the video brenda got a baby", "answer": ["Tracy Lewis"], "scores": [[0.000698089599609375, 0.16796875, 0.00046515464782714844]], "normalized_score": [0.0037923839408904314], "tokens": [["\u2581T", "racy", "\u2581Lewis"]], "entropy": [[1.5615234375, 1.6455078125, 1.53125]], "avg_entropy": [1.5794270833333333], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ethel \"Edy\" Proctor", "score_of_biggest_cluster": 0.0037923839408904314, "score_of_first_answer": 0.0037923839408904314, "max_score_of_first_answer": 0.16796875, "min_score_of_first_answer": 0.00046515464782714844, "avg_score": 0.0037923839408904314, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.07890710610541363, "std_of_first_answer": 0.07890710610541363, "avg_entropy_of_first_answer": 1.5794270833333333, "lex_sim": 1.0}
{"question": "who is responsible for establishing local licensing forum", "answer": ["Local Licensing Forum #463549 - 12/16/19 03:58 PM Re: A New Look at an Old Fantasy: Fool's Fate [Re"], "scores": [[0.09912109375, 0.66552734375, 1.0, 1.0, 0.95849609375, 1.5497207641601562e-06, 0.07366943359375, 0.00995635986328125, 0.00783538818359375, 0.0258941650390625, 0.03314208984375, 0.0222625732421875, 0.0008001327514648438, 0.0107269287109375, 0.2203369140625, 0.292236328125, 0.0110931396484375, 0.348876953125, 0.06951904296875, 0.9091796875, 0.1444091796875, 0.7607421875, 0.0079193115234375, 0.059722900390625, 0.0887451171875, 0.98583984375, 0.09735107421875, 0.09478759765625, 0.450439453125, 0.0029277801513671875, 0.9423828125, 0.002796173095703125, 0.0218048095703125, 0.00917816162109375, 0.349853515625, 0.03131103515625, 0.92236328125, 0.0001710653305053711, 0.98681640625, 0.047637939453125, 0.0055999755859375, 0.001987457275390625, 0.2203369140625, 0.99951171875, 0.0244903564453125, 0.65087890625, 0.31884765625, 0.9931640625]], "normalized_score": [0.06080768629908562], "tokens": [["\u2581Local", "\u2581Lic", "ens", "ing", "\u2581Forum", "\u2581#", "4", "6", "3", "5", "4", "9", "\u2581-", "\u2581", "1", "2", "/", "1", "6", "/", "1", "9", "\u2581", "0", "3", ":", "5", "8", "\u2581PM", "\u2581Re", ":", "\u2581A", "\u2581New", "\u2581Look", "\u2581at", "\u2581an", "\u2581Old", "\u2581Fant", "asy", ":", "\u2581F", "ool", "'", "s", "\u2581F", "ate", "\u2581[", "Re"]], "entropy": [[2.775390625, 1.4990234375, 0.0005831718444824219, 0.00010561943054199219, 0.2822265625, 1.91796875, 2.224609375, 2.181640625, 2.638671875, 2.779296875, 2.76953125, 2.486328125, 2.7265625, 5.74609375, 2.447265625, 2.84375, 1.4013671875, 1.7216796875, 2.392578125, 0.54443359375, 0.8994140625, 1.0068359375, 1.5400390625, 1.806640625, 2.390625, 0.1142578125, 1.771484375, 2.283203125, 2.03125, 2.6328125, 0.4111328125, 4.3203125, 6.14453125, 4.625, 2.4765625, 4.7890625, 0.493896484375, 3.92578125, 0.10723876953125, 3.544921875, 5.55078125, 5.1171875, 2.41015625, 0.007293701171875, 2.8203125, 1.740234375, 3.408203125, 0.05126953125]], "avg_entropy": [2.287490571538607], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "unitary authorities", "score_of_biggest_cluster": 0.06080768629908562, "score_of_first_answer": 0.06080768629908562, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.5497207641601562e-06, "avg_score": 0.06080768629908562, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3817260031889257, "std_of_first_answer": 0.3817260031889257, "avg_entropy_of_first_answer": 2.287490571538607, "lex_sim": 1.0}
{"question": "who played the mom in the partridge family", "answer": ["Shirley Jones #9051598, By MrRubik What do you think of this new Xbox 360 dashboard update?"], "scores": [[0.99365234375, 1.0, 1.0, 0.998046875, 1.7881393432617188e-07, 0.00550079345703125, 0.05908203125, 0.04461669921875, 0.09490966796875, 0.04656982421875, 0.040802001953125, 0.067138671875, 0.0034656524658203125, 0.00021767616271972656, 0.00016009807586669922, 0.0010318756103515625, 0.003932952880859375, 0.040863037109375, 3.3974647521972656e-06, 0.02032470703125, 0.89990234375, 0.1751708984375, 0.287841796875, 0.296875, 0.01229095458984375, 5.745887756347656e-05, 0.0047607421875, 0.014862060546875, 0.34130859375, 0.9853515625, 0.9990234375, 0.004852294921875, 0.9814453125, 0.1519775390625, 0.853515625]], "normalized_score": [0.02475673332810402], "tokens": [["\u2581Sh", "ir", "ley", "\u2581Jones", "\u2581#", "9", "0", "5", "1", "5", "9", "8", ",", "\u2581By", "\u2581Mr", "R", "ub", "ik", "\u2581What", "\u2581do", "\u2581you", "\u2581think", "\u2581of", "\u2581this", "\u2581new", "\u2581X", "box", "\u2581", "3", "6", "0", "\u2581dash", "board", "\u2581update", "?"]], "entropy": [[0.0726318359375, 0.0003559589385986328, 7.18235969543457e-05, 0.019012451171875, 0.65673828125, 4.8671875, 3.578125, 2.6640625, 2.80859375, 3.013671875, 2.939453125, 2.8828125, 2.890625, 3.783203125, 3.66796875, 3.5234375, 4.48828125, 2.841796875, 3.62109375, 3.470703125, 0.66064453125, 1.994140625, 2.146484375, 3.3125, 2.185546875, 5.8671875, 4.62109375, 2.3671875, 1.4853515625, 0.1392822265625, 0.011077880859375, 3.880859375, 0.172607421875, 1.8779296875, 1.0537109375]], "avg_entropy": [2.3875837206840513], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Shirley Mae Jones", "score_of_biggest_cluster": 0.02475673332810402, "score_of_first_answer": 0.02475673332810402, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.02475673332810402, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4040061302724826, "std_of_first_answer": 0.4040061302724826, "avg_entropy_of_first_answer": 2.3875837206840513, "lex_sim": 1.0}
{"question": "when was corporal punishment banned in south africa", "answer": ["1997 #Telef\u00f3nica"], "scores": [[0.87646484375, 0.99951171875, 1.0, 0.99951171875, 0.970703125, 5.960464477539063e-08, 0.0025177001953125, 0.0018634796142578125, 0.0015468597412109375, 0.404052734375]], "normalized_score": [0.026133021339774132], "tokens": [["\u2581", "1", "9", "9", "7", "\u2581#", "T", "ele", "f", "\u00f3nica"]], "entropy": [[0.6455078125, 0.0029506683349609375, 0.00020551681518554688, 0.00266265869140625, 0.149658203125, 0.8681640625, 5.58203125, 0.7265625, 0.55224609375, 3.3984375]], "avg_entropy": [1.1928426265716552], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1997", "score_of_biggest_cluster": 0.026133021339774132, "score_of_first_answer": 0.026133021339774132, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.026133021339774132, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4592427120738358, "std_of_first_answer": 0.4592427120738358, "avg_entropy_of_first_answer": 1.1928426265716552, "lex_sim": 1.0}
{"question": "who played doctor smith in lost in space", "answer": ["Bill Mumy"], "scores": [[0.0210113525390625, 1.0, 0.998046875, 1.0]], "normalized_score": [0.3805408179759979], "tokens": [["\u2581Bill", "\u2581M", "um", "y"]], "entropy": [[0.58203125, 0.0016374588012695312, 0.016571044921875, 4.26173210144043e-05]], "avg_entropy": [0.15007059276103973], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Jonathan Harris", "score_of_biggest_cluster": 0.3805408179759979, "score_of_first_answer": 0.3805408179759979, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0210113525390625, "avg_score": 0.3805408179759979, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4236333604412429, "std_of_first_answer": 0.4236333604412429, "avg_entropy_of_first_answer": 0.15007059276103973, "lex_sim": 1.0}
{"question": "what is the oasis in ready player one", "answer": ["OASIS"], "scores": [[0.8681640625, 0.78271484375, 0.9990234375]], "normalized_score": [0.8788747787475586], "tokens": [["\u2581O", "AS", "IS"]], "entropy": [[0.6923828125, 0.52587890625, 0.00914764404296875]], "avg_entropy": [0.40913645426432294], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "a virtual reality simulator", "score_of_biggest_cluster": 0.8788747787475586, "score_of_first_answer": 0.8788747787475586, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 0.78271484375, "avg_score": 0.8788747787475586, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.08895389113997237, "std_of_first_answer": 0.08895389113997237, "avg_entropy_of_first_answer": 0.40913645426432294, "lex_sim": 1.0}
{"question": "what happened to the actor who played frost on rizzoli and isles", "answer": ["He was written off the show due to creative differences."], "scores": [[0.212646484375, 0.0709228515625, 0.0921630859375, 0.037322998046875, 0.9970703125, 0.998046875, 0.62451171875, 1.0, 0.03375244140625, 1.0, 0.90185546875, 0.64453125]], "normalized_score": [0.30438509583473206], "tokens": [["\u2581He", "\u2581was", "\u2581written", "\u2581off", "\u2581the", "\u2581show", "\u2581due", "\u2581to", "\u2581cre", "ative", "\u2581differences", "."]], "entropy": [[2.599609375, 0.90625, 2.453125, 0.16357421875, 0.022186279296875, 0.0164642333984375, 1.2822265625, 0.00115966796875, 2.41796875, 0.000438690185546875, 0.39306640625, 0.92822265625]], "avg_entropy": [0.9320243199666342], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "committed suicide", "score_of_biggest_cluster": 0.30438509583473206, "score_of_first_answer": 0.30438509583473206, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.03375244140625, "avg_score": 0.30438509583473206, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4109116679209625, "std_of_first_answer": 0.4109116679209625, "avg_entropy_of_first_answer": 0.9320243199666342, "lex_sim": 1.0}
{"question": "who are the artists in the traveling wilburys", "answer": ["George Harrison, Roy Orbison, Jeff Lynne, Tom Petty, and Bob Dylan."], "scores": [[0.71923828125, 1.0, 0.99853515625, 0.170654296875, 0.99951171875, 1.0, 0.99951171875, 0.9990234375, 0.89599609375, 0.99853515625, 1.0, 0.99951171875, 0.994140625, 1.0, 1.0, 0.85986328125, 0.99169921875, 0.98681640625, 1.0, 1.0, 1.0, 0.53466796875, 0.0, 0.00029778480529785156]], "normalized_score": [0.0], "tokens": [["\u2581George", "\u2581Harrison", ",", "\u2581Roy", "\u2581Or", "b", "ison", ",", "\u2581Jeff", "\u2581Lyn", "ne", ",", "\u2581Tom", "\u2581Pet", "ty", ",", "\u2581and", "\u2581Bob", "\u2581D", "yl", "an", ".", "\u2581###", "\u2581Introduction"]], "entropy": [[1.029296875, 0.0006475448608398438, 0.012176513671875, 0.6865234375, 0.006500244140625, 0.0002722740173339844, 0.0026340484619140625, 0.0093231201171875, 0.404541015625, 0.0106353759765625, 0.001308441162109375, 0.006134033203125, 0.038787841796875, 0.0002624988555908203, 0.0008645057678222656, 0.41845703125, 0.05328369140625, 0.11785888671875, 0.0003504753112792969, 4.267692565917969e-05, 4.291534423828125e-05, 0.82861328125, 0.1290283203125, 4.2734375]], "avg_entropy": [0.3346259395281474], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Roy Orbison", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3159029974197481, "std_of_first_answer": 0.3159029974197481, "avg_entropy_of_first_answer": 0.3346259395281474, "lex_sim": 1.0}
{"question": "what is the origin of the name robinson", "answer": ["Named after the Old French \"Robinet\" or \"Robinett\" which means \"little ROBIN\"."], "scores": [[0.0117950439453125, 0.498291015625, 0.9853515625, 0.833984375, 0.049530029296875, 0.9111328125, 0.490966796875, 0.802734375, 0.31103515625, 0.2369384765625, 0.1202392578125, 0.94921875, 0.96875, 0.378173828125, 0.00847625732421875, 0.173095703125, 0.345458984375, 0.783203125, 0.9638671875, 0.880859375, 1.0, 0.0262603759765625, 0.6630859375, 0.861328125, 0.1925048828125, 0.0, 0.0038814544677734375, 0.203125, 0.001003265380859375, 0.125]], "normalized_score": [0.0], "tokens": [["\u2581N", "amed", "\u2581after", "\u2581the", "\u2581Old", "\u2581French", "\u2581\"", "Rob", "inet", "\"", "\u2581or", "\u2581\"", "Rob", "in", "ett", "\"", "\u2581which", "\u2581means", "\u2581\"", "l", "ittle", "\u2581R", "OB", "IN", "\".", "\u2581##", "E", "QU", "1", "##"]], "entropy": [[2.171875, 1.62890625, 0.0799560546875, 0.7197265625, 1.962890625, 0.365966796875, 1.599609375, 0.83056640625, 1.4912109375, 1.1162109375, 1.1435546875, 0.28271484375, 0.1829833984375, 1.30078125, 1.056640625, 0.98583984375, 0.78173828125, 0.94775390625, 0.1923828125, 0.517578125, 0.0018377304077148438, 3.439453125, 1.84375, 0.55712890625, 1.4072265625, 1.7578125, 6.3203125, 3.76953125, 1.66796875, 3.052734375]], "avg_entropy": [1.4392214139302573], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "English language patronymic surname", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37406630227490384, "std_of_first_answer": 0.37406630227490384, "avg_entropy_of_first_answer": 1.4392214139302573, "lex_sim": 1.0}
{"question": "where was harry potter and the deathly hallows part 1 filmed", "answer": ["The movie was filmed in various locations in the UK, including Warner Bros. Studios Leavesden and various locations in England, Scotland, and Wales."], "scores": [[0.11260986328125, 0.376953125, 0.9580078125, 0.927734375, 1.0, 0.69873046875, 0.58740234375, 0.994140625, 0.7197265625, 0.99853515625, 0.1666259765625, 0.8974609375, 0.9912109375, 0.01026153564453125, 0.99951171875, 1.0, 0.99462890625, 0.87109375, 0.262451171875, 1.0, 1.0, 0.1402587890625, 0.475341796875, 0.96337890625, 0.87890625, 0.1036376953125, 0.9599609375, 0.96728515625, 0.671875, 0.99755859375, 0.970703125, 0.984375, 6.9141387939453125e-06, 0.0633544921875, 5.364418029785156e-06, 0.63671875, 0.034881591796875, 0.45703125, 0.498046875, 1.7285346984863281e-06, 0.411376953125, 0.292236328125, 0.0287933349609375, 0.2386474609375, 0.1602783203125, 0.0100860595703125, 0.09735107421875]], "normalized_score": [0.184940367937088], "tokens": [["\u2581The", "\u2581movie", "\u2581was", "\u2581fil", "med", "\u2581in", "\u2581various", "\u2581locations", "\u2581in", "\u2581the", "\u2581UK", ",", "\u2581including", "\u2581Warner", "\u2581B", "ros", ".", "\u2581Studios", "\u2581Le", "aves", "den", "\u2581and", "\u2581various", "\u2581locations", "\u2581in", "\u2581England", ",", "\u2581Scotland", ",", "\u2581and", "\u2581Wales", ".", "\u2581To", "\u2581be", "\u2581released", "\u2581in", "\u2581the", "\u2581UK", "\u2581on", "\u2581Monday", ",", "\u2581", "2", "1", "st", "\u2581March", "."]], "entropy": [[2.8203125, 1.744140625, 0.2108154296875, 0.33642578125, 1.1324882507324219e-06, 0.87939453125, 1.0634765625, 0.044708251953125, 0.880859375, 0.01153564453125, 0.45263671875, 0.41748046875, 0.05816650390625, 3.15234375, 0.0025806427001953125, 0.0003848075866699219, 0.03857421875, 0.40234375, 0.84814453125, 0.0008835792541503906, 0.0008869171142578125, 0.6728515625, 2.0859375, 0.2255859375, 0.439697265625, 1.609375, 0.190673828125, 0.1829833984375, 0.6376953125, 0.019500732421875, 0.221923828125, 0.10052490234375, 0.85400390625, 2.86328125, 0.74072265625, 1.416015625, 1.3662109375, 1.720703125, 1.716796875, 0.53564453125, 2.08984375, 2.958984375, 0.331298828125, 2.02734375, 1.7001953125, 1.400390625, 1.27734375]], "avg_entropy": [0.9096090273654207], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "on location", "score_of_biggest_cluster": 0.184940367937088, "score_of_first_answer": 0.184940367937088, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7285346984863281e-06, "avg_score": 0.184940367937088, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39204848405696885, "std_of_first_answer": 0.39204848405696885, "avg_entropy_of_first_answer": 0.9096090273654207, "lex_sim": 1.0}
{"question": "where do rory and paris go to college", "answer": ["France"], "scores": [[0.01129913330078125]], "normalized_score": [0.011299132369458675], "tokens": [["\u2581France"]], "entropy": [[3.44140625]], "avg_entropy": [3.44140625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Yale University", "score_of_biggest_cluster": 0.011299132369458675, "score_of_first_answer": 0.011299132369458675, "max_score_of_first_answer": 0.01129913330078125, "min_score_of_first_answer": 0.01129913330078125, "avg_score": 0.011299132369458675, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.0, "std_of_first_answer": 0.0, "avg_entropy_of_first_answer": 3.44140625, "lex_sim": 1.0}
{"question": "where is fe best absorbed in the body", "answer": ["in the small intestine"], "scores": [[0.1802978515625, 0.96240234375, 0.76025390625, 0.99755859375, 1.0, 0.98681640625]], "normalized_score": [0.7116177678108215], "tokens": [["\u2581in", "\u2581the", "\u2581small", "\u2581int", "est", "ine"]], "entropy": [[3.26171875, 0.267333984375, 1.0615234375, 0.0184783935546875, 0.0003871917724609375, 0.0738525390625]], "avg_entropy": [0.7805490493774414], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "in the duodenum", "score_of_biggest_cluster": 0.7116177678108215, "score_of_first_answer": 0.7116177678108215, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.1802978515625, "avg_score": 0.7116177678108215, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.2957036048743048, "std_of_first_answer": 0.2957036048743048, "avg_entropy_of_first_answer": 0.7805490493774414, "lex_sim": 1.0}
{"question": "who wrote song what a friend we have in jesus", "answer": ["Alfred Henry Ackley"], "scores": [[0.0247039794921875, 0.927734375, 0.99755859375, 0.99951171875, 0.99951171875]], "normalized_score": [0.4696138799190521], "tokens": [["\u2581Alfred", "\u2581Henry", "\u2581A", "ck", "ley"]], "entropy": [[3.095703125, 0.45068359375, 0.0259552001953125, 0.004230499267578125, 0.00414276123046875]], "avg_entropy": [0.7161430358886719], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Charles Crozat Converse", "score_of_biggest_cluster": 0.4696138799190521, "score_of_first_answer": 0.4696138799190521, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.0247039794921875, "avg_score": 0.4696138799190521, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38354125086085633, "std_of_first_answer": 0.38354125086085633, "avg_entropy_of_first_answer": 0.7161430358886719, "lex_sim": 1.0}
{"question": "which film won the oscar for best animated feature in 2007", "answer": ["\"The Golden Compass\""], "scores": [[0.00439453125, 0.004367828369140625, 0.63623046875, 1.0, 1.0, 0.96923828125]], "normalized_score": [0.15096300840377808], "tokens": [["\u2581\"", "The", "\u2581Golden", "\u2581Com", "pass", "\""]], "entropy": [[0.043060302734375, 0.08001708984375, 1.634765625, 0.0022487640380859375, 0.0008678436279296875, 0.1751708984375]], "avg_entropy": [0.32268842061360675], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ratatouille", "score_of_biggest_cluster": 0.15096300840377808, "score_of_first_answer": 0.15096300840377808, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.004367828369140625, "avg_score": 0.15096300840377808, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4410478733298564, "std_of_first_answer": 0.4410478733298564, "avg_entropy_of_first_answer": 0.32268842061360675, "lex_sim": 1.0}
{"question": "when did they stop putting lead in paint", "answer": ["Lead has not been routinely used as an additive in paint in the United States since 1978, when the Consumer Product Safety Commission (CPSC) banned lead-based paint for use in residential buildings"], "scores": [[0.122314453125, 1.0, 0.775390625, 0.8974609375, 0.99951171875, 0.00098419189453125, 1.0, 1.0, 0.92626953125, 0.1461181640625, 0.298828125, 0.7744140625, 1.0, 0.998046875, 0.92236328125, 0.70654296875, 0.9970703125, 0.90966796875, 0.99951171875, 0.990234375, 0.440673828125, 1.0, 1.0, 1.0, 0.99072265625, 0.435546875, 0.97998046875, 0.89111328125, 0.96484375, 1.0, 0.99951171875, 0.99951171875, 1.0, 1.0, 0.9482421875, 1.0, 1.0, 0.99951171875, 0.94873046875, 1.0, 0.2203369140625, 0.95263671875, 0.94287109375, 0.9951171875, 0.974609375, 0.73583984375, 0.99951171875, 0.4189453125, 1.0, 0.73779296875]], "normalized_score": [0.691290020942688], "tokens": [["\u2581Le", "ad", "\u2581has", "\u2581not", "\u2581been", "\u2581rout", "in", "ely", "\u2581used", "\u2581as", "\u2581an", "\u2581add", "itive", "\u2581in", "\u2581paint", "\u2581in", "\u2581the", "\u2581United", "\u2581States", "\u2581since", "\u2581", "1", "9", "7", "8", ",", "\u2581when", "\u2581the", "\u2581Cons", "umer", "\u2581Product", "\u2581Saf", "ety", "\u2581Commission", "\u2581(", "CP", "SC", ")", "\u2581b", "anned", "\u2581lead", "-", "based", "\u2581paint", "\u2581for", "\u2581use", "\u2581in", "\u2581resident", "ial", "\u2581buildings"]], "entropy": [[2.08203125, 0.0007948875427246094, 0.78466796875, 0.365478515625, 0.003353118896484375, 1.845703125, 3.695487976074219e-05, 7.212162017822266e-06, 0.2705078125, 0.416748046875, 0.6533203125, 0.67578125, 0.0004105567932128906, 0.017425537109375, 0.4384765625, 0.85546875, 0.023895263671875, 0.334228515625, 0.0026035308837890625, 0.060943603515625, 0.70849609375, 2.8967857360839844e-05, 3.039836883544922e-06, 0.0013303756713867188, 0.05523681640625, 1.07421875, 0.1473388671875, 0.39306640625, 0.2032470703125, 0.0002467632293701172, 0.002742767333984375, 0.0026111602783203125, 1.4483928680419922e-05, 0.0021686553955078125, 0.2325439453125, 0.0011167526245117188, 0.0015697479248046875, 0.003326416015625, 0.300048828125, 0.00010991096496582031, 0.96923828125, 0.24560546875, 0.2203369140625, 0.037750244140625, 0.156494140625, 0.70166015625, 0.005481719970703125, 0.93408203125, 7.992982864379883e-05, 1.1533203125]], "avg_entropy": [0.32770795583724976], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1992", "score_of_biggest_cluster": 0.691290020942688, "score_of_first_answer": 0.691290020942688, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.00098419189453125, "avg_score": 0.691290020942688, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.27130744598742806, "std_of_first_answer": 0.27130744598742806, "avg_entropy_of_first_answer": 0.32770795583724976, "lex_sim": 1.0}
{"question": "los angeles stadium at hollywood park opening date", "answer": ["Formal opening on April 17, 2020, event open to the public on July 11, 2020."], "scores": [[0.0004229545593261719, 0.564453125, 0.5517578125, 0.0865478515625, 0.039459228515625, 0.99755859375, 0.5791015625, 0.6083984375, 0.857421875, 0.98974609375, 0.99951171875, 1.0, 1.0, 0.98193359375, 0.126220703125, 0.01078033447265625, 0.0188751220703125, 0.88525390625, 0.58740234375, 0.99755859375, 0.53271484375, 0.321533203125, 0.9990234375, 0.4951171875, 0.0310821533203125, 0.9677734375, 0.99560546875, 0.99951171875, 1.0, 1.0, 0.9990234375, 0.444580078125, 1.2159347534179688e-05, 0.0055084228515625, 0.0002014636993408203, 0.01338958740234375, 0.00873565673828125, 6.252527236938477e-05, 1.1563301086425781e-05, 0.0011873245239257812, 0.0059967041015625, 0.1337890625, 0.290771484375, 0.06658935546875, 0.18212890625, 0.98876953125, 0.65380859375, 0.97998046875]], "normalized_score": [0.10332154482603073], "tokens": [["\u2581F", "ormal", "\u2581opening", "\u2581on", "\u2581April", "\u2581", "1", "7", ",", "\u2581", "2", "0", "2", "0", ",", "\u2581event", "\u2581open", "\u2581to", "\u2581the", "\u2581public", "\u2581on", "\u2581July", "\u2581", "1", "1", ",", "\u2581", "2", "0", "2", "0", ".", "\u2581#", "B", "log", "T", "our", "\u2581The", "\u2581Secret", "\u2581by", "\u2581L", "ulu", "\u2581Taylor", "\u2581@", "L", "ulu", "T", "aylor"]], "entropy": [[3.154296875, 2.32421875, 1.67578125, 1.6865234375, 0.4482421875, 0.0179443359375, 0.99853515625, 1.4111328125, 0.47265625, 0.0693359375, 0.005527496337890625, 2.014636993408203e-05, 0.002147674560546875, 0.10321044921875, 1.6845703125, 1.9296875, 3.44140625, 0.5859375, 0.90576171875, 0.0197296142578125, 1.8095703125, 1.0888671875, 0.0079345703125, 0.8564453125, 1.607421875, 0.2060546875, 0.036407470703125, 0.00408935546875, 0.00104522705078125, 0.0022907257080078125, 0.007740020751953125, 1.1728515625, 1.283203125, 3.80078125, 3.880859375, 3.365234375, 2.76953125, 4.18359375, 4.55859375, 2.470703125, 1.3515625, 2.921875, 3.3359375, 3.33984375, 2.044921875, 0.07977294921875, 1.5546875, 0.1429443359375]], "avg_entropy": [1.433779778579871], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2020", "score_of_biggest_cluster": 0.10332154482603073, "score_of_first_answer": 0.10332154482603073, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1563301086425781e-05, "avg_score": 0.10332154482603073, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41861307635963163, "std_of_first_answer": 0.41861307635963163, "avg_entropy_of_first_answer": 1.433779778579871, "lex_sim": 1.0}
{"question": "who owns the golden nugget casino in atlantic city", "answer": ["Landry's Inc. #248: A Dish Too Far"], "scores": [[0.98974609375, 0.99951171875, 0.99267578125, 1.0, 0.61767578125, 0.91015625, 5.960464477539063e-08, 0.03741455078125, 0.04931640625, 0.08380126953125, 0.0014925003051757812, 0.00133514404296875, 0.0027523040771484375, 0.0002498626708984375, 0.001689910888671875, 0.025787353515625, 0.7353515625]], "normalized_score": [0.02363089844584465], "tokens": [["\u2581Land", "ry", "'", "s", "\u2581Inc", ".", "\u2581#", "2", "4", "8", ":", "\u2581A", "\u2581D", "ish", "\u2581To", "o", "\u2581Far"]], "entropy": [[0.0780029296875, 0.003917694091796875, 0.048919677734375, 2.0265579223632812e-06, 1.05078125, 0.361572265625, 0.57080078125, 4.48828125, 2.806640625, 3.095703125, 3.095703125, 3.833984375, 5.8828125, 1.5595703125, 5.296875, 1.705078125, 1.3623046875]], "avg_entropy": [2.0729970441145054], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Landry's, Inc.", "score_of_biggest_cluster": 0.02363089844584465, "score_of_first_answer": 0.02363089844584465, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.02363089844584465, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4392370291667501, "std_of_first_answer": 0.4392370291667501, "avg_entropy_of_first_answer": 2.0729970441145054, "lex_sim": 1.0}
{"question": "who does the voice of amy on futurama", "answer": ["Katey Sagal #8219;s not enough time for kids to develop healthy lifestyles."], "scores": [[0.111083984375, 1.0, 0.99755859375, 1.0, 1.0, 5.960464477539063e-08, 0.019256591796875, 0.705078125, 0.08709716796875, 0.0002505779266357422, 0.9404296875, 0.064453125, 0.0001653432846069336, 0.000545501708984375, 0.0019388198852539062, 0.1065673828125, 0.00011098384857177734, 0.0158538818359375, 0.147705078125, 0.033599853515625, 0.001354217529296875, 0.97265625, 0.0165557861328125, 0.9697265625, 0.5419921875, 0.2080078125, 0.005428314208984375, 0.13525390625, 0.05194091796875, 0.869140625, 0.52490234375, 0.01052093505859375, 0.99853515625, 0.9287109375, 0.25830078125, 0.0760498046875, 0.17822265625, 0.0137786865234375, 0.0697021484375, 0.267578125, 0.0330810546875, 0.99853515625, 0.95166015625, 0.14599609375, 0.09918212890625, 0.93359375, 0.05426025390625, 0.4375]], "normalized_score": [0.06145484745502472], "tokens": [["\u2581Kate", "y", "\u2581S", "ag", "al", "\u2581#", "8", "2", "1", "9", ";", "s", "\u2581not", "\u2581enough", "\u2581time", "\u2581for", "\u2581k", "ids", "\u2581to", "\u2581develop", "\u2581health", "y", "\u2581l", "ifest", "yles", ".", "\u2581What", "\u2581is", "\u2581needed", "\u2581is", "\u2581a", "\u2581concert", "ed", "\u2581effort", "\u2581to", "\u2581create", "\u2581a", "\u2581national", "\u2581strategy", "\u2581that", "\u2581focus", "es", "\u2581on", "\u2581the", "\u2581development", "\u2581of", "\u2581a", "\u2581health"]], "entropy": [[4.32421875, 0.0003914833068847656, 0.018951416015625, 0.00026869773864746094, 3.927946090698242e-05, 0.779296875, 5.1328125, 1.609375, 0.7724609375, 0.63818359375, 0.43603515625, 3.931640625, 3.203125, 4.51953125, 3.126953125, 1.9560546875, 1.962890625, 1.240234375, 3.3671875, 4.32421875, 4.578125, 0.170654296875, 3.1484375, 0.15869140625, 0.7001953125, 3.353515625, 4.76953125, 3.6875, 2.955078125, 0.72216796875, 3.068359375, 4.546875, 0.0137176513671875, 0.485107421875, 1.84375, 4.07421875, 3.09765625, 3.412109375, 3.537109375, 2.17578125, 3.994140625, 0.016357421875, 0.31640625, 4.05078125, 3.521484375, 0.357177734375, 2.369140625, 2.904296875]], "avg_entropy": [2.2785882440706096], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Lauren Tom", "score_of_biggest_cluster": 0.06145484745502472, "score_of_first_answer": 0.06145484745502472, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.06145484745502472, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40164940991146775, "std_of_first_answer": 0.40164940991146775, "avg_entropy_of_first_answer": 2.2785882440706096, "lex_sim": 1.0}
{"question": "when was the last time america hosted the summer olympics", "answer": ["Atlanta 1996"], "scores": [[0.1103515625, 0.416015625, 0.99951171875, 1.0, 1.0, 1.0]], "normalized_score": [0.5983371734619141], "tokens": [["\u2581Atlanta", "\u2581", "1", "9", "9", "6"]], "entropy": [[1.052734375, 0.94189453125, 0.002819061279296875, 0.0004601478576660156, 0.0008378028869628906, 0.0018291473388671875]], "avg_entropy": [0.33342917760213214], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Salt Lake City", "score_of_biggest_cluster": 0.5983371734619141, "score_of_first_answer": 0.5983371734619141, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.1103515625, "avg_score": 0.5983371734619141, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.35831554169066815, "std_of_first_answer": 0.35831554169066815, "avg_entropy_of_first_answer": 0.33342917760213214, "lex_sim": 1.0}
{"question": "who plays the robot on the orville show", "answer": ["Rob Lowe #ThrowbackThursday: \u201cPrayer, Our Greatest Weapon\u201d"], "scores": [[0.008544921875, 0.267578125, 0.99853515625, 7.152557373046875e-07, 9.745359420776367e-05, 0.99853515625, 0.51953125, 0.99951171875, 0.99853515625, 0.0008802413940429688, 0.005496978759765625, 0.04290771484375, 0.0006504058837890625, 0.0556640625, 0.005374908447265625, 0.00010722875595092773, 0.0655517578125, 0.91943359375, 0.314208984375, 0.99951171875, 1.0, 0.75830078125]], "normalized_score": [0.03406064584851265], "tokens": [["\u2581Rob", "\u2581L", "owe", "\u2581#", "Throw", "back", "Th", "urs", "day", ":", "\u2581\u201c", "P", "ray", "er", ",", "\u2581Our", "\u2581Great", "est", "\u2581We", "ap", "on", "\u201d"]], "entropy": [[2.775390625, 0.875, 0.01343536376953125, 0.7275390625, 4.33203125, 0.01134490966796875, 2.029296875, 0.00452423095703125, 0.014495849609375, 1.8212890625, 5.0078125, 3.490234375, 2.978515625, 2.0078125, 2.23046875, 4.828125, 3.1875, 0.3525390625, 1.064453125, 0.003307342529296875, 0.000713348388671875, 1.3466796875]], "avg_entropy": [1.7773867520419033], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Mark Jackson", "score_of_biggest_cluster": 0.03406064584851265, "score_of_first_answer": 0.03406064584851265, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 7.152557373046875e-07, "avg_score": 0.03406064584851265, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4374999207033633, "std_of_first_answer": 0.4374999207033633, "avg_entropy_of_first_answer": 1.7773867520419033, "lex_sim": 1.0}
{"question": "who played emma in h2o just add water", "answer": ["Cariba Heine"], "scores": [[0.7197265625, 1.0, 0.99951171875, 1.0]], "normalized_score": [0.9209559559822083], "tokens": [["\u2581Car", "iba", "\u2581He", "ine"]], "entropy": [[1.6083984375, 0.00261688232421875, 0.00640106201171875, 0.0016298294067382812]], "avg_entropy": [0.40476155281066895], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Claire Rhiannon Holt", "score_of_biggest_cluster": 0.9209559559822083, "score_of_first_answer": 0.9209559559822083, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.7197265625, "avg_score": 0.9209559559822083, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.12129164491812904, "std_of_first_answer": 0.12129164491812904, "avg_entropy_of_first_answer": 0.40476155281066895, "lex_sim": 1.0}
{"question": "what is the third book in the lunar chronicles", "answer": ["Cress ### Introduction to the Python programming language"], "scores": [[0.72412109375, 0.95166015625, 0.0, 0.0002644062042236328, 0.10675048828125, 0.322998046875, 4.5299530029296875e-06, 0.58544921875, 0.984375]], "normalized_score": [0.0], "tokens": [["\u2581C", "ress", "\u2581###", "\u2581Introduction", "\u2581to", "\u2581the", "\u2581Python", "\u2581programming", "\u2581language"]], "entropy": [[1.22265625, 0.198974609375, 1.1630859375, 4.24609375, 3.146484375, 3.732421875, 3.625, 2.02734375, 0.114990234375]], "avg_entropy": [2.1641167534722223], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Cress", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.984375, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3882071378972897, "std_of_first_answer": 0.3882071378972897, "avg_entropy_of_first_answer": 2.1641167534722223, "lex_sim": 1.0}
{"question": "who played john coffey in the movie the green mile", "answer": ["Michael Clarke Duncan"], "scores": [[0.943359375, 0.99365234375, 1.0, 0.99951171875, 0.9970703125]], "normalized_score": [0.9864726662635803], "tokens": [["\u2581Michael", "\u2581Clar", "ke", "\u2581Dun", "can"]], "entropy": [[0.395263671875, 0.05169677734375, 0.000774383544921875, 0.005901336669921875, 0.020416259765625]], "avg_entropy": [0.09481048583984375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Michael Clarke Duncan", "score_of_biggest_cluster": 0.9864726662635803, "score_of_first_answer": 0.9864726662635803, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.943359375, "avg_score": 0.9864726662635803, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.02179594742089936, "std_of_first_answer": 0.02179594742089936, "avg_entropy_of_first_answer": 0.09481048583984375, "lex_sim": 1.0}
{"question": "who wrote the french declaration of the rights of man and of the citizen", "answer": ["The French Declaration of the Rights of Man and of the Citizen was written by a committee of representatives from the National Assembly, which included Georges Danton, Antoine Barnave, and Raymond de Sach\u00e9."], "scores": [[0.344970703125, 0.0168609619140625, 0.34716796875, 1.0, 0.99609375, 0.99951171875, 0.99951171875, 1.0, 0.9990234375, 0.9990234375, 0.8466796875, 0.99951171875, 1.0, 1.0, 0.9921875, 0.72265625, 0.97509765625, 0.46337890625, 0.7607421875, 0.52734375, 0.62109375, 1.0, 0.46728515625, 0.94580078125, 0.94287109375, 0.853515625, 0.8974609375, 0.1846923828125, 0.379150390625, 0.00933837890625, 0.77197265625, 0.99072265625, 0.93408203125, 0.427978515625, 0.57861328125, 0.99951171875, 1.0, 0.99072265625, 0.826171875, 0.00327301025390625, 0.343994140625, 0.00110626220703125, 0.6435546875, 0.763671875, 0.06951904296875, 1.0, 0.6611328125, 0.128662109375, 0.402587890625, 0.791015625]], "normalized_score": [0.45037320256233215], "tokens": [["\u2581The", "\u2581French", "\u2581Dec", "laration", "\u2581of", "\u2581the", "\u2581Rights", "\u2581of", "\u2581Man", "\u2581and", "\u2581of", "\u2581the", "\u2581Cit", "izen", "\u2581was", "\u2581written", "\u2581by", "\u2581a", "\u2581committee", "\u2581of", "\u2581represent", "atives", "\u2581from", "\u2581the", "\u2581National", "\u2581Assembly", ",", "\u2581which", "\u2581included", "\u2581Georges", "\u2581D", "anton", ",", "\u2581Antoine", "\u2581Bar", "na", "ve", ",", "\u2581and", "\u2581Raymond", "\u2581de", "\u2581Sach", "\u00e9", ".", "\u2581However", ",", "\u2581the", "\u2581main", "\u2581author", "\u2581of"]], "entropy": [[3.107421875, 1.07421875, 0.8046875, 0.0012969970703125, 0.031402587890625, 0.004634857177734375, 0.005710601806640625, 0.00217437744140625, 0.00933074951171875, 0.006977081298828125, 0.44677734375, 0.00322723388671875, 8.279085159301758e-05, 0.0001373291015625, 0.061737060546875, 1.244140625, 0.1480712890625, 1.115234375, 0.81982421875, 1.5263671875, 1.75390625, 0.00043082237243652344, 1.2900390625, 0.31591796875, 0.276123046875, 0.50537109375, 0.498046875, 1.6982421875, 0.70703125, 3.93359375, 0.85205078125, 0.058868408203125, 0.264892578125, 1.919921875, 1.4609375, 0.0028324127197265625, 4.863739013671875e-05, 0.055908203125, 0.85009765625, 1.8447265625, 2.984375, 1.6572265625, 1.4111328125, 0.64990234375, 1.384765625, 0.00247955322265625, 0.98681640625, 1.8125, 1.80859375, 0.74169921875]], "avg_entropy": [0.8428386604785919], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "General Lafayette", "score_of_biggest_cluster": 0.45037320256233215, "score_of_first_answer": 0.45037320256233215, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.00110626220703125, "avg_score": 0.45037320256233215, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3344777274911227, "std_of_first_answer": 0.3344777274911227, "avg_entropy_of_first_answer": 0.8428386604785919, "lex_sim": 1.0}
{"question": "when did hollywood become the centre of the film industry", "answer": ["1910s"], "scores": [[0.060394287109375, 0.95703125, 1.0, 0.95068359375, 0.9990234375, 0.99560546875]], "normalized_score": [0.6160323023796082], "tokens": [["\u2581", "1", "9", "1", "0", "s"]], "entropy": [[2.2734375, 0.18212890625, 0.0020656585693359375, 0.21533203125, 0.0107879638671875, 0.0347900390625]], "avg_entropy": [0.4530903498331706], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1912", "score_of_biggest_cluster": 0.6160323023796082, "score_of_first_answer": 0.6160323023796082, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.060394287109375, "avg_score": 0.6160323023796082, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.34347218536940644, "std_of_first_answer": 0.34347218536940644, "avg_entropy_of_first_answer": 0.4530903498331706, "lex_sim": 1.0}
{"question": "when did jelly beans became associated with easter", "answer": ["jelly beans have been associated with Easter since the late 19th century."], "scores": [[0.040557861328125, 0.9990234375, 0.98681640625, 1.0, 0.31591796875, 0.95068359375, 0.939453125, 1.0, 0.99658203125, 1.0, 0.81298828125, 0.98095703125, 0.673828125, 0.99951171875, 1.0, 0.67919921875, 0.9990234375, 0.994140625, 0.794921875, 0.0, 1.7523765563964844e-05]], "normalized_score": [0.0], "tokens": [["\u2581jel", "ly", "\u2581be", "ans", "\u2581have", "\u2581been", "\u2581associated", "\u2581with", "\u2581E", "aster", "\u2581since", "\u2581the", "\u2581late", "\u2581", "1", "9", "th", "\u2581century", ".", "\u2581##", "\u2581Introduction"]], "entropy": [[2.396484375, 0.006923675537109375, 0.0823974609375, 2.8967857360839844e-05, 1.5751953125, 0.2548828125, 0.3271484375, 0.0021514892578125, 0.02410888671875, 0.00022912025451660156, 0.548828125, 0.1192626953125, 0.775390625, 0.00464630126953125, 4.5239925384521484e-05, 0.6279296875, 0.0089111328125, 0.044219970703125, 0.7890625, 1.046875, 6.66015625]], "avg_entropy": [0.728327526932671], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "during the 1930s", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.34966929862196516, "std_of_first_answer": 0.34966929862196516, "avg_entropy_of_first_answer": 0.728327526932671, "lex_sim": 1.0}
{"question": "where did they get the tree for rockefeller center", "answer": ["From the forests of Canada."], "scores": [[0.005886077880859375, 0.79541015625, 0.2626953125, 0.99951171875, 0.9873046875, 0.405517578125, 0.36083984375, 6.973743438720703e-06, 0.004581451416015625, 0.006076812744140625, 0.0270538330078125, 0.08941650390625, 0.03131103515625, 0.00013053417205810547, 0.0005321502685546875, 0.5068359375, 4.6193599700927734e-05, 0.84716796875, 0.72509765625, 0.1368408203125, 0.004093170166015625, 0.044158935546875, 0.720703125, 0.9931640625, 0.419189453125, 1.0, 0.8369140625, 0.97314453125, 0.99951171875, 0.97412109375, 1.0, 0.97021484375, 1.0, 0.99951171875, 1.0]], "normalized_score": [0.10114394128322601], "tokens": [["\u2581From", "\u2581the", "\u2581for", "ests", "\u2581of", "\u2581Canada", ".", "\u2581#", "1", "-", "0", "0", "7", "\u2581M", "ole", "cular", "\u2581Character", "ization", "\u2581of", "\u2581the", "\u2581R", "ice", "\u2581Bl", "ast", "\u2581F", "ung", "us", "\u2581Mag", "nap", "ort", "he", "\u2581or", "y", "za", "e"]], "entropy": [[2.19921875, 1.33203125, 2.6796875, 0.0041961669921875, 0.07916259765625, 2.419921875, 1.248046875, 1.0908203125, 4.09375, 2.765625, 2.908203125, 2.86328125, 3.021484375, 2.701171875, 2.5859375, 2.212890625, 2.439453125, 0.58154296875, 1.4140625, 4.34765625, 5.71484375, 3.87890625, 1.287109375, 0.053009033203125, 1.19921875, 0.0013322830200195312, 0.484619140625, 0.2017822265625, 0.0032062530517578125, 0.138916015625, 0.0008311271667480469, 0.180908203125, 0.0013513565063476562, 0.004032135009765625, 0.0009531974792480469]], "avg_entropy": [1.6039760862077985], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "State College, PA", "score_of_biggest_cluster": 0.10114394128322601, "score_of_first_answer": 0.10114394128322601, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 6.973743438720703e-06, "avg_score": 0.10114394128322601, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4252717809938716, "std_of_first_answer": 0.4252717809938716, "avg_entropy_of_first_answer": 1.6039760862077985, "lex_sim": 1.0}
{"question": "who is the actor that plays jt on the young and the restless", "answer": ["Justin Hartley ### Canvas in the browser"], "scores": [[0.2763671875, 0.9970703125, 1.0, 0.0, 1.9669532775878906e-05, 0.0006918907165527344, 0.00016260147094726562, 0.04876708984375, 0.0200653076171875]], "normalized_score": [0.0], "tokens": [["\u2581Justin", "\u2581Hart", "ley", "\u2581###", "\u2581Can", "vas", "\u2581in", "\u2581the", "\u2581browser"]], "entropy": [[3.08984375, 0.025390625, 0.0003731250762939453, 0.90673828125, 2.654296875, 2.056640625, 4.01171875, 5.92578125, 5.89453125]], "avg_entropy": [2.7294793923695884], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Thaddeus Rowe Luckinbill", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40321945671149545, "std_of_first_answer": 0.40321945671149545, "avg_entropy_of_first_answer": 2.7294793923695884, "lex_sim": 1.0}
{"question": "what time do tam tams start in montreal", "answer": ["Tam tams typically start around 2 PM on Sundays in Montreal, but the schedule may vary depending on the location and the season."], "scores": [[0.65478515625, 0.376708984375, 1.0, 0.09814453125, 0.826171875, 0.4677734375, 0.58642578125, 0.9638671875, 0.1424560546875, 0.220458984375, 0.6328125, 1.0, 0.9326171875, 0.9814453125, 0.05670166015625, 0.81494140625, 0.210205078125, 0.278564453125, 0.74072265625, 0.982421875, 0.69775390625, 1.0, 0.99462890625, 0.2369384765625, 0.9853515625, 0.290283203125, 0.51953125, 0.9951171875, 5.960464477539063e-08, 0.00047850608825683594, 3.7550926208496094e-06, 0.0, 0.951171875, 0.0187530517578125, 0.00384521484375, 0.0330810546875, 0.57666015625, 0.0877685546875, 0.0374755859375, 0.97705078125, 0.0936279296875, 0.77978515625, 0.0019445419311523438, 0.89990234375]], "normalized_score": [0.0], "tokens": [["\u2581Tam", "\u2581t", "ams", "\u2581typically", "\u2581start", "\u2581around", "\u2581", "2", "\u2581PM", "\u2581on", "\u2581Sund", "ays", "\u2581in", "\u2581Montreal", ",", "\u2581but", "\u2581the", "\u2581schedule", "\u2581may", "\u2581vary", "\u2581depending", "\u2581on", "\u2581the", "\u2581location", "\u2581and", "\u2581the", "\u2581season", ".", "\u2581#", "B", "onas", "\u2581fac", "ulty", "\u2581members", "\u2581publish", "\u2581book", "\u2581on", "\u2581the", "\u2581intersection", "\u2581of", "\u2581law", "\u2581and", "\u2581sexual", "ity"]], "entropy": [[1.609375, 1.080078125, 0.00020515918731689453, 1.888671875, 0.59423828125, 1.1455078125, 0.77099609375, 0.18115234375, 1.4296875, 1.1337890625, 1.0361328125, 0.0009984970092773438, 0.3115234375, 0.1280517578125, 0.4833984375, 0.7724609375, 1.4189453125, 1.259765625, 0.708984375, 0.097412109375, 0.94580078125, 0.0015439987182617188, 0.039581298828125, 1.44921875, 0.0902099609375, 1.998046875, 1.6337890625, 0.036285400390625, 0.99560546875, 2.455078125, 0.5947265625, 3.42578125, 0.346923828125, 3.52734375, 4.66015625, 3.271484375, 1.7412109375, 6.21484375, 4.83984375, 0.1455078125, 4.3984375, 0.63720703125, 3.359375, 0.54150390625]], "avg_entropy": [1.4409290904348546], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "around 10:30am", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3898655104680028, "std_of_first_answer": 0.3898655104680028, "avg_entropy_of_first_answer": 1.4409290904348546, "lex_sim": 1.0}
{"question": "when did little polveir win the grand national", "answer": ["I'm sorry, there is no information available on a horse named \"Little Polveir\" winning the Grand National."], "scores": [[0.309814453125, 0.78857421875, 1.0, 0.99072265625, 0.98193359375, 0.059417724609375, 0.73193359375, 0.99560546875, 0.1683349609375, 0.2396240234375, 0.68701171875, 0.533203125, 0.6181640625, 0.98876953125, 0.6796875, 0.3662109375, 1.0, 0.97607421875, 0.99951171875, 0.99951171875, 0.9931640625, 0.99609375, 0.998046875, 0.99853515625, 0.99951171875, 0.9794921875, 0.256103515625, 0.640625, 0.9990234375, 0.98828125, 0.491455078125, 0.97998046875, 0.8193359375, 1.0, 1.0, 0.99951171875, 1.0, 0.1043701171875, 0.19189453125, 0.95703125, 0.453125, 0.99853515625, 0.058685302734375, 0.2274169921875, 0.115966796875, 0.07757568359375, 0.08819580078125, 0.685546875, 0.50634765625, 0.85498046875]], "normalized_score": [0.5389844179153442], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581there", "\u2581is", "\u2581no", "\u2581information", "\u2581available", "\u2581on", "\u2581a", "\u2581horse", "\u2581named", "\u2581\"", "L", "ittle", "\u2581Pol", "ve", "ir", "\"", "\u2581winning", "\u2581the", "\u2581Grand", "\u2581National", ".", "\u2581The", "\u2581Grand", "\u2581National", "\u2581is", "\u2581an", "\u2581annual", "\u2581ste", "e", "ple", "ch", "ase", "\u2581race", "\u2581in", "\u2581the", "\u2581United", "\u2581Kingdom", ".", "\u2581It", "\u2581is", "\u2581a", "\u2581popular", "\u2581event", "\u2581and", "\u2581has"]], "entropy": [[1.5712890625, 0.91015625, 0.0014972686767578125, 0.0648193359375, 0.10101318359375, 1.2958984375, 0.95947265625, 0.032928466796875, 1.78125, 1.5673828125, 1.0068359375, 1.1376953125, 0.91552734375, 0.07611083984375, 0.67529296875, 0.66650390625, 0.002193450927734375, 0.147705078125, 0.0046539306640625, 0.0050201416015625, 0.044586181640625, 0.03314208984375, 0.0152435302734375, 0.01045989990234375, 0.0039520263671875, 0.1285400390625, 1.5458984375, 1.052734375, 0.007747650146484375, 0.0830078125, 0.70751953125, 0.1380615234375, 0.4970703125, 5.525350570678711e-05, 0.00017881393432617188, 0.0034046173095703125, 0.0005578994750976562, 0.395751953125, 1.0517578125, 0.2117919921875, 0.69140625, 0.01140594482421875, 1.3466796875, 1.359375, 1.05859375, 2.62109375, 2.5546875, 1.056640625, 1.263671875, 0.69287109375]], "avg_entropy": [0.6302226722240448], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1989", "score_of_biggest_cluster": 0.5389844179153442, "score_of_first_answer": 0.5389844179153442, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.058685302734375, "avg_score": 0.5389844179153442, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.34629177661742233, "std_of_first_answer": 0.34629177661742233, "avg_entropy_of_first_answer": 0.6302226722240448, "lex_sim": 1.0}
{"question": "when did movies start coming out in color", "answer": ["1930s #FindingTheAnthem"], "scores": [[0.5908203125, 0.9931640625, 1.0, 0.99267578125, 0.9599609375, 0.9619140625, 1.7881393432617188e-07, 0.0014543533325195312, 0.005214691162109375, 0.0192413330078125, 0.00786590576171875, 0.014923095703125, 0.344482421875]], "normalized_score": [0.0394875630736351], "tokens": [["\u2581", "1", "9", "3", "0", "s", "\u2581#", "F", "inding", "The", "An", "th", "em"]], "entropy": [[1.4951171875, 0.042633056640625, 0.0007848739624023438, 0.045257568359375, 0.2142333984375, 0.1871337890625, 1.2734375, 4.8984375, 3.583984375, 3.197265625, 3.3046875, 3.126953125, 1.98046875]], "avg_entropy": [1.796184172997108], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "introduced around 1940", "score_of_biggest_cluster": 0.0394875630736351, "score_of_first_answer": 0.0394875630736351, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.0394875630736351, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44865828377403827, "std_of_first_answer": 0.44865828377403827, "avg_entropy_of_first_answer": 1.796184172997108, "lex_sim": 1.0}
{"question": "where does sound travel fastest solid liquid or gas", "answer": ["Gas #ThrowbackThursday Review: Raging Heat by Richard Castle"], "scores": [[0.130615234375, 9.5367431640625e-07, 7.450580596923828e-06, 0.99658203125, 0.251708984375, 1.0, 0.99951171875, 0.0, 0.11627197265625, 0.002254486083984375, 0.005401611328125, 0.0022258758544921875, 0.49169921875, 0.455322265625, 0.96875, 0.54150390625]], "normalized_score": [0.0], "tokens": [["\u2581Gas", "\u2581#", "Throw", "back", "Th", "urs", "day", "\u2581Review", ":", "\u2581R", "aging", "\u2581He", "at", "\u2581by", "\u2581Richard", "\u2581Castle"]], "entropy": [[1.86328125, 0.89697265625, 2.68359375, 0.02874755859375, 1.7685546875, 0.0013799667358398438, 0.005298614501953125, 1.283203125, 2.84765625, 5.140625, 4.890625, 1.466796875, 0.791015625, 2.46484375, 0.254638671875, 2.931640625]], "avg_entropy": [1.832429587841034], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "solids", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3988641976713585, "std_of_first_answer": 0.3988641976713585, "avg_entropy_of_first_answer": 1.832429587841034, "lex_sim": 1.0}
{"question": "who was elected the president of constituent assembly", "answer": ["Dr. B.R."], "scores": [[0.9111328125, 0.98681640625, 0.771484375, 0.98974609375, 0.76611328125, 0.9638671875, 0.99560546875, 1.0, 0.99951171875, 2.980232238769531e-07, 0.0005350112915039062, 0.045562744140625, 7.30752944946289e-05, 0.0016679763793945312, 0.0005693435668945312, 0.0002467632293701172, 0.990234375, 0.99951171875, 0.76318359375, 0.0005178451538085938, 0.0157623291015625, 0.91552734375, 0.0298614501953125, 0.0038013458251953125, 0.059356689453125, 0.1453857421875, 0.253662109375, 0.8466796875]], "normalized_score": [0.04720766097307205], "tokens": [["\u2581Dr", ".", "\u2581B", ".", "R", ".", "\u2581Am", "bed", "kar", "\u2581#", "6", "0", ")", "\u2581The", "\u2581D", "ile", "m", "ma", "\u2581of", "\u2581Public", "\u2581and", "\u2581Private", ":", "\u2581Can", "\u2581We", "\u2581Have", "\u2581Both", "?"]], "entropy": [[0.68798828125, 0.0794677734375, 0.93798828125, 0.057861328125, 0.544921875, 0.16162109375, 0.031646728515625, 0.001861572265625, 0.00473785400390625, 1.029296875, 3.609375, 3.28515625, 3.515625, 2.00390625, 3.994140625, 0.74755859375, 0.06500244140625, 0.00495147705078125, 1.5263671875, 2.857421875, 3.919921875, 0.576171875, 4.41015625, 4.8125, 3.865234375, 3.869140625, 2.84765625, 1.06640625]], "avg_entropy": [1.804074423653739], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Rajendra Prasad", "score_of_biggest_cluster": 0.04720766097307205, "score_of_first_answer": 0.04720766097307205, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.04720766097307205, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44830400993238506, "std_of_first_answer": 0.44830400993238506, "avg_entropy_of_first_answer": 1.804074423653739, "lex_sim": 1.0}
{"question": "when did they stop making jello pudding pops", "answer": ["2010"], "scores": [[0.046630859375, 0.8154296875, 0.9990234375, 0.4853515625, 0.227783203125]], "normalized_score": [0.33469003438949585], "tokens": [["\u2581", "2", "0", "1", "0"]], "entropy": [[1.7861328125, 0.494873046875, 0.00835418701171875, 0.80908203125, 2.189453125]], "avg_entropy": [1.0575790405273438], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the 90s", "score_of_biggest_cluster": 0.33469003438949585, "score_of_first_answer": 0.33469003438949585, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 0.046630859375, "avg_score": 0.33469003438949585, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3541973272777419, "std_of_first_answer": 0.3541973272777419, "avg_entropy_of_first_answer": 1.0575790405273438, "lex_sim": 1.0}
{"question": "who performed the halftime show at super bowl 51", "answer": ["Justin Timberlake."], "scores": [[0.035614013671875, 0.99951171875, 1.0, 1.0, 1.0, 0.0298004150390625, 0.0, 0.65771484375]], "normalized_score": [0.0], "tokens": [["\u2581Justin", "\u2581Tim", "ber", "la", "ke", ".", "\u2581#####", "#"]], "entropy": [[0.1669921875, 0.0033130645751953125, 0.00031566619873046875, 0.0005040168762207031, 3.451108932495117e-05, 0.427490234375, 0.02581787109375, 1.4755859375]], "avg_entropy": [0.2625066861510277], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Lady Gaga", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4535762990984481, "std_of_first_answer": 0.4535762990984481, "avg_entropy_of_first_answer": 0.2625066861510277, "lex_sim": 1.0}
{"question": "when was the first dark tower book published", "answer": ["1982"], "scores": [[0.90673828125, 1.0, 1.0, 1.0, 1.0]], "normalized_score": [0.9806101322174072], "tokens": [["\u2581", "1", "9", "8", "2"]], "entropy": [[0.421630859375, 0.0005784034729003906, 0.0004413127899169922, 0.00115203857421875, 0.0026187896728515625]], "avg_entropy": [0.08528428077697754], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1982", "score_of_biggest_cluster": 0.9806101322174072, "score_of_first_answer": 0.9806101322174072, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.90673828125, "avg_score": 0.9806101322174072, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.0373046875, "std_of_first_answer": 0.0373046875, "avg_entropy_of_first_answer": 0.08528428077697754, "lex_sim": 1.0}
{"question": "who made possible the first reproduction of the human voice on the phonograph", "answer": ["Thomas Edison ######  QUESTA SEDE TI USENDE PER I PROCESSI UMANI E NON PER RAGIONALMENTE ####"], "scores": [[0.93359375, 0.99462890625, 1.0, 0.0, 0.44482421875, 0.005340576171875, 0.0017147064208984375, 0.399658203125, 0.99951171875, 5.125999450683594e-06, 0.008087158203125, 0.001491546630859375, 0.01049041748046875, 0.472900390625, 0.0008358955383300781, 0.0001761913299560547, 0.01031494140625, 0.176025390625, 0.9853515625, 0.035552978515625, 0.01482391357421875, 0.02947998046875, 0.99658203125, 0.00347900390625, 0.76806640625, 0.93017578125, 0.01216888427734375, 0.51416015625, 0.998046875, 0.80322265625, 0.98681640625, 0.10064697265625, 0.0660400390625, 0.59033203125, 0.689453125, 0.346435546875, 0.955078125, 0.005443572998046875]], "normalized_score": [0.0], "tokens": [["\u2581Thomas", "\u2581Ed", "ison", "\u2581#####", "#", "\u2581", "\u2581Q", "UE", "ST", "A", "\u2581SE", "DE", "\u2581T", "I", "\u2581US", "EN", "DE", "\u2581P", "ER", "\u2581I", "\u2581PRO", "CESS", "I", "\u2581U", "MA", "NI", "\u2581E", "\u2581N", "ON", "\u2581P", "ER", "\u2581R", "AG", "ION", "AL", "MENT", "E", "\u2581####"]], "entropy": [[0.27978515625, 0.03814697265625, 0.0017766952514648438, 0.86962890625, 2.58984375, 2.107421875, 2.826171875, 2.353515625, 0.003509521484375, 0.0172271728515625, 3.294921875, 2.234375, 4.1015625, 1.9775390625, 3.265625, 1.607421875, 2.7421875, 3.388671875, 0.11578369140625, 3.5234375, 3.529296875, 1.9609375, 0.03466796875, 2.28125, 1.1611328125, 0.352783203125, 1.693359375, 2.50390625, 0.0201568603515625, 1.0888671875, 0.0948486328125, 3.353515625, 1.4453125, 0.966796875, 0.8505859375, 1.259765625, 0.190673828125, 2.736328125]], "avg_entropy": [1.6542825949819464], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Thomas Alva Edison", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41330497285831286, "std_of_first_answer": 0.41330497285831286, "avg_entropy_of_first_answer": 1.6542825949819464, "lex_sim": 1.0}
{"question": "who won the workd series of poker 2017", "answer": ["Chris Ferguson #FuturesChat: The Role of Universities in the Future of Work"], "scores": [[0.6416015625, 0.55712890625, 1.0, 0.99951171875, 1.0, 5.364418029785156e-07, 0.003215789794921875, 1.1920928955078125e-07, 0.01611328125, 0.0015888214111328125, 0.0009646415710449219, 0.0018415451049804688, 0.041595458984375, 0.0012264251708984375, 0.96630859375, 0.966796875, 0.00041365623474121094, 0.99609375, 0.9189453125, 0.1412353515625, 0.11407470703125, 0.95263671875, 0.90625]], "normalized_score": [0.02700606919825077], "tokens": [["\u2581Chris", "\u2581Fer", "g", "us", "on", "\u2581#", "F", "ut", "ures", "Ch", "at", ":", "\u2581The", "\u2581Ro", "le", "\u2581of", "\u2581Univers", "ities", "\u2581in", "\u2581the", "\u2581Future", "\u2581of", "\u2581Work"]], "entropy": [[2.3359375, 0.89599609375, 4.351139068603516e-06, 0.002529144287109375, 0.0008244514465332031, 0.78759765625, 4.3515625, 0.64404296875, 3.892578125, 4.45703125, 0.479736328125, 2.107421875, 4.9765625, 5.30078125, 0.2232666015625, 0.1754150390625, 2.88671875, 0.033416748046875, 0.52001953125, 3.25390625, 3.03515625, 0.303955078125, 0.62451171875]], "avg_entropy": [1.7951726939367212], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Scott Blumstein", "score_of_biggest_cluster": 0.02700606919825077, "score_of_first_answer": 0.02700606919825077, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.02700606919825077, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44925126860917397, "std_of_first_answer": 0.44925126860917397, "avg_entropy_of_first_answer": 1.7951726939367212, "lex_sim": 1.0}
{"question": "what's the medal count for canada in the olympics", "answer": ["Through 2020: 168 gold, 164 silver, 139 bronze."], "scores": [[0.0008416175842285156, 0.291748046875, 0.99755859375, 0.99853515625, 0.8603515625, 0.81689453125, 0.0872802734375, 0.95751953125, 0.83544921875, 0.042205810546875, 0.1524658203125, 0.2388916015625, 0.88671875, 0.9990234375, 0.9619140625, 0.0130615234375, 0.0716552734375, 0.99951171875, 0.998046875, 0.8115234375, 0.99072265625, 0.0249176025390625, 0.1529541015625, 0.9990234375, 0.61279296875, 1.1324882507324219e-06, 3.7550926208496094e-06, 0.57275390625, 2.09808349609375e-05, 0.6767578125]], "normalized_score": [0.09983712434768677], "tokens": [["\u2581Through", "\u2581", "2", "0", "2", "0", ":", "\u2581", "1", "6", "8", "\u2581gold", ",", "\u2581", "1", "6", "4", "\u2581silver", ",", "\u2581", "1", "3", "9", "\u2581bronze", ".", "\u2581\\", "section", "{", "Introduction", "}"]], "entropy": [[1.9755859375, 1.1982421875, 0.02020263671875, 0.0163421630859375, 0.41943359375, 0.5810546875, 0.78564453125, 0.225830078125, 0.5234375, 1.5283203125, 2.388671875, 1.318359375, 0.359619140625, 0.006420135498046875, 0.1973876953125, 1.4677734375, 2.24609375, 0.004787445068359375, 0.01453399658203125, 0.494140625, 0.054656982421875, 1.71484375, 2.236328125, 0.00902557373046875, 1.1005859375, 1.03515625, 1.30078125, 1.841796875, 3.87890625, 1.71484375]], "avg_entropy": [1.021960194905599], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "501", "score_of_biggest_cluster": 0.09983712434768677, "score_of_first_answer": 0.09983712434768677, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 1.1324882507324219e-06, "avg_score": 0.09983712434768677, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41372874637872015, "std_of_first_answer": 0.41372874637872015, "avg_entropy_of_first_answer": 1.021960194905599, "lex_sim": 1.0}
{"question": "who is credited with creating the gothic art movement", "answer": ["Not a science fact, but the correct answer is Vittorio Alfieri."], "scores": [[0.09222412109375, 0.263427734375, 2.3603439331054688e-05, 0.01934814453125, 0.270751953125, 0.75341796875, 0.37451171875, 0.1416015625, 0.9970703125, 0.79345703125, 0.004901885986328125, 0.9921875, 0.1917724609375, 0.9990234375, 0.7587890625, 2.086162567138672e-06, 0.0002789497375488281]], "normalized_score": [0.0480697862803936], "tokens": [["\u2581Not", "\u2581a", "\u2581science", "\u2581fact", ",", "\u2581but", "\u2581the", "\u2581correct", "\u2581answer", "\u2581is", "\u2581Vitt", "orio", "\u2581Alf", "ieri", ".", "\u2581###", "\u2581Question"]], "entropy": [[5.0078125, 1.8271484375, 0.9228515625, 1.857421875, 1.6337890625, 1.3017578125, 2.7734375, 1.5625, 0.0225830078125, 0.638671875, 4.0078125, 0.05621337890625, 3.953125, 0.0107269287109375, 0.91064453125, 0.822265625, 4.86328125]], "avg_entropy": [1.892473108628217], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Abbot Suger", "score_of_biggest_cluster": 0.0480697862803936, "score_of_first_answer": 0.0480697862803936, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 2.086162567138672e-06, "avg_score": 0.0480697862803936, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.383082809887177, "std_of_first_answer": 0.383082809887177, "avg_entropy_of_first_answer": 1.892473108628217, "lex_sim": 1.0}
{"question": "who plays jack in battle of the sexes", "answer": ["Emma Stone"], "scores": [[0.99072265625, 1.0]], "normalized_score": [0.9953505396842957], "tokens": [["\u2581Emma", "\u2581Stone"]], "entropy": [[0.07000732421875, 0.0009765625]], "avg_entropy": [0.035491943359375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Bill Pullman", "score_of_biggest_cluster": 0.9953505396842957, "score_of_first_answer": 0.9953505396842957, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.99072265625, "avg_score": 0.9953505396842957, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.004638671875, "std_of_first_answer": 0.004638671875, "avg_entropy_of_first_answer": 0.035491943359375, "lex_sim": 1.0}
{"question": "who was the declaration of independence written for", "answer": ["The Declaration of Independence was written to announce the separation of the 13 American colonies from British rule and to establish the United States of America as a sovereign nation."], "scores": [[0.75, 0.0001819133758544922, 1.0, 0.99951171875, 0.99853515625, 1.0, 0.9921875, 0.99462890625, 0.043060302734375, 0.1234130859375, 1.0, 0.9248046875, 0.33154296875, 0.99267578125, 0.9765625, 0.71533203125, 1.0, 1.0, 0.94970703125, 0.9990234375, 1.0, 1.0, 0.48193359375, 0.99169921875, 0.62646484375, 0.8427734375, 0.6611328125, 0.9853515625, 0.9990234375, 0.99951171875, 0.95458984375, 1.0, 0.92578125, 0.320556640625, 0.599609375, 1.0, 1.0, 0.98193359375, 0.99560546875, 4.708766937255859e-06, 2.288818359375e-05, 0.370849609375, 0.99951171875, 0.0924072265625, 0.0034084320068359375, 9.59634780883789e-06, 0.9814453125, 0.9990234375]], "normalized_score": [0.26950666308403015], "tokens": [["\u2581The", "\u2581Dec", "laration", "\u2581of", "\u2581Independ", "ence", "\u2581was", "\u2581written", "\u2581to", "\u2581announ", "ce", "\u2581the", "\u2581separation", "\u2581of", "\u2581the", "\u2581", "1", "3", "\u2581American", "\u2581colon", "ies", "\u2581from", "\u2581British", "\u2581rule", "\u2581and", "\u2581to", "\u2581establish", "\u2581the", "\u2581United", "\u2581States", "\u2581of", "\u2581America", "\u2581as", "\u2581a", "\u2581so", "ver", "eign", "\u2581nation", ".", "\u2581#", "Me", "To", "o", "\u2581movement", ":", "\u2581Tan", "ush", "ree"]], "entropy": [[0.97216796875, 1.466796875, 0.0004227161407470703, 0.004642486572265625, 0.0107574462890625, 0.0007739067077636719, 0.052825927734375, 0.042266845703125, 0.422607421875, 1.294921875, 8.088350296020508e-05, 0.35107421875, 1.2333984375, 0.0477294921875, 0.1241455078125, 1.017578125, 1.901388168334961e-05, 5.21540641784668e-05, 0.26318359375, 0.00814056396484375, 1.7642974853515625e-05, 0.0012559890747070312, 0.76806640625, 0.051971435546875, 0.79052734375, 0.74560546875, 0.94775390625, 0.0850830078125, 0.01256561279296875, 0.0033416748046875, 0.1932373046875, 0.0010156631469726562, 0.2734375, 0.63232421875, 0.939453125, 8.445978164672852e-05, 1.8596649169921875e-05, 0.1004638671875, 0.036590576171875, 1.017578125, 3.630859375, 2.685546875, 0.006763458251953125, 2.591796875, 2.943359375, 4.4140625, 0.1611328125, 0.0074310302734375]], "avg_entropy": [0.6323943684498469], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the Second Continental Congress", "score_of_biggest_cluster": 0.26950666308403015, "score_of_first_answer": 0.26950666308403015, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.708766937255859e-06, "avg_score": 0.26950666308403015, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3672054743074628, "std_of_first_answer": 0.3672054743074628, "avg_entropy_of_first_answer": 0.6323943684498469, "lex_sim": 1.0}
{"question": "who did kenny rogers sing mary did you know with", "answer": ["Wynonna Judd"], "scores": [[0.52490234375, 1.0, 0.99609375, 0.99951171875, 0.9990234375]], "normalized_score": [0.8781090974807739], "tokens": [["\u2581W", "yn", "onna", "\u2581Jud", "d"]], "entropy": [[2.0, 0.0018482208251953125, 0.0297393798828125, 0.0054931640625, 0.007663726806640625]], "avg_entropy": [0.4089488983154297], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Wynonna Judd", "score_of_biggest_cluster": 0.8781090974807739, "score_of_first_answer": 0.8781090974807739, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.52490234375, "avg_score": 0.8781090974807739, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.18950682832599394, "std_of_first_answer": 0.18950682832599394, "avg_entropy_of_first_answer": 0.4089488983154297, "lex_sim": 1.0}
{"question": "who scored the most points in a single game in the nba", "answer": ["Wilt Chamberlain, scored 100 points in a game on March 2, 1962."], "scores": [[0.7646484375, 1.0, 0.9990234375, 0.99951171875, 0.2010498046875, 0.040435791015625, 0.99951171875, 1.0, 1.0, 1.0, 0.998046875, 0.84521484375, 0.99658203125, 0.64990234375, 0.32421875, 0.99853515625, 0.99951171875, 1.0, 0.98876953125, 0.99658203125, 1.0, 1.0, 1.0, 0.99951171875, 0.578125, 2.9206275939941406e-06, 0.08612060546875, 5.781650543212891e-06, 0.0186767578125, 0.01116943359375, 0.00011676549911499023, 2.8789043426513672e-05, 0.351318359375, 1.0, 0.984375, 0.93603515625, 0.033172607421875, 0.3896484375, 0.1484375, 0.2861328125, 1.0, 0.99560546875, 0.99755859375, 0.9990234375, 0.5068359375, 0.02044677734375, 0.307861328125, 0.50341796875]], "normalized_score": [0.19815436005592346], "tokens": [["\u2581W", "ilt", "\u2581Chamber", "lain", ",", "\u2581scored", "\u2581", "1", "0", "0", "\u2581points", "\u2581in", "\u2581a", "\u2581game", "\u2581on", "\u2581March", "\u2581", "2", ",", "\u2581", "1", "9", "6", "2", ".", "\u2581#", "1", "\u2581Post", "\u2581by", "\u2581A", "J", "MD", "4", "2", "9", "\u2581\u00bb", "\u2581", "0", "4", "\u2581A", "pr", "\u2581", "2", "0", "1", "6", "\u2581", "1"]], "entropy": [[0.81982421875, 0.0003285408020019531, 0.00928497314453125, 0.00494384765625, 1.908203125, 1.6455078125, 0.00649261474609375, 0.0004253387451171875, 0.0002536773681640625, 5.078315734863281e-05, 0.0153350830078125, 0.68408203125, 0.025665283203125, 0.6630859375, 1.7578125, 0.01320648193359375, 0.00370025634765625, 0.00234222412109375, 0.062225341796875, 0.023406982421875, 8.32676887512207e-05, 4.112720489501953e-06, 4.9173831939697266e-05, 0.002681732177734375, 1.0986328125, 0.075927734375, 2.103515625, 2.3671875, 2.87890625, 6.21484375, 0.27685546875, 1.490234375, 1.9052734375, 0.0002732276916503906, 0.106689453125, 0.360107421875, 2.302734375, 1.37109375, 2.166015625, 2.25, 0.00029587745666503906, 0.040985107421875, 0.01812744140625, 0.00873565673828125, 0.708984375, 1.1748046875, 0.69970703125, 1.0927734375]], "avg_entropy": [0.7992020783325037], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Wilt Chamberlain", "score_of_biggest_cluster": 0.19815436005592346, "score_of_first_answer": 0.19815436005592346, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.9206275939941406e-06, "avg_score": 0.19815436005592346, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4086161002032864, "std_of_first_answer": 0.4086161002032864, "avg_entropy_of_first_answer": 0.7992020783325037, "lex_sim": 1.0}
{"question": "what year is the deer hunter set in", "answer": ["The Deer Hunter is set in the years 1968-1971."], "scores": [[0.351318359375, 0.97119140625, 1.0, 1.0, 0.96435546875, 0.9990234375, 0.97998046875, 0.84716796875, 0.254150390625, 0.9951171875, 1.0, 1.0, 0.94287109375, 0.488525390625, 0.619140625, 0.90234375, 1.0, 0.99853515625, 0.2298583984375, 0.81884765625, 1.2516975402832031e-06, 0.0038547515869140625, 0.08135986328125, 0.0016384124755859375, 0.35888671875, 0.00010448694229125977, 3.546476364135742e-05]], "normalized_score": [0.13427242636680603], "tokens": [["\u2581The", "\u2581De", "er", "\u2581Hunter", "\u2581is", "\u2581set", "\u2581in", "\u2581the", "\u2581years", "\u2581", "1", "9", "6", "8", "-", "1", "9", "7", "1", ".", "\u2581#", "2", "4", "\u2581-", "\u2581The", "\u2581New", "\u2581Class"]], "entropy": [[1.0, 0.1922607421875, 0.00014591217041015625, 0.0007982254028320312, 0.2001953125, 0.0095977783203125, 0.11431884765625, 0.43359375, 1.28515625, 0.038818359375, 1.6570091247558594e-05, 2.0265579223632812e-06, 0.2459716796875, 1.48828125, 1.1396484375, 0.335693359375, 0.000347137451171875, 0.0128936767578125, 1.7080078125, 0.70263671875, 0.29443359375, 3.41796875, 2.654296875, 3.23828125, 3.552734375, 0.3271484375, 0.68212890625]], "avg_entropy": [0.8546435568067763], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "late 1967", "score_of_biggest_cluster": 0.13427242636680603, "score_of_first_answer": 0.13427242636680603, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.2516975402832031e-06, "avg_score": 0.13427242636680603, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.405744673848667, "std_of_first_answer": 0.405744673848667, "avg_entropy_of_first_answer": 0.8546435568067763, "lex_sim": 1.0}
{"question": "who sings the song let me love you", "answer": ["Mario Winans (Feat."], "scores": [[0.9765625, 0.87841796875, 1.0, 0.01358795166015625, 0.164794921875, 0.77978515625, 0.99755859375, 0.91064453125, 0.96875, 0.72021484375, 0.99755859375, 0.9306640625, 0.87841796875, 1.0, 1.0, 0.99658203125]], "normalized_score": [0.6389418244361877], "tokens": [["\u2581Mario", "\u2581Win", "ans", "\u2581(", "Fe", "at", ".", "\u2581En", "ya", "\u2581&", "\u2581P", ".", "\u2581D", "idd", "y", ")"]], "entropy": [[0.18408203125, 0.62744140625, 0.001941680908203125, 1.744140625, 1.1259765625, 0.52880859375, 0.0249481201171875, 0.64306640625, 0.1619873046875, 1.001953125, 0.0250244140625, 0.44580078125, 0.376953125, 0.002338409423828125, 1.6450881958007812e-05, 0.02789306640625]], "avg_entropy": [0.4326482564210892], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "DJ Snake featuring Justin Bieber", "score_of_biggest_cluster": 0.6389418244361877, "score_of_first_answer": 0.6389418244361877, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.01358795166015625, "avg_score": 0.6389418244361877, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.29111676504164635, "std_of_first_answer": 0.29111676504164635, "avg_entropy_of_first_answer": 0.4326482564210892, "lex_sim": 1.0}
{"question": "when was the first epistle of john written", "answer": ["Traditionally dated to the late 1st century AD, around 90-110 AD."], "scores": [[0.053955078125, 0.984375, 0.8017578125, 0.68994140625, 0.69873046875, 0.459228515625, 0.9892578125, 1.0, 1.0, 0.9990234375, 0.4873046875, 0.357666015625, 0.1099853515625, 0.94970703125, 0.771484375, 0.9716796875, 0.92236328125, 0.92138671875, 0.0665283203125, 1.0, 0.84423828125, 0.66552734375, 2.980232238769531e-07, 0.0009007453918457031, 0.0010671615600585938, 0.99609375, 0.0001138448715209961, 0.99951171875, 0.99169921875, 0.001922607421875, 8.422136306762695e-05, 0.0012369155883789062, 0.495361328125, 0.01024627685546875, 0.0112457275390625, 1.0, 0.99560546875, 0.61669921875, 1.0, 0.268798828125, 1.0, 0.1539306640625, 1.0, 0.01873779296875, 0.476806640625, 0.9931640625, 0.99853515625, 0.66162109375]], "normalized_score": [0.1492312103509903], "tokens": [["\u2581Trad", "itionally", "\u2581dated", "\u2581to", "\u2581the", "\u2581late", "\u2581", "1", "st", "\u2581century", "\u2581AD", ",", "\u2581around", "\u2581", "9", "0", "-", "1", "1", "0", "\u2581AD", ".", "\u2581#", "F", "rid", "ay", "Fl", "ash", "back", ":", "\u2581Watch", "\u2581Michael", "\u2581Jackson", "\u2581and", "\u2581Whit", "ney", "\u2581Houston", "'", "s", "\u2581Ep", "ic", "\u2581Du", "et", "\u2581From", "\u2581", "1", "9", "9"]], "entropy": [[3.537109375, 0.08880615234375, 0.7763671875, 0.978515625, 0.96533203125, 1.0029296875, 0.06787109375, 2.2292137145996094e-05, 0.0012454986572265625, 0.01068115234375, 1.3896484375, 1.38671875, 1.55078125, 0.208251953125, 0.53857421875, 0.128662109375, 0.356201171875, 0.278076171875, 0.246826171875, 0.0003223419189453125, 0.63818359375, 0.96044921875, 1.0439453125, 4.33203125, 2.50390625, 0.037628173828125, 1.0654296875, 0.0029392242431640625, 0.063720703125, 1.28515625, 4.546875, 3.6875, 2.4453125, 1.5439453125, 3.439453125, 0.00021886825561523438, 0.0360107421875, 1.5732421875, 0.0003871917724609375, 2.86328125, 0.0001270771026611328, 2.302734375, 0.0012521743774414062, 2.869140625, 1.423828125, 0.0458984375, 0.0127105712890625, 0.640625]], "avg_entropy": [1.1016432270407677], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "AD 95\u2013110", "score_of_biggest_cluster": 0.1492312103509903, "score_of_first_answer": 0.1492312103509903, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.1492312103509903, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4065619080849223, "std_of_first_answer": 0.4065619080849223, "avg_entropy_of_first_answer": 1.1016432270407677, "lex_sim": 1.0}
{"question": "how many counties does the state of georgia have", "answer": ["159 CHAPTER VIII."], "scores": [[0.9951171875, 1.0, 0.99951171875, 0.99951171875, 0.0, 0.0010328292846679688, 0.255859375, 0.0012683868408203125, 0.441162109375, 0.1546630859375, 0.9931640625]], "normalized_score": [0.0], "tokens": [["\u2581", "1", "5", "9", "\u2581CHAPTER", "\u2581VIII", ".", "\u2581PL", "AN", "N", "ING"]], "entropy": [[0.04290771484375, 0.0025234222412109375, 0.0037517547607421875, 0.00553131103515625, 0.75830078125, 1.8779296875, 3.279296875, 4.0390625, 1.4072265625, 1.677734375, 0.04736328125]], "avg_entropy": [1.1946934786709873], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "159", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.44280226501851244, "std_of_first_answer": 0.44280226501851244, "avg_entropy_of_first_answer": 1.1946934786709873, "lex_sim": 1.0}
{"question": "what is the minimum dollar amount for federal court", "answer": ["I'm sorry, I do not have that information."], "scores": [[0.0919189453125, 0.49755859375, 0.99951171875, 0.921875, 0.99072265625, 0.6298828125, 0.145263671875, 0.9990234375, 0.86572265625, 0.2147216796875, 0.98291015625, 0.9609375, 0.09246826171875, 0.9951171875, 0.8662109375, 0.1829833984375, 0.3662109375, 0.35107421875, 0.9970703125, 0.099853515625, 0.06671142578125, 0.0003871917724609375, 0.6552734375, 0.99951171875, 0.8427734375, 0.96923828125, 0.60205078125, 0.9970703125, 0.87353515625, 0.0001493692398071289, 0.375244140625, 0.7255859375, 0.982421875, 0.7587890625, 0.11737060546875, 0.08026123046875, 0.8330078125, 0.0003714561462402344, 9.059906005859375e-05, 0.88623046875, 5.3048133850097656e-05, 0.03363037109375, 0.001445770263671875, 0.0007648468017578125, 0.716796875, 0.3603515625, 0.90771484375, 0.98095703125]], "normalized_score": [0.15746724605560303], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581I", "\u2581do", "\u2581not", "\u2581have", "\u2581that", "\u2581information", ".", "\u2581Could", "\u2581you", "\u2581please", "\u2581specify", "\u2581which", "\u2581type", "\u2581of", "\u2581court", "\u2581and", "\u2581or", "\u2581juris", "diction", "\u2581you", "\u2581are", "\u2581referring", "\u2581to", "?", "\u2581In", "\u2581the", "\u2581United", "\u2581States", ",", "\u2581there", "\u2581is", "\u2581a", "\u2581significant", "\u2581divide", "\u2581between", "\u2581those", "\u2581who", "\u2581support", "\u2581v", "acc", "ines", "\u2581and", "\u2581those"]], "entropy": [[2.322265625, 1.13671875, 0.0038890838623046875, 0.2919921875, 0.060394287109375, 1.09765625, 1.6884765625, 0.00711822509765625, 0.441162109375, 1.705078125, 0.09661865234375, 0.245849609375, 2.0234375, 0.033966064453125, 0.482421875, 0.99658203125, 1.353515625, 1.6767578125, 0.0198211669921875, 1.27734375, 0.740234375, 1.5341796875, 1.572265625, 0.005535125732421875, 0.6201171875, 0.166259765625, 1.1337890625, 0.0226287841796875, 0.5146484375, 0.4853515625, 1.2109375, 0.8193359375, 0.10052490234375, 0.97802734375, 1.33984375, 0.55712890625, 0.7041015625, 2.771484375, 1.4267578125, 0.46728515625, 1.3466796875, 1.5791015625, 2.72265625, 3.6484375, 1.298828125, 1.3232421875, 0.52978515625, 0.163330078125]], "avg_entropy": [0.9738242228825887], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "$75,000", "score_of_biggest_cluster": 0.15746724605560303, "score_of_first_answer": 0.15746724605560303, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 5.3048133850097656e-05, "avg_score": 0.15746724605560303, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39445988969736245, "std_of_first_answer": 0.39445988969736245, "avg_entropy_of_first_answer": 0.9738242228825887, "lex_sim": 1.0}
{"question": "who won the most on who wants to be a millionaire", "answer": ["no single person has won the most on Who Wants to Be a Millionaire, as the show is a game of knowledge and skill, and the winners are determined by their own abilities rather than any external factors such as luck or chance"], "scores": [[0.00801849365234375, 0.00453948974609375, 0.595703125, 0.3466796875, 0.98779296875, 0.99365234375, 0.9951171875, 0.984375, 0.152099609375, 0.99951171875, 1.0, 0.9521484375, 0.7900390625, 0.99951171875, 1.0, 1.0, 1.0, 0.2320556640625, 0.94140625, 0.84716796875, 0.5244140625, 0.3818359375, 0.921875, 0.94482421875, 0.724609375, 0.0208587646484375, 0.873046875, 0.2117919921875, 0.70458984375, 0.83349609375, 0.6962890625, 0.332275390625, 0.6923828125, 0.83203125, 0.7021484375, 0.98095703125, 0.85986328125, 0.1875, 0.650390625, 1.0, 0.0144500732421875, 0.9990234375, 0.5205078125, 0.286865234375, 0.779296875, 0.064697265625, 0.99951171875, 0.283203125, 0.7841796875, 0.18212890625]], "normalized_score": [0.4419248104095459], "tokens": [["\u2581no", "\u2581single", "\u2581person", "\u2581has", "\u2581won", "\u2581the", "\u2581most", "\u2581on", "\u2581Who", "\u2581W", "ants", "\u2581to", "\u2581Be", "\u2581a", "\u2581Mill", "ion", "aire", ",", "\u2581as", "\u2581the", "\u2581show", "\u2581is", "\u2581a", "\u2581game", "\u2581of", "\u2581knowledge", "\u2581and", "\u2581skill", ",", "\u2581and", "\u2581the", "\u2581w", "inners", "\u2581are", "\u2581determined", "\u2581by", "\u2581their", "\u2581own", "\u2581ab", "ilities", "\u2581rather", "\u2581than", "\u2581any", "\u2581external", "\u2581factors", "\u2581such", "\u2581as", "\u2581luck", "\u2581or", "\u2581chance"]], "entropy": [[3.166015625, 0.62255859375, 1.1337890625, 1.5634765625, 0.08477783203125, 0.049896240234375, 0.041229248046875, 0.112548828125, 1.314453125, 0.00604248046875, 0.0001842975616455078, 0.1943359375, 0.52001953125, 0.0050506591796875, 0.0019683837890625, 0.0005779266357421875, 0.0008087158203125, 1.4951171875, 0.333251953125, 0.4765625, 1.482421875, 1.3876953125, 0.48193359375, 0.335205078125, 1.033203125, 0.64453125, 0.583984375, 2.29296875, 1.154296875, 0.80712890625, 1.46875, 1.662109375, 0.6171875, 0.7919921875, 1.05859375, 0.118896484375, 0.56689453125, 1.326171875, 1.2646484375, 0.0007796287536621094, 0.79345703125, 0.00799560546875, 1.33984375, 2.408203125, 0.6611328125, 0.40283203125, 0.0027103424072265625, 2.615234375, 0.58642578125, 3.48046875]], "avg_entropy": [0.8500072240829468], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Kevin Olmstead", "score_of_biggest_cluster": 0.4419248104095459, "score_of_first_answer": 0.4419248104095459, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.00453948974609375, "avg_score": 0.4419248104095459, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.342424424041962, "std_of_first_answer": 0.342424424041962, "avg_entropy_of_first_answer": 0.8500072240829468, "lex_sim": 1.0}
{"question": "when did ga state get a football team", "answer": ["2010 #8 in Nonfiction, History, Asian, Japan"], "scores": [[0.46533203125, 0.31689453125, 0.99609375, 0.806640625, 0.69580078125, 4.172325134277344e-07, 0.0018672943115234375, 0.0013685226440429688, 1.3709068298339844e-05, 0.017578125, 0.93505859375, 0.1197509765625, 0.060821533203125, 0.3125, 0.002407073974609375, 0.477783203125, 0.05560302734375]], "normalized_score": [0.027467073872685432], "tokens": [["\u2581", "2", "0", "1", "0", "\u2581#", "8", "\u2581in", "\u2581Non", "f", "iction", ",", "\u2581History", ",", "\u2581Asian", ",", "\u2581Japan"]], "entropy": [[1.822265625, 0.6396484375, 0.0318603515625, 0.61474609375, 1.2470703125, 1.08203125, 5.98046875, 3.810546875, 4.83984375, 1.3935546875, 0.319091796875, 2.76953125, 3.568359375, 2.6640625, 3.86328125, 2.296875, 3.421875]], "avg_entropy": [2.3744183708639706], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2010", "score_of_biggest_cluster": 0.027467073872685432, "score_of_first_answer": 0.027467073872685432, "max_score_of_first_answer": 0.99609375, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.027467073872685432, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.345965456602405, "std_of_first_answer": 0.345965456602405, "avg_entropy_of_first_answer": 2.3744183708639706, "lex_sim": 1.0}
{"question": "where is the second largest mall in america", "answer": ["King of Prussia Mall in Pennsylvania #BookReview :: A Very Expensive Poison - The Definitive Story of the Murder of Litvinenko by #LukeHarding"], "scores": [[0.1904296875, 0.99951171875, 1.0, 1.0, 1.0, 0.986328125, 0.276611328125, 0.89453125, 4.76837158203125e-07, 3.272294998168945e-05, 0.0017490386962890625, 0.2098388671875, 2.0205974578857422e-05, 0.0212249755859375, 0.0006842613220214844, 0.002178192138671875, 0.98291015625, 0.9716796875, 0.986328125, 0.01265716552734375, 0.41552734375, 0.83251953125, 0.99853515625, 1.0, 0.239990234375, 0.9775390625, 0.99609375, 0.9599609375, 0.9990234375, 0.998046875, 0.79248046875, 0.998046875, 1.0, 0.99462890625, 0.1014404296875, 0.0037097930908203125, 0.86083984375, 0.97705078125, 0.99072265625, 0.42724609375]], "normalized_score": [0.1350342184305191], "tokens": [["\u2581King", "\u2581of", "\u2581Pr", "uss", "ia", "\u2581Mall", "\u2581in", "\u2581Pennsylvania", "\u2581#", "Book", "Re", "view", "\u2581::", "\u2581A", "\u2581Very", "\u2581Exp", "ensive", "\u2581Po", "ison", "\u2581-", "\u2581The", "\u2581Def", "init", "ive", "\u2581Story", "\u2581of", "\u2581the", "\u2581Mur", "der", "\u2581of", "\u2581Lit", "vin", "en", "ko", "\u2581by", "\u2581#", "Lu", "ke", "H", "arding"]], "entropy": [[2.767578125, 0.0033130645751953125, 0.0013370513916015625, 0.0017604827880859375, 0.0004763603210449219, 0.0888671875, 1.4609375, 0.354248046875, 1.1865234375, 3.626953125, 2.1640625, 0.5986328125, 2.19921875, 4.48828125, 5.26953125, 2.34375, 0.11376953125, 0.265869140625, 0.10040283203125, 0.430419921875, 3.138671875, 0.95849609375, 0.0123138427734375, 0.0021343231201171875, 1.6826171875, 0.12744140625, 0.035247802734375, 0.35009765625, 0.0108795166015625, 0.0188140869140625, 0.61474609375, 0.01479339599609375, 0.002208709716796875, 0.037078857421875, 1.091796875, 0.373291015625, 0.9033203125, 0.11376953125, 0.07781982421875, 0.78759765625]], "avg_entropy": [0.9454767107963562], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Florida", "score_of_biggest_cluster": 0.1350342184305191, "score_of_first_answer": 0.1350342184305191, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.76837158203125e-07, "avg_score": 0.1350342184305191, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.428063461800371, "std_of_first_answer": 0.428063461800371, "avg_entropy_of_first_answer": 0.9454767107963562, "lex_sim": 1.0}
{"question": "hazels boyfriend in the fault in our stars", "answer": ["Isaac"], "scores": [[0.7880859375]], "normalized_score": [0.7880859375], "tokens": [["\u2581Isaac"]], "entropy": [[0.76318359375]], "avg_entropy": [0.76318359375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Augustus Waters", "score_of_biggest_cluster": 0.7880859375, "score_of_first_answer": 0.7880859375, "max_score_of_first_answer": 0.7880859375, "min_score_of_first_answer": 0.7880859375, "avg_score": 0.7880859375, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.0, "std_of_first_answer": 0.0, "avg_entropy_of_first_answer": 0.76318359375, "lex_sim": 1.0}
{"question": "who was the german leader who signed the treaty of versailles", "answer": ["Woodrow Wilson"], "scores": [[0.62109375, 1.0, 0.97705078125]], "normalized_score": [0.8466256856918335], "tokens": [["\u2581Wood", "row", "\u2581Wilson"]], "entropy": [[2.01953125, 8.130073547363281e-05, 0.1439208984375]], "avg_entropy": [0.7211778163909912], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Gustav Bauer", "score_of_biggest_cluster": 0.8466256856918335, "score_of_first_answer": 0.8466256856918335, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.62109375, "avg_score": 0.8466256856918335, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.17346213836858249, "std_of_first_answer": 0.17346213836858249, "avg_entropy_of_first_answer": 0.7211778163909912, "lex_sim": 1.0}
{"question": "who performed the first c section in 1794", "answer": ["Dr. William Morton"], "scores": [[0.2198486328125, 0.998046875, 0.048370361328125, 0.0114898681640625, 0.9462890625]], "normalized_score": [0.16309422254562378], "tokens": [["\u2581Dr", ".", "\u2581William", "\u2581Mort", "on"]], "entropy": [[3.466796875, 0.0194854736328125, 3.3515625, 2.21875, 0.281005859375]], "avg_entropy": [1.8675201416015625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Dr. Jesse Bennett", "score_of_biggest_cluster": 0.16309422254562378, "score_of_first_answer": 0.16309422254562378, "max_score_of_first_answer": 0.998046875, "min_score_of_first_answer": 0.0114898681640625, "avg_score": 0.16309422254562378, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4365983578694969, "std_of_first_answer": 0.4365983578694969, "avg_entropy_of_first_answer": 1.8675201416015625, "lex_sim": 1.0}
{"question": "what kind of animals live in the great victoria desert", "answer": ["The Great Victoria Desert is home to a variety of animals, including kangaroos, emus, cockatoos, lizards, and snails."], "scores": [[0.03411865234375, 0.58642578125, 0.94140625, 0.99755859375, 1.0, 0.9892578125, 0.08837890625, 1.0, 0.7900390625, 0.75927734375, 1.0, 0.8935546875, 0.457275390625, 0.86376953125, 0.72265625, 1.0, 0.984375, 1.0, 1.0, 0.966796875, 1.0, 0.99951171875, 0.0005130767822265625, 0.99951171875, 0.998046875, 1.0, 0.9921875, 0.0556640625, 1.0, 1.0, 0.93212890625, 0.57958984375, 0.9443359375, 1.2099742889404297e-05, 0.98193359375, 0.1917724609375, 0.8671875, 0.94921875, 0.94775390625, 1.0, 0.06640625, 0.1533203125, 0.2421875, 0.6904296875, 1.0, 0.9716796875, 0.50927734375, 0.99951171875, 0.564453125, 0.9169921875]], "normalized_score": [0.4451785385608673], "tokens": [["\u2581The", "\u2581Great", "\u2581Victoria", "\u2581Des", "ert", "\u2581is", "\u2581home", "\u2581to", "\u2581a", "\u2581variety", "\u2581of", "\u2581animals", ",", "\u2581including", "\u2581k", "ang", "aro", "os", ",", "\u2581em", "us", ",", "\u2581co", "ck", "ato", "os", ",", "\u2581l", "iz", "ards", ",", "\u2581and", "\u2581sn", "ails", ".", "\u2581It", "\u2581is", "\u2581also", "\u2581home", "\u2581to", "\u2581some", "\u2581unique", "\u2581species", "\u2581such", "\u2581as", "\u2581the", "\u2581bil", "by", "\u2581and", "\u2581the"]], "entropy": [[3.5234375, 1.291015625, 0.2269287109375, 0.018585205078125, 0.00013208389282226562, 0.0780029296875, 1.2490234375, 0.0013256072998046875, 0.845703125, 0.8427734375, 0.0005803108215332031, 0.50537109375, 1.05078125, 0.408203125, 1.2841796875, 0.0017223358154296875, 0.0802001953125, 0.0006971359252929688, 0.0018405914306640625, 0.2197265625, 0.0007886886596679688, 0.003231048583984375, 2.28125, 0.0032444000244140625, 0.016357421875, 0.0008325576782226562, 0.045379638671875, 0.69140625, 0.0009012222290039062, 0.00020134449005126953, 0.25, 0.82275390625, 0.378173828125, 0.00019490718841552734, 0.10272216796875, 1.8720703125, 0.47119140625, 0.26904296875, 0.291748046875, 0.0016994476318359375, 1.7939453125, 1.7119140625, 1.6982421875, 0.873046875, 0.0023136138916015625, 0.18017578125, 2.404296875, 0.00437164306640625, 0.703125, 0.52099609375]], "avg_entropy": [0.580516939163208], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "malleefowl", "score_of_biggest_cluster": 0.4451785385608673, "score_of_first_answer": 0.4451785385608673, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.2099742889404297e-05, "avg_score": 0.4451785385608673, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.34148976030237777, "std_of_first_answer": 0.34148976030237777, "avg_entropy_of_first_answer": 0.580516939163208, "lex_sim": 1.0}
{"question": "when does god of war ghost of sparta take place", "answer": ["God of War: Ghost of Sparta takes place between the events of God of War and God of War II."], "scores": [[0.205810546875, 1.0, 1.0, 0.98095703125, 1.0, 1.0, 0.99853515625, 1.0, 0.87060546875, 0.99951171875, 0.587890625, 0.6279296875, 0.96435546875, 0.99951171875, 0.8173828125, 0.99951171875, 1.0, 0.953125, 0.9931640625, 1.0, 1.0, 0.95263671875, 0.841796875, 2.205371856689453e-06, 0.0007205009460449219, 0.291259765625, 0.06817626953125, 5.841255187988281e-06, 4.971027374267578e-05, 6.139278411865234e-06, 0.82421875, 1.0, 0.015625, 0.3017578125, 0.2081298828125, 0.12432861328125, 0.0130462646484375, 0.151611328125, 0.8330078125, 0.002803802490234375, 0.0003266334533691406, 0.611328125, 0.96337890625]], "normalized_score": [0.11925899982452393], "tokens": [["\u2581God", "\u2581of", "\u2581War", ":", "\u2581Ghost", "\u2581of", "\u2581Spart", "a", "\u2581takes", "\u2581place", "\u2581between", "\u2581the", "\u2581events", "\u2581of", "\u2581God", "\u2581of", "\u2581War", "\u2581and", "\u2581God", "\u2581of", "\u2581War", "\u2581II", ".", "\u2581#", "0", "0", "3", "\u2581\u2013", "\u2581Building", "\u2581res", "ili", "ence", "\u2581for", "\u2581the", "\u2581long", "\u2581run", "\u2581with", "\u2581Dr", ".", "\u2581Sarah", "\u2581Lav", "ender", "\u2581Smith"]], "entropy": [[2.822265625, 0.0019779205322265625, 0.0020809173583984375, 0.10736083984375, 0.0017137527465820312, 0.0015773773193359375, 0.01212310791015625, 3.874301910400391e-06, 0.4296875, 0.003322601318359375, 1.3935546875, 0.6865234375, 0.177490234375, 0.004840850830078125, 0.4990234375, 0.002349853515625, 0.0007109642028808594, 0.257080078125, 0.043701171875, 0.0020427703857421875, 0.0018281936645507812, 0.197509765625, 0.650390625, 1.1435546875, 2.09765625, 3.19921875, 2.220703125, 2.72265625, 4.33984375, 3.865234375, 0.58984375, 0.0001952648162841797, 3.119140625, 3.8046875, 2.408203125, 2.087890625, 2.74609375, 5.02734375, 1.3359375, 3.107421875, 4.19140625, 1.5517578125, 0.2454833984375]], "avg_entropy": [1.3279867906903111], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "ancient Greece", "score_of_biggest_cluster": 0.11925899982452393, "score_of_first_answer": 0.11925899982452393, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.205371856689453e-06, "avg_score": 0.11925899982452393, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4197647415141354, "std_of_first_answer": 0.4197647415141354, "avg_entropy_of_first_answer": 1.3279867906903111, "lex_sim": 1.0}
{"question": "where does the synthesis of new dna from existing dna occurs", "answer": ["in the nucleus of eukaryotic cells during the process of replication."], "scores": [[0.57666015625, 0.919921875, 0.82861328125, 0.982421875, 0.548828125, 0.435302734375, 0.99755859375, 1.0, 0.998046875, 0.99658203125, 0.378662109375, 0.80517578125, 0.7998046875, 0.9521484375, 0.382080078125, 0.998046875, 0.1510009765625, 6.556510925292969e-07, 0.05963134765625, 0.062408447265625, 0.0010471343994140625, 0.00020754337310791016, 0.00015747547149658203, 0.04119873046875, 5.602836608886719e-05, 0.0033702850341796875, 0.99853515625, 0.033905029296875, 0.81884765625, 1.0, 0.2088623046875, 0.9990234375, 0.99853515625, 0.28515625, 0.0015363693237304688, 0.94873046875, 0.51611328125, 0.031829833984375, 0.09271240234375, 0.89794921875, 0.9833984375, 0.059722900390625, 0.492431640625, 0.411865234375, 1.0, 0.927734375, 0.9873046875, 0.0011882781982421875]], "normalized_score": [0.12455913424491882], "tokens": [["\u2581in", "\u2581the", "\u2581nucle", "us", "\u2581of", "\u2581e", "uk", "ary", "otic", "\u2581cells", "\u2581during", "\u2581the", "\u2581process", "\u2581of", "\u2581rep", "lication", ".", "\u2581#", "1", "6", "\u2581-", "\u2581We", "\u2581talk", "\u2581to", "\u2581Adam", "\u2581Sav", "age", "\u2581from", "\u2581M", "yth", "B", "ust", "ers", "\u2581about", "\u2581special", "\u2581effects", ",", "\u2581science", "\u2581education", ",", "\u2581and", "\u2581what", "\u2581it", "'", "s", "\u2581like", "\u2581to", "\u2581run"]], "entropy": [[2.005859375, 0.521484375, 0.7685546875, 0.09295654296875, 1.2431640625, 1.177734375, 0.017059326171875, 0.0019016265869140625, 0.0168609619140625, 0.026458740234375, 1.669921875, 0.82275390625, 0.53515625, 0.2181396484375, 1.1875, 0.01534271240234375, 1.7802734375, 0.281005859375, 4.04296875, 2.91015625, 2.978515625, 4.671875, 3.697265625, 2.212890625, 3.74609375, 3.244140625, 0.0125732421875, 2.267578125, 0.91064453125, 0.0006723403930664062, 0.53271484375, 0.00936126708984375, 0.0102386474609375, 2.55859375, 2.93359375, 0.35205078125, 1.45703125, 4.47265625, 1.638671875, 0.375732421875, 0.1741943359375, 3.23828125, 2.078125, 1.244140625, 0.0006046295166015625, 0.270263671875, 0.0994873046875, 2.83203125]], "avg_entropy": [1.4032348990440369], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "origins of replication", "score_of_biggest_cluster": 0.12455913424491882, "score_of_first_answer": 0.12455913424491882, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 6.556510925292969e-07, "avg_score": 0.12455913424491882, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41176577850159873, "std_of_first_answer": 0.41176577850159873, "avg_entropy_of_first_answer": 1.4032348990440369, "lex_sim": 1.0}
{"question": "name two fibres which are made of proteins", "answer": ["Collagen and elastin."], "scores": [[0.51806640625, 0.99609375, 0.96484375, 0.35009765625, 0.9990234375, 1.0, 0.325927734375, 1.1920928955078125e-07, 0.0002377033233642578, 0.005680084228515625, 0.191650390625, 0.0013484954833984375, 0.0455322265625, 0.97119140625, 0.9990234375, 0.0204620361328125]], "normalized_score": [0.05105958506464958], "tokens": [["\u2581Col", "lagen", "\u2581and", "\u2581el", "ast", "in", ".", "\u2581#", "Ar", "men", "ia", "-", "T", "ur", "key", "\u2581relations"]], "entropy": [[1.4052734375, 0.0268402099609375, 0.177001953125, 0.68701171875, 0.0077667236328125, 0.000949859619140625, 0.931640625, 0.069091796875, 4.23828125, 3.169921875, 3.142578125, 2.712890625, 5.27734375, 0.203857421875, 0.0097503662109375, 2.99609375]], "avg_entropy": [1.5660183429718018], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "feathers", "score_of_biggest_cluster": 0.05105958506464958, "score_of_first_answer": 0.05105958506464958, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.05105958506464958, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.432028863179716, "std_of_first_answer": 0.432028863179716, "avg_entropy_of_first_answer": 1.5660183429718018, "lex_sim": 1.0}
{"question": "who won so you think you can dance season 13", "answer": ["Lex Ishii"], "scores": [[0.67724609375, 0.99560546875, 0.99462890625, 0.248291015625]], "normalized_score": [0.6387985944747925], "tokens": [["\u2581Lex", "\u2581I", "sh", "ii"]], "entropy": [[1.701171875, 0.0391845703125, 0.056884765625, 1.009765625]], "avg_entropy": [0.701751708984375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Kida", "score_of_biggest_cluster": 0.6387985944747925, "score_of_first_answer": 0.6387985944747925, "max_score_of_first_answer": 0.99560546875, "min_score_of_first_answer": 0.248291015625, "avg_score": 0.6387985944747925, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.30634815701220913, "std_of_first_answer": 0.30634815701220913, "avg_entropy_of_first_answer": 0.701751708984375, "lex_sim": 1.0}
{"question": "when will notre dame played michigan state again", "answer": ["The next scheduled game between Notre Dame and Michigan State is on October 24, 2020."], "scores": [[0.0848388671875, 0.51171875, 0.489990234375, 0.64111328125, 0.67041015625, 0.7431640625, 1.0, 1.0, 0.99951171875, 1.0, 0.99951171875, 0.958984375, 0.95849609375, 0.6591796875, 0.9990234375, 0.75537109375, 0.1661376953125, 0.64013671875, 0.9990234375, 1.0, 1.0, 1.0, 0.8896484375, 0.84912109375, 1.9669532775878906e-06, 0.00395965576171875, 0.03338623046875, 4.667043685913086e-05, 0.002643585205078125, 0.0022869110107421875, 0.0220794677734375, 0.0013704299926757812, 0.99951171875, 0.01018524169921875, 0.0084075927734375, 0.016082763671875, 0.2471923828125, 0.034881591796875]], "normalized_score": [0.11861400306224823], "tokens": [["\u2581The", "\u2581next", "\u2581scheduled", "\u2581game", "\u2581between", "\u2581Notre", "\u2581D", "ame", "\u2581and", "\u2581Michigan", "\u2581State", "\u2581is", "\u2581on", "\u2581October", "\u2581", "2", "4", ",", "\u2581", "2", "0", "2", "0", ".", "\u2581#", "1", "5", "1", ":", "\u2581How", "\u2581to", "\u2581Cho", "ose", "\u2581Your", "\u2581First", "\u2581C", "rypto", "asset"]], "entropy": [[1.8076171875, 1.6787109375, 1.5439453125, 0.994140625, 0.7314453125, 0.76806640625, 0.0018396377563476562, 0.0021305084228515625, 0.002964019775390625, 0.000762939453125, 0.00543975830078125, 0.208984375, 0.27587890625, 1.1103515625, 0.0081329345703125, 0.6904296875, 1.3837890625, 0.6611328125, 0.0084228515625, 8.678436279296875e-05, 0.00014781951904296875, 0.00042557716369628906, 0.48779296875, 0.65478515625, 1.0732421875, 3.064453125, 2.04296875, 0.75146484375, 3.16015625, 5.046875, 2.048828125, 5.54296875, 0.00658416748046875, 1.697265625, 4.10546875, 5.1796875, 1.55078125, 3.30859375]], "avg_entropy": [1.3580726636083502], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2026", "score_of_biggest_cluster": 0.11861400306224823, "score_of_first_answer": 0.11861400306224823, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.9669532775878906e-06, "avg_score": 0.11861400306224823, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42376714280381594, "std_of_first_answer": 0.42376714280381594, "avg_entropy_of_first_answer": 1.3580726636083502, "lex_sim": 1.0}
{"question": "who did cubs beat in 2016 world series", "answer": ["Cleveland Indians #Tech News"], "scores": [[0.904296875, 0.99609375, 1.0132789611816406e-06, 0.002315521240234375, 0.0010728836059570312, 5.900859832763672e-06]], "normalized_score": [0.0015407877508550882], "tokens": [["\u2581Cleveland", "\u2581Indians", "\u2581#", "T", "ech", "\u2581News"]], "entropy": [[0.429443359375, 0.0304107666015625, 1.0341796875, 4.4296875, 2.294921875, 4.4140625]], "avg_entropy": [2.1054509480794272], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the Indians", "score_of_biggest_cluster": 0.0015407877508550882, "score_of_first_answer": 0.0015407877508550882, "max_score_of_first_answer": 0.99609375, "min_score_of_first_answer": 1.0132789611816406e-06, "avg_score": 0.0015407877508550882, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.44831077197105895, "std_of_first_answer": 0.44831077197105895, "avg_entropy_of_first_answer": 2.1054509480794272, "lex_sim": 1.0}
{"question": "where are more than half your bones located", "answer": ["In the human body, more than half of the bones are located in the hands and feet."], "scores": [[0.170654296875, 0.943359375, 0.012420654296875, 0.8291015625, 0.98876953125, 0.78515625, 1.0, 0.99951171875, 0.97119140625, 0.89794921875, 0.98779296875, 1.0, 0.99853515625, 0.97802734375, 1.0, 1.0, 0.64208984375, 0.99951171875, 0.99755859375, 0.970703125, 1.5497207641601562e-06, 5.960464477539063e-08, 0.0001437664031982422, 0.0030612945556640625, 0.0012187957763671875, 0.6083984375, 0.0179901123046875, 0.06695556640625, 0.2421875, 0.003185272216796875, 0.9697265625, 0.96533203125, 0.99853515625, 0.94580078125, 0.9716796875, 0.99853515625, 0.99951171875, 0.9951171875, 0.223876953125, 0.75146484375, 0.99853515625, 0.96533203125, 0.97216796875, 0.9990234375, 0.99951171875, 0.99462890625, 0.99951171875, 1.0]], "normalized_score": [0.2093370258808136], "tokens": [["\u2581In", "\u2581the", "\u2581human", "\u2581body", ",", "\u2581more", "\u2581than", "\u2581half", "\u2581of", "\u2581the", "\u2581b", "ones", "\u2581are", "\u2581located", "\u2581in", "\u2581the", "\u2581hands", "\u2581and", "\u2581feet", ".", "\u2581[", "archive", "org", "\u2581The", "Sh", "adow", "7", "6", "2", "\u2581width", "=", "5", "0", "0", "\u2581height", "=", "3", "7", "5", "\u2581frame", "border", "=", "0", "\u2581web", "kit", "allow", "full", "screen"]], "entropy": [[2.935546875, 0.279052734375, 2.5703125, 0.705078125, 0.0814208984375, 0.96142578125, 0.00202178955078125, 0.00278472900390625, 0.1402587890625, 0.3515625, 0.08392333984375, 0.0017919540405273438, 0.0112762451171875, 0.1165771484375, 0.001495361328125, 0.00141143798828125, 1.380859375, 0.0028057098388671875, 0.0218353271484375, 0.1617431640625, 0.40673828125, 1.173828125, 0.251708984375, 5.45703125, 4.8359375, 2.30859375, 4.0625, 2.33984375, 3.150390625, 0.427978515625, 0.1390380859375, 0.211669921875, 0.01251220703125, 0.327392578125, 0.204833984375, 0.0111236572265625, 0.005146026611328125, 0.03814697265625, 1.3603515625, 1.109375, 0.01371002197265625, 0.1524658203125, 0.1339111328125, 0.00913238525390625, 0.0029430389404296875, 0.03717041015625, 0.004375457763671875, 0.0012874603271484375]], "avg_entropy": [0.7917150060335795], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the appendicular skeleton", "score_of_biggest_cluster": 0.2093370258808136, "score_of_first_answer": 0.2093370258808136, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.2093370258808136, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.39547001004453697, "std_of_first_answer": 0.39547001004453697, "avg_entropy_of_first_answer": 0.7917150060335795, "lex_sim": 1.0}
{"question": "when did muhammad ali win an olympic gold medal", "answer": ["1960"], "scores": [[0.83837890625, 0.99951171875, 0.99951171875, 1.0, 1.0]], "normalized_score": [0.9651687145233154], "tokens": [["\u2581", "1", "9", "6", "0"]], "entropy": [[0.69775390625, 0.003978729248046875, 0.005084991455078125, 0.0007829666137695312, 0.001953125]], "avg_entropy": [0.14191074371337892], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1960", "score_of_biggest_cluster": 0.9651687145233154, "score_of_first_answer": 0.9651687145233154, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.83837890625, "avg_score": 0.9651687145233154, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.06455115059935936, "std_of_first_answer": 0.06455115059935936, "avg_entropy_of_first_answer": 0.14191074371337892, "lex_sim": 1.0}
{"question": "what is the width of a cricket bat", "answer": ["The width of a cricket bat can vary, but it is typically between 6.625 inches (16.8 cm) and 7.25 inches (18.4 cm) at the shoulders."], "scores": [[0.32373046875, 0.9560546875, 0.99951171875, 0.9951171875, 0.998046875, 1.0, 0.99951171875, 0.54736328125, 0.99560546875, 0.63427734375, 0.99462890625, 0.8798828125, 0.9052734375, 0.7822265625, 0.89892578125, 0.99609375, 0.0030651092529296875, 0.6220703125, 0.84033203125, 0.25732421875, 0.99609375, 0.609375, 0.4765625, 0.99560546875, 0.99853515625, 0.99755859375, 0.9990234375, 0.6669921875, 1.0, 0.9814453125, 0.99951171875, 0.8740234375, 0.9775390625, 0.60986328125, 1.0, 0.99853515625, 0.99951171875, 1.0, 1.0, 0.99951171875, 0.9970703125, 0.9833984375, 0.697265625, 0.64306640625, 0.1461181640625, 0.023040771484375, 0.71044921875, 3.5762786865234375e-07]], "normalized_score": [0.48578914999961853], "tokens": [["\u2581The", "\u2581width", "\u2581of", "\u2581a", "\u2581cr", "icket", "\u2581bat", "\u2581can", "\u2581vary", ",", "\u2581but", "\u2581it", "\u2581is", "\u2581typically", "\u2581between", "\u2581", "6", ".", "6", "2", "5", "\u2581inches", "\u2581(", "1", "6", ".", "8", "\u2581cm", ")", "\u2581and", "\u2581", "7", ".", "2", "5", "\u2581inches", "\u2581(", "1", "8", ".", "4", "\u2581cm", ")", "\u2581at", "\u2581the", "\u2581shoulders", ".", "\u2581#"]], "entropy": [[1.6748046875, 0.295166015625, 0.004222869873046875, 0.035308837890625, 0.0169830322265625, 5.263090133666992e-05, 0.0028133392333984375, 1.046875, 0.031646728515625, 1.076171875, 0.044403076171875, 0.5634765625, 0.392578125, 0.6767578125, 0.367919921875, 0.034942626953125, 0.82080078125, 1.427734375, 0.68505859375, 1.7412109375, 0.034088134765625, 0.9033203125, 0.7978515625, 0.042694091796875, 0.01204681396484375, 0.0183868408203125, 0.01062774658203125, 0.9921875, 0.002346038818359375, 0.09771728515625, 0.003570556640625, 0.51708984375, 0.11297607421875, 1.302734375, 0.00182342529296875, 0.011932373046875, 0.002529144287109375, 0.0015659332275390625, 0.0012054443359375, 0.00438690185546875, 0.0216064453125, 0.09307861328125, 0.630859375, 1.20703125, 0.417724609375, 2.60546875, 0.79833984375, 0.8173828125]], "avg_entropy": [0.46669791514674824], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "no more than 4.25 inches", "score_of_biggest_cluster": 0.48578914999961853, "score_of_first_answer": 0.48578914999961853, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 3.5762786865234375e-07, "avg_score": 0.48578914999961853, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.29603138589819133, "std_of_first_answer": 0.29603138589819133, "avg_entropy_of_first_answer": 0.46669791514674824, "lex_sim": 1.0}
{"question": "who is jack's mother in when calls the heart", "answer": ["Elizabeth Thatcher (played by Erin Krakow) Chapter One: First Contact"], "scores": [[0.984375, 0.8955078125, 0.99462890625, 0.99951171875, 0.08428955078125, 0.0516357421875, 1.0, 0.99951171875, 0.9892578125, 0.99951171875, 0.99951171875, 0.99853515625, 0.96240234375, 0.0, 0.0131988525390625, 0.1973876953125, 0.0003132820129394531, 8.046627044677734e-06]], "normalized_score": [0.0], "tokens": [["\u2581Elizabeth", "\u2581Th", "atch", "er", "\u2581(", "play", "ed", "\u2581by", "\u2581Er", "in", "\u2581Krak", "ow", ")", "\u2581Chapter", "\u2581One", ":", "\u2581First", "\u2581Contact"]], "entropy": [[0.1236572265625, 0.52783203125, 0.044586181640625, 0.004116058349609375, 1.5234375, 2.853515625, 0.00015985965728759766, 0.00441741943359375, 0.0836181640625, 0.005359649658203125, 0.0030040740966796875, 0.01122283935546875, 0.1727294921875, 0.98388671875, 2.0703125, 3.166015625, 2.205078125, 0.47412109375]], "avg_entropy": [0.7920594546529982], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Charlotte Thornton", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.45801780685473775, "std_of_first_answer": 0.45801780685473775, "avg_entropy_of_first_answer": 0.7920594546529982, "lex_sim": 1.0}
{"question": "how many plane surfaces does a cylinder have", "answer": ["Two (top and bottom) > Home > Municipal Government > Municipal Departments > Public Works > Waste Management > Household Hazardous Waste > Paint Disposal Options"], "scores": [[0.0345458984375, 0.054534912109375, 0.6279296875, 0.99853515625, 1.0, 0.97900390625, 5.960464477539063e-08, 8.404254913330078e-06, 0.00087738037109375, 2.9206275939941406e-06, 0.0027751922607421875, 0.93212890625, 0.0023021697998046875, 0.173095703125, 1.0, 0.98974609375, 0.370361328125, 0.9326171875, 0.9619140625, 0.024169921875, 0.99267578125, 0.5537109375, 0.94482421875, 0.09039306640625, 0.99951171875, 0.73876953125, 1.0, 1.0, 0.99609375, 1.0, 0.82763671875, 0.0160064697265625, 0.740234375, 0.03533935546875, 1.0, 1.0, 0.0228729248046875]], "normalized_score": [0.09121401607990265], "tokens": [["\u2581Two", "\u2581(", "top", "\u2581and", "\u2581bottom", ")", "\u2581>", "\u2581Home", "\u2581>", "\u2581Municipal", "\u2581Government", "\u2581>", "\u2581Municipal", "\u2581Depart", "ments", "\u2581>", "\u2581Public", "\u2581Works", "\u2581>", "\u2581W", "aste", "\u2581Management", "\u2581>", "\u2581House", "hold", "\u2581Haz", "ard", "ous", "\u2581W", "aste", "\u2581>", "\u2581P", "aint", "\u2581Dis", "pos", "al", "\u2581Options"]], "entropy": [[1.9443359375, 1.251953125, 1.5537109375, 0.01514434814453125, 0.0017538070678710938, 0.12396240234375, 0.319091796875, 2.2421875, 0.4189453125, 4.73828125, 4.28515625, 0.46923828125, 2.478515625, 3.1953125, 0.0012416839599609375, 0.08587646484375, 3.171875, 0.422119140625, 0.2445068359375, 3.3359375, 0.061676025390625, 1.3408203125, 0.360107421875, 3.25390625, 0.0028285980224609375, 0.80517578125, 0.0004570484161376953, 6.139278411865234e-05, 0.0280914306640625, 0.0017328262329101562, 0.89501953125, 3.197265625, 0.8271484375, 2.859375, 0.0024776458740234375, 0.0014486312866210938, 1.646484375]], "avg_entropy": [1.2319789738268465], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "two parallel planes", "score_of_biggest_cluster": 0.09121401607990265, "score_of_first_answer": 0.09121401607990265, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.09121401607990265, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.43998499264183655, "std_of_first_answer": 0.43998499264183655, "avg_entropy_of_first_answer": 1.2319789738268465, "lex_sim": 1.0}
{"question": "when did frank sinatra first sing new york new york", "answer": ["1979 Preface"], "scores": [[0.91455078125, 1.0, 1.0, 0.99853515625, 0.62353515625, 0.0, 0.205078125]], "normalized_score": [0.0], "tokens": [["\u2581", "1", "9", "7", "9", "\u2581Pref", "ace"]], "entropy": [[0.54638671875, 0.0005488395690917969, 0.0013446807861328125, 0.01457977294921875, 0.83251953125, 0.97216796875, 2.10546875]], "avg_entropy": [0.6390023231506348], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1980", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38773517014506265, "std_of_first_answer": 0.38773517014506265, "avg_entropy_of_first_answer": 0.6390023231506348, "lex_sim": 1.0}
{"question": "who sings song at the end of beauty and the beast", "answer": ["Angela Lansbury Tags: US | Obit | Hume | 2nd"], "scores": [[0.802734375, 0.99609375, 0.998046875, 1.0, 1.0, 0.0, 0.99169921875, 0.00017940998077392578, 5.507469177246094e-05, 0.0016241073608398438, 3.427267074584961e-05, 0.8505859375, 0.00238037109375, 0.0017795562744140625, 0.391357421875, 0.08184814453125, 0.336181640625, 0.00640869140625]], "normalized_score": [0.0], "tokens": [["\u2581Ang", "ela", "\u2581L", "ans", "bury", "\u2581Tags", ":", "\u2581US", "\u2581|", "\u2581O", "bit", "\u2581|", "\u2581H", "ume", "\u2581|", "\u2581", "2", "nd"]], "entropy": [[0.69677734375, 0.0343017578125, 0.0150299072265625, 0.0021343231201171875, 0.001644134521484375, 0.7431640625, 0.07855224609375, 3.6640625, 2.85546875, 5.34375, 2.78515625, 1.1103515625, 5.6953125, 5.05078125, 1.6025390625, 5.6640625, 2.029296875, 1.185546875]], "avg_entropy": [2.1421073277791343], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Josh Groban", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4422157070564063, "std_of_first_answer": 0.4422157070564063, "avg_entropy_of_first_answer": 2.1421073277791343, "lex_sim": 1.0}
{"question": "who played bat masterson in the tv series", "answer": ["Gene Barry ###### A Hands-On Approach to Selling and Negotiating Cars **By Glenn B. Williams, CMSBB, Master CPIA** Glenn B. Williams is a veteran of"], "scores": [[0.93017578125, 0.9873046875, 0.0, 0.705078125, 0.0024433135986328125, 7.706880569458008e-05, 0.0006809234619140625, 0.006473541259765625, 0.55126953125, 0.1395263671875, 0.99951171875, 0.28955078125, 0.00543975830078125, 0.275146484375, 0.01296234130859375, 0.018951416015625, 0.99658203125, 0.9990234375, 0.00182342529296875, 0.9169921875, 0.013214111328125, 0.00222015380859375, 0.0011091232299804688, 0.99853515625, 0.76611328125, 0.1971435546875, 0.1846923828125, 0.409912109375, 0.328369140625, 0.267822265625, 0.016754150390625, 0.8798828125, 0.5830078125, 0.2470703125, 0.513671875, 0.5927734375, 0.97021484375, 0.72412109375, 0.0182342529296875, 0.99951171875, 0.6748046875, 0.9853515625, 0.98583984375, 0.43994140625, 0.619140625, 0.0833740234375, 0.99951171875, 0.3505859375]], "normalized_score": [0.0], "tokens": [["\u2581Gene", "\u2581Barry", "\u2581#####", "#", "\u2581A", "\u2581H", "ands", "-", "On", "\u2581Appro", "ach", "\u2581to", "\u2581S", "elling", "\u2581and", "\u2581Neg", "oti", "ating", "\u2581C", "ars", "\u2581**", "By", "\u2581Gl", "enn", "\u2581B", ".", "\u2581Williams", ",", "\u2581C", "M", "SB", "B", ",", "\u2581Master", "\u2581C", "PI", "A", "**", "\u2581Gl", "enn", "\u2581B", ".", "\u2581Williams", "\u2581is", "\u2581a", "\u2581veter", "an", "\u2581of"]], "entropy": [[0.47265625, 0.09405517578125, 0.8203125, 2.0390625, 3.767578125, 2.1875, 2.107421875, 0.28955078125, 1.3935546875, 4.5234375, 0.003406524658203125, 2.75390625, 5.29296875, 2.921875, 4.078125, 4.046875, 0.023651123046875, 0.007671356201171875, 3.537109375, 0.62841796875, 4.109375, 4.93359375, 4.7890625, 0.01204681396484375, 1.3193359375, 3.763671875, 4.3203125, 1.337890625, 3.345703125, 0.98876953125, 1.8486328125, 0.85302734375, 0.79052734375, 2.31640625, 1.404296875, 1.865234375, 0.2293701171875, 0.64892578125, 4.17578125, 0.006011962890625, 1.2607421875, 0.08721923828125, 0.1114501953125, 1.888671875, 1.4453125, 3.130859375, 0.005718231201171875, 2.068359375]], "avg_entropy": [1.9592800935109456], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Gene Barry", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3876533545366033, "std_of_first_answer": 0.3876533545366033, "avg_entropy_of_first_answer": 1.9592800935109456, "lex_sim": 1.0}
{"question": "where did they film the game of thrones", "answer": ["Game of Thrones was primarily filmed in Northern Ireland, Republic of Ireland, Scotland, Spain, Croatia, Iceland, and Morocco."], "scores": [[0.1182861328125, 0.99951171875, 0.99853515625, 1.0, 1.0, 0.95703125, 0.272216796875, 0.99853515625, 1.0, 0.99755859375, 0.787109375, 0.998046875, 0.9892578125, 0.00080108642578125, 0.99951171875, 0.998046875, 0.99951171875, 0.026458740234375, 0.9990234375, 0.471923828125, 0.998046875, 0.76611328125, 1.0, 0.99658203125, 0.8408203125, 1.0, 1.0, 0.97802734375, 0.74365234375, 0.9208984375, 1.0, 1.0, 0.9912109375, 1.7285346984863281e-06, 2.47955322265625e-05, 0.0631103515625, 0.0015773773193359375, 0.0001341104507446289, 0.12744140625, 0.00017070770263671875, 3.415346145629883e-05, 0.9873046875, 0.0211181640625, 0.15478515625, 0.7001953125, 0.23193359375, 0.98486328125, 0.06146240234375]], "normalized_score": [0.15498466789722443], "tokens": [["\u2581Game", "\u2581of", "\u2581Th", "ron", "es", "\u2581was", "\u2581primarily", "\u2581fil", "med", "\u2581in", "\u2581Northern", "\u2581Ireland", ",", "\u2581Republic", "\u2581of", "\u2581Ireland", ",", "\u2581Scotland", ",", "\u2581Spain", ",", "\u2581Cro", "atia", ",", "\u2581I", "cel", "and", ",", "\u2581and", "\u2581Mor", "oc", "co", ".", "\u2581#", "5", "8", ".", "\u2581To", "o", "\u2581Much", "\u2581Sug", "ar", "\u2581Can", "\u2581Make", "\u2581You", "\u2581S", "ick", ","]], "entropy": [[3.0625, 0.003620147705078125, 0.01334381103515625, 0.00021338462829589844, 1.7881393432617188e-05, 0.212158203125, 0.65673828125, 0.01320648193359375, 0.0002617835998535156, 0.01751708984375, 0.91357421875, 0.016021728515625, 0.0687255859375, 1.1904296875, 0.0036163330078125, 0.0169525146484375, 0.005199432373046875, 1.1533203125, 0.00904083251953125, 0.9150390625, 0.0159759521484375, 0.75537109375, 0.00018298625946044922, 0.025482177734375, 0.572265625, 0.00010448694229125977, 4.756450653076172e-05, 0.106689453125, 0.7890625, 0.335693359375, 0.0009860992431640625, 0.0004825592041015625, 0.05877685546875, 0.62744140625, 2.087890625, 3.658203125, 2.779296875, 3.013671875, 3.904296875, 0.53955078125, 2.97265625, 0.096435546875, 2.939453125, 2.208984375, 1.4404296875, 3.55078125, 0.10205078125, 2.68359375]], "avg_entropy": [0.9070282044510046], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Croatia", "score_of_biggest_cluster": 0.15498466789722443, "score_of_first_answer": 0.15498466789722443, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7285346984863281e-06, "avg_score": 0.15498466789722443, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4259185411024873, "std_of_first_answer": 0.4259185411024873, "avg_entropy_of_first_answer": 0.9070282044510046, "lex_sim": 1.0}
{"question": "where can tight junctions be found in the body", "answer": ["tight junctions can be found in various tissues and organs of the body such as the epithelial cells of the gut, kidney, and brain, as well as in the endothelial cells of blood vessels."], "scores": [[0.66357421875, 0.99755859375, 1.0, 0.9990234375, 0.5986328125, 0.99951171875, 1.0, 0.9853515625, 0.27587890625, 0.87451171875, 0.99609375, 0.3720703125, 0.974609375, 1.0, 0.06396484375, 1.0, 0.99462890625, 0.06695556640625, 1.0, 0.71337890625, 0.3115234375, 1.0, 0.97998046875, 0.974609375, 0.1640625, 0.46044921875, 0.99755859375, 0.35888671875, 0.94580078125, 0.6826171875, 0.953125, 0.63818359375, 0.97216796875, 0.1202392578125, 0.444580078125, 0.4697265625, 1.0, 0.99951171875, 0.96728515625, 0.3798828125, 0.98388671875, 1.0, 0.99853515625, 0.9814453125, 1.0, 0.9765625, 0.705078125, 0.9931640625, 0.8828125]], "normalized_score": [0.6622839570045471], "tokens": [["\u2581tight", "\u2581j", "unction", "s", "\u2581can", "\u2581be", "\u2581found", "\u2581in", "\u2581various", "\u2581t", "issues", "\u2581and", "\u2581org", "ans", "\u2581of", "\u2581the", "\u2581body", "\u2581such", "\u2581as", "\u2581the", "\u2581ep", "ith", "el", "ial", "\u2581cells", "\u2581of", "\u2581the", "\u2581gut", ",", "\u2581kid", "ney", ",", "\u2581and", "\u2581brain", ",", "\u2581as", "\u2581well", "\u2581as", "\u2581in", "\u2581the", "\u2581end", "oth", "el", "ial", "\u2581cells", "\u2581of", "\u2581blood", "\u2581vessels", "."]], "entropy": [[1.3056640625, 0.018218994140625, 0.00032329559326171875, 0.00977325439453125, 0.6953125, 0.00397491455078125, 0.0009031295776367188, 0.091064453125, 0.8525390625, 0.61767578125, 0.0264739990234375, 1.2646484375, 0.16943359375, 6.210803985595703e-05, 0.72216796875, 0.0023403167724609375, 0.037261962890625, 0.487548828125, 0.0014505386352539062, 0.67578125, 2.07421875, 8.493661880493164e-05, 0.09820556640625, 0.11767578125, 1.2080078125, 1.4365234375, 0.0232391357421875, 1.2783203125, 0.218994140625, 1.1357421875, 0.1888427734375, 0.8701171875, 0.1788330078125, 1.744140625, 1.0810546875, 1.3349609375, 0.0010194778442382812, 0.0035152435302734375, 0.1666259765625, 0.88720703125, 0.10601806640625, 0.001056671142578125, 0.00992584228515625, 0.09246826171875, 0.00019407272338867188, 0.11932373046875, 0.61376953125, 0.048736572265625, 0.489013671875]], "avg_entropy": [0.45939701795578003], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Internal epithelia", "score_of_biggest_cluster": 0.6622839570045471, "score_of_first_answer": 0.6622839570045471, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.06396484375, "avg_score": 0.6622839570045471, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3029309475363282, "std_of_first_answer": 0.3029309475363282, "avg_entropy_of_first_answer": 0.45939701795578003, "lex_sim": 1.0}
{"question": "who did bette midler portray in the rose", "answer": ["Rose Flood"], "scores": [[0.08209228515625, 0.039154052734375, 0.986328125]], "normalized_score": [0.14690393209457397], "tokens": [["\u2581Rose", "\u2581Flo", "od"]], "entropy": [[3.072265625, 4.35546875, 0.1297607421875]], "avg_entropy": [2.5191650390625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Mary Rose Foster", "score_of_biggest_cluster": 0.14690393209457397, "score_of_first_answer": 0.14690393209457397, "max_score_of_first_answer": 0.986328125, "min_score_of_first_answer": 0.039154052734375, "avg_score": 0.14690393209457397, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.43673343879224474, "std_of_first_answer": 0.43673343879224474, "avg_entropy_of_first_answer": 2.5191650390625, "lex_sim": 1.0}
{"question": "who decides the number of judges in the high court", "answer": ["The President of India, in consultation with the Chief Justice of India, decides the number of judges in the High Court [Update] Yostar VR Arcade Game For Hive VR TPC Joins Ticket"], "scores": [[0.650390625, 0.69384765625, 0.89794921875, 0.947265625, 0.6396484375, 0.381103515625, 0.99951171875, 1.0, 1.0, 0.998046875, 0.99365234375, 0.99951171875, 0.99560546875, 1.0, 0.39111328125, 0.7421875, 1.0, 0.998046875, 0.98046875, 1.0, 0.94384765625, 1.0, 0.96875, 0.99951171875, 0.9931640625, 0.998046875, 1.8596649169921875e-05, 2.384185791015625e-06, 0.07537841796875, 8.165836334228516e-06, 2.205371856689453e-05, 0.01189422607421875, 0.00225067138671875, 0.0022487640380859375, 0.001148223876953125, 0.59521484375, 0.047943115234375, 0.0011444091796875, 0.0008993148803710938, 0.00018107891082763672, 0.0231170654296875, 0.94580078125, 0.408447265625, 0.0248870849609375, 0.0079498291015625, 0.008331298828125, 0.01111602783203125, 0.001354217529296875]], "normalized_score": [0.06514441221952438], "tokens": [["\u2581The", "\u2581President", "\u2581of", "\u2581India", ",", "\u2581in", "\u2581consult", "ation", "\u2581with", "\u2581the", "\u2581Chief", "\u2581Justice", "\u2581of", "\u2581India", ",", "\u2581dec", "ides", "\u2581the", "\u2581number", "\u2581of", "\u2581jud", "ges", "\u2581in", "\u2581the", "\u2581High", "\u2581Court", "\u2581[", "Update", "]", "\u2581Y", "ost", "ar", "\u2581V", "R", "\u2581Ar", "cade", "\u2581Game", "\u2581For", "\u2581H", "ive", "\u2581V", "R", "\u2581T", "PC", "\u2581Jo", "ins", "\u2581T", "icket"]], "entropy": [[1.396484375, 1.3212890625, 0.460205078125, 0.235595703125, 1.298828125, 1.6884765625, 0.00482177734375, 0.0005884170532226562, 0.0004489421844482422, 0.0189361572265625, 0.05712890625, 0.002330780029296875, 0.0335693359375, 0.00205230712890625, 1.4345703125, 1.0517578125, 0.00010263919830322266, 0.016204833984375, 0.101806640625, 0.0014095306396484375, 0.2301025390625, 5.632638931274414e-05, 0.156005859375, 0.006259918212890625, 0.044647216796875, 0.01513671875, 0.32373046875, 2.435546875, 1.171875, 1.0703125, 3.275390625, 4.15234375, 5.27734375, 3.765625, 5.30078125, 2.97265625, 3.921875, 4.6640625, 2.23828125, 1.2080078125, 5.05078125, 0.2919921875, 2.6640625, 3.36328125, 4.1640625, 1.1611328125, 5.125, 3.80859375]], "avg_entropy": [1.603865711639325], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the President of India", "score_of_biggest_cluster": 0.06514441221952438, "score_of_first_answer": 0.06514441221952438, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-06, "avg_score": 0.06514441221952438, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44748490532017365, "std_of_first_answer": 0.44748490532017365, "avg_entropy_of_first_answer": 1.603865711639325, "lex_sim": 1.0}
{"question": "nobel laureate who began career as accountant in calcutta", "answer": ["Ronald Coase #IWD2019: \u201cInvestment in Women and Girls is an Investment in Our Future\u201d"], "scores": [[0.78271484375, 1.0, 0.9619140625, 1.0, 1.0132789611816406e-06, 0.0008907318115234375, 0.00617218017578125, 0.98583984375, 1.0, 0.003482818603515625, 0.89990234375, 0.00011265277862548828, 0.0016012191772460938, 0.036285400390625, 0.01137542724609375, 0.049072265625, 0.625, 0.0008478164672851562, 0.0657958984375, 0.93115234375, 0.58349609375, 0.016204833984375, 0.95703125, 1.0, 1.0, 0.998046875, 0.00988006591796875, 0.52490234375, 0.78857421875]], "normalized_score": [0.06593389809131622], "tokens": [["\u2581Ron", "ald", "\u2581Co", "ase", "\u2581#", "I", "WD", "2", "0", "1", "9", ":", "\u2581\u201c", "In", "vest", "ment", "\u2581in", "\u2581Women", "\u2581and", "\u2581Girls", "\u2581is", "\u2581an", "\u2581In", "vest", "ment", "\u2581in", "\u2581Our", "\u2581Future", "\u201d"]], "entropy": [[0.8271484375, 0.0011501312255859375, 0.236083984375, 0.0014247894287109375, 0.8837890625, 3.814453125, 3.0078125, 0.091064453125, 0.0023593902587890625, 0.0246124267578125, 0.38525390625, 0.82666015625, 3.21875, 3.59765625, 3.421875, 1.2119140625, 1.5302734375, 3.451171875, 2.31640625, 0.43408203125, 1.59765625, 2.109375, 0.263427734375, 0.0008568763732910156, 0.0012073516845703125, 0.016693115234375, 1.1123046875, 1.484375, 0.8408203125]], "avg_entropy": [1.2658847447099357], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Amartya Sen", "score_of_biggest_cluster": 0.06593389809131622, "score_of_first_answer": 0.06593389809131622, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.0132789611816406e-06, "avg_score": 0.06593389809131622, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4450151730908225, "std_of_first_answer": 0.4450151730908225, "avg_entropy_of_first_answer": 1.2658847447099357, "lex_sim": 1.0}
{"question": "the assassination of gianni versace american crime story season 2 episode 2", "answer": ["The Assassination of Gianni Versace: American Crime Story is a television series."], "scores": [[0.08819580078125, 0.8759765625, 1.0, 1.0, 0.9990234375, 0.9970703125, 1.0, 1.0, 1.0, 0.99560546875, 0.99951171875, 1.0, 1.0, 0.73876953125, 0.98095703125, 0.6572265625, 0.94189453125, 0.141357421875, 0.281494140625, 0.83837890625, 0.9248046875, 0.9931640625, 0.9287109375, 0.98046875, 1.0, 0.91357421875, 0.090576171875, 0.98974609375, 0.48583984375, 0.998046875, 0.9990234375, 0.2034912109375, 0.06298828125, 0.392822265625, 0.53564453125, 1.0, 0.93359375, 1.0, 1.0, 0.97265625, 0.328369140625, 1.0, 0.99560546875, 0.81005859375, 0.99951171875, 0.1632080078125, 0.3095703125, 0.94921875, 0.99951171875, 0.99951171875]], "normalized_score": [0.6628969311714172], "tokens": [["\u2581The", "\u2581Ass", "ass", "ination", "\u2581of", "\u2581Gian", "ni", "\u2581Vers", "ace", ":", "\u2581American", "\u2581Crime", "\u2581Story", "\u2581is", "\u2581a", "\u2581television", "\u2581series", ".", "\u2581The", "\u2581second", "\u2581episode", "\u2581of", "\u2581the", "\u2581second", "\u2581season", "\u2581is", "\u2581called", "\u2581\"", "Man", "h", "unt", ".\"", "\u2581It", "\u2581was", "\u2581directed", "\u2581by", "\u2581Ryan", "\u2581Mur", "phy", "\u2581and", "\u2581a", "ired", "\u2581on", "\u2581January", "\u2581", "1", "7", ",", "\u2581", "2"]], "entropy": [[1.291015625, 0.6455078125, 0.0003743171691894531, 0.00017535686492919922, 0.00847625732421875, 0.029022216796875, 0.0002340078353881836, 0.0009126663208007812, 0.00013434886932373047, 0.03717041015625, 0.005275726318359375, 0.00036215782165527344, 0.0006995201110839844, 0.95166015625, 0.1112060546875, 1.2724609375, 0.328369140625, 1.462890625, 1.9521484375, 0.8037109375, 0.271484375, 0.047393798828125, 0.27294921875, 0.11651611328125, 0.002338409423828125, 0.378662109375, 0.3662109375, 0.06494140625, 0.998046875, 0.0202789306640625, 0.010009765625, 0.53857421875, 1.02734375, 1.81640625, 0.876953125, 0.001918792724609375, 0.445068359375, 2.8371810913085938e-05, 0.0007648468017578125, 0.146240234375, 0.81591796875, 0.0006823539733886719, 0.031463623046875, 0.60693359375, 0.005451202392578125, 1.119140625, 1.4453125, 0.203125, 0.00600433349609375, 0.0035877227783203125]], "avg_entropy": [0.4108311104774475], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Manhunt", "score_of_biggest_cluster": 0.6628969311714172, "score_of_first_answer": 0.6628969311714172, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.06298828125, "avg_score": 0.6628969311714172, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3158349418413076, "std_of_first_answer": 0.3158349418413076, "avg_entropy_of_first_answer": 0.4108311104774475, "lex_sim": 1.0}
{"question": "who signed the largest on the declaration of independence", "answer": ["John Hancock #91 \u2013 The Last Days of Night by Graham Moore \u2013 4/5 stars"], "scores": [[0.132568359375, 0.990234375, 1.0, 4.172325134277344e-07, 0.005626678466796875, 0.0036106109619140625, 7.37309455871582e-05, 0.0195770263671875, 0.005157470703125, 3.719329833984375e-05, 0.6669921875, 0.0007257461547851562, 0.12371826171875, 0.87109375, 1.0, 0.0491943359375, 0.1226806640625, 0.0266265869140625, 0.239013671875, 0.434814453125, 0.46533203125]], "normalized_score": [0.02429693564772606], "tokens": [["\u2581John", "\u2581Han", "cock", "\u2581#", "9", "1", "\u2581\u2013", "\u2581The", "\u2581Last", "\u2581Days", "\u2581of", "\u2581Night", "\u2581by", "\u2581Graham", "\u2581Moore", "\u2581\u2013", "\u2581", "4", "/", "5", "\u2581stars"]], "entropy": [[3.65625, 0.06146240234375, 0.0001100301742553711, 0.87353515625, 5.33984375, 1.61328125, 3.11328125, 5.3984375, 4.09375, 3.87109375, 1.7314453125, 2.015625, 2.298828125, 0.85888671875, 0.00014197826385498047, 1.9375, 5.015625, 2.01953125, 3.16015625, 1.5517578125, 2.083984375]], "avg_entropy": [2.4140250909896124], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "John Hancock", "score_of_biggest_cluster": 0.02429693564772606, "score_of_first_answer": 0.02429693564772606, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.02429693564772606, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3711801060714521, "std_of_first_answer": 0.3711801060714521, "avg_entropy_of_first_answer": 2.4140250909896124, "lex_sim": 1.0}
{"question": "who discovered one of the first taxonomic classification schemes", "answer": ["Carolus Linnaeus."], "scores": [[0.9560546875, 1.0, 0.99609375, 0.99951171875, 1.0, 0.07366943359375, 4.172325134277344e-07, 0.0032596588134765625, 0.033233642578125, 0.0002758502960205078, 0.36572265625, 0.0684814453125, 0.031494140625, 0.07086181640625, 0.91162109375, 0.00014901161193847656, 0.0003676414489746094, 0.88525390625, 0.287841796875, 0.99755859375, 0.0020694732666015625, 0.35986328125, 0.99951171875, 0.1556396484375, 0.72412109375, 0.2332763671875, 0.00457763671875, 0.7890625, 1.0, 0.943359375, 0.94189453125]], "normalized_score": [0.07762855291366577], "tokens": [["\u2581Carol", "us", "\u2581Lin", "na", "eus", ".", "\u2581#", "M", "ini", "Movie", "Re", "views", ":", "\u2581", "1", "8", "\u2581Block", "b", "ust", "ers", "\u2581Crit", "iqu", "ed", "\u2581in", "\u2581", "1", "9", "\u2581W", "ords", "\u2581or", "\u2581Less"]], "entropy": [[0.251220703125, 4.1484832763671875e-05, 0.034088134765625, 0.00572967529296875, 0.0006070137023925781, 0.92578125, 0.150634765625, 4.2890625, 4.2578125, 3.248046875, 2.923828125, 0.7529296875, 1.3466796875, 4.3359375, 0.4833984375, 0.67626953125, 3.771484375, 0.7724609375, 0.60107421875, 0.024688720703125, 3.0859375, 1.0634765625, 0.0035648345947265625, 2.98046875, 0.93359375, 1.6640625, 1.2841796875, 1.109375, 0.001125335693359375, 0.363525390625, 0.2401123046875]], "avg_entropy": [1.3413289593112083], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Swedish botanist Carl Linnaeus", "score_of_biggest_cluster": 0.07762855291366577, "score_of_first_answer": 0.07762855291366577, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.07762855291366577, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.43184244210032463, "std_of_first_answer": 0.43184244210032463, "avg_entropy_of_first_answer": 1.3413289593112083, "lex_sim": 1.0}
{"question": "where does half life 2 episode 2 take place", "answer": ["in City 17 and its surroundings, a dystopian metropolis in Eastern Europe in a parallel universe."], "scores": [[0.011688232421875, 0.019287109375, 0.99853515625, 0.99951171875, 0.99951171875, 0.6630859375, 0.5146484375, 0.52197265625, 1.0, 1.0, 0.09356689453125, 0.1077880859375, 0.8701171875, 1.0, 1.0, 0.99853515625, 0.58154296875, 0.99951171875, 0.7666015625, 0.9306640625, 0.99951171875, 0.0008330345153808594, 0.354736328125, 0.056640625, 0.97509765625, 0.2978515625, 6.556510925292969e-07, 0.002231597900390625, 0.0227813720703125, 0.0026302337646484375, 0.00013267993927001953, 0.0269622802734375, 0.00015866756439208984, 0.018402099609375, 0.0008177757263183594, 0.9921875, 0.0012531280517578125, 0.0003037452697753906, 0.16650390625, 1.0, 0.99853515625, 0.116455078125, 0.0228271484375, 0.904296875, 0.98828125, 0.95654296875, 0.99951171875, 0.90673828125]], "normalized_score": [0.09456770867109299], "tokens": [["\u2581in", "\u2581City", "\u2581", "1", "7", "\u2581and", "\u2581its", "\u2581surr", "ound", "ings", ",", "\u2581a", "\u2581d", "yst", "op", "ian", "\u2581metropol", "is", "\u2581in", "\u2581Eastern", "\u2581Europe", "\u2581in", "\u2581a", "\u2581parallel", "\u2581universe", ".", "\u2581#", "2", "6", "\u2581|", "\u2581RE", ":", "\u2581Pl", "ane", "\u2581Ge", "ometry", "\u2581T", "ue", "\u2581A", "pr", "\u2581", "2", "2", ",", "\u2581", "2", "0", "1"]], "entropy": [[2.677734375, 2.05078125, 0.0141143798828125, 0.00594329833984375, 0.003170013427734375, 0.9892578125, 1.3447265625, 1.212890625, 0.0018558502197265625, 0.0003464221954345703, 1.4423828125, 2.830078125, 0.7900390625, 6.16908073425293e-05, 0.0010242462158203125, 0.0108489990234375, 1.390625, 0.0055694580078125, 1.13671875, 0.3310546875, 0.0028076171875, 1.283203125, 1.140625, 1.1015625, 0.155029296875, 1.876953125, 0.5888671875, 2.068359375, 2.9609375, 3.23046875, 4.31640625, 2.5703125, 4.71875, 3.685546875, 4.59375, 0.0660400390625, 2.927734375, 1.9140625, 2.609375, 6.628036499023438e-05, 0.01541900634765625, 1.1240234375, 1.7880859375, 0.412841796875, 0.07611083984375, 0.19873046875, 0.005466461181640625, 0.37109375]], "avg_entropy": [1.292538591971], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "outside City 17", "score_of_biggest_cluster": 0.09456770867109299, "score_of_first_answer": 0.09456770867109299, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 6.556510925292969e-07, "avg_score": 0.09456770867109299, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4414959878735735, "std_of_first_answer": 0.4414959878735735, "avg_entropy_of_first_answer": 1.292538591971, "lex_sim": 1.0}
{"question": "where was the hindenburg scheduled to fly and how many passengers were on it", "answer": ["The Hindenburg was a zeppelin that was scheduled to fly from Germany to the United States in 1937."], "scores": [[0.276611328125, 0.99755859375, 1.0, 1.0, 0.99853515625, 0.0008916854858398438, 0.002582550048828125, 1.0, 1.0, 0.73046875, 0.97705078125, 0.90771484375, 1.0, 0.98583984375, 0.9951171875, 0.09912109375, 1.0, 0.90478515625, 0.9912109375, 1.0, 0.0256805419921875, 0.77734375, 1.0, 1.0, 1.0, 1.0, 0.796875, 0.724609375, 0.434326171875, 0.953125, 0.98779296875, 0.91796875, 0.9921875, 0.9990234375, 0.9912109375, 0.1607666015625, 1.0, 0.99951171875, 1.0, 0.98583984375, 0.77392578125, 0.9990234375, 0.8544921875, 0.9921875, 0.9990234375, 0.9951171875, 1.0, 0.1409912109375]], "normalized_score": [0.5717521905899048], "tokens": [["\u2581The", "\u2581H", "inden", "burg", "\u2581was", "\u2581a", "\u2581ze", "ppel", "in", "\u2581that", "\u2581was", "\u2581scheduled", "\u2581to", "\u2581fly", "\u2581from", "\u2581Germany", "\u2581to", "\u2581the", "\u2581United", "\u2581States", "\u2581in", "\u2581", "1", "9", "3", "7", ".", "\u2581It", "\u2581was", "\u2581carrying", "\u2581", "3", "6", "\u2581passengers", "\u2581and", "\u2581", "6", "1", "\u2581crew", "\u2581members", "\u2581when", "\u2581it", "\u2581caught", "\u2581fire", "\u2581and", "\u2581crash", "ed", "."]], "entropy": [[1.888671875, 0.02471923828125, 0.000125885009765625, 0.000736236572265625, 0.0131072998046875, 0.05615234375, 0.1036376953125, 0.0007805824279785156, 0.00022649765014648438, 1.1005859375, 0.1688232421875, 0.50830078125, 0.0009899139404296875, 0.09088134765625, 0.03778076171875, 0.50146484375, 0.0025386810302734375, 0.444091796875, 0.059417724609375, 0.0015039443969726562, 1.24609375, 0.68115234375, 0.00040411949157714844, 9.769201278686523e-05, 0.0006279945373535156, 0.0024318695068359375, 0.67724609375, 0.923828125, 0.822265625, 0.283447265625, 0.08795166015625, 0.3232421875, 0.054168701171875, 0.011260986328125, 0.052459716796875, 0.8291015625, 0.001346588134765625, 0.00356292724609375, 0.0006198883056640625, 0.0885009765625, 0.7021484375, 0.0078125, 0.50439453125, 0.045745849609375, 0.01016998291015625, 0.037445068359375, 0.00040650367736816406, 0.7822265625]], "avg_entropy": [0.27468116953969], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "36 passengers", "score_of_biggest_cluster": 0.5717521905899048, "score_of_first_answer": 0.5717521905899048, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0008916854858398438, "avg_score": 0.5717521905899048, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3171098301514017, "std_of_first_answer": 0.3171098301514017, "avg_entropy_of_first_answer": 0.27468116953969, "lex_sim": 1.0}
{"question": "who plays caesar planet of the apes 2014", "answer": ["Andy Serkis #815 \u2013 Linda\u2019s Ranty Pants"], "scores": [[0.94091796875, 0.99951171875, 1.0, 1.0, 1.3113021850585938e-06, 0.0022258758544921875, 0.032196044921875, 0.0469970703125, 1.1801719665527344e-05, 0.0008234977722167969, 0.01319122314453125, 0.004344940185546875, 0.99853515625, 0.01119232177734375, 0.0078582763671875, 0.0004131793975830078, 0.9384765625, 0.67041015625]], "normalized_score": [0.018296923488378525], "tokens": [["\u2581Andy", "\u2581Ser", "k", "is", "\u2581#", "8", "1", "5", "\u2581\u2013", "\u2581L", "inda", "\u2019", "s", "\u2581R", "ant", "y", "\u2581P", "ants"]], "entropy": [[0.246337890625, 0.004405975341796875, 0.0003075599670410156, 4.398822784423828e-05, 0.85595703125, 4.9453125, 2.548828125, 2.447265625, 2.603515625, 5.01171875, 4.34375, 4.4140625, 0.0166168212890625, 6.6484375, 2.798828125, 3.25, 0.52197265625, 0.7734375]], "avg_entropy": [2.3017110096083746], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Andy Serkis", "score_of_biggest_cluster": 0.018296923488378525, "score_of_first_answer": 0.018296923488378525, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.3113021850585938e-06, "avg_score": 0.018296923488378525, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.45617855610611946, "std_of_first_answer": 0.45617855610611946, "avg_entropy_of_first_answer": 2.3017110096083746, "lex_sim": 1.0}
{"question": "who is young george bailey in it's a wonderful life", "answer": ["James Steward"], "scores": [[0.07513427734375, 0.007091522216796875, 0.83349609375]], "normalized_score": [0.07629458606243134], "tokens": [["\u2581James", "\u2581Ste", "ward"]], "entropy": [[2.63671875, 0.084716796875, 0.75]], "avg_entropy": [1.1571451822916667], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Robert James Anderson", "score_of_biggest_cluster": 0.07629458606243134, "score_of_first_answer": 0.07629458606243134, "max_score_of_first_answer": 0.83349609375, "min_score_of_first_answer": 0.007091522216796875, "avg_score": 0.07629458606243134, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37456448442887647, "std_of_first_answer": 0.37456448442887647, "avg_entropy_of_first_answer": 1.1571451822916667, "lex_sim": 1.0}
{"question": "on which river did the exploration of the louisiana purchase begin", "answer": ["Mississippi #42 How to Create Impactful Product Demos with Andrew Hazen"], "scores": [[0.54296875, 1.1920928955078125e-07, 0.0012388229370117188, 0.076416015625, 1.627206802368164e-05, 0.05108642578125, 0.0005221366882324219, 8.118152618408203e-05, 0.8662109375, 0.7529296875, 0.0019741058349609375, 0.0282440185546875, 0.9453125, 0.12255859375, 0.0007538795471191406, 0.0170440673828125, 0.9619140625]], "normalized_score": [0.008793648332357407], "tokens": [["\u2581Mississippi", "\u2581#", "4", "2", "\u2581How", "\u2581to", "\u2581Create", "\u2581Imp", "act", "ful", "\u2581Product", "\u2581Dem", "os", "\u2581with", "\u2581Andrew", "\u2581Haz", "en"]], "entropy": [[1.392578125, 1.0166015625, 3.103515625, 3.298828125, 3.541015625, 3.681640625, 5.23046875, 2.439453125, 0.66748046875, 1.3447265625, 3.70703125, 3.986328125, 0.2149658203125, 3.271484375, 5.171875, 4.34375, 0.1998291015625]], "avg_entropy": [2.7418571920955883], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Missouri River", "score_of_biggest_cluster": 0.008793648332357407, "score_of_first_answer": 0.008793648332357407, "max_score_of_first_answer": 0.9619140625, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.008793648332357407, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37041516464444646, "std_of_first_answer": 0.37041516464444646, "avg_entropy_of_first_answer": 2.7418571920955883, "lex_sim": 1.0}
{"question": "who were the the continent of the americas named after logically", "answer": ["Christopher Columbus"], "scores": [[0.841796875, 0.9970703125, 1.0]], "normalized_score": [0.9432881474494934], "tokens": [["\u2581Christopher", "\u2581Columb", "us"]], "entropy": [[0.615234375, 0.0208740234375, 0.00135040283203125]], "avg_entropy": [0.21248626708984375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Amerigo Vespucci", "score_of_biggest_cluster": 0.9432881474494934, "score_of_first_answer": 0.9432881474494934, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.841796875, "avg_score": 0.9432881474494934, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.07389681411090865, "std_of_first_answer": 0.07389681411090865, "avg_entropy_of_first_answer": 0.21248626708984375, "lex_sim": 1.0}
{"question": "who won season 8 of america's next top model", "answer": ["McKey Sullivan #21 \"Why does lightning bolt in opposite direction when it enters a house\""], "scores": [[0.47705078125, 0.99658203125, 0.99853515625, 0.99462890625, 0.99853515625, 1.1920928955078125e-07, 0.11590576171875, 0.12249755859375, 0.000156402587890625, 0.0010519027709960938, 0.0004298686981201172, 1.0132789611816406e-06, 0.5234375, 0.75244140625, 0.84814453125, 0.01198577880859375, 0.001621246337890625, 0.66455078125, 0.12042236328125, 0.299072265625, 0.0116424560546875, 0.4619140625, 0.0034809112548828125, 0.156005859375]], "normalized_score": [0.02715935930609703], "tokens": [["\u2581Mc", "Key", "\u2581S", "ull", "ivan", "\u2581#", "2", "1", "\u2581\"", "Why", "\u2581does", "\u2581light", "ning", "\u2581b", "olt", "\u2581in", "\u2581opposite", "\u2581direction", "\u2581when", "\u2581it", "\u2581enters", "\u2581a", "\u2581house", "\""]], "entropy": [[1.701171875, 0.025238037109375, 0.0140838623046875, 0.049530029296875, 0.0113525390625, 0.736328125, 2.7109375, 2.07421875, 1.072265625, 3.98046875, 3.2109375, 1.9775390625, 1.2333984375, 1.44921875, 0.55810546875, 2.57421875, 2.8359375, 1.4208984375, 2.755859375, 4.0703125, 2.30859375, 2.3203125, 1.8193359375, 2.6484375]], "avg_entropy": [1.8149458567301433], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Jaslene Gonzalez", "score_of_biggest_cluster": 0.02715935930609703, "score_of_first_answer": 0.02715935930609703, "max_score_of_first_answer": 0.99853515625, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.02715935930609703, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38311041764273046, "std_of_first_answer": 0.38311041764273046, "avg_entropy_of_first_answer": 1.8149458567301433, "lex_sim": 1.0}
{"question": "first jnanpith award was an autor of which language", "answer": ["First Jnanpith Award was given to the poet Akkitham in Malayalam Language."], "scores": [[0.04986572265625, 0.98876953125, 0.99951171875, 1.0, 1.0, 0.7607421875, 0.97705078125, 0.79638671875, 0.9541015625, 0.351318359375, 0.0157470703125, 0.004123687744140625, 0.1800537109375, 0.99658203125, 0.9521484375, 0.41796875, 0.58056640625, 1.0, 0.99951171875, 1.0, 0.0718994140625, 0.6318359375, 4.172325134277344e-07, 7.748603820800781e-06, 0.63916015625]], "normalized_score": [0.14986751973628998], "tokens": [["\u2581First", "\u2581J", "nan", "p", "ith", "\u2581Award", "\u2581was", "\u2581given", "\u2581to", "\u2581the", "\u2581poet", "\u2581A", "kk", "ith", "am", "\u2581in", "\u2581Mal", "ay", "al", "am", "\u2581Language", ".", "\u2581###", "\u2581Sum", "mary"]], "entropy": [[1.5029296875, 0.09698486328125, 0.006244659423828125, 0.002262115478515625, 0.00036025047302246094, 0.59423828125, 0.1566162109375, 0.8544921875, 0.2071533203125, 2.490234375, 1.0869140625, 3.19140625, 1.8515625, 0.0302276611328125, 0.35986328125, 1.6591796875, 0.958984375, 0.0007171630859375, 0.003871917724609375, 0.00012731552124023438, 1.1123046875, 1.1220703125, 0.38916015625, 4.875, 0.79248046875]], "avg_entropy": [0.9338154315948486], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Malayalam", "score_of_biggest_cluster": 0.14986751973628998, "score_of_first_answer": 0.14986751973628998, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.14986751973628998, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3995204952559547, "std_of_first_answer": 0.3995204952559547, "avg_entropy_of_first_answer": 0.9338154315948486, "lex_sim": 1.0}
{"question": "where does the show the path take place", "answer": ["In the town of Hawkins, Indiana."], "scores": [[0.0814208984375, 0.5986328125, 0.055633544921875, 0.99658203125, 0.044769287109375, 0.98291015625, 0.98779296875, 0.99267578125, 0.491943359375, 8.344650268554688e-07, 4.172325134277344e-07, 0.0025634765625, 0.0921630859375, 0.163818359375, 0.01593017578125, 0.0004067420959472656, 0.99853515625, 0.9638671875, 0.06597900390625, 1.0, 0.30615234375, 1.0, 0.85888671875, 0.10235595703125, 0.0288543701171875, 0.9814453125, 0.0147705078125, 0.40576171875, 0.1353759765625, 0.048095703125, 0.37060546875, 0.0002104043960571289, 0.317626953125, 0.99658203125, 1.0, 0.95849609375]], "normalized_score": [0.07917845994234085], "tokens": [["\u2581In", "\u2581the", "\u2581town", "\u2581of", "\u2581Haw", "kins", ",", "\u2581Indiana", ".", "\u2581#", "Book", "Re", "view", ":", "\u2581A", "\u2581Gent", "le", "man", "'", "s", "\u2581Mur", "der", "\u2581by", "\u2581@", "jas", "per", "bol", "ton", "\u2581-", "\u2581", "4", "\u2581W", "ine", "\u2581G", "lass", "es"]], "entropy": [[3.703125, 1.830078125, 3.490234375, 0.0309600830078125, 2.923828125, 0.1015625, 0.08123779296875, 0.059326171875, 1.42578125, 0.77490234375, 0.9853515625, 2.32421875, 0.72119140625, 2.609375, 3.2421875, 5.546875, 0.01309967041015625, 0.253173828125, 0.404541015625, 0.00045752525329589844, 1.26953125, 0.0006093978881835938, 0.70068359375, 3.037109375, 4.234375, 0.17626953125, 2.703125, 3.67578125, 2.294921875, 2.580078125, 1.83203125, 1.8076171875, 3.380859375, 0.0253753662109375, 7.18832015991211e-05, 0.240234375]], "avg_entropy": [1.6244494683212705], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Upstate New York", "score_of_biggest_cluster": 0.07917845994234085, "score_of_first_answer": 0.07917845994234085, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.07917845994234085, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42409613795492906, "std_of_first_answer": 0.42409613795492906, "avg_entropy_of_first_answer": 1.6244494683212705, "lex_sim": 1.0}
{"question": "how oxygenated blood returns to the heart from the lungs", "answer": ["through the pulmonary veins."], "scores": [[0.61328125, 0.953125, 0.97216796875, 1.0, 0.998046875, 1.0, 0.99462890625, 0.39111328125]], "normalized_score": [0.8278624415397644], "tokens": [["\u2581through", "\u2581the", "\u2581pul", "mon", "ary", "\u2581ve", "ins", "."]], "entropy": [[1.2802734375, 0.2354736328125, 0.1876220703125, 0.00027179718017578125, 0.01541900634765625, 0.00218963623046875, 0.033538818359375, 1.0751953125]], "avg_entropy": [0.3537479639053345], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "pulmonary circulation", "score_of_biggest_cluster": 0.8278624415397644, "score_of_first_answer": 0.8278624415397644, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.39111328125, "avg_score": 0.8278624415397644, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.21740985678142524, "std_of_first_answer": 0.21740985678142524, "avg_entropy_of_first_answer": 0.3537479639053345, "lex_sim": 1.0}
{"question": "where are trigger points located in the body", "answer": ["Trigger points are located in muscles or the tissues surrounding them."], "scores": [[0.36328125, 1.0, 0.99853515625, 0.432373046875, 0.98828125, 0.8974609375, 0.845703125, 0.98291015625, 0.50244140625, 0.128662109375, 0.1263427734375, 0.8271484375, 0.7138671875, 0.94287109375, 0.96728515625, 0.30126953125, 0.66357421875, 0.55322265625, 0.716796875, 0.1904296875, 0.99951171875, 0.9970703125, 0.5703125, 0.57666015625, 0.95556640625, 0.09466552734375, 0.67333984375, 0.99951171875, 0.384033203125, 0.8759765625, 0.78271484375, 0.98291015625, 0.9677734375, 1.0, 0.8447265625, 0.441650390625, 0.8935546875, 0.0, 0.0008935928344726562, 0.427490234375, 0.49658203125, 0.10589599609375, 0.98095703125, 0.2509765625, 0.00016546249389648438, 0.9365234375, 0.94091796875, 0.626953125]], "normalized_score": [0.0], "tokens": [["\u2581Tr", "igger", "\u2581points", "\u2581are", "\u2581located", "\u2581in", "\u2581mus", "cles", "\u2581or", "\u2581the", "\u2581t", "issues", "\u2581surrounding", "\u2581them", ".", "\u2581They", "\u2581can", "\u2581be", "\u2581found", "\u2581throughout", "\u2581the", "\u2581body", ",", "\u2581but", "\u2581are", "\u2581commonly", "\u2581found", "\u2581in", "\u2581areas", "\u2581of", "\u2581mus", "cle", "\u2581t", "ension", "\u2581or", "\u2581pain", ".", "\u2581###", "\u2581What", "\u2581is", "\u2581the", "\u2581difference", "\u2581between", "\u2581a", "\u2581module", "\u2581and", "\u2581a", "\u2581package"]], "entropy": [[1.8046875, 0.0009140968322753906, 0.01198577880859375, 0.7646484375, 0.094970703125, 0.373779296875, 0.56982421875, 0.08721923828125, 1.3447265625, 1.6455078125, 1.7509765625, 0.47314453125, 0.66015625, 0.2412109375, 0.1785888671875, 0.90283203125, 0.6962890625, 1.056640625, 1.05859375, 1.12109375, 0.004383087158203125, 0.02215576171875, 1.1767578125, 0.85205078125, 0.252685546875, 0.79296875, 0.658203125, 0.00323486328125, 0.74365234375, 0.492919921875, 0.87109375, 0.0992431640625, 0.1949462890625, 0.0002262592315673828, 0.5927734375, 1.78125, 0.37353515625, 0.44970703125, 5.76171875, 2.59765625, 1.4658203125, 3.916015625, 0.11187744140625, 3.77734375, 0.98486328125, 0.380859375, 0.341552734375, 1.8798828125]], "avg_entropy": [0.9461909880240759], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "muscles", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.33222672445250495, "std_of_first_answer": 0.33222672445250495, "avg_entropy_of_first_answer": 0.9461909880240759, "lex_sim": 1.0}
{"question": "who is mostly responsible for writing the declaration of independence", "answer": ["Thomas Jefferson #MegaMatch: Win the Ultimate Football Experience!"], "scores": [[0.9833984375, 1.0, 2.205371856689453e-06, 0.00247955322265625, 0.0003311634063720703, 1.537799835205078e-05, 0.003253936767578125, 9.5367431640625e-06, 0.0276031494140625, 0.0072174072265625, 0.99853515625, 0.001735687255859375, 0.416259765625, 1.0, 0.33349609375]], "normalized_score": [0.008078507147729397], "tokens": [["\u2581Thomas", "\u2581Jefferson", "\u2581#", "M", "ega", "Match", ":", "\u2581Win", "\u2581the", "\u2581Ult", "imate", "\u2581Football", "\u2581Exper", "ience", "!"]], "entropy": [[0.1336669921875, 0.0009937286376953125, 1.3896484375, 5.01953125, 1.490234375, 4.6328125, 2.783203125, 3.556640625, 2.173828125, 2.521484375, 0.011749267578125, 4.34765625, 1.8134765625, 0.0018033981323242188, 2.591796875]], "avg_entropy": [2.1645683924357098], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Thomas Jefferson", "score_of_biggest_cluster": 0.008078507147729397, "score_of_first_answer": 0.008078507147729397, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.205371856689453e-06, "avg_score": 0.008078507147729397, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4266029207895812, "std_of_first_answer": 0.4266029207895812, "avg_entropy_of_first_answer": 2.1645683924357098, "lex_sim": 1.0}
{"question": "who sings too much time on my hands lyrics", "answer": ["Styx #NerdProm2012"], "scores": [[0.60302734375, 1.0, 1.0, 1.1920928955078125e-06, 0.0007343292236328125, 0.003978729248046875, 0.0007419586181640625, 0.010833740234375, 0.919921875, 0.003173828125, 0.00788116455078125]], "normalized_score": [0.011313024908304214], "tokens": [["\u2581St", "y", "x", "\u2581#", "N", "erd", "Prom", "2", "0", "1", "2"]], "entropy": [[2.490234375, 0.002063751220703125, 0.0021495819091796875, 0.85498046875, 4.3203125, 3.48046875, 1.927734375, 0.8212890625, 0.4697265625, 0.079833984375, 1.4453125]], "avg_entropy": [1.4449187192049893], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Tommy Shaw", "score_of_biggest_cluster": 0.011313024908304214, "score_of_first_answer": 0.011313024908304214, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-06, "avg_score": 0.011313024908304214, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43319458317452736, "std_of_first_answer": 0.43319458317452736, "avg_entropy_of_first_answer": 1.4449187192049893, "lex_sim": 1.0}
{"question": "who sang our god is an awesome god", "answer": ["Tommy Walker"], "scores": [[0.0009093284606933594, 0.30517578125]], "normalized_score": [0.0166584812104702], "tokens": [["\u2581Tommy", "\u2581Walker"]], "entropy": [[3.525390625, 1.5966796875]], "avg_entropy": [2.56103515625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Rich Mullins", "score_of_biggest_cluster": 0.0166584812104702, "score_of_first_answer": 0.0166584812104702, "max_score_of_first_answer": 0.30517578125, "min_score_of_first_answer": 0.0009093284606933594, "avg_score": 0.0166584812104702, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.15213322639465332, "std_of_first_answer": 0.15213322639465332, "avg_entropy_of_first_answer": 2.56103515625, "lex_sim": 1.0}
{"question": "under article 1 what is the minimum age required to serve in the house of representatives", "answer": ["25 years old ##### TRAVEL 2023 #####"], "scores": [[0.728515625, 1.0, 1.0, 0.6923828125, 0.85986328125, 0.0, 0.00014495849609375, 0.004100799560546875, 0.037567138671875, 0.99609375, 0.00479888916015625, 0.321044921875, 0.324951171875, 0.5244140625, 0.73095703125, 0.04986572265625]], "normalized_score": [0.0], "tokens": [["\u2581", "2", "5", "\u2581years", "\u2581old", "\u2581#####", "\u2581T", "RA", "V", "EL", "\u2581", "2", "0", "2", "3", "\u2581#####"]], "entropy": [[1.009765625, 0.002231597900390625, 0.0011320114135742188, 0.873046875, 0.5615234375, 1.126953125, 1.5166015625, 4.21484375, 1.09375, 0.0377197265625, 3.662109375, 2.1328125, 2.255859375, 1.8671875, 0.89013671875, 2.408203125]], "avg_entropy": [1.478367269039154], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "25", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.3917929008277084, "std_of_first_answer": 0.3917929008277084, "avg_entropy_of_first_answer": 1.478367269039154, "lex_sim": 1.0}
{"question": "when does a wrinkle in time come out in canada", "answer": ["I am sorry, I couldn't find any information on the release date of A Wrinkle in Time in Canada."], "scores": [[0.1602783203125, 0.258544921875, 0.217529296875, 0.939453125, 0.8046875, 0.00435638427734375, 0.99365234375, 1.0, 0.98583984375, 0.243408203125, 0.9326171875, 0.1356201171875, 0.54541015625, 0.9306640625, 0.95166015625, 0.96923828125, 0.26025390625, 0.73388671875, 0.99951171875, 1.0, 1.0, 0.98974609375, 0.99951171875, 0.9921875, 0.9921875, 0.94677734375, 0.0099029541015625, 0.051483154296875, 0.046356201171875, 0.95751953125, 0.99951171875, 1.0, 1.0, 0.998046875, 0.99951171875, 0.58935546875, 0.387939453125, 0.5107421875, 1.0, 0.98876953125, 0.9951171875, 0.9013671875, 1.0, 0.88232421875, 1.0, 0.982421875, 0.0081634521484375, 0.97412109375, 0.6005859375, 0.9990234375]], "normalized_score": [0.49780911207199097], "tokens": [["\u2581I", "\u2581am", "\u2581sorry", ",", "\u2581I", "\u2581couldn", "'", "t", "\u2581find", "\u2581any", "\u2581information", "\u2581on", "\u2581the", "\u2581release", "\u2581date", "\u2581of", "\u2581A", "\u2581W", "r", "ink", "le", "\u2581in", "\u2581Time", "\u2581in", "\u2581Canada", ".", "\u2581But", ",", "\u2581A", "\u2581W", "r", "ink", "le", "\u2581in", "\u2581Time", "\u2581is", "\u2581an", "\u2581up", "coming", "\u2581American", "\u2581science", "\u2581fant", "asy", "\u2581advent", "ure", "\u2581film", "\u2581that", "\u2581is", "\u2581directed", "\u2581by"]], "entropy": [[1.912109375, 1.3125, 1.06640625, 0.279296875, 0.693359375, 1.17578125, 0.047119140625, 0.000141143798828125, 0.1064453125, 1.6337890625, 0.398193359375, 1.0693359375, 1.4794921875, 0.4189453125, 0.202880859375, 0.15478515625, 1.3427734375, 0.5810546875, 0.004123687744140625, 4.947185516357422e-06, 0.00012373924255371094, 0.059234619140625, 0.00665283203125, 0.053009033203125, 0.0501708984375, 0.303955078125, 1.6708984375, 1.2783203125, 1.2216796875, 0.180419921875, 0.0032501220703125, 5.91278076171875e-05, 0.0006513595581054688, 0.0168914794921875, 0.006282806396484375, 1.1904296875, 1.0419921875, 0.70751953125, 0.0013065338134765625, 0.077880859375, 0.03619384765625, 0.332275390625, 0.0004057884216308594, 0.435302734375, 2.1398067474365234e-05, 0.09320068359375, 0.455810546875, 0.16015625, 1.2529296875, 0.007755279541015625]], "avg_entropy": [0.49046634435653685], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "March 9, 2018", "score_of_biggest_cluster": 0.49780911207199097, "score_of_first_answer": 0.49780911207199097, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.00435638427734375, "avg_score": 0.49780911207199097, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.35648230508629447, "std_of_first_answer": 0.35648230508629447, "avg_entropy_of_first_answer": 0.49046634435653685, "lex_sim": 1.0}
{"question": "what is the meaning of auv in cars", "answer": ["AUV stands for Autonomous Underwater Vehicle."], "scores": [[0.1470947265625, 0.9091796875, 1.0, 0.95361328125, 0.99951171875, 0.810546875, 1.0, 1.0, 0.99853515625, 1.0, 1.0, 1.0, 0.99951171875, 0.77099609375, 0.2802734375, 0.94287109375, 0.8408203125, 0.06024169921875, 1.0, 0.306396484375, 0.9013671875, 0.64794921875, 0.9990234375, 0.50341796875, 0.5693359375, 0.19189453125, 0.327392578125, 0.1903076171875, 0.87939453125, 0.99951171875, 0.98876953125, 0.39013671875, 0.0208892822265625, 0.998046875, 0.12396240234375, 1.0, 0.0007386207580566406, 0.6552734375, 0.9814453125, 1.3768672943115234e-05, 2.384185791015625e-07, 0.86767578125, 0.00394439697265625, 0.00592803955078125, 0.78271484375, 0.0004730224609375, 0.0095062255859375, 0.427001953125]], "normalized_score": [0.19049100577831268], "tokens": [["\u2581A", "U", "V", "\u2581stands", "\u2581for", "\u2581Aut", "onom", "ous", "\u2581Under", "water", "\u2581Ve", "h", "icle", ".", "\u2581It", "\u2581is", "\u2581a", "\u2581self", "-", "oper", "ating", "\u2581under", "water", "\u2581vehicle", "\u2581that", "\u2581can", "\u2581perform", "\u2581a", "\u2581variety", "\u2581of", "\u2581tasks", "\u2581without", "\u2581direct", "\u2581human", "\u2581inter", "vention", "\u2581or", "\u2581control", ".", "\u2581[", "quote", "]", "\u2581[", "i", "]", "On", "\u2581", "2"]], "entropy": [[2.505859375, 0.429443359375, 0.002410888671875, 0.26318359375, 0.0026187896728515625, 0.5673828125, 0.0004725456237792969, 0.0011777877807617188, 0.0108642578125, 0.00045037269592285156, 0.0013713836669921875, 1.615285873413086e-05, 0.003353118896484375, 0.77880859375, 1.080078125, 0.2685546875, 0.5771484375, 1.43359375, 0.0015974044799804688, 1.6708984375, 0.3251953125, 1.2392578125, 0.00873565673828125, 0.85009765625, 0.8837890625, 0.6552734375, 1.0146484375, 1.2265625, 0.484130859375, 0.00445556640625, 0.0736083984375, 1.326171875, 0.350341796875, 0.0163116455078125, 1.1318359375, 0.000537872314453125, 0.1251220703125, 1.525390625, 0.1112060546875, 1.1279296875, 0.9609375, 0.7060546875, 3.2578125, 3.3203125, 0.97021484375, 3.78515625, 3.59765625, 1.724609375]], "avg_entropy": [0.8417216675976912], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "action utility vehicles", "score_of_biggest_cluster": 0.19049100577831268, "score_of_first_answer": 0.19049100577831268, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.19049100577831268, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39545434287611986, "std_of_first_answer": 0.39545434287611986, "avg_entropy_of_first_answer": 0.8417216675976912, "lex_sim": 1.0}
{"question": "where does the coral sea meet the pacific ocean", "answer": ["at the northeastern corner of Australia ### What is a **database**?"], "scores": [[0.238525390625, 0.9990234375, 0.299560546875, 0.53076171875, 1.0, 1.0, 0.0219573974609375, 0.98388671875, 0.86572265625, 0.0, 0.0014400482177734375, 0.418701171875, 0.014801025390625, 0.0007462501525878906, 0.0004315376281738281, 0.87548828125, 0.71923828125]], "normalized_score": [0.0], "tokens": [["\u2581at", "\u2581the", "\u2581n", "ort", "he", "astern", "\u2581corner", "\u2581of", "\u2581Australia", "\u2581###", "\u2581What", "\u2581is", "\u2581a", "\u2581**", "database", "**", "?"]], "entropy": [[2.693359375, 0.0106201171875, 1.35546875, 0.69580078125, 0.00041556358337402344, 0.0014581680297851562, 1.6513671875, 0.0965576171875, 0.425537109375, 1.1123046875, 3.400390625, 2.693359375, 1.64453125, 6.13671875, 6.1171875, 0.85400390625, 1.47265625]], "avg_entropy": [1.7859845301684212], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "in the east", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41065968230559385, "std_of_first_answer": 0.41065968230559385, "avg_entropy_of_first_answer": 1.7859845301684212, "lex_sim": 1.0}
{"question": "when was the last time the vikings made the superbowl", "answer": ["2017 ### What is a Dashboard?"], "scores": [[0.58935546875, 0.98291015625, 1.0, 0.86572265625, 0.241943359375, 1.1920928955078125e-07, 0.0014257431030273438, 0.28515625, 0.021697998046875, 0.0008220672607421875, 0.0204925537109375, 0.034454345703125, 0.324951171875]], "normalized_score": [0.03096543252468109], "tokens": [["\u2581", "2", "0", "1", "7", "\u2581###", "\u2581What", "\u2581is", "\u2581a", "\u2581D", "ash", "board", "?"]], "entropy": [[1.515625, 0.08880615234375, 0.0018854141235351562, 0.425048828125, 1.3466796875, 1.609375, 4.25, 3.380859375, 1.75390625, 6.26171875, 4.42578125, 3.6328125, 2.6953125]], "avg_entropy": [2.4144469774686375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "in the 1970s", "score_of_biggest_cluster": 0.03096543252468109, "score_of_first_answer": 0.03096543252468109, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.03096543252468109, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3764385906907983, "std_of_first_answer": 0.3764385906907983, "avg_entropy_of_first_answer": 2.4144469774686375, "lex_sim": 1.0}
{"question": "who was the first president of the constituent assembly", "answer": ["Dr. Rajendra Prasad."], "scores": [[0.94140625, 0.9921875, 0.235595703125, 0.99560546875, 0.9990234375, 1.0, 1.0, 0.1590576171875, 3.5762786865234375e-07, 9.059906005859375e-06, 0.031280517578125]], "normalized_score": [0.048544954508543015], "tokens": [["\u2581Dr", ".", "\u2581Raj", "endra", "\u2581Pr", "as", "ad", ".", "\u2581###", "\u2581Cont", "ents"]], "entropy": [[0.426025390625, 0.054931640625, 1.2548828125, 0.033050537109375, 0.0106964111328125, 0.0015888214111328125, 0.0017642974853515625, 1.083984375, 0.4423828125, 3.271484375, 1.3984375]], "avg_entropy": [0.7253844521262429], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Dr. Rajendra Prasad", "score_of_biggest_cluster": 0.048544954508543015, "score_of_first_answer": 0.048544954508543015, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 3.5762786865234375e-07, "avg_score": 0.048544954508543015, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.45439768748135795, "std_of_first_answer": 0.45439768748135795, "avg_entropy_of_first_answer": 0.7253844521262429, "lex_sim": 1.0}
{"question": "how many terms can a mayor serve in texas", "answer": ["limitless; there is no term limit for a mayor in Texas."], "scores": [[0.0011959075927734375, 0.52734375, 0.00035262107849121094, 0.048004150390625, 0.8505859375, 0.99560546875, 0.300048828125, 0.96630859375, 0.966796875, 0.36572265625, 0.88037109375, 0.99462890625, 0.9794921875, 0.63037109375, 0.0, 5.2809715270996094e-05, 0.0275115966796875, 0.031707763671875, 0.2265625, 0.00788116455078125, 0.00153350830078125, 0.2352294921875, 0.307373046875, 6.318092346191406e-06, 0.3037109375]], "normalized_score": [0.0], "tokens": [["\u2581limit", "less", ";", "\u2581there", "\u2581is", "\u2581no", "\u2581term", "\u2581limit", "\u2581for", "\u2581a", "\u2581mayor", "\u2581in", "\u2581Texas", ".", "\u2581###", "\u2581Can", "\u2581we", "\u2581do", "\u2581this", "\u2581without", "\u2581creating", "\u2581a", "\u2581new", "\u2581enum", "?"]], "entropy": [[1.9990234375, 1.5283203125, 1.1318359375, 2.248046875, 0.5048828125, 0.03680419921875, 2.05078125, 0.1644287109375, 0.215087890625, 1.0498046875, 0.3955078125, 0.041748046875, 0.1121826171875, 0.96533203125, 0.47314453125, 4.671875, 2.517578125, 3.392578125, 2.412109375, 1.6015625, 3.8203125, 4.06640625, 4.640625, 5.15234375, 2.90625]], "avg_entropy": [1.92394287109375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "two four-year terms", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.99560546875, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3888451365888633, "std_of_first_answer": 0.3888451365888633, "avg_entropy_of_first_answer": 1.92394287109375, "lex_sim": 1.0}
{"question": "who did corbin dance with on dancing with the stars", "answer": ["Karina Smirnoff #2393: Daredevil Season 1-3 Box Set"], "scores": [[0.336181640625, 0.6513671875, 0.99853515625, 1.0, 0.99951171875, 1.0, 7.748603820800781e-07, 0.0006508827209472656, 0.047332763671875, 0.012115478515625, 0.07196044921875, 0.0014047622680664062, 0.00392913818359375, 0.00019085407257080078, 0.01561737060546875, 0.94482421875, 0.0802001953125, 0.982421875, 0.04486083984375, 0.023101806640625, 0.7470703125, 9.47713851928711e-06, 0.414306640625]], "normalized_score": [0.030775703489780426], "tokens": [["\u2581Kar", "ina", "\u2581Sm", "ir", "no", "ff", "\u2581#", "2", "3", "9", "3", ":", "\u2581D", "are", "dev", "il", "\u2581Season", "\u2581", "1", "-", "3", "\u2581Box", "\u2581Set"]], "entropy": [[2.818359375, 0.75732421875, 0.01303863525390625, 0.00021445751190185547, 0.0026645660400390625, 0.0002384185791015625, 0.89111328125, 1.861328125, 2.908203125, 2.548828125, 2.984375, 2.7421875, 4.1875, 1.5126953125, 0.492431640625, 0.216796875, 4.13671875, 0.1533203125, 0.5888671875, 3.9375, 0.91650390625, 3.265625, 1.3876953125]], "avg_entropy": [1.6662403967069543], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Karina Smirnoff", "score_of_biggest_cluster": 0.030775703489780426, "score_of_first_answer": 0.030775703489780426, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 7.748603820800781e-07, "avg_score": 0.030775703489780426, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4215800448096901, "std_of_first_answer": 0.4215800448096901, "avg_entropy_of_first_answer": 1.6662403967069543, "lex_sim": 1.0}
{"question": "who is the cast of despicable me 3", "answer": ["Steve Carell, Kristen Wiig, Trey Parker, Miranda Cosgrove, Pierre Coffin, and Jenny Slate."], "scores": [[0.931640625, 0.99951171875, 1.0, 0.9892578125, 0.99365234375, 1.0, 1.0, 0.9990234375, 0.99658203125, 0.97705078125, 1.0, 0.99609375, 0.9794921875, 0.92822265625, 0.998046875, 0.99853515625, 1.0, 1.0, 0.97998046875, 0.016845703125, 0.99951171875, 1.0, 1.0, 0.9345703125, 0.7373046875, 0.10906982421875, 0.98291015625, 0.99951171875, 1.0, 0.56103515625]], "normalized_score": [0.7786222100257874], "tokens": [["\u2581Steve", "\u2581Care", "ll", ",", "\u2581Krist", "en", "\u2581Wi", "ig", ",", "\u2581Tre", "y", "\u2581Parker", ",", "\u2581Mir", "anda", "\u2581Cos", "gro", "ve", ",", "\u2581Pierre", "\u2581C", "off", "in", ",", "\u2581and", "\u2581Jen", "ny", "\u2581S", "late", "."]], "entropy": [[0.45751953125, 0.00472259521484375, 0.0006766319274902344, 0.077392578125, 0.04296875, 0.0007243156433105469, 0.0010280609130859375, 0.0063629150390625, 0.0269317626953125, 0.14453125, 1.2934207916259766e-05, 0.0293426513671875, 0.11541748046875, 0.36962890625, 0.018157958984375, 0.0133514404296875, 0.0007419586181640625, 0.001445770263671875, 0.11700439453125, 0.537109375, 0.0056915283203125, 0.0012874603271484375, 0.0005283355712890625, 0.30517578125, 1.07421875, 2.08984375, 0.1038818359375, 0.003688812255859375, 0.0005002021789550781, 1.0244140625]], "avg_entropy": [0.21914339264233906], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Steve Carell", "score_of_biggest_cluster": 0.7786222100257874, "score_of_first_answer": 0.7786222100257874, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.016845703125, "avg_score": 0.7786222100257874, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2421546609979998, "std_of_first_answer": 0.2421546609979998, "avg_entropy_of_first_answer": 0.21914339264233906, "lex_sim": 1.0}
{"question": "when does it's a wonderful life comes on", "answer": ["It's a Wonderful Life is not a movie that airs on a specific date or time."], "scores": [[0.228271484375, 0.94384765625, 1.0, 0.92431640625, 1.0, 1.0, 0.99951171875, 0.94580078125, 0.0294952392578125, 0.2213134765625, 0.193359375, 0.9638671875, 0.444580078125, 0.99951171875, 0.89111328125, 0.03961181640625, 0.9521484375, 0.76318359375, 0.962890625, 0.9892578125, 0.62451171875, 0.9697265625, 0.921875, 0.87255859375, 0.0247955322265625, 0.99462890625, 0.658203125, 1.0, 0.97509765625, 0.8876953125, 0.994140625, 0.9970703125, 0.51220703125, 4.172325134277344e-07, 0.00251007080078125, 0.004062652587890625, 0.0017080307006835938, 0.736328125, 0.01213836669921875, 0.4658203125, 0.0230560302734375, 1.5676021575927734e-05, 6.4373016357421875e-06, 0.0002894401550292969, 0.00162506103515625, 0.97607421875]], "normalized_score": [0.11882676929235458], "tokens": [["\u2581It", "'", "s", "\u2581a", "\u2581Wonder", "ful", "\u2581Life", "\u2581is", "\u2581not", "\u2581a", "\u2581movie", "\u2581that", "\u2581air", "s", "\u2581on", "\u2581a", "\u2581specific", "\u2581date", "\u2581or", "\u2581time", ".", "\u2581It", "\u2581is", "\u2581a", "\u2581film", "\u2581that", "\u2581can", "\u2581be", "\u2581watched", "\u2581at", "\u2581any", "\u2581time", ".", "\u2581#", "The", "C", "ool", "est", "C", "ool", "est", "\u2581Prom", "otes", "\u2581National", "\u2581Park", "s"]], "entropy": [[1.6416015625, 0.315185546875, 7.748603820800781e-05, 0.30322265625, 0.002147674560546875, 2.5928020477294922e-05, 0.004726409912109375, 0.35986328125, 0.29736328125, 1.0751953125, 2.03515625, 0.2176513671875, 1.470703125, 0.0030612945556640625, 0.469482421875, 0.791015625, 0.2607421875, 0.67431640625, 0.2044677734375, 0.0770263671875, 0.87841796875, 0.168212890625, 0.29833984375, 0.51904296875, 1.1572265625, 0.040740966796875, 0.9326171875, 0.0014667510986328125, 0.1578369140625, 0.48974609375, 0.036224365234375, 0.02197265625, 1.4609375, 1.1611328125, 5.29296875, 5.078125, 2.955078125, 1.89453125, 2.23828125, 2.103515625, 1.0390625, 2.404296875, 0.0124664306640625, 4.85546875, 4.14453125, 0.216064453125]], "avg_entropy": [1.0817682108153468], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Christmas season", "score_of_biggest_cluster": 0.11882676929235458, "score_of_first_answer": 0.11882676929235458, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.11882676929235458, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42048021436448413, "std_of_first_answer": 0.42048021436448413, "avg_entropy_of_first_answer": 1.0817682108153468, "lex_sim": 1.0}
{"question": "who painted the world famous painting the last supper", "answer": ["Leonardo da Vinci"], "scores": [[0.994140625, 1.0, 0.99267578125, 0.99951171875, 1.0]], "normalized_score": [0.9972605109214783], "tokens": [["\u2581Leon", "ardo", "\u2581da", "\u2581V", "inci"]], "entropy": [[0.05035400390625, 0.000133514404296875, 0.050048828125, 0.00490570068359375, 0.0018434524536132812]], "avg_entropy": [0.021457099914550783], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Leonardo da Vinci", "score_of_biggest_cluster": 0.9972605109214783, "score_of_first_answer": 0.9972605109214783, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.99267578125, "avg_score": 0.9972605109214783, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.0031884429135379897, "std_of_first_answer": 0.0031884429135379897, "avg_entropy_of_first_answer": 0.021457099914550783, "lex_sim": 1.0}
{"question": "who was the captain of the mayflower which brought the pilgrims to plymouth", "answer": ["Christopher Jones Proof of Heaven: A Neurosurgeon's Experience with the Afterlife by Eben Alexander III, M.D."], "scores": [[0.998046875, 0.99951171875, 0.0, 0.0113372802734375, 4.64320182800293e-05, 0.219970703125, 0.994140625, 0.1478271484375, 1.0, 0.9970703125, 1.0, 0.88525390625, 1.0, 0.0031604766845703125, 0.8994140625, 0.95263671875, 0.99951171875, 0.99609375, 0.99951171875, 0.0994873046875, 0.95068359375, 0.99169921875, 0.99755859375, 0.0084228515625, 0.08489990234375, 0.73095703125, 0.99853515625, 0.99609375, 0.95849609375]], "normalized_score": [0.0], "tokens": [["\u2581Christopher", "\u2581Jones", "\u2581Proof", "\u2581of", "\u2581Heaven", ":", "\u2581A", "\u2581Neu", "ros", "ur", "geon", "'", "s", "\u2581Exper", "ience", "\u2581with", "\u2581the", "\u2581After", "life", "\u2581by", "\u2581E", "ben", "\u2581Alexander", "\u2581III", ",", "\u2581M", ".", "D", "."]], "entropy": [[0.0206298828125, 0.002948760986328125, 0.7119140625, 3.181640625, 3.794921875, 2.4296875, 0.054168701171875, 0.73876953125, 7.903575897216797e-05, 0.0203857421875, 0.00032138824462890625, 0.360107421875, 4.291534423828125e-05, 0.053985595703125, 0.349365234375, 0.2176513671875, 0.005588531494140625, 0.032073974609375, 0.007049560546875, 3.314453125, 0.265625, 0.0540771484375, 0.022613525390625, 2.583984375, 3.6953125, 0.7958984375, 0.01488494873046875, 0.032440185546875, 0.26806640625]], "avg_entropy": [0.7940926675138802], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Master Christopher Jones", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.42331706067212416, "std_of_first_answer": 0.42331706067212416, "avg_entropy_of_first_answer": 0.7940926675138802, "lex_sim": 1.0}
{"question": "the art and science of making objects from clay is called", "answer": ["ceramics #NewRelease #Review: Wicked Chain (Savage Trilogy #2) by L.W."], "scores": [[0.669921875, 1.0, 0.9990234375, 1.1920928955078125e-07, 0.00012242794036865234, 1.3709068298339844e-05, 0.072021484375, 0.006267547607421875, 0.00608062744140625, 0.054718017578125, 0.0016727447509765625, 0.1431884765625, 0.00827789306640625, 0.00238800048828125, 0.108154296875, 0.029449462890625, 0.0307769775390625, 0.76318359375, 0.042236328125, 0.95849609375, 1.0, 0.31396484375, 0.306884765625, 0.9912109375, 0.94580078125, 0.01397705078125, 0.461181640625, 0.006610870361328125, 0.9921875, 0.00438690185546875, 0.00951385498046875, 0.994140625]], "normalized_score": [0.035634614527225494], "tokens": [["\u2581cer", "am", "ics", "\u2581#", "New", "Release", "\u2581#", "Re", "view", ":", "\u2581W", "icked", "\u2581Ch", "ain", "\u2581(", "S", "av", "age", "\u2581Tr", "il", "ogy", "\u2581#", "2", ")", "\u2581by", "\u2581L", ".", "W", ".", "\u2581N", "iel", "sen"]], "entropy": [[0.8154296875, 0.0005087852478027344, 0.0070343017578125, 0.712890625, 5.00390625, 3.87109375, 1.6103515625, 5.21484375, 0.77294921875, 2.85546875, 3.9609375, 3.908203125, 4.23828125, 1.462890625, 1.2578125, 3.251953125, 4.1640625, 0.89794921875, 3.44921875, 0.2958984375, 0.00017142295837402344, 1.01953125, 1.0908203125, 0.0667724609375, 0.39599609375, 3.310546875, 2.376953125, 1.5654296875, 0.06707763671875, 3.6875, 3.3515625, 0.03741455078125]], "avg_entropy": [2.022545613348484], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ceramic art", "score_of_biggest_cluster": 0.035634614527225494, "score_of_first_answer": 0.035634614527225494, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.035634614527225494, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41497146620534175, "std_of_first_answer": 0.41497146620534175, "avg_entropy_of_first_answer": 2.022545613348484, "lex_sim": 1.0}
{"question": "what is the minimum size of a udp datagram", "answer": ["8 bytes #ThursdayThoughts: What Is The Purpose of Your Life?"], "scores": [[0.92431640625, 0.939453125, 0.7841796875, 2.384185791015625e-06, 9.006261825561523e-05, 0.00010895729064941406, 0.97900390625, 0.0310821533203125, 0.1087646484375, 0.289306640625, 0.001964569091796875, 0.05517578125, 0.0023326873779296875, 0.4287109375, 0.01666259765625, 0.99951171875, 0.18310546875, 0.053436279296875, 0.56103515625, 0.97509765625]], "normalized_score": [0.04059073328971863], "tokens": [["\u2581", "8", "\u2581bytes", "\u2581#", "Th", "urs", "day", "Th", "ought", "s", ":", "\u2581What", "\u2581Is", "\u2581The", "\u2581Pur", "pose", "\u2581of", "\u2581Your", "\u2581Life", "?"]], "entropy": [[0.5302734375, 0.31982421875, 0.79541015625, 1.3828125, 4.28515625, 0.345947265625, 0.16552734375, 2.458984375, 1.1962890625, 1.81640625, 1.7041015625, 3.83203125, 2.33984375, 1.3115234375, 0.88330078125, 0.00302886962890625, 0.544921875, 2.71484375, 2.1484375, 0.184814453125]], "avg_entropy": [1.4481739044189452], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "8 bytes", "score_of_biggest_cluster": 0.04059073328971863, "score_of_first_answer": 0.04059073328971863, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 2.384185791015625e-06, "avg_score": 0.04059073328971863, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4003764623077766, "std_of_first_answer": 0.4003764623077766, "avg_entropy_of_first_answer": 1.4481739044189452, "lex_sim": 1.0}
{"question": "what is the poorest county in the state of florida", "answer": ["Lowndes County"], "scores": [[0.006008148193359375, 0.994140625, 1.0, 0.9375]], "normalized_score": [0.2735520303249359], "tokens": [["\u2581Low", "nd", "es", "\u2581County"]], "entropy": [[3.083984375, 0.042755126953125, 0.0003685951232910156, 0.30029296875]], "avg_entropy": [0.856850266456604], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Union", "score_of_biggest_cluster": 0.2735520303249359, "score_of_first_answer": 0.2735520303249359, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.006008148193359375, "avg_score": 0.2735520303249359, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42125195888535394, "std_of_first_answer": 0.42125195888535394, "avg_entropy_of_first_answer": 0.856850266456604, "lex_sim": 1.0}
{"question": "who owns the majority of the us debt", "answer": ["The Federal Reserve and other foreign and domestic institutions Preface"], "scores": [[0.81787109375, 0.85302734375, 0.99951171875, 0.03204345703125, 0.3740234375, 0.9140625, 0.8876953125, 0.97216796875, 0.016632080078125, 0.0, 0.0025882720947265625]], "normalized_score": [0.0], "tokens": [["\u2581The", "\u2581Federal", "\u2581Reserve", "\u2581and", "\u2581other", "\u2581foreign", "\u2581and", "\u2581domestic", "\u2581institutions", "\u2581Pref", "ace"]], "entropy": [[0.9658203125, 0.6708984375, 0.005191802978515625, 0.80322265625, 1.5439453125, 0.4892578125, 0.46337890625, 0.1353759765625, 0.56396484375, 1.666015625, 0.09271240234375]], "avg_entropy": [0.6727076443758878], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "China", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.423553857286641, "std_of_first_answer": 0.423553857286641, "avg_entropy_of_first_answer": 0.6727076443758878, "lex_sim": 1.0}
{"question": "input that tells the computer which task to execute is", "answer": ["instruction Chapter 10: Love"], "scores": [[0.142578125, 0.0, 0.8984375, 0.28515625, 0.1881103515625, 0.066650390625, 1.9073486328125e-06]], "normalized_score": [0.0], "tokens": [["\u2581instruction", "\u2581Chapter", "\u2581", "1", "0", ":", "\u2581Love"]], "entropy": [[1.357421875, 1.0146484375, 0.7646484375, 1.8994140625, 2.65625, 2.044921875, 3.224609375]], "avg_entropy": [1.8517020089285714], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "source code", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.8984375, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2907158066666076, "std_of_first_answer": 0.2907158066666076, "avg_entropy_of_first_answer": 1.8517020089285714, "lex_sim": 1.0}
{"question": "who does tyler end up with in you get me", "answer": ["Uma"], "scores": [[7.18235969543457e-05, 0.380859375]], "normalized_score": [0.005230169277638197], "tokens": [["\u2581U", "ma"]], "entropy": [[3.59375, 2.701171875]], "avg_entropy": [3.1474609375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ali", "score_of_biggest_cluster": 0.005230169277638197, "score_of_first_answer": 0.005230169277638197, "max_score_of_first_answer": 0.380859375, "min_score_of_first_answer": 7.18235969543457e-05, "avg_score": 0.005230169277638197, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.19039377570152283, "std_of_first_answer": 0.19039377570152283, "avg_entropy_of_first_answer": 3.1474609375, "lex_sim": 1.0}
{"question": "the group that officially elects the president of the united states is called", "answer": ["the Electoral College #3 | RE: Silly Season Starts Early!"], "scores": [[0.576171875, 0.59326171875, 1.0, 0.99951171875, 2.384185791015625e-07, 0.01168060302734375, 0.0001035928726196289, 0.0006880760192871094, 0.00640106201171875, 7.808208465576172e-06, 0.08013916015625, 0.00024628639221191406, 0.012298583984375, 0.64013671875, 0.231689453125, 0.10589599609375, 8.392333984375e-05, 0.403076171875, 0.02288818359375, 0.98876953125, 0.44091796875, 0.09210205078125, 0.237548828125, 0.9970703125, 0.9580078125, 0.998046875, 0.353759765625, 0.19384765625, 0.96533203125, 0.461181640625, 0.303466796875, 0.99560546875, 0.1781005859375, 0.08929443359375, 0.4794921875]], "normalized_score": [0.0546158105134964], "tokens": [["\u2581the", "\u2581Elect", "oral", "\u2581College", "\u2581#", "3", "\u2581|", "\u2581RE", ":", "\u2581Sil", "ly", "\u2581Season", "\u2581St", "arts", "\u2581Early", "!", "\u2581Th", "u", "\u2581Sep", "\u2581", "1", "5", ",", "\u2581", "2", "0", "1", "1", "\u2581", "1", "0", ":", "3", "9", "\u2581pm"]], "entropy": [[1.2265625, 0.94189453125, 0.0016164779663085938, 0.00499725341796875, 0.8232421875, 5.9765625, 2.8828125, 4.07421875, 2.93359375, 5.14453125, 2.083984375, 4.1484375, 3.65625, 1.4189453125, 3.021484375, 3.2109375, 3.794921875, 2.3515625, 1.904296875, 0.07916259765625, 1.4677734375, 2.09375, 0.703125, 0.034393310546875, 0.252197265625, 0.0184326171875, 0.982421875, 0.5126953125, 0.2222900390625, 1.8154296875, 1.40234375, 0.0350341796875, 1.79296875, 2.3046875, 0.7646484375]], "avg_entropy": [1.8309201649257114], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the U.S. Electoral College", "score_of_biggest_cluster": 0.0546158105134964, "score_of_first_answer": 0.0546158105134964, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.0546158105134964, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.37756408916831075, "std_of_first_answer": 0.37756408916831075, "avg_entropy_of_first_answer": 1.8309201649257114, "lex_sim": 1.0}
{"question": "when did virgin australia (formerly virgin blue) commence flying in australia", "answer": ["August 31, 2000"], "scores": [[0.03570556640625, 0.99560546875, 0.91015625, 0.99267578125, 0.98388671875, 0.99560546875, 0.98486328125, 1.0, 0.9990234375, 0.9951171875]], "normalized_score": [0.7060906887054443], "tokens": [["\u2581August", "\u2581", "3", "1", ",", "\u2581", "2", "0", "0", "0"]], "entropy": [[0.56005859375, 0.0306396484375, 0.39599609375, 0.05267333984375, 0.10052490234375, 0.032745361328125, 0.07928466796875, 8.171796798706055e-05, 0.00650787353515625, 0.038177490234375]], "avg_entropy": [0.12966896891593932], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "November 1999", "score_of_biggest_cluster": 0.7060906887054443, "score_of_first_answer": 0.7060906887054443, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.03570556640625, "avg_score": 0.7060906887054443, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.28564255157828033, "std_of_first_answer": 0.28564255157828033, "avg_entropy_of_first_answer": 0.12966896891593932, "lex_sim": 1.0}
{"question": "who created the pieta and also painted the ceiling of the sistine chapel", "answer": ["Michelangelo Buonarroti #60DaysOfImpact: Meet Oyindamola Oyewumi, Founder of Easyliv"], "scores": [[0.9892578125, 1.0, 1.0, 0.61572265625, 1.0, 1.0, 0.9970703125, 1.0, 2.980232238769531e-07, 0.00426483154296875, 0.0875244140625, 7.12275505065918e-05, 0.438720703125, 0.0002224445343017578, 0.67578125, 0.01397705078125, 6.330013275146484e-05, 0.5078125, 0.00015437602996826172, 0.003875732421875, 0.0275421142578125, 0.98388671875, 0.99853515625, 0.0017642974853515625, 0.62353515625, 0.07525634765625, 0.4921875, 0.642578125, 0.04608154296875, 0.9970703125, 0.8720703125, 0.0289459228515625, 0.004459381103515625, 0.6279296875, 0.0634765625]], "normalized_score": [0.055665627121925354], "tokens": [["\u2581Michel", "ang", "elo", "\u2581Bu", "on", "ar", "ro", "ti", "\u2581#", "6", "0", "Days", "Of", "Imp", "act", ":", "\u2581Me", "et", "\u2581O", "y", "ind", "am", "ola", "\u2581O", "y", "ew", "umi", ",", "\u2581Found", "er", "\u2581of", "\u2581E", "as", "yl", "iv"]], "entropy": [[0.07244873046875, 0.0013132095336914062, 0.0002980232238769531, 0.99072265625, 0.00234222412109375, 0.0013780593872070312, 0.02264404296875, 8.511543273925781e-05, 0.80859375, 3.673828125, 3.025390625, 3.0078125, 2.958984375, 1.37109375, 1.828125, 1.400390625, 2.396484375, 2.501953125, 2.94140625, 4.15625, 3.07421875, 0.130859375, 0.014190673828125, 1.5087890625, 2.181640625, 1.2744140625, 1.6708984375, 1.9775390625, 2.43359375, 0.024810791015625, 0.6728515625, 5.3984375, 2.849609375, 1.3349609375, 3.021484375]], "avg_entropy": [1.6779955114637102], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Michelangelo", "score_of_biggest_cluster": 0.055665627121925354, "score_of_first_answer": 0.055665627121925354, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.055665627121925354, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4238518593791793, "std_of_first_answer": 0.4238518593791793, "avg_entropy_of_first_answer": 1.6779955114637102, "lex_sim": 1.0}
{"question": "who won the first season of america's got talent", "answer": ["Bianca Ryan"], "scores": [[0.333740234375, 0.99951171875, 0.99951171875]], "normalized_score": [0.693417489528656], "tokens": [["\u2581Bian", "ca", "\u2581Ryan"]], "entropy": [[1.95703125, 0.005466461181640625, 0.004070281982421875]], "avg_entropy": [0.6555226643880209], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Bianca Ryan", "score_of_biggest_cluster": 0.693417489528656, "score_of_first_answer": 0.693417489528656, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.333740234375, "avg_score": 0.693417489528656, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.3138476875481307, "std_of_first_answer": 0.3138476875481307, "avg_entropy_of_first_answer": 0.6555226643880209, "lex_sim": 1.0}
{"question": "where did aeneas go when he left carthage", "answer": ["He sailed to Italy."], "scores": [[0.07672119140625, 0.01171112060546875, 1.0, 0.9775390625, 0.96484375, 0.53759765625]], "normalized_score": [0.27739185094833374], "tokens": [["\u2581He", "\u2581sa", "iled", "\u2581to", "\u2581Italy", "."]], "entropy": [[1.83203125, 0.56884765625, 1.5914440155029297e-05, 0.139892578125, 0.2117919921875, 1.4775390625]], "avg_entropy": [0.7050197422504425], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Sicily", "score_of_biggest_cluster": 0.27739185094833374, "score_of_first_answer": 0.27739185094833374, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.01171112060546875, "avg_score": 0.27739185094833374, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4201743652353616, "std_of_first_answer": 0.4201743652353616, "avg_entropy_of_first_answer": 0.7050197422504425, "lex_sim": 1.0}
{"question": "when was the last time vancouver had an earthquake", "answer": ["The last significant earthquake in Vancouver was in 2018."], "scores": [[0.0771484375, 0.923828125, 0.453857421875, 0.99951171875, 1.0, 0.99951171875, 0.70751953125, 0.9970703125, 1.0, 0.93505859375, 0.285888671875, 0.978515625, 0.8916015625, 1.0, 0.97705078125, 0.0694580078125, 0.83740234375, 1.3113021850585938e-06, 0.008392333984375, 2.086162567138672e-05, 0.148193359375, 0.0011568069458007812, 0.0029392242431640625, 0.0130157470703125, 0.001880645751953125, 0.050537109375, 0.28271484375, 0.81494140625, 0.36669921875, 0.0005445480346679688, 0.61962890625, 0.473876953125, 0.998046875, 0.313720703125, 0.9169921875, 0.99755859375]], "normalized_score": [0.11528252810239792], "tokens": [["\u2581The", "\u2581last", "\u2581significant", "\u2581earth", "qu", "ake", "\u2581in", "\u2581V", "ancouver", "\u2581was", "\u2581in", "\u2581", "2", "0", "1", "8", ".", "\u2581#", "S", "ales", "force", ":", "\u2581How", "\u2581to", "\u2581Add", "\u2581an", "\u2581Image", "\u2581to", "\u2581a", "\u2581Form", "\u2581in", "\u2581Light", "ning", "\u2581Web", "\u2581Com", "ponents"]], "entropy": [[2.259765625, 0.383544921875, 1.2783203125, 0.0044097900390625, 0.0004875659942626953, 0.0054779052734375, 0.64599609375, 0.024139404296875, 0.0007028579711914062, 0.288818359375, 1.1396484375, 0.1326904296875, 0.3427734375, 0.0004725456237792969, 0.12054443359375, 0.5595703125, 0.60400390625, 1.267578125, 3.072265625, 0.30419921875, 3.802734375, 3.66015625, 4.9296875, 1.6201171875, 5.2890625, 3.271484375, 3.65625, 1.0693359375, 2.275390625, 2.734375, 1.880859375, 1.251953125, 0.0160064697265625, 1.9853515625, 0.366943359375, 0.01904296875]], "avg_entropy": [1.396226664384206], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1946", "score_of_biggest_cluster": 0.11528252810239792, "score_of_first_answer": 0.11528252810239792, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.3113021850585938e-06, "avg_score": 0.11528252810239792, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4146296602674307, "std_of_first_answer": 0.4146296602674307, "avg_entropy_of_first_answer": 1.396226664384206, "lex_sim": 1.0}
{"question": "who sang the song you got a friend in me", "answer": ["Randy Newman #TBT: NICKY ROMERO \u2013 SUPERHEROES (FEAT."], "scores": [[0.99609375, 1.0, 1.0, 1.0, 4.172325134277344e-07, 0.0005011558532714844, 0.95361328125, 0.0019702911376953125, 0.0004875659942626953, 0.0155487060546875, 0.356201171875, 0.00516510009765625, 0.14501953125, 0.1993408203125, 0.99951171875, 1.0, 0.0184173583984375, 0.042877197265625, 0.031494140625, 0.98193359375, 0.00304412841796875, 0.99951171875, 0.56982421875, 0.783203125, 0.0804443359375, 0.98974609375, 0.9208984375, 0.038177490234375, 0.0540771484375, 0.58642578125, 0.99853515625, 0.0007405281066894531, 0.66357421875, 0.9423828125, 0.92333984375]], "normalized_score": [0.08940199762582779], "tokens": [["\u2581R", "andy", "\u2581New", "man", "\u2581#", "TB", "T", ":", "\u2581N", "IC", "K", "Y", "\u2581R", "OM", "ER", "O", "\u2581\u2013", "\u2581S", "UP", "ER", "HER", "O", "ES", "\u2581(", "FE", "AT", ".", "\u2581N", "AN", "C", "Y", "\u2581AND", "RE", "WS", ")"]], "entropy": [[0.038726806640625, 0.00127410888671875, 0.0006084442138671875, 0.00025081634521484375, 0.78369140625, 4.92578125, 0.39013671875, 2.75390625, 4.27734375, 2.638671875, 1.53125, 3.59375, 2.876953125, 2.111328125, 0.0064544677734375, 0.00147247314453125, 3.513671875, 3.02734375, 3.953125, 0.134033203125, 2.220703125, 0.0072021484375, 1.2392578125, 1.32421875, 4.125, 0.075439453125, 0.409423828125, 2.59375, 3.46484375, 1.2109375, 0.01422119140625, 2.88671875, 1.859375, 0.326171875, 0.494873046875]], "avg_entropy": [1.6803402764456612], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Lyle Lovett", "score_of_biggest_cluster": 0.08940199762582779, "score_of_first_answer": 0.08940199762582779, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.08940199762582779, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44078671401274844, "std_of_first_answer": 0.44078671401274844, "avg_entropy_of_first_answer": 1.6803402764456612, "lex_sim": 1.0}
{"question": "when was the first commercial cell phone released", "answer": ["April 3, 1973 (Motorola DynaTAC) #16 A Different Kind of Bravery: An Interview with David Goggins"], "scores": [[0.08837890625, 0.99658203125, 0.99658203125, 0.98388671875, 0.9990234375, 1.0, 1.0, 0.99951171875, 1.0, 0.2724609375, 0.7734375, 0.99951171875, 1.0, 1.0, 0.99755859375, 0.99365234375, 0.98583984375, 0.3427734375, 8.344650268554688e-06, 0.07965087890625, 0.005306243896484375, 2.586841583251953e-05, 0.00022268295288085938, 0.03521728515625, 0.07501220703125, 0.88720703125, 0.003459930419921875, 0.06524658203125, 0.054718017578125, 0.006748199462890625, 0.299072265625, 0.89794921875, 0.96337890625, 0.0025768280029296875, 0.1998291015625, 0.9853515625, 1.0, 0.99951171875]], "normalized_score": [0.1395593136548996], "tokens": [["\u2581April", "\u2581", "3", ",", "\u2581", "1", "9", "7", "3", "\u2581(", "M", "ot", "or", "ola", "\u2581D", "yna", "TAC", ")", "\u2581#", "1", "6", "\u2581A", "\u2581D", "ifferent", "\u2581Kind", "\u2581of", "\u2581Bra", "very", ":", "\u2581An", "\u2581Inter", "view", "\u2581with", "\u2581David", "\u2581G", "og", "g", "ins"]], "entropy": [[0.69189453125, 0.0240936279296875, 0.0264434814453125, 0.0869140625, 0.006946563720703125, 0.0001780986785888672, -0.0, 0.004825592041015625, 0.0009975433349609375, 1.62890625, 0.92822265625, 0.006221771240234375, 0.00199127197265625, 0.0003695487976074219, 0.0185699462890625, 0.03973388671875, 0.0823974609375, 0.685546875, 0.67578125, 4.37109375, 2.705078125, 3.232421875, 2.61328125, 4.02734375, 1.953125, 0.3828125, 4.3671875, 1.345703125, 2.560546875, 3.84375, 3.0234375, 0.53564453125, 0.2037353515625, 5.390625, 4.40234375, 0.11187744140625, 0.00041961669921875, 0.003078460693359375]], "avg_entropy": [1.315356311045195], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1983", "score_of_biggest_cluster": 0.1395593136548996, "score_of_first_answer": 0.1395593136548996, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 8.344650268554688e-06, "avg_score": 0.1395593136548996, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4477747265232209, "std_of_first_answer": 0.4477747265232209, "avg_entropy_of_first_answer": 1.315356311045195, "lex_sim": 1.0}
{"question": "in which country bikram sambhat the official calender", "answer": ["Nepal"], "scores": [[0.72119140625, 1.0]], "normalized_score": [0.8492298722267151], "tokens": [["\u2581Nep", "al"]], "entropy": [[0.99560546875, 0.0005412101745605469]], "avg_entropy": [0.4980733394622803], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Nepal", "score_of_biggest_cluster": 0.8492298722267151, "score_of_first_answer": 0.8492298722267151, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.72119140625, "avg_score": 0.8492298722267151, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.139404296875, "std_of_first_answer": 0.139404296875, "avg_entropy_of_first_answer": 0.4980733394622803, "lex_sim": 1.0}
{"question": "who sang rip it up and start again", "answer": ["David Bowie and Trevor Bowie"], "scores": [[0.990234375, 0.6396484375, 1.0, 0.005641937255859375, 0.02435302734375, 0.99951171875, 0.998046875, 0.01763916015625]], "normalized_score": [0.18755759298801422], "tokens": [["\u2581David", "\u2581B", "owie", "\u2581and", "\u2581Tre", "vor", "\u2581B", "owie"]], "entropy": [[0.07916259765625, 2.1328125, 0.0010156631469726562, 0.88330078125, 4.89453125, 0.00555419921875, 0.01641845703125, 0.36083984375]], "avg_entropy": [1.0467044115066528], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Scottish post-punk band Orange Juice", "score_of_biggest_cluster": 0.18755759298801422, "score_of_first_answer": 0.18755759298801422, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.005641937255859375, "avg_score": 0.18755759298801422, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4546606042471797, "std_of_first_answer": 0.4546606042471797, "avg_entropy_of_first_answer": 1.0467044115066528, "lex_sim": 1.0}
{"question": "when did red bull come to the united states", "answer": ["1997 \\r\\nAfter graduating from college, Amelia worked at the United Nations in New York City, where she focused on environmental issues and international relations."], "scores": [[0.94873046875, 0.9990234375, 1.0, 1.0, 0.99560546875, 2.980232238769531e-07, 1.2040138244628906e-05, 0.64306640625, 0.998046875, 0.00037026405334472656, 2.9146671295166016e-05, 0.91455078125, 0.9345703125, 0.2354736328125, 0.26708984375, 7.748603820800781e-07, 0.01038360595703125, 0.0016956329345703125, 0.1131591796875, 0.1688232421875, 0.01275634765625, 0.611328125, 0.242431640625, 0.76220703125, 0.98974609375, 0.75927734375, 0.2218017578125, 0.52880859375, 0.92919921875, 0.09991455078125, 0.98681640625, 0.08868408203125, 0.5625, 0.4306640625, 0.10833740234375, 0.25634765625, 0.93310546875, 0.387939453125, 0.006755828857421875, 0.13916015625, 0.0006728172302246094, 0.425537109375, 0.9990234375, 0.98828125, 0.01308441162109375, 0.96142578125, 0.740234375, 0.9794921875]], "normalized_score": [0.08785755187273026], "tokens": [["\u2581", "1", "9", "9", "7", "\u2581\\", "r", "\\", "n", "After", "\u2581gradu", "ating", "\u2581from", "\u2581college", ",", "\u2581Am", "elia", "\u2581worked", "\u2581at", "\u2581the", "\u2581United", "\u2581Nations", "\u2581in", "\u2581New", "\u2581York", "\u2581City", ",", "\u2581where", "\u2581she", "\u2581focused", "\u2581on", "\u2581environmental", "\u2581issues", "\u2581and", "\u2581international", "\u2581relations", ".", "\u2581She", "\u2581is", "\u2581a", "\u2581regular", "\u2581contrib", "utor", "\u2581to", "\u2581H", "uff", "ington", "\u2581Post"]], "entropy": [[0.346923828125, 0.00634765625, 0.0002942085266113281, 0.0018291473388671875, 0.034271240234375, 0.86669921875, 0.271484375, 1.037109375, 0.018310546875, 2.951171875, 3.6015625, 0.296875, 0.440185546875, 3.017578125, 1.380859375, 0.484130859375, 4.05078125, 3.9765625, 1.587890625, 3.36328125, 5.73828125, 0.884765625, 2.83203125, 1.12890625, 0.06719970703125, 1.0634765625, 2.06640625, 2.5625, 0.361572265625, 3.814453125, 0.09515380859375, 3.642578125, 1.626953125, 1.5087890625, 3.708984375, 2.2734375, 0.33447265625, 2.34375, 2.470703125, 2.572265625, 4.53515625, 2.021484375, 0.01009368896484375, 0.0858154296875, 3.376953125, 0.2105712890625, 0.642578125, 0.1290283203125]], "avg_entropy": [1.6633855998516083], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1997", "score_of_biggest_cluster": 0.08785755187273026, "score_of_first_answer": 0.08785755187273026, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.08785755187273026, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4014167246612654, "std_of_first_answer": 0.4014167246612654, "avg_entropy_of_first_answer": 1.6633855998516083, "lex_sim": 1.0}
{"question": "when did houston go to the american league", "answer": ["April 10, 2013."], "scores": [[0.0007576942443847656, 0.99609375, 0.53662109375, 0.11151123046875, 0.90234375, 0.994140625, 0.97412109375, 1.0, 0.9990234375, 0.99951171875, 0.2275390625, 1.4901161193847656e-06, 0.006938934326171875, 0.279541015625, 0.00994873046875, 0.057647705078125, 0.00206756591796875, 0.0012683868408203125, 0.01134490966796875, 0.91943359375, 0.426025390625, 0.61669921875, 0.1112060546875, 0.99853515625, 0.97265625, 0.0004367828369140625, 0.00975799560546875, 0.5556640625, 0.998046875]], "normalized_score": [0.08157867193222046], "tokens": [["\u2581April", "\u2581", "1", "0", ",", "\u2581", "2", "0", "1", "3", ".", "\u2581#", "2", "0", "8", "3", ":", "\u2581J", "our", "ney", "\u2581to", "\u2581the", "\u2581Center", "\u2581of", "\u2581the", "\u2581C", "ere", "bell", "um"]], "entropy": [[0.61181640625, 0.0304718017578125, 1.2763671875, 1.123046875, 0.345703125, 0.037261962890625, 0.12066650390625, 2.205371856689453e-05, 0.00798797607421875, 0.004550933837890625, 1.033203125, 0.51416015625, 3.791015625, 2.84765625, 1.849609375, 3.4296875, 2.7109375, 4.6328125, 4.59765625, 0.344482421875, 2.861328125, 1.67578125, 3.419921875, 0.0143280029296875, 0.23486328125, 0.48046875, 1.8583984375, 0.837890625, 0.01702880859375]], "avg_entropy": [1.4037629201494415], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2013", "score_of_biggest_cluster": 0.08157867193222046, "score_of_first_answer": 0.08157867193222046, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.4901161193847656e-06, "avg_score": 0.08157867193222046, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4296089384382767, "std_of_first_answer": 0.4296089384382767, "avg_entropy_of_first_answer": 1.4037629201494415, "lex_sim": 1.0}
{"question": "when is beyblade burst super z coming out", "answer": ["I do not have information about the release date of Beyblade Burst Super Z."], "scores": [[0.5888671875, 0.167724609375, 0.99951171875, 0.939453125, 0.67529296875, 0.306396484375, 0.62548828125, 0.6962890625, 0.966796875, 0.93798828125, 0.4248046875, 0.9658203125, 1.0, 0.98876953125, 1.0, 0.9970703125, 0.9990234375, 0.73974609375]], "normalized_score": [0.7129587531089783], "tokens": [["\u2581I", "\u2581do", "\u2581not", "\u2581have", "\u2581information", "\u2581about", "\u2581the", "\u2581release", "\u2581date", "\u2581of", "\u2581Bey", "bla", "de", "\u2581Bur", "st", "\u2581Super", "\u2581Z", "."]], "entropy": [[1.9443359375, 1.169921875, 0.0031337738037109375, 0.2337646484375, 1.27734375, 0.82666015625, 1.4462890625, 1.0439453125, 0.1689453125, 0.292724609375, 1.7314453125, 0.156494140625, 6.490945816040039e-05, 0.0751953125, 0.000591278076171875, 0.028839111328125, 0.00748443603515625, 0.880859375]], "avg_entropy": [0.6271132396327125], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "April 2, 2018", "score_of_biggest_cluster": 0.7129587531089783, "score_of_first_answer": 0.7129587531089783, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.167724609375, "avg_score": 0.7129587531089783, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2591424526248019, "std_of_first_answer": 0.2591424526248019, "avg_entropy_of_first_answer": 0.6271132396327125, "lex_sim": 1.0}
{"question": "who won last year's ncaa women's basketball", "answer": ["The Baylor Lady Bears won the 2019 NCAA Women's Basketball Championship."], "scores": [[0.157470703125, 0.1416015625, 1.0, 0.27587890625, 1.0, 1.0, 0.1541748046875, 0.98828125, 0.912109375, 1.0, 1.0, 0.025177001953125, 0.92529296875, 0.99755859375, 0.98193359375, 0.99853515625, 1.0, 0.97265625, 0.5712890625, 0.978515625, 3.337860107421875e-06, 1.7881393432617188e-07, 1.8477439880371094e-06, 0.278564453125, 0.00731658935546875, 0.002010345458984375, 0.002468109130859375, 0.998046875, 0.0386962890625, 0.9990234375, 0.227294921875, 0.015655517578125, 0.0155181884765625, 0.0027523040771484375, 0.37255859375]], "normalized_score": [0.07394471019506454], "tokens": [["\u2581The", "\u2581Bay", "lor", "\u2581Lady", "\u2581B", "ears", "\u2581won", "\u2581the", "\u2581", "2", "0", "1", "9", "\u2581NCAA", "\u2581Women", "'", "s", "\u2581Basketball", "\u2581Championship", ".", "\u2581#", "Book", "Re", "view", "\u2581The", "\u2581Un", "sp", "oken", "\u2581Tr", "uth", "\u2581by", "\u2581Ang", "ie", "\u2581St", "anton"]], "entropy": [[0.9111328125, 1.2412109375, 0.0004096031188964844, 1.173828125, 0.002216339111328125, 0.00039958953857421875, 1.5537109375, 0.074951171875, 0.311279296875, 1.3053417205810547e-05, 7.31348991394043e-05, 0.1177978515625, 0.271484375, 0.0201873779296875, 0.10302734375, 0.013702392578125, 2.4497509002685547e-05, 0.1407470703125, 0.8037109375, 0.135009765625, 0.5361328125, 0.64208984375, 0.07427978515625, 1.412109375, 2.984375, 5.6015625, 2.30859375, 0.016357421875, 4.0390625, 0.01024627685546875, 3.421875, 4.328125, 0.09967041015625, 4.6015625, 3.150390625]], "avg_entropy": [1.1457528403827122], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "South Carolina", "score_of_biggest_cluster": 0.07394471019506454, "score_of_first_answer": 0.07394471019506454, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.07394471019506454, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44599860872235697, "std_of_first_answer": 0.44599860872235697, "avg_entropy_of_first_answer": 1.1457528403827122, "lex_sim": 1.0}
{"question": "name the process of fusion of an egg with a sperm", "answer": ["fertilization"], "scores": [[0.80810546875, 1.0, 0.99853515625]], "normalized_score": [0.9309874176979065], "tokens": [["\u2581fert", "il", "ization"]], "entropy": [[0.51123046875, 0.0009059906005859375, 0.011962890625]], "avg_entropy": [0.1746997833251953], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "fertilization", "score_of_biggest_cluster": 0.9309874176979065, "score_of_first_answer": 0.9309874176979065, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.80810546875, "avg_score": 0.9309874176979065, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.09011666683448419, "std_of_first_answer": 0.09011666683448419, "avg_entropy_of_first_answer": 0.1746997833251953, "lex_sim": 1.0}
{"question": "who is the longest serving manager in manchester united history", "answer": ["Sir Alex Ferguson   3."], "scores": [[0.96728515625, 0.99365234375, 1.0, 1.0, 1.0, 1.0, 5.960464477539063e-08, 0.00019860267639160156, 0.024932861328125, 0.11065673828125, 1.2516975402832031e-05, 0.293212890625, 0.0347900390625, 0.114501953125]], "normalized_score": [0.029911601915955544], "tokens": [["\u2581Sir", "\u2581Alex", "\u2581Fer", "g", "us", "on", "\u2581\u2581\u2581", "3", ".", "\u2581", "\u751f", "\u547d", "\u610f", "\u7fa9"]], "entropy": [[0.156005859375, 0.040557861328125, 0.0012102127075195312, 7.581710815429688e-05, 0.0009646415710449219, 9.328126907348633e-05, 1.419921875, 1.2548828125, 3.22265625, 4.09765625, 4.06640625, 3.556640625, 4.30078125, 2.716796875]], "avg_entropy": [1.7739035614899226], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Sir Alex Ferguson", "score_of_biggest_cluster": 0.029911601915955544, "score_of_first_answer": 0.029911601915955544, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.029911601915955544, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4614990925978843, "std_of_first_answer": 0.4614990925978843, "avg_entropy_of_first_answer": 1.7739035614899226, "lex_sim": 1.0}
{"question": "who wrote the song if i were a boy", "answer": ["Beyonc\u00e9"], "scores": [[0.143310546875, 0.68994140625, 0.99951171875]], "normalized_score": [0.46233779191970825], "tokens": [["\u2581Bey", "on", "c\u00e9"]], "entropy": [[3.166015625, 0.796875, 0.0037441253662109375]], "avg_entropy": [1.3222115834554036], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "BC Jean and Toby Gad", "score_of_biggest_cluster": 0.46233779191970825, "score_of_first_answer": 0.46233779191970825, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.143310546875, "avg_score": 0.46233779191970825, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.35398046423222, "std_of_first_answer": 0.35398046423222, "avg_entropy_of_first_answer": 1.3222115834554036, "lex_sim": 1.0}
{"question": "what time can you legally buy alcohol in michigan", "answer": ["10:00 AM #35 The Strangest Secret"], "scores": [[0.970703125, 0.962890625, 0.99169921875, 0.6494140625, 0.99951171875, 1.0, 0.53759765625, 1.7881393432617188e-07, 0.0204925537109375, 0.07080078125, 1.4662742614746094e-05, 9.506940841674805e-05, 0.01430511474609375, 0.9951171875, 0.12493896484375]], "normalized_score": [0.035854559391736984], "tokens": [["\u2581", "1", "0", ":", "0", "0", "\u2581AM", "\u2581#", "3", "5", "\u2581The", "\u2581Str", "ang", "est", "\u2581Secret"]], "entropy": [[0.2489013671875, 0.2037353515625, 0.058685302734375, 1.05078125, 0.0063934326171875, 0.0006322860717773438, 1.2509765625, 1.0751953125, 5.578125, 3.20703125, 2.517578125, 4.98046875, 2.19921875, 0.046966552734375, 3.763671875]], "avg_entropy": [1.745890744527181], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "7 a.m.", "score_of_biggest_cluster": 0.035854559391736984, "score_of_first_answer": 0.035854559391736984, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.035854559391736984, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44608142105704734, "std_of_first_answer": 0.44608142105704734, "avg_entropy_of_first_answer": 1.745890744527181, "lex_sim": 1.0}
{"question": "who becomes chief resident on grey's anatomy season 7", "answer": ["Arizona Robbins"], "scores": [[0.87939453125, 0.99853515625, 1.0, 1.0]], "normalized_score": [0.9680254459381104], "tokens": [["\u2581Arizona", "\u2581Rob", "b", "ins"]], "entropy": [[0.65478515625, 0.01416778564453125, 0.0006618499755859375, 4.0531158447265625e-06]], "avg_entropy": [0.16740471124649048], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "April Kepner M.D.", "score_of_biggest_cluster": 0.9680254459381104, "score_of_first_answer": 0.9680254459381104, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.87939453125, "avg_score": 0.9680254459381104, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.052015705707885065, "std_of_first_answer": 0.052015705707885065, "avg_entropy_of_first_answer": 0.16740471124649048, "lex_sim": 1.0}
{"question": "where was part of the classic surfing movie endless summer filmed", "answer": ["In the Pacific islands of Hawaii, Tahiti, and Africa."], "scores": [[0.059478759765625, 0.52197265625, 0.0791015625, 0.01099395751953125, 0.5732421875, 0.478759765625, 1.0, 0.82080078125, 0.8798828125, 0.9736328125, 0.99951171875, 0.92724609375, 0.99853515625, 0.06549072265625, 0.81689453125, 5.960464477539063e-08, 0.0038204193115234375, 0.057464599609375, 0.0246734619140625, 0.080810546875, 0.037628173828125, 0.0819091796875, 0.043792724609375, 0.0005831718444824219, 0.491455078125, 0.09771728515625, 0.227783203125, 0.2958984375, 0.1976318359375, 0.052734375, 0.98095703125, 0.019012451171875, 0.0284881591796875, 0.1650390625, 0.640625, 0.11151123046875, 0.98388671875, 0.155029296875, 0.10247802734375, 0.2978515625, 0.0020732879638671875, 0.270751953125, 0.0016632080078125, 0.0009374618530273438, 0.55517578125, 0.6279296875, 0.0221710205078125, 0.1324462890625]], "normalized_score": [0.08523354679346085], "tokens": [["\u2581In", "\u2581the", "\u2581Pacific", "\u2581islands", "\u2581of", "\u2581Hawai", "i", ",", "\u2581T", "ah", "iti", ",", "\u2581and", "\u2581Africa", ".", "\u2581#", "2", "4", "0", "2", "9", "0", "6", "\u2581-", "\u2581", "1", "2", "/", "0", "7", "/", "1", "5", "\u2581", "0", "8", ":", "1", "5", "\u2581PM", "\u2581Re", ":", "\u2581Do", "\u2581any", "\u2581of", "\u2581you", "\u2581use", "\u2581a"]], "entropy": [[3.3828125, 2.064453125, 3.236328125, 1.072265625, 1.2646484375, 1.744140625, 0.0001418590545654297, 0.5869140625, 0.64892578125, 0.122802734375, 0.004169464111328125, 0.263671875, 0.01568603515625, 1.408203125, 0.6044921875, 0.367431640625, 2.54296875, 3.35546875, 3.10546875, 2.7734375, 2.328125, 2.515625, 1.802734375, 1.5419921875, 2.8515625, 0.7392578125, 1.9609375, 2.14453125, 1.80078125, 2.078125, 0.116943359375, 0.1358642578125, 1.23046875, 1.83203125, 0.99072265625, 2.2578125, 0.09552001953125, 1.7939453125, 2.30859375, 0.9736328125, 2.056640625, 2.189453125, 5.11328125, 0.6640625, 3.208984375, 1.26171875, 2.556640625, 4.5546875]], "avg_entropy": [1.7014397134383519], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ghana", "score_of_biggest_cluster": 0.08523354679346085, "score_of_first_answer": 0.08523354679346085, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.08523354679346085, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.35891685053370076, "std_of_first_answer": 0.35891685053370076, "avg_entropy_of_first_answer": 1.7014397134383519, "lex_sim": 1.0}
{"question": "who become the ceo of it wipro company in 2016", "answer": ["Abhishek Khosla #194 \u2013 Kyle Hinton\u2019s Tips for Successful Real Estate Investing"], "scores": [[0.9970703125, 0.28271484375, 1.0, 1.0, 0.003326416015625, 0.12384033203125, 0.99951171875, 1.1920928955078125e-06, 0.004230499267578125, 0.048919677734375, 0.0589599609375, 4.1961669921875e-05, 0.0016317367553710938, 0.00041031837463378906, 0.0094757080078125, 0.0025386810302734375, 0.003368377685546875, 0.9921875, 0.007232666015625, 0.0178070068359375, 0.353271484375, 0.038299560546875, 0.0577392578125, 0.0124664306640625, 0.9892578125, 1.0, 0.7392578125, 0.99951171875, 0.943359375]], "normalized_score": [0.03711896389722824], "tokens": [["\u2581Ab", "his", "he", "k", "\u2581Kh", "os", "la", "\u2581#", "1", "9", "4", "\u2581\u2013", "\u2581K", "yle", "\u2581H", "inton", "\u2019", "s", "\u2581T", "ips", "\u2581for", "\u2581Success", "ful", "\u2581Real", "\u2581Est", "ate", "\u2581In", "vest", "ing"]], "entropy": [[0.0291290283203125, 0.94189453125, 0.0015459060668945312, 0.0018663406372070312, 3.287109375, 0.919921875, 0.00504302978515625, 1.1787109375, 2.12890625, 3.515625, 3.267578125, 2.673828125, 4.609375, 5.0625, 4.30859375, 4.45703125, 2.62109375, 0.07513427734375, 6.56640625, 2.345703125, 2.5625, 5.37890625, 3.228515625, 4.8359375, 0.0916748046875, 0.0005698204040527344, 1.37109375, 0.00543975830078125, 0.263427734375]], "avg_entropy": [2.26672624719554], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Abid Ali Neemuchwala", "score_of_biggest_cluster": 0.03711896389722824, "score_of_first_answer": 0.03711896389722824, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-06, "avg_score": 0.03711896389722824, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4427642934794527, "std_of_first_answer": 0.4427642934794527, "avg_entropy_of_first_answer": 2.26672624719554, "lex_sim": 1.0}
{"question": "this inventor co-created the film fred ott\u2019s sneeze", "answer": ["Thomas Edison"], "scores": [[0.440185546875, 0.986328125, 1.0]], "normalized_score": [0.7572147250175476], "tokens": [["\u2581Thomas", "\u2581Ed", "ison"]], "entropy": [[2.462890625, 0.07891845703125, 0.0004525184631347656]], "avg_entropy": [0.8474205334981283], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Fred Ott", "score_of_biggest_cluster": 0.7572147250175476, "score_of_first_answer": 0.7572147250175476, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.440185546875, "avg_score": 0.7572147250175476, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2607363201343202, "std_of_first_answer": 0.2607363201343202, "avg_entropy_of_first_answer": 0.8474205334981283, "lex_sim": 1.0}
{"question": "where was the killing of a sacred deer filmed", "answer": ["Greece"], "scores": [[0.94140625]], "normalized_score": [0.94140625], "tokens": [["\u2581Greece"]], "entropy": [[0.453369140625]], "avg_entropy": [0.453369140625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Cincinnati", "score_of_biggest_cluster": 0.94140625, "score_of_first_answer": 0.94140625, "max_score_of_first_answer": 0.94140625, "min_score_of_first_answer": 0.94140625, "avg_score": 0.94140625, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.0, "std_of_first_answer": 0.0, "avg_entropy_of_first_answer": 0.453369140625, "lex_sim": 1.0}
{"question": "when was the seat moved to the capitol", "answer": ["The United States government was founded in 1789, and the capital has been located in Washington, D.C. since 1800."], "scores": [[0.1773681640625, 0.278076171875, 0.9990234375, 0.0015840530395507812, 0.5751953125, 0.34765625, 0.93603515625, 0.99853515625, 1.0, 1.0, 0.951171875, 0.99462890625, 0.826171875, 0.94677734375, 0.9677734375, 0.8095703125, 0.37158203125, 0.63720703125, 0.29296875, 1.0, 0.99462890625, 0.91552734375, 0.99853515625, 1.0, 1.0, 0.99951171875, 0.9951171875, 0.9990234375, 1.0, 0.99560546875, 0.83203125, 1.0, 0.98193359375, 0.292236328125, 0.29296875, 0.99951171875, 0.99951171875, 0.99853515625, 0.372314453125, 0.06683349609375, 0.0556640625, 0.98828125, 0.99853515625, 0.76025390625, 0.97998046875, 0.99365234375, 0.99853515625, 0.99951171875, 0.77783203125]], "normalized_score": [0.6094319820404053], "tokens": [["\u2581The", "\u2581United", "\u2581States", "\u2581government", "\u2581was", "\u2581founded", "\u2581in", "\u2581", "1", "7", "8", "9", ",", "\u2581and", "\u2581the", "\u2581capital", "\u2581has", "\u2581been", "\u2581located", "\u2581in", "\u2581Washington", ",", "\u2581D", ".", "C", ".", "\u2581since", "\u2581", "1", "8", "0", "0", ".", "\u2581The", "\u2581U", ".", "S", ".", "\u2581Congress", "\u2581has", "\u2581always", "\u2581met", "\u2581in", "\u2581Washington", ",", "\u2581D", ".", "C", "."]], "entropy": [[1.5068359375, 1.962890625, 0.006969451904296875, 0.8232421875, 1.373046875, 1.3564453125, 0.24853515625, 0.0114898681640625, 6.973743438720703e-06, 4.26173210144043e-05, 0.1966552734375, 0.03619384765625, 0.5361328125, 0.271484375, 0.214599609375, 0.89013671875, 0.982421875, 0.9140625, 0.63916015625, 0.0012121200561523438, 0.042205810546875, 0.29443359375, 0.0126495361328125, 0.0020771026611328125, 0.0011415481567382812, 0.00450897216796875, 0.038055419921875, 0.009918212890625, 3.993511199951172e-06, 0.0295257568359375, 0.462158203125, 0.0005488395690917969, 0.10345458984375, 1.951171875, 2.353515625, 0.004425048828125, 0.0037822723388671875, 0.01264190673828125, 0.80322265625, 2.673828125, 2.017578125, 0.08453369140625, 0.0125579833984375, 0.55810546875, 0.11419677734375, 0.05316162109375, 0.01000213623046875, 0.003993988037109375, 0.5478515625]], "avg_entropy": [0.4934043823456278], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "November 17, 1800", "score_of_biggest_cluster": 0.6094319820404053, "score_of_first_answer": 0.6094319820404053, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0015840530395507812, "avg_score": 0.6094319820404053, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.3165628560225536, "std_of_first_answer": 0.3165628560225536, "avg_entropy_of_first_answer": 0.4934043823456278, "lex_sim": 1.0}
{"question": "the road that connects the tombs is called", "answer": ["The Road of the Dead #AtoZChallenge: J is for Judge \u2013 The Power of Perspective"], "scores": [[0.25146484375, 0.38720703125, 0.9111328125, 0.8017578125, 0.98681640625, 9.5367431640625e-07, 0.007061004638671875, 0.00278472900390625, 0.986328125, 0.96630859375, 0.97021484375, 1.4185905456542969e-05, 0.0017604827880859375, 0.302734375, 0.998046875, 0.002391815185546875, 0.0014257431030273438, 0.09991455078125, 0.0019741058349609375, 0.96240234375, 0.1668701171875, 0.900390625]], "normalized_score": [0.04306605085730553], "tokens": [["\u2581The", "\u2581Road", "\u2581of", "\u2581the", "\u2581Dead", "\u2581#", "A", "to", "Z", "Ch", "allenge", ":", "\u2581J", "\u2581is", "\u2581for", "\u2581Judge", "\u2581\u2013", "\u2581The", "\u2581Power", "\u2581of", "\u2581Pers", "pective"]], "entropy": [[2.72265625, 3.029296875, 0.324951171875, 0.98876953125, 0.109619140625, 0.74560546875, 4.28515625, 2.689453125, 0.1170654296875, 0.218505859375, 0.1512451171875, 0.3037109375, 2.287109375, 2.119140625, 0.0199432373046875, 2.943359375, 3.037109375, 4.765625, 4.25, 0.2205810546875, 3.306640625, 0.344482421875]], "avg_entropy": [1.771819374778054], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "\"Spirit Way\"", "score_of_biggest_cluster": 0.04306605085730553, "score_of_first_answer": 0.04306605085730553, "max_score_of_first_answer": 0.998046875, "min_score_of_first_answer": 9.5367431640625e-07, "avg_score": 0.04306605085730553, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43094342505604216, "std_of_first_answer": 0.43094342505604216, "avg_entropy_of_first_answer": 1.771819374778054, "lex_sim": 1.0}
{"question": "time of the state of the nation address", "answer": ["The time of the State of the Nation address varies from year to year and country to country, but it is typically a national event that is held annually or bi-annually and is delivered by the head of state or government."], "scores": [[0.267822265625, 0.662109375, 0.9560546875, 0.99755859375, 0.677734375, 1.0, 0.99951171875, 0.9990234375, 0.472412109375, 0.5771484375, 1.0, 0.2529296875, 0.89453125, 0.9990234375, 0.9990234375, 0.330078125, 0.61962890625, 0.99951171875, 0.99658203125, 0.204833984375, 0.2181396484375, 0.92236328125, 0.923828125, 0.66455078125, 0.399658203125, 0.103515625, 0.6328125, 0.74658203125, 0.63623046875, 0.1729736328125, 0.5888671875, 1.0, 0.2469482421875, 0.08203125, 0.99072265625, 0.99951171875, 1.0, 0.0894775390625, 0.935546875, 0.51318359375, 0.9990234375, 0.98291015625, 0.9228515625, 0.99951171875, 0.9755859375, 0.8271484375, 0.98828125, 0.923828125, 0.086669921875, 0.82275390625]], "normalized_score": [0.5827922821044922], "tokens": [["\u2581The", "\u2581time", "\u2581of", "\u2581the", "\u2581State", "\u2581of", "\u2581the", "\u2581Nation", "\u2581address", "\u2581var", "ies", "\u2581from", "\u2581year", "\u2581to", "\u2581year", "\u2581and", "\u2581country", "\u2581to", "\u2581country", ",", "\u2581but", "\u2581it", "\u2581is", "\u2581typically", "\u2581a", "\u2581national", "\u2581event", "\u2581that", "\u2581is", "\u2581held", "\u2581ann", "ually", "\u2581or", "\u2581bi", "-", "ann", "ually", "\u2581and", "\u2581is", "\u2581delivered", "\u2581by", "\u2581the", "\u2581head", "\u2581of", "\u2581state", "\u2581or", "\u2581government", ".", "\u2581For", "\u2581example"]], "entropy": [[2.61328125, 1.3515625, 0.2088623046875, 0.019439697265625, 0.6962890625, 0.001499176025390625, 0.00323486328125, 0.007320404052734375, 0.6982421875, 1.27734375, 9.882450103759766e-05, 1.744140625, 0.3544921875, 0.0099639892578125, 0.0063934326171875, 1.2890625, 1.2109375, 0.003665924072265625, 0.02313232421875, 0.57421875, 1.3984375, 0.39404296875, 0.354248046875, 0.7236328125, 1.455078125, 2.583984375, 1.0615234375, 1.1552734375, 0.794921875, 1.6162109375, 1.341796875, 0.00013589859008789062, 1.5576171875, 1.193359375, 0.0582275390625, 0.00528717041015625, 0.002368927001953125, 1.177734375, 0.4150390625, 1.7802734375, 0.009735107421875, 0.09027099609375, 0.326904296875, 0.0023651123046875, 0.1387939453125, 0.6015625, 0.07647705078125, 0.3662109375, 2.349609375, 0.77099609375]], "avg_entropy": [0.7179060006141662], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "after 9pm\u00a0ET", "score_of_biggest_cluster": 0.5827922821044922, "score_of_first_answer": 0.5827922821044922, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.08203125, "avg_score": 0.5827922821044922, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.32123004966416724, "std_of_first_answer": 0.32123004966416724, "avg_entropy_of_first_answer": 0.7179060006141662, "lex_sim": 1.0}
{"question": "who sings the christmas song all i want for christmas is you", "answer": ["Mariah Carey"], "scores": [[0.99755859375, 1.0, 0.99951171875, 1.0]], "normalized_score": [0.999267041683197], "tokens": [["\u2581Maria", "h", "\u2581Care", "y"]], "entropy": [[0.0251007080078125, 5.0067901611328125e-06, 0.0027103424072265625, 4.26173210144043e-05]], "avg_entropy": [0.00696466863155365], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Mariah Carey", "score_of_biggest_cluster": 0.999267041683197, "score_of_first_answer": 0.999267041683197, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.99755859375, "avg_score": 0.999267041683197, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.0010066175843793117, "std_of_first_answer": 0.0010066175843793117, "avg_entropy_of_first_answer": 0.00696466863155365, "lex_sim": 1.0}
{"question": "anastomosis between the epididymis and the vas deferens", "answer": ["Efferent duct #191285 - 11/28/08 09:27 PM Re: Do you believe in reincarnation?"], "scores": [[0.0191802978515625, 0.2459716796875, 0.99951171875, 0.99951171875, 0.9638671875, 1.0, 1.7285346984863281e-06, 0.5791015625, 2.6881694793701172e-05, 0.0016956329345703125, 0.09881591796875, 0.08062744140625, 0.0921630859375, 0.001125335693359375, 0.0484619140625, 0.2978515625, 0.06634521484375, 0.2174072265625, 0.318603515625, 0.0826416015625, 0.97802734375, 0.0093841552734375, 0.130615234375, 0.285400390625, 0.07330322265625, 0.1605224609375, 0.97998046875, 0.190673828125, 0.09686279296875, 0.09051513671875, 0.0012369155883789062, 0.58984375, 0.000591278076171875, 0.6455078125, 0.0194244384765625, 0.70703125, 0.0396728515625, 0.98095703125, 0.99951171875, 0.99560546875, 0.74658203125, 0.00984954833984375, 0.91552734375, 0.00859832763671875, 0.96044921875, 0.89501953125, 0.145751953125, 0.99365234375]], "normalized_score": [0.09007146209478378], "tokens": [["\u2581E", "f", "fer", "ent", "\u2581du", "ct", "\u2581#", "1", "9", "1", "2", "8", "5", "\u2581-", "\u2581", "1", "1", "/", "2", "8", "/", "0", "8", "\u2581", "0", "9", ":", "2", "7", "\u2581PM", "\u2581Re", ":", "\u2581Do", "\u2581you", "\u2581believe", "\u2581in", "\u2581re", "inc", "arn", "ation", "?", "\u2581Why", "\u2581or", "\u2581Why", "\u2581not", "?", "\u2581[", "Re"]], "entropy": [[3.2265625, 0.62890625, 0.005695343017578125, 0.0031566619873046875, 0.27880859375, 0.0016307830810546875, 1.4912109375, 1.431640625, 2.25390625, 3.0, 2.623046875, 2.763671875, 2.55078125, 2.787109375, 3.744140625, 2.271484375, 3.369140625, 3.388671875, 1.6123046875, 2.39453125, 0.1639404296875, 0.482177734375, 2.279296875, 2.978515625, 1.9658203125, 2.330078125, 0.154541015625, 1.791015625, 2.3046875, 2.982421875, 3.201171875, 2.005859375, 3.828125, 2.263671875, 2.59375, 1.6904296875, 4.23046875, 0.1563720703125, 0.006458282470703125, 0.0389404296875, 1.453125, 3.859375, 0.432373046875, 0.1383056640625, 0.24560546875, 0.67822265625, 3.6484375, 0.053253173828125]], "avg_entropy": [1.8288091818491619], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Vasoepididymostomy", "score_of_biggest_cluster": 0.09007146209478378, "score_of_first_answer": 0.09007146209478378, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7285346984863281e-06, "avg_score": 0.09007146209478378, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4008368133245411, "std_of_first_answer": 0.4008368133245411, "avg_entropy_of_first_answer": 1.8288091818491619, "lex_sim": 1.0}
{"question": "mention the chemical change that proinsulin undergo to be able to act as mature insulin", "answer": ["Proinsulin undergoes a cleavage to produce insulin and C-peptide."], "scores": [[0.12353515625, 0.9990234375, 1.0, 1.0, 0.35009765625, 1.0, 0.958984375, 0.8798828125, 0.517578125, 1.0, 1.0, 0.255126953125, 0.607421875, 0.2247314453125, 1.0, 1.0, 0.9599609375, 0.94873046875, 0.99560546875, 0.99951171875, 1.0, 1.0, 0.83349609375, 0.1331787109375, 0.359619140625, 1.0, 1.0, 0.4072265625, 0.78515625, 0.9892578125, 1.0, 0.99951171875, 0.83203125, 0.94482421875, 1.0, 0.99951171875, 0.52392578125, 0.00026297569274902344, 0.015655517578125, 0.2176513671875, 0.300537109375, 0.151123046875, 0.054779052734375, 0.9990234375, 0.99951171875, 0.1929931640625, 0.99853515625, 1.0, 0.0232086181640625, 0.60546875]], "normalized_score": [0.46282345056533813], "tokens": [["\u2581Pro", "ins", "ul", "in", "\u2581under", "go", "es", "\u2581a", "\u2581cle", "av", "age", "\u2581to", "\u2581produce", "\u2581ins", "ul", "in", "\u2581and", "\u2581C", "-", "pe", "pt", "ide", ".", "\u2581The", "\u2581cle", "av", "age", "\u2581is", "\u2581catal", "yz", "ed", "\u2581by", "\u2581the", "\u2581en", "zym", "e", "\u2581pro", "\u2581converted", "\u2581from", "\u2581the", "\u2581pro", "-", "ins", "ul", "in", "\u2581mole", "c", "ule", "\u2581by", "\u2581the"]], "entropy": [[1.669921875, 0.0095672607421875, 0.00011146068572998047, 0.000133514404296875, 1.7451171875, 0.000514984130859375, 0.231201171875, 0.46337890625, 1.1787109375, 0.00013637542724609375, 0.00023818016052246094, 2.0390625, 1.34375, 1.7412109375, 0.00010484457015991211, 0.00019049644470214844, 0.2186279296875, 0.343994140625, 0.0282440185546875, 0.003864288330078125, 6.121397018432617e-05, 0.0004749298095703125, 0.5888671875, 1.1650390625, 2.140625, 0.000583648681640625, 0.0012798309326171875, 0.9853515625, 0.8935546875, 0.060455322265625, 0.00035881996154785156, 0.006603240966796875, 0.60546875, 0.336181640625, 0.0009870529174804688, 0.0029850006103515625, 1.8388671875, 1.3681640625, 3.33203125, 1.5927734375, 1.3505859375, 2.072265625, 2.521484375, 0.00946807861328125, 0.003936767578125, 1.849609375, 0.0118865966796875, 0.00020170211791992188, 1.548828125, 1.44140625]], "avg_entropy": [0.7349693346023559], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "post translational modification", "score_of_biggest_cluster": 0.46282345056533813, "score_of_first_answer": 0.46282345056533813, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.00026297569274902344, "avg_score": 0.46282345056533813, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3648153487912762, "std_of_first_answer": 0.3648153487912762, "avg_entropy_of_first_answer": 0.7349693346023559, "lex_sim": 1.0}
{"question": "locations for the film an englishman who went up a hill", "answer": ["Kent and London"], "scores": [[0.130859375, 0.310546875, 0.077880859375]], "normalized_score": [0.1468207985162735], "tokens": [["\u2581Kent", "\u2581and", "\u2581London"]], "entropy": [[3.783203125, 1.2509765625, 3.486328125]], "avg_entropy": [2.8401692708333335], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Llanrhaeadr-ym-Mochnant", "score_of_biggest_cluster": 0.1468207985162735, "score_of_first_answer": 0.1468207985162735, "max_score_of_first_answer": 0.310546875, "min_score_of_first_answer": 0.077880859375, "avg_score": 0.1468207985162735, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.09957007337152124, "std_of_first_answer": 0.09957007337152124, "avg_entropy_of_first_answer": 2.8401692708333335, "lex_sim": 1.0}
{"question": "when does season 7 game of thrones dvd release", "answer": ["Unknown Tags: 5 Seconds of Summer"], "scores": [[0.0081329345703125, 0.9599609375, 0.0, 0.5849609375, 0.010711669921875, 0.03155517578125, 5.543231964111328e-06, 0.65771484375, 0.724609375, 0.98828125]], "normalized_score": [0.0], "tokens": [["\u2581Un", "known", "\u2581Tags", ":", "\u2581", "5", "\u2581Second", "s", "\u2581of", "\u2581Summer"]], "entropy": [[2.869140625, 0.20654296875, 1.8134765625, 2.08984375, 4.11328125, 2.427734375, 3.939453125, 0.82470703125, 0.62353515625, 0.07379150390625]], "avg_entropy": [1.898150634765625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "December 12, 2017", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.98828125, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4032822972288142, "std_of_first_answer": 0.4032822972288142, "avg_entropy_of_first_answer": 1.898150634765625, "lex_sim": 1.0}
{"question": "where is the capital city of alabama located", "answer": ["Montgomery"], "scores": [[0.98486328125, 0.9990234375, 1.0]], "normalized_score": [0.994604766368866], "tokens": [["\u2581Mont", "gom", "ery"]], "entropy": [[0.1004638671875, 0.007114410400390625, 0.001995086669921875]], "avg_entropy": [0.036524454752604164], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Montgomery", "score_of_biggest_cluster": 0.994604766368866, "score_of_first_answer": 0.994604766368866, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.98486328125, "avg_score": 0.994604766368866, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.006916838984660084, "std_of_first_answer": 0.006916838984660084, "avg_entropy_of_first_answer": 0.036524454752604164, "lex_sim": 1.0}
{"question": "who is the writer of 50 shades of grey", "answer": ["E.L. James #FollowFriday: @SciGirls Club \u2013 a Twitter Account Promoting STEM Education for Girls"], "scores": [[0.483154296875, 0.89013671875, 0.83984375, 0.9775390625, 0.9990234375, 0.0, 0.006710052490234375, 0.0028629302978515625, 0.01043701171875, 0.984375, 1.0, 0.01149749755859375, 0.2232666015625, 0.0129241943359375, 0.1168212890625, 0.0022869110107421875, 0.0309295654296875, 0.0009703636169433594, 0.004138946533203125, 0.047515869140625, 0.1478271484375, 0.00015032291412353516, 0.0135040283203125, 0.99853515625, 0.40283203125, 0.99658203125, 0.99755859375, 0.8037109375, 0.9404296875, 0.95751953125]], "normalized_score": [0.0], "tokens": [["\u2581E", ".", "L", ".", "\u2581James", "\u2581#", "F", "ollow", "F", "rid", "ay", ":", "\u2581@", "S", "ci", "G", "irls", "\u2581Club", "\u2581\u2013", "\u2581a", "\u2581Twitter", "\u2581Account", "\u2581Prom", "oting", "\u2581S", "TE", "M", "\u2581Education", "\u2581for", "\u2581Girls"]], "entropy": [[0.71240234375, 0.3662109375, 0.44091796875, 0.1116943359375, 0.00850677490234375, 0.603515625, 4.140625, 1.140625, 3.1953125, 0.135986328125, 0.0001779794692993164, 1.7822265625, 3.76953125, 3.7421875, 2.142578125, 2.75, 1.291015625, 4.49609375, 2.435546875, 2.57421875, 1.6689453125, 0.351318359375, 2.220703125, 0.0119781494140625, 1.595703125, 0.0286407470703125, 0.0185546875, 0.78515625, 0.319091796875, 0.2493896484375]], "avg_entropy": [1.4362951477368673], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Erika Mitchell Leonard", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.439248195914724, "std_of_first_answer": 0.439248195914724, "avg_entropy_of_first_answer": 1.4362951477368673, "lex_sim": 1.0}
{"question": "who sang a whiter shade of pale first", "answer": ["Procol Harum #TGIF - 5 Awesome Things That Happened this Week"], "scores": [[0.9970703125, 0.9921875, 0.99951171875, 1.0, 1.3113021850585938e-06, 0.0013866424560546875, 0.0002505779266357422, 0.3623046875, 0.0006036758422851562, 0.11846923828125, 0.09478759765625, 2.956390380859375e-05, 0.99462890625, 0.0284576416015625, 0.07647705078125, 0.9267578125, 0.966796875, 0.9873046875, 0.002986907958984375, 0.88818359375]], "normalized_score": [0.04083468019962311], "tokens": [["\u2581Pro", "col", "\u2581Har", "um", "\u2581#", "T", "G", "IF", "\u2581-", "\u2581", "5", "\u2581Aw", "esome", "\u2581Things", "\u2581That", "\u2581H", "app", "ened", "\u2581this", "\u2581Week"]], "entropy": [[0.0263824462890625, 0.04608154296875, 0.0028972625732421875, 0.0005311965942382812, 0.8876953125, 4.3515625, 0.89990234375, 3.01171875, 1.8818359375, 5.07421875, 2.234375, 3.515625, 0.035552978515625, 3.103515625, 2.44921875, 0.4677734375, 0.1627197265625, 0.0806884765625, 0.496337890625, 0.408935546875]], "avg_entropy": [1.456878423690796], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Procol Harum", "score_of_biggest_cluster": 0.04083468019962311, "score_of_first_answer": 0.04083468019962311, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.3113021850585938e-06, "avg_score": 0.04083468019962311, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.45995049606306115, "std_of_first_answer": 0.45995049606306115, "avg_entropy_of_first_answer": 1.456878423690796, "lex_sim": 1.0}
{"question": "when was the last time tug-of-war was an official olympic sport", "answer": ["1920"], "scores": [[0.9150390625, 0.9990234375, 0.99951171875, 0.99755859375, 0.9990234375]], "normalized_score": [0.9814393520355225], "tokens": [["\u2581", "1", "9", "2", "0"]], "entropy": [[0.58349609375, 0.006378173828125, 0.0057373046875, 0.0169219970703125, 0.00826263427734375]], "avg_entropy": [0.12415924072265624], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1920", "score_of_biggest_cluster": 0.9814393520355225, "score_of_first_answer": 0.9814393520355225, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.9150390625, "avg_score": 0.9814393520355225, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.03350249915978168, "std_of_first_answer": 0.03350249915978168, "avg_entropy_of_first_answer": 0.12415924072265624, "lex_sim": 1.0}
{"question": "who sings the wire season 5 theme song", "answer": ["The Wire does not have a traditional theme song."], "scores": [[0.1673583984375, 0.1279296875, 0.99560546875, 0.58837890625, 1.0, 1.0, 0.9912109375, 0.006130218505859375, 0.9677734375, 1.0, 0.5029296875, 0.2099609375, 0.35888671875, 0.369873046875, 0.998046875, 0.599609375, 0.038116455078125, 0.455810546875, 1.0, 0.515625, 0.1751708984375, 0.91943359375, 0.329345703125, 0.2763671875, 1.0, 0.9755859375, 0.291015625, 0.5400390625, 0.4912109375, 0.740234375, 0.73095703125, 0.9990234375, 0.7294921875, 0.87353515625, 0.99560546875, 0.9970703125, 0.9990234375, 0.9970703125, 0.9970703125, 0.99951171875, 0.9990234375, 1.0, 0.83349609375, 0.8515625, 0.012115478515625, 0.12298583984375, 0.7724609375, 1.0, 0.99169921875, 0.99951171875]], "normalized_score": [0.5064162611961365], "tokens": [["\u2581The", "\u2581W", "ire", "\u2581does", "\u2581not", "\u2581have", "\u2581a", "\u2581traditional", "\u2581theme", "\u2581song", ".", "\u2581It", "\u2581is", "\u2581known", "\u2581for", "\u2581its", "\u2581opening", "\u2581cred", "its", "\u2581sequence", "\u2581that", "\u2581features", "\u2581a", "\u2581mont", "age", "\u2581of", "\u2581images", "\u2581from", "\u2581the", "\u2581show", "\u2581set", "\u2581to", "\u2581the", "\u2581song", "\u2581\"", "W", "ay", "\u2581Down", "\u2581in", "\u2581the", "\u2581H", "ole", "\"", "\u2581by", "\u2581singer", "\u2581and", "\u2581song", "writer", "\u2581Tom", "\u2581Wa"]], "entropy": [[4.2421875, 3.578125, 0.045166015625, 1.7685546875, 0.0015277862548828125, 0.002132415771484375, 0.054168701171875, 1.109375, 0.1898193359375, 0.00045990943908691406, 1.3427734375, 1.580078125, 1.7080078125, 1.94140625, 0.01715087890625, 0.75927734375, 0.435546875, 1.453125, 6.258487701416016e-06, 1.6103515625, 1.646484375, 0.43994140625, 2.203125, 2.6875, 0.00013911724090576172, 0.1259765625, 1.3642578125, 1.3740234375, 0.71044921875, 0.86572265625, 1.0166015625, 0.00646209716796875, 0.95751953125, 0.7001953125, 0.03826904296875, 0.023773193359375, 0.00878143310546875, 0.0255889892578125, 0.02117919921875, 0.005748748779296875, 0.0083770751953125, 0.00017023086547851562, 0.482177734375, 0.55029296875, 1.25, 0.9140625, 0.73046875, 0.0010013580322265625, 0.08172607421875, 0.007587432861328125]], "avg_entropy": [0.8017368543148041], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Steve Earle", "score_of_biggest_cluster": 0.5064162611961365, "score_of_first_answer": 0.5064162611961365, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.006130218505859375, "avg_score": 0.5064162611961365, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3415497181618193, "std_of_first_answer": 0.3415497181618193, "avg_entropy_of_first_answer": 0.8017368543148041, "lex_sim": 1.0}
{"question": "when does the little couples new season start", "answer": ["There is no information available on a new season of \"Little Couple.\""], "scores": [[0.0167388916015625, 0.89501953125, 0.95458984375, 0.53857421875, 0.4619140625, 0.490478515625, 0.806640625, 0.96826171875, 0.99951171875, 0.92041015625, 0.401611328125, 0.9140625, 1.0, 0.9990234375, 0.986328125, 0.1798095703125, 1.1920928955078125e-07, 0.003177642822265625, 3.5703182220458984e-05, 0.0006117820739746094, 0.93798828125, 0.94140625, 0.04815673828125, 0.0233001708984375, 0.0001671314239501953, 0.638671875, 0.951171875, 0.0033969879150390625, 0.401123046875, 0.9951171875, 0.99658203125, 1.0, 0.0038394927978515625, 0.99951171875, 0.56396484375, 0.402587890625, 0.63134765625]], "normalized_score": [0.11831842362880707], "tokens": [["\u2581There", "\u2581is", "\u2581no", "\u2581information", "\u2581available", "\u2581on", "\u2581a", "\u2581new", "\u2581season", "\u2581of", "\u2581\"", "L", "ittle", "\u2581Cou", "ple", ".\"", "\u2581#", "The", "First", "1", "0", "0", "Days", ":", "\u2581Ch", "alleng", "es", "\u2581And", "\u2581O", "pport", "un", "ities", "\u2581F", "acing", "\u2581The", "\u2581New", "\u2581Administration"]], "entropy": [[2.134765625, 0.5009765625, 0.210693359375, 1.78515625, 1.279296875, 1.3037109375, 0.7578125, 0.1812744140625, 0.006107330322265625, 0.3271484375, 0.94873046875, 0.321533203125, 0.0019989013671875, 0.0088653564453125, 0.0726318359375, 0.7861328125, 1.0908203125, 5.3203125, 3.140625, 2.005859375, 0.38525390625, 0.489013671875, 1.07421875, 2.826171875, 4.32421875, 1.3935546875, 0.2144775390625, 2.892578125, 2.765625, 0.03277587890625, 0.027191162109375, 0.0018987655639648438, 2.52734375, 0.0066375732421875, 1.8154296875, 2.412109375, 1.546875]], "avg_entropy": [1.2681033933484875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "September 19, 2017", "score_of_biggest_cluster": 0.11831842362880707, "score_of_first_answer": 0.11831842362880707, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.11831842362880707, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40236833327816324, "std_of_first_answer": 0.40236833327816324, "avg_entropy_of_first_answer": 1.2681033933484875, "lex_sim": 1.0}
{"question": "when does the new adventure time come out", "answer": ["September 2, 2018"], "scores": [[0.0168609619140625, 0.97119140625, 0.806640625, 0.037841796875, 0.998046875, 0.99951171875, 1.0, 0.970703125, 0.9814453125]], "normalized_score": [0.4273146986961365], "tokens": [["\u2581September", "\u2581", "2", ",", "\u2581", "2", "0", "1", "8"]], "entropy": [[2.447265625, 0.1600341796875, 0.64208984375, 0.880859375, 0.016876220703125, 0.0058135986328125, 6.711483001708984e-05, 0.1368408203125, 0.116455078125]], "avg_entropy": [0.4895890951156616], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "April 21, 2017", "score_of_biggest_cluster": 0.4273146986961365, "score_of_first_answer": 0.4273146986961365, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0168609619140625, "avg_score": 0.4273146986961365, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3923208157453032, "std_of_first_answer": 0.3923208157453032, "avg_entropy_of_first_answer": 0.4895890951156616, "lex_sim": 1.0}
{"question": "what is the name of the weapon the grim reaper carries", "answer": ["Scythe #Review: The Art of Holding On and Letting Go by Kristin Bartley Lenz - YA Contemporary Novel"], "scores": [[0.367919921875, 0.99853515625, 0.99951171875, 2.384185791015625e-07, 0.00354766845703125, 4.3511390686035156e-05, 0.005558013916015625, 0.1217041015625, 0.0019159317016601562, 0.87890625, 0.00018906593322753906, 0.99755859375, 0.0543212890625, 0.92822265625, 0.9970703125, 1.0, 0.9970703125, 0.57470703125, 0.9775390625, 0.99609375, 0.76220703125, 0.84619140625, 0.970703125, 0.84619140625, 0.031585693359375, 0.005115509033203125, 0.97802734375, 0.123046875, 1.0, 0.26611328125, 0.98876953125]], "normalized_score": [0.10258731991052628], "tokens": [["\u2581S", "cy", "the", "\u2581#", "Re", "view", ":", "\u2581The", "\u2581Art", "\u2581of", "\u2581Hold", "ing", "\u2581On", "\u2581and", "\u2581Let", "ting", "\u2581Go", "\u2581by", "\u2581Krist", "in", "\u2581Bart", "ley", "\u2581L", "enz", "\u2581-", "\u2581Y", "A", "\u2581Contempor", "ary", "\u2581Nov", "el"]], "entropy": [[1.728515625, 0.01203155517578125, 0.002994537353515625, 1.2158203125, 4.1171875, 0.501953125, 3.673828125, 4.76171875, 3.921875, 0.689453125, 3.45703125, 0.02679443359375, 3.208984375, 0.45849609375, 0.029327392578125, 7.867813110351562e-05, 0.026275634765625, 2.119140625, 0.146728515625, 0.03314208984375, 1.349609375, 0.54541015625, 0.1875, 1.0986328125, 1.9716796875, 3.447265625, 0.1798095703125, 3.810546875, 0.00096893310546875, 2.923828125, 0.07061767578125]], "avg_entropy": [1.4747498573795441], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "scythe", "score_of_biggest_cluster": 0.10258731991052628, "score_of_first_answer": 0.10258731991052628, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.10258731991052628, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43604581164046613, "std_of_first_answer": 0.43604581164046613, "avg_entropy_of_first_answer": 1.4747498573795441, "lex_sim": 1.0}
{"question": "what mall did they use in back to the future", "answer": ["Green Hills"], "scores": [[0.0006189346313476562, 0.7109375]], "normalized_score": [0.020976746454834938], "tokens": [["\u2581Green", "\u2581Hills"]], "entropy": [[2.0625, 1.830078125]], "avg_entropy": [1.9462890625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Puente Hills Mall", "score_of_biggest_cluster": 0.020976746454834938, "score_of_first_answer": 0.020976746454834938, "max_score_of_first_answer": 0.7109375, "min_score_of_first_answer": 0.0006189346313476562, "avg_score": 0.020976746454834938, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.35515928268432617, "std_of_first_answer": 0.35515928268432617, "avg_entropy_of_first_answer": 1.9462890625, "lex_sim": 1.0}
{"question": "india south africa test series 2018 highest runs", "answer": ["Virat Kohli made 213 runs in the 1st Test."], "scores": [[0.1962890625, 0.99951171875, 0.99609375, 1.0, 0.0006375312805175781, 0.88037109375, 0.98046875, 0.006877899169921875, 0.94580078125, 0.72802734375, 0.81298828125, 0.99609375, 0.278564453125, 0.48291015625, 0.99951171875, 0.5322265625, 0.07354736328125, 8.404254913330078e-06, 0.0007991790771484375, 0.043670654296875, 0.06884765625, 0.00010603666305541992, 0.00015020370483398438, 5.602836608886719e-06, 0.98193359375, 0.9736328125]], "normalized_score": [0.05659814924001694], "tokens": [["\u2581Vir", "at", "\u2581Koh", "li", "\u2581made", "\u2581", "2", "1", "3", "\u2581runs", "\u2581in", "\u2581the", "\u2581", "1", "st", "\u2581Test", ".", "\u2581#", "3", "3", "8", "\u2581/", "\u2581Con", "viv", "ial", "ity"]], "entropy": [[2.37109375, 0.0038738250732421875, 0.02899169921875, 0.00205230712890625, 1.87890625, 0.4169921875, 0.12646484375, 0.07110595703125, 0.2822265625, 0.9189453125, 0.83154296875, 0.03814697265625, 1.60546875, 1.064453125, 0.004558563232421875, 0.75634765625, 1.4013671875, 0.90380859375, 1.6669921875, 2.4296875, 2.630859375, 2.78515625, 4.37890625, 0.41552734375, 0.09954833984375, 0.2452392578125]], "avg_entropy": [1.0522408852210412], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "286", "score_of_biggest_cluster": 0.05659814924001694, "score_of_first_answer": 0.05659814924001694, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.602836608886719e-06, "avg_score": 0.05659814924001694, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4333279457312894, "std_of_first_answer": 0.4333279457312894, "avg_entropy_of_first_answer": 1.0522408852210412, "lex_sim": 1.0}
{"question": "who is in charge of new issues not mentioned in the constitution", "answer": ["Congress, based on their delegated powers and responsibilities outlined in the Constitution."], "scores": [[0.368408203125, 0.04132080078125, 0.0014333724975585938, 0.99951171875, 0.583984375, 0.01013946533203125, 0.9990234375, 0.95263671875, 0.8466796875, 0.57470703125, 1.0, 1.0, 0.310791015625, 1.0, 0.99365234375, 0.9951171875, 0.95556640625, 0.8857421875, 7.152557373046875e-07, 0.0007114410400390625, 2.4437904357910156e-06, 0.396728515625, 2.6106834411621094e-05, 0.99560546875, 0.8369140625, 0.99951171875, 0.6630859375, 0.0203704833984375, 0.39306640625, 0.91943359375, 0.050689697265625, 0.002216339111328125, 0.00212860107421875, 0.93212890625, 0.02386474609375, 0.137451171875, 0.21142578125, 0.27001953125, 0.0016069412231445312, 0.345458984375, 0.99755859375, 0.80859375, 0.99951171875]], "normalized_score": [0.09571602940559387], "tokens": [["\u2581Congress", ",", "\u2581based", "\u2581on", "\u2581their", "\u2581deleg", "ated", "\u2581powers", "\u2581and", "\u2581respons", "ib", "ilities", "\u2581out", "lined", "\u2581in", "\u2581the", "\u2581Constitution", ".", "\u2581#", "New", "Release", "\u2581#", "Kind", "le", "Un", "limited", "\u2581#", "G", "ive", "away", "\u2581-", "\u2581W", "IL", "D", "\u2581F", "LA", "ME", "\u2581by", "\u2581R", "ene", "e", "\u2581Har", "less"]], "entropy": [[1.71875, 1.443359375, 2.408203125, 0.004924774169921875, 1.359375, 2.05859375, 0.007595062255859375, 0.2354736328125, 0.74462890625, 1.25390625, 0.0001590251922607422, 2.0444393157958984e-05, 1.9384765625, 0.00016999244689941406, 0.04058837890625, 0.031463623046875, 0.2115478515625, 0.50048828125, 0.4609375, 3.630859375, 0.9228515625, 2.697265625, 5.3828125, 0.044403076171875, 1.0986328125, 0.004718780517578125, 1.396484375, 4.4921875, 2.46484375, 0.398681640625, 2.634765625, 5.15625, 3.337890625, 0.41650390625, 3.470703125, 2.708984375, 1.3583984375, 2.189453125, 3.078125, 2.919921875, 0.0231781005859375, 0.998046875, 0.00585174560546875]], "avg_entropy": [1.5174529150474902], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Congress", "score_of_biggest_cluster": 0.09571602940559387, "score_of_first_answer": 0.09571602940559387, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 7.152557373046875e-07, "avg_score": 0.09571602940559387, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4166498375461578, "std_of_first_answer": 0.4166498375461578, "avg_entropy_of_first_answer": 1.5174529150474902, "lex_sim": 1.0}
{"question": "who wrote how do you do it by gerry and the pacemakers", "answer": ["The Beatles"], "scores": [[0.032745361328125, 0.2353515625, 1.0]], "normalized_score": [0.19752509891986847], "tokens": [["\u2581The", "\u2581Beat", "les"]], "entropy": [[3.341796875, 2.09765625, 0.0014142990112304688]], "avg_entropy": [1.8136224746704102], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Mitch Murray", "score_of_biggest_cluster": 0.19752509891986847, "score_of_first_answer": 0.19752509891986847, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.032745361328125, "avg_score": 0.19752509891986847, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41650904241974934, "std_of_first_answer": 0.41650904241974934, "avg_entropy_of_first_answer": 1.8136224746704102, "lex_sim": 1.0}
{"question": "who wrote i'm in the mood for dancing", "answer": ["Nena (band)"], "scores": [[0.81494140625, 0.00896453857421875, 0.0121917724609375, 0.7861328125, 0.9990234375]], "normalized_score": [0.1475566029548645], "tokens": [["\u2581N", "ena", "\u2581(", "band", ")"]], "entropy": [[0.96875, 2.6484375, 0.86328125, 1.201171875, 0.01091766357421875]], "avg_entropy": [1.1385116577148438], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ben Findon", "score_of_biggest_cluster": 0.1475566029548645, "score_of_first_answer": 0.1475566029548645, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 0.00896453857421875, "avg_score": 0.1475566029548645, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4257268263217994, "std_of_first_answer": 0.4257268263217994, "avg_entropy_of_first_answer": 1.1385116577148438, "lex_sim": 1.0}
{"question": "what is the angle of the tower of pisa", "answer": ["The angle of the lean of the Tower of Pisa is approximately 3.9 degrees."], "scores": [[0.2144775390625, 0.0816650390625, 0.99267578125, 0.9853515625, 0.107666015625, 0.87744140625, 0.99951171875, 0.96826171875, 1.0, 1.0, 1.0, 0.9990234375, 0.4921875, 0.99951171875, 0.978515625, 1.0, 1.0, 0.638671875, 0.97021484375, 3.039836883544922e-06, 0.0308685302734375, 0.0005035400390625, 0.00850677490234375, 0.7353515625, 0.0411376953125, 0.352294921875, 1.0, 0.88671875, 0.998046875, 0.99951171875, 1.0, 0.98974609375, 0.01068115234375, 0.0018014907836914062, 0.0034732818603515625, 0.0005059242248535156, 0.64306640625, 0.001705169677734375, 0.00026035308837890625, 0.998046875, 0.280517578125, 0.2939453125, 1.0, 0.315185546875, 0.0024623870849609375, 0.2159423828125, 0.9951171875, 0.9189453125]], "normalized_score": [0.14911209046840668], "tokens": [["\u2581The", "\u2581angle", "\u2581of", "\u2581the", "\u2581lean", "\u2581of", "\u2581the", "\u2581Tower", "\u2581of", "\u2581P", "isa", "\u2581is", "\u2581approximately", "\u2581", "3", ".", "9", "\u2581degrees", ".", "\u2581**", "[", "T", "ele", "gram", "](", "https", "://", "tele", "gram", ".", "me", "/", "zi", "pp", "yl", "end", ")", "\u2581or", "\u2581Jo", "in", "\u2581our", "\u2581Disc", "ord", "\u2581server", "[", "https", "://", "dis"]], "entropy": [[1.1630859375, 1.80859375, 0.04437255859375, 0.093505859375, 1.1201171875, 0.421630859375, 0.0034503936767578125, 0.1590576171875, 0.0003402233123779297, 0.00014281272888183594, 0.0009188652038574219, 0.00824737548828125, 1.1513671875, 0.005260467529296875, 0.1298828125, 0.0018358230590820312, 0.0007543563842773438, 0.86181640625, 0.18798828125, 0.31640625, 5.01171875, 2.1875, 3.6953125, 0.92236328125, 4.9765625, 2.373046875, 0.0003085136413574219, 0.697265625, 0.0131988525390625, 0.0031833648681640625, 0.001255035400390625, 0.07452392578125, 5.79296875, 2.140625, 4.67578125, 2.619140625, 2.302734375, 0.38427734375, 1.818359375, 0.0174102783203125, 1.857421875, 3.005859375, 0.00012576580047607422, 2.775390625, 2.794921875, 2.740234375, 0.04180908203125, 0.5517578125]], "avg_entropy": [1.2698715006311734], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "about 3.99 degrees", "score_of_biggest_cluster": 0.14911209046840668, "score_of_first_answer": 0.14911209046840668, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 3.039836883544922e-06, "avg_score": 0.14911209046840668, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43034378444811716, "std_of_first_answer": 0.43034378444811716, "avg_entropy_of_first_answer": 1.2698715006311734, "lex_sim": 1.0}
{"question": "what is the name of the chief justice of ghana", "answer": ["Justice William Atuguba ##### THE HERETICAL IMAGE CONTENTS PAGE ####"], "scores": [[0.63232421875, 0.06982421875, 0.90869140625, 0.990234375, 1.0, 0.0, 0.00016427040100097656, 0.0016269683837890625, 0.0024242401123046875, 0.0005793571472167969, 0.97900390625, 0.02142333984375, 0.002628326416015625, 0.2861328125, 0.37744140625, 0.003467559814453125, 0.9072265625, 0.340087890625, 0.002468109130859375, 0.036224365234375, 0.1513671875, 0.015045166015625]], "normalized_score": [0.0], "tokens": [["\u2581Justice", "\u2581William", "\u2581At", "ug", "uba", "\u2581#####", "\u2581THE", "\u2581H", "ER", "ET", "IC", "AL", "\u2581I", "MA", "GE", "\u2581CON", "T", "ENT", "S", "\u2581P", "AGE", "\u2581####"]], "entropy": [[1.2998046875, 0.51220703125, 0.499267578125, 0.0772705078125, 0.0020751953125, 0.9091796875, 2.84375, 2.09375, 0.90234375, 2.05859375, 0.1507568359375, 3.962890625, 2.515625, 1.9189453125, 0.94873046875, 2.615234375, 0.408935546875, 0.81298828125, 2.1484375, 4.12109375, 2.173828125, 2.16796875]], "avg_entropy": [1.5974398526278408], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Sophia Akuffo", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38727831254571676, "std_of_first_answer": 0.38727831254571676, "avg_entropy_of_first_answer": 1.5974398526278408, "lex_sim": 1.0}
{"question": "who wrote catch 22 (both names)", "answer": ["Joseph Heller"], "scores": [[0.9990234375, 1.0, 1.0]], "normalized_score": [0.999674379825592], "tokens": [["\u2581Joseph", "\u2581H", "eller"]], "entropy": [[0.00812530517578125, 0.0019044876098632812, 3.039836883544922e-06]], "avg_entropy": [0.003344277540842692], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Joseph Heller.", "score_of_biggest_cluster": 0.999674379825592, "score_of_first_answer": 0.999674379825592, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.9990234375, "avg_score": 0.999674379825592, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.0004603559773349919, "std_of_first_answer": 0.0004603559773349919, "avg_entropy_of_first_answer": 0.003344277540842692, "lex_sim": 1.0}
{"question": "how many episodes of the killing on netflix", "answer": ["22 \\r\\nDr."], "scores": [[0.95263671875, 0.982421875, 0.05712890625, 4.172325134277344e-07, 1.1920928955078125e-07, 0.383544921875, 0.9970703125, 8.881092071533203e-06, 0.293212890625, 0.0010175704956054688, 0.031890869140625, 0.147216796875, 0.005550384521484375, 0.061981201171875, 0.1297607421875, 0.00179290771484375, 0.96484375, 0.73583984375, 0.0008683204650878906, 0.2403564453125, 0.99951171875, 1.0, 0.875, 0.2098388671875, 0.9755859375, 0.98974609375, 0.96875, 0.0045623779296875, 0.231689453125, 0.06121826171875, 0.061187744140625, 0.0667724609375, 0.677734375, 0.8984375, 0.3046875, 0.974609375, 0.7021484375, 0.2313232421875, 0.82861328125, 0.1806640625, 0.1302490234375, 0.55908203125, 0.013824462890625, 0.513671875, 0.0003561973571777344, 0.53515625, 0.09112548828125, 0.173095703125]], "normalized_score": [0.07034746557474136], "tokens": [["\u2581", "2", "2", "\u2581\\", "r", "\\", "n", "Dr", ".", "\u2581O", "'", "Ne", "al", "\u2581is", "\u2581a", "\u2581member", "\u2581of", "\u2581the", "\u2581Executive", "\u2581Le", "ad", "ership", "\u2581Team", "\u2581(", "E", "LT", ")", "\u2581that", "\u2581sets", "\u2581strategy", ",", "\u2581vision", ",", "\u2581and", "\u2581direction", "\u2581for", "\u2581the", "\u2581organization", ".", "\u2581He", "\u2581leads", "\u2581the", "\u2581Learning", "\u2581and", "\u2581Communic", "ations", "\u2581team", "\u2581and"]], "entropy": [[0.305419921875, 0.115478515625, 1.51953125, 1.06640625, 0.0147552490234375, 0.8662109375, 0.025146484375, 2.21875, 3.92578125, 5.4296875, 2.04296875, 2.390625, 0.37060546875, 4.15234375, 4.05859375, 5.5078125, 0.2252197265625, 1.8544921875, 4.21484375, 2.134765625, 0.0030651092529296875, 0.0017871856689453125, 0.498046875, 1.951171875, 0.2138671875, 0.0701904296875, 0.1890869140625, 1.744140625, 3.072265625, 1.2021484375, 1.1103515625, 3.775390625, 0.697265625, 0.578125, 2.306640625, 0.1748046875, 2.357421875, 3.671875, 0.880859375, 2.630859375, 2.49609375, 2.638671875, 5.34765625, 1.9716796875, 1.4453125, 0.6923828125, 3.4140625, 1.86328125]], "avg_entropy": [1.8632904688517253], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "6", "score_of_biggest_cluster": 0.07034746557474136, "score_of_first_answer": 0.07034746557474136, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.07034746557474136, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.387229596526489, "std_of_first_answer": 0.387229596526489, "avg_entropy_of_first_answer": 1.8632904688517253, "lex_sim": 1.0}
{"question": "when was the last time the dodgers played yankees in the world series", "answer": ["1981"], "scores": [[0.82568359375, 0.373779296875, 1.0, 0.99951171875, 1.0]], "normalized_score": [0.7903934717178345], "tokens": [["\u2581", "1", "9", "8", "1"]], "entropy": [[0.6416015625, 0.66162109375, 0.0011510848999023438, 0.00649261474609375, 0.001621246337890625]], "avg_entropy": [0.2624975204467773], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1981", "score_of_biggest_cluster": 0.7903934717178345, "score_of_first_answer": 0.7903934717178345, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.373779296875, "avg_score": 0.7903934717178345, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.24257389869632584, "std_of_first_answer": 0.24257389869632584, "avg_entropy_of_first_answer": 0.2624975204467773, "lex_sim": 1.0}
{"question": "what is the average height of a chinese man", "answer": ["171 cm #HITMC Social Media Healthcare Marketing Conference Unveils Its 2014 Agenda Featuring Google Glass Session"], "scores": [[0.52783203125, 0.98681640625, 0.88671875, 0.377197265625, 0.88232421875, 0.0, 0.00452423095703125, 0.00020945072174072266, 2.1457672119140625e-06, 1.7881393432617188e-05, 0.49169921875, 0.00031256675720214844, 0.07257080078125, 0.299560546875, 0.99755859375, 0.0155029296875, 4.9233436584472656e-05, 0.136962890625, 0.7939453125, 0.058563232421875, 0.0853271484375, 0.79345703125, 0.892578125, 0.1405029296875, 0.0188751220703125, 0.13134765625, 0.99951171875, 0.0142059326171875, 0.9541015625, 0.020294189453125, 0.1634521484375, 0.9990234375, 0.0035724639892578125]], "normalized_score": [0.0], "tokens": [["\u2581", "1", "7", "1", "\u2581cm", "\u2581#", "H", "IT", "MC", "\u2581Social", "\u2581Media", "\u2581Health", "care", "\u2581Mark", "eting", "\u2581Conference", "\u2581Un", "ve", "ils", "\u2581Its", "\u2581", "2", "0", "1", "4", "\u2581Ag", "enda", "\u2581Fe", "aturing", "\u2581Google", "\u2581G", "lass", "\u2581Session"]], "entropy": [[1.7578125, 0.074951171875, 0.388916015625, 1.185546875, 0.485107421875, 1.1103515625, 5.92578125, 3.779296875, 2.037109375, 2.470703125, 2.921875, 4.50390625, 2.74609375, 2.83984375, 0.021636962890625, 3.470703125, 3.34375, 2.845703125, 0.72802734375, 4.265625, 3.958984375, 0.865234375, 0.4453125, 0.517578125, 1.18359375, 3.625, 0.00391387939453125, 3.396484375, 0.246826171875, 3.228515625, 2.15625, 0.0080413818359375, 2.419921875]], "avg_entropy": [2.089648391261245], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "5\u00a0ft 6\u00a0in", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.39569834927869085, "std_of_first_answer": 0.39569834927869085, "avg_entropy_of_first_answer": 2.089648391261245, "lex_sim": 1.0}
{"question": "where was the movie the glass castle filmed", "answer": ["The movie \"The Glass Castle\" was filmed in various locations, including New York, Louisiana, and Montreal."], "scores": [[0.24267578125, 0.85986328125, 0.74658203125, 0.9990234375, 1.0, 1.0, 1.0, 1.0, 0.98828125, 0.79541015625, 1.0, 0.9423828125, 0.86669921875, 0.9990234375, 0.48681640625, 0.97314453125, 0.2978515625, 0.6884765625, 0.66357421875, 0.372314453125, 0.95751953125, 0.97705078125, 0.0007233619689941406, 0.97412109375, 5.364418029785156e-07, 0.0009899139404296875, 1.239776611328125e-05, 0.80029296875, 0.99951171875, 0.99951171875, 0.0284271240234375, 2.9981136322021484e-05, 0.59619140625]], "normalized_score": [0.15877459943294525], "tokens": [["\u2581The", "\u2581movie", "\u2581\"", "The", "\u2581G", "lass", "\u2581Castle", "\"", "\u2581was", "\u2581fil", "med", "\u2581in", "\u2581various", "\u2581locations", ",", "\u2581including", "\u2581New", "\u2581York", ",", "\u2581Louisiana", ",", "\u2581and", "\u2581Montreal", ".", "\u2581#", "G", "iving", "T", "ues", "day", "\u2581is", "\u2581Today", "!"]], "entropy": [[2.376953125, 0.5380859375, 0.69873046875, 0.00896453857421875, 0.0015172958374023438, 4.786252975463867e-05, 0.0002617835998535156, 0.001064300537109375, 0.082275390625, 0.71240234375, -0.0, 0.256591796875, 0.619140625, 0.0083160400390625, 1.2509765625, 0.1634521484375, 2.87890625, 0.90478515625, 0.8583984375, 2.287109375, 0.1771240234375, 0.1629638671875, 1.1708984375, 0.1278076171875, 0.828125, 2.5390625, 0.08538818359375, 1.134765625, 0.0040283203125, 0.0037975311279296875, 2.20703125, 1.2431640625, 1.72265625]], "avg_entropy": [0.7592361244288358], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "in Welch, West Virginia", "score_of_biggest_cluster": 0.15877459943294525, "score_of_first_answer": 0.15877459943294525, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.364418029785156e-07, "avg_score": 0.15877459943294525, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3786148115498406, "std_of_first_answer": 0.3786148115498406, "avg_entropy_of_first_answer": 0.7592361244288358, "lex_sim": 1.0}
{"question": "who are the australia's got talent judges", "answer": ["Dealz, Dannielle and Nine's own Manzone."], "scores": [[0.006282806396484375, 0.162353515625, 0.07244873046875, 0.50244140625, 0.254150390625, 0.80224609375, 0.01522064208984375, 0.04180908203125, 0.5849609375, 0.296142578125, 0.103271484375, 0.9990234375, 0.01107025146484375, 0.470703125, 0.00016546249389648438, 0.4921875, 7.933378219604492e-05, 0.0015707015991210938, 0.007625579833984375, 0.02410888671875, 0.0654296875, 0.0751953125, 0.08038330078125, 0.00901031494140625, 0.61865234375, 0.400390625, 0.042510986328125, 0.9921875, 0.3349609375, 0.1351318359375, 0.9990234375, 0.0004832744598388672, 0.254150390625, 0.6240234375, 0.69482421875, 0.118896484375, 0.99609375, 0.1429443359375, 0.09466552734375, 0.7646484375, 0.235595703125, 0.79833984375, 0.005970001220703125, 0.370849609375, 0.006999969482421875, 0.2354736328125, 0.006855010986328125, 0.61328125]], "normalized_score": [0.08423589169979095], "tokens": [["\u2581De", "al", "z", ",", "\u2581D", "ann", "ielle", "\u2581and", "\u2581N", "ine", "'", "s", "\u2581own", "\u2581Man", "zone", ".", "\u2581#", "3", "8", "9", "7", "7", "1", "\u2581-", "\u2581", "0", "8", "/", "0", "5", "/", "0", "8", "\u2581", "0", "3", ":", "5", "1", "\u2581PM", "\u2581Re", ":", "\u2581How", "\u2581many", "\u2581of", "\u2581you", "\u2581would", "\u2581like"]], "entropy": [[3.97265625, 3.796875, 3.82421875, 2.16796875, 1.3525390625, 1.0302734375, 0.1275634765625, 3.962890625, 2.1640625, 2.87109375, 1.220703125, 0.00830841064453125, 4.19921875, 3.55859375, 0.29345703125, 1.3056640625, 1.1337890625, 0.9609375, 2.482421875, 3.5703125, 2.666015625, 2.71484375, 2.58984375, 2.046875, 2.810546875, 1.109375, 1.8623046875, 0.06268310546875, 1.2734375, 2.17578125, 0.0102691650390625, 0.0162200927734375, 2.056640625, 1.0595703125, 0.7041015625, 2.201171875, 0.031005859375, 1.79296875, 2.31640625, 0.60693359375, 1.716796875, 0.71923828125, 4.6484375, 2.76953125, 4.125, 2.3984375, 4.44921875, 2.30078125]], "avg_entropy": [2.02579132715861], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Kelly Osbourne", "score_of_biggest_cluster": 0.08423589169979095, "score_of_first_answer": 0.08423589169979095, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 7.933378219604492e-05, "avg_score": 0.08423589169979095, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.32182786573483446, "std_of_first_answer": 0.32182786573483446, "avg_entropy_of_first_answer": 2.02579132715861, "lex_sim": 1.0}
{"question": "when did the philadelphia eagles play in the super bowl last", "answer": ["Super Bowl LII, 2018."], "scores": [[0.200927734375, 0.9990234375, 0.998046875, 0.99951171875, 0.284423828125, 0.1871337890625, 0.99951171875, 1.0, 1.0, 0.99853515625, 0.41796875]], "normalized_score": [0.6111937165260315], "tokens": [["\u2581Super", "\u2581Bowl", "\u2581L", "II", ",", "\u2581", "2", "0", "1", "8", "."]], "entropy": [[1.44921875, 0.0082550048828125, 0.0178985595703125, 0.006076812744140625, 1.78125, 1.3701171875, 0.006977081298828125, 0.002239227294921875, 0.00046062469482421875, 0.01055908203125, 1.1806640625]], "avg_entropy": [0.53033785386519], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Super Bowl LII", "score_of_biggest_cluster": 0.6111937165260315, "score_of_first_answer": 0.6111937165260315, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.1871337890625, "avg_score": 0.6111937165260315, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.35389443479877486, "std_of_first_answer": 0.35389443479877486, "avg_entropy_of_first_answer": 0.53033785386519, "lex_sim": 1.0}
{"question": "when was nepal declared a secular state in bs", "answer": ["Falgun 8, 2046 (March 10, 1993) #HumpDayHottie: Dylan Penn Nude For \u2018Lui\u2019 Magazine"], "scores": [[2.2590160369873047e-05, 0.498046875, 0.99658203125, 0.966796875, 0.298583984375, 0.9541015625, 0.97998046875, 0.998046875, 0.99951171875, 0.962890625, 0.853515625, 0.59130859375, 0.7783203125, 1.0, 0.99853515625, 0.9326171875, 0.88671875, 0.99853515625, 0.998046875, 0.453369140625, 1.0, 1.0, 0.86328125, 0.939453125, 1.7285346984863281e-06, 0.0029201507568359375, 2.5033950805664062e-06, 0.767578125, 0.009033203125, 0.0007700920104980469, 0.82470703125, 0.00550079345703125, 0.006298065185546875, 0.006542205810546875, 0.99853515625, 0.0230560302734375, 0.97265625, 0.00023853778839111328, 0.28271484375, 0.011688232421875, 0.01331329345703125, 0.1624755859375, 0.50732421875, 0.91552734375, 0.6806640625]], "normalized_score": [0.10920526832342148], "tokens": [["\u2581F", "alg", "un", "\u2581", "8", ",", "\u2581", "2", "0", "4", "6", "\u2581(", "M", "arch", "\u2581", "1", "0", ",", "\u2581", "1", "9", "9", "3", ")", "\u2581#", "H", "ump", "Day", "H", "ott", "ie", ":", "\u2581D", "yl", "an", "\u2581P", "enn", "\u2581N", "ude", "\u2581For", "\u2581\u2018", "L", "ui", "\u2019", "\u2581Magazine"]], "entropy": [[1.1142578125, 1.6787109375, 0.025482177734375, 0.2298583984375, 0.8671875, 0.26806640625, 0.1378173828125, 0.0129241943359375, 0.00278472900390625, 0.213623046875, 0.64599609375, 1.1943359375, 0.8857421875, 0.0010633468627929688, 0.013397216796875, 0.360107421875, 0.55126953125, 0.01255035400390625, 0.01427459716796875, 0.689453125, 0.0003566741943359375, 0.0016002655029296875, 0.58154296875, 0.288330078125, 0.703125, 3.77734375, 1.6044921875, 1.2041015625, 2.134765625, 2.150390625, 0.64599609375, 2.134765625, 5.5078125, 3.224609375, 0.01416015625, 1.4833984375, 0.198974609375, 3.33203125, 3.123046875, 4.4375, 3.861328125, 3.615234375, 1.142578125, 0.370361328125, 1.671875]], "avg_entropy": [1.2473027335272895], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "January 15, 2007", "score_of_biggest_cluster": 0.10920526832342148, "score_of_first_answer": 0.10920526832342148, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7285346984863281e-06, "avg_score": 0.10920526832342148, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4194197289824794, "std_of_first_answer": 0.4194197289824794, "avg_entropy_of_first_answer": 1.2473027335272895, "lex_sim": 1.0}
{"question": "who plays the little girl in jurassic park", "answer": ["Ariana Richards"], "scores": [[0.98046875, 0.9990234375, 0.998046875, 1.0]], "normalized_score": [0.994351863861084], "tokens": [["\u2581Ari", "ana", "\u2581Rich", "ards"]], "entropy": [[0.14892578125, 0.00963592529296875, 0.0186004638671875, 0.0006289482116699219]], "avg_entropy": [0.04444777965545654], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ariana Clarice Richards", "score_of_biggest_cluster": 0.994351863861084, "score_of_first_answer": 0.994351863861084, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.98046875, "avg_score": 0.994351863861084, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.008064035432086789, "std_of_first_answer": 0.008064035432086789, "avg_entropy_of_first_answer": 0.04444777965545654, "lex_sim": 1.0}
{"question": "who wrote the treasure of the sierra madre", "answer": ["Peter B. Kyne"], "scores": [[0.001529693603515625, 0.99072265625, 0.994140625, 0.9990234375, 1.0]], "normalized_score": [0.27259379625320435], "tokens": [["\u2581Peter", "\u2581B", ".", "\u2581Ky", "ne"]], "entropy": [[3.732421875, 0.0693359375, 0.056884765625, 0.0120697021484375, 9.834766387939453e-06]], "avg_entropy": [0.774144423007965], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "B. Traven", "score_of_biggest_cluster": 0.27259379625320435, "score_of_first_answer": 0.27259379625320435, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.001529693603515625, "avg_score": 0.27259379625320435, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3977909844498565, "std_of_first_answer": 0.3977909844498565, "avg_entropy_of_first_answer": 0.774144423007965, "lex_sim": 1.0}
{"question": "when is the next episode of flash airing", "answer": ["Unfortunately, I don't have access to current information about TV schedules."], "scores": [[0.01352691650390625, 0.96337890625, 0.5732421875, 0.1654052734375, 0.98828125, 1.0, 0.921875, 0.378173828125, 0.99951171875, 0.37841796875, 0.29345703125, 0.4853515625, 0.494384765625, 0.7861328125, 0.99462890625, 0.84814453125, 0.176513671875, 0.453857421875, 0.1563720703125, 0.50537109375, 0.62255859375, 0.61767578125, 0.6767578125, 0.2294921875, 0.77587890625, 0.291259765625, 0.129638671875, 0.34130859375, 0.970703125, 0.68017578125, 0.05621337890625, 0.7646484375, 0.85693359375, 5.364418029785156e-07, 2.849102020263672e-05, 0.00023353099822998047, 0.00098419189453125, 0.014251708984375, 0.82177734375, 0.25537109375, 0.09814453125, 0.66748046875, 0.00036597251892089844, 0.00908660888671875, 0.002201080322265625, 0.042724609375, 0.252197265625, 0.509765625]], "normalized_score": [0.12280125916004181], "tokens": [["\u2581Unfortunately", ",", "\u2581I", "\u2581don", "'", "t", "\u2581have", "\u2581access", "\u2581to", "\u2581current", "\u2581information", "\u2581about", "\u2581TV", "\u2581sched", "ules", ".", "\u2581You", "\u2581may", "\u2581check", "\u2581with", "\u2581your", "\u2581local", "\u2581TV", "\u2581provider", "\u2581or", "\u2581a", "\u2581TV", "\u2581schedule", "\u2581website", "\u2581for", "\u2581more", "\u2581information", ".", "\u2581###", "\u2581P", "ain", "ter", "\u2581P", "ain", "ter", "\u2581is", "\u2581a", "\u2581**", "2", "D", "\u2581drawing", "\u2581library", "**"]], "entropy": [[1.6123046875, 0.195556640625, 1.1806640625, 1.408203125, 0.07757568359375, 0.0002613067626953125, 0.2822265625, 1.447265625, 0.004547119140625, 2.095703125, 1.8115234375, 1.6171875, 1.259765625, 0.7392578125, 0.032501220703125, 0.66455078125, 1.978515625, 1.240234375, 1.0048828125, 1.4921875, 0.966796875, 1.1435546875, 1.3115234375, 1.46875, 0.615234375, 2.23046875, 1.380859375, 1.576171875, 0.1829833984375, 0.85107421875, 0.9228515625, 0.81689453125, 0.515625, 0.8544921875, 5.5, 2.583984375, 0.7021484375, 4.1484375, 0.8583984375, 1.0810546875, 4.51953125, 1.716796875, 4.875, 4.5546875, 2.455078125, 2.61328125, 1.9912109375, 1.12109375]], "avg_entropy": [1.5354770421981812], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "May\u00a08,\u00a02018", "score_of_biggest_cluster": 0.12280125916004181, "score_of_first_answer": 0.12280125916004181, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.364418029785156e-07, "avg_score": 0.12280125916004181, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.34563278462911834, "std_of_first_answer": 0.34563278462911834, "avg_entropy_of_first_answer": 1.5354770421981812, "lex_sim": 1.0}
{"question": "who has the most goals in soccer 2018", "answer": ["Harry Kane [Deadline: April."], "scores": [[0.12457275390625, 1.0, 0.99951171875, 4.112720489501953e-05, 0.0004963874816894531, 0.0051727294921875, 0.85595703125, 0.33740234375, 0.0022220611572265625, 7.933378219604492e-05, 0.72412109375, 0.212646484375, 0.10009765625, 0.040679931640625, 2.9206275939941406e-06, 0.0007801055908203125, 0.328125, 5.960464477539063e-08, 0.044403076171875, 0.3125, 0.0052642822265625, 0.0006761550903320312, 0.09283447265625, 0.9638671875, 0.0083160400390625, 0.9677734375, 0.9697265625, 0.400634765625, 0.287841796875, 0.227783203125, 0.03363037109375, 0.01407623291015625, 0.99853515625, 0.4404296875, 0.29541015625, 0.034820556640625, 0.376953125, 0.1748046875, 0.83740234375, 0.99951171875, 0.99951171875, 0.043212890625, 0.058837890625, 0.931640625]], "normalized_score": [0.044845566153526306], "tokens": [["\u2581Harry", "\u2581K", "ane", "\u2581[", "D", "ead", "line", ":", "\u2581April", ".", "\u2581", "2", "8", "]", "\u2581Sub", "mit", "\u2581your", "\u2581abstract", "\u2581for", "\u2581the", "\u2581G", "ender", "\u2581Equ", "ality", "\u2581", "2", "0", "1", "8", "\u2581Conference", "\u2581and", "\u2581comp", "ete", "\u2581for", "\u2581a", "\u2581", "1", ",", "0", "0", "0", "\u20ac", "\u2581travel", "\u2581grant"]], "entropy": [[2.140625, 0.0026645660400390625, 0.004138946533203125, 1.734375, 3.279296875, 2.017578125, 0.70458984375, 3.0234375, 1.6337890625, 0.12091064453125, 1.2001953125, 1.498046875, 2.234375, 1.228515625, 1.509765625, 0.074951171875, 3.48046875, 1.5849609375, 2.931640625, 3.650390625, 4.76953125, 2.880859375, 3.15625, 0.1661376953125, 3.154296875, 0.21875, 0.1824951171875, 0.76611328125, 0.669921875, 3.5, 3.236328125, 3.876953125, 0.01226806640625, 1.2099609375, 2.4921875, 1.2666015625, 1.5849609375, 1.197265625, 0.48828125, 0.002925872802734375, 0.00276947021484375, 2.556640625, 1.822265625, 0.412841796875]], "avg_entropy": [1.6745755022222346], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ali Daei", "score_of_biggest_cluster": 0.044845566153526306, "score_of_first_answer": 0.044845566153526306, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.044845566153526306, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38431004512599737, "std_of_first_answer": 0.38431004512599737, "avg_entropy_of_first_answer": 1.6745755022222346, "lex_sim": 1.0}
{"question": "where in the bible are the 12 disciples", "answer": ["The 12 disciples are mentioned throughout the New Testament of the Bible, in books such as the Gospels (Matthew, Mark, Luke, and John) and the Acts of the Apostles."], "scores": [[0.1370849609375, 0.045501708984375, 0.99951171875, 1.0, 0.9814453125, 1.0, 1.0, 0.9619140625, 0.853515625, 0.9482421875, 1.0, 0.83935546875, 1.0, 0.2303466796875, 1.0, 0.955078125, 0.47119140625, 0.0194091796875, 0.134765625, 0.97802734375, 1.0, 0.87744140625, 0.99609375, 0.83544921875, 1.0, 0.04571533203125, 0.99951171875, 1.0, 1.0, 0.9990234375, 0.99951171875, 0.9990234375, 1.0, 0.99267578125, 0.9736328125, 0.99951171875, 0.908203125, 0.99267578125, 0.98193359375, 0.99853515625, 1.0, 1.0, 1.0, 0.99951171875, 1.0, 0.99560546875, 1.7881393432617188e-07, 0.002620697021484375]], "normalized_score": [0.44556617736816406], "tokens": [["\u2581The", "\u2581", "1", "2", "\u2581dis", "ci", "ples", "\u2581are", "\u2581mentioned", "\u2581throughout", "\u2581the", "\u2581New", "\u2581Testament", "\u2581of", "\u2581the", "\u2581Bible", ",", "\u2581in", "\u2581books", "\u2581such", "\u2581as", "\u2581the", "\u2581G", "osp", "els", "\u2581(", "M", "att", "hew", ",", "\u2581Mark", ",", "\u2581Luke", ",", "\u2581and", "\u2581John", ")", "\u2581and", "\u2581the", "\u2581Act", "s", "\u2581of", "\u2581the", "\u2581Apost", "les", ".", "\u2581#", "1"]], "entropy": [[2.060546875, 1.7392578125, 0.00592803955078125, 0.0008320808410644531, 0.109130859375, 0.00038552284240722656, 0.0006880760192871094, 0.2015380859375, 0.58251953125, 0.213134765625, 0.0009593963623046875, 0.58203125, 0.0022144317626953125, 1.2724609375, 0.0014314651489257812, 0.1859130859375, 0.791015625, 1.8271484375, 0.9990234375, 0.114501953125, 0.00159454345703125, 0.383544921875, 0.029541015625, 0.447265625, 0.001026153564453125, 0.230712890625, 0.00664520263671875, 0.00042748451232910156, 0.0008068084716796875, 0.00693511962890625, 0.0026798248291015625, 0.007617950439453125, 0.0006403923034667969, 0.046417236328125, 0.12225341796875, 0.00287628173828125, 0.364990234375, 0.051300048828125, 0.0941162109375, 0.01119232177734375, 7.766485214233398e-05, 0.000759124755859375, 0.0005102157592773438, 0.003444671630859375, 0.00025844573974609375, 0.03125, 0.84033203125, 1.19140625]], "avg_entropy": [0.30356841161847115], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Acts 1:13", "score_of_biggest_cluster": 0.44556617736816406, "score_of_first_answer": 0.44556617736816406, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.44556617736816406, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.34212211196626785, "std_of_first_answer": 0.34212211196626785, "avg_entropy_of_first_answer": 0.30356841161847115, "lex_sim": 1.0}
{"question": "what is the 3rd largest state in usa", "answer": ["California #256: What Do Employers Really Want?"], "scores": [[0.947265625, 1.7881393432617188e-07, 0.030487060546875, 0.037506103515625, 0.07080078125, 0.0033321380615234375, 0.010894775390625, 2.9802322387695312e-05, 0.00016772747039794922, 0.97705078125, 0.51513671875, 0.050201416015625, 0.94921875, 0.60595703125, 1.0, 0.681640625]], "normalized_score": [0.02508939802646637], "tokens": [["\u2581California", "\u2581#", "2", "5", "6", ":", "\u2581What", "\u2581Do", "\u2581Emp", "loy", "ers", "\u2581Re", "ally", "\u2581W", "ant", "?"]], "entropy": [[0.359130859375, 0.87109375, 3.998046875, 2.984375, 3.57421875, 3.455078125, 4.10546875, 0.958984375, 1.7890625, 0.131591796875, 0.7001953125, 1.2353515625, 0.2086181640625, 1.208984375, 0.0011301040649414062, 1.3935546875]], "avg_entropy": [1.68593031167984], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Alaska", "score_of_biggest_cluster": 0.02508939802646637, "score_of_first_answer": 0.02508939802646637, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.02508939802646637, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41075140471802424, "std_of_first_answer": 0.41075140471802424, "avg_entropy_of_first_answer": 1.68593031167984, "lex_sim": 1.0}
{"question": "what are the main sources of economic growth in the us currently", "answer": ["Technology and innovation, improvements in the business environment, and increased consumer and business spending."], "scores": [[0.0046234130859375, 0.3369140625, 0.89208984375, 0.99951171875, 0.89892578125, 0.0008716583251953125, 0.9990234375, 0.0841064453125, 0.02655029296875, 0.52001953125, 0.953125, 0.65625, 0.06365966796875, 0.55126953125, 0.260009765625, 0.4716796875, 0.74658203125, 1.0, 0.92724609375, 0.0, 0.2034912109375, 0.005306243896484375, 0.052459716796875, 0.2529296875, 0.019256591796875, 0.0001285076141357422, 0.01076507568359375, 0.0010967254638671875, 0.888671875, 0.99560546875]], "normalized_score": [0.0], "tokens": [["\u2581Technology", "\u2581and", "\u2581innov", "ation", ",", "\u2581improvements", "\u2581in", "\u2581the", "\u2581business", "\u2581environment", ",", "\u2581and", "\u2581increased", "\u2581consumer", "\u2581and", "\u2581business", "\u2581sp", "ending", ".", "\u2581#####", "#", "\u2581", "1", ".", "\u2581The", "\u2581W", "itch", "ing", "\u2581H", "our"]], "entropy": [[3.419921875, 0.98388671875, 0.62109375, 0.002559661865234375, 0.5087890625, 2.197265625, 0.00804901123046875, 1.291015625, 0.386474609375, 1.23046875, 0.20947265625, 1.7822265625, 3.068359375, 1.26953125, 0.7333984375, 0.70947265625, 0.6025390625, 2.7954578399658203e-05, 0.37548828125, 0.399169921875, 1.7138671875, 1.228515625, 2.453125, 2.41796875, 3.70703125, 5.1875, 1.4052734375, 0.474365234375, 0.54150390625, 0.0283355712890625]], "avg_entropy": [1.2985565602779388], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "pharmaceuticals", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3981777394002235, "std_of_first_answer": 0.3981777394002235, "avg_entropy_of_first_answer": 1.2985565602779388, "lex_sim": 1.0}
{"question": "how many episodes of ray donovan series 3 are there", "answer": ["12 #112 - The Dale Earnhardt Jr. Podcast"], "scores": [[0.958984375, 0.720703125, 0.9951171875, 1.7881393432617188e-07, 0.007312774658203125, 0.0295562744140625, 0.082275390625, 0.00473785400390625, 0.0294647216796875, 0.002899169921875, 0.0003566741943359375, 0.1422119140625, 0.90576171875, 0.99951171875, 0.1640625, 0.98828125, 0.00016951560974121094, 0.9990234375]], "normalized_score": [0.0318162776529789], "tokens": [["\u2581", "1", "2", "\u2581#", "1", "1", "2", "\u2581-", "\u2581The", "\u2581D", "ale", "\u2581E", "arn", "hardt", "\u2581Jr", ".", "\u2581Pod", "cast"]], "entropy": [[0.24755859375, 0.7890625, 0.0345458984375, 0.859375, 4.3515625, 2.916015625, 3.6953125, 2.47265625, 4.47265625, 5.703125, 5.75, 4.15234375, 0.57763671875, 0.006103515625, 3.94140625, 0.11016845703125, 3.99609375, 0.01010894775390625]], "avg_entropy": [2.449207305908203], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "60", "score_of_biggest_cluster": 0.0318162776529789, "score_of_first_answer": 0.0318162776529789, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.0318162776529789, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4430508370641979, "std_of_first_answer": 0.4430508370641979, "avg_entropy_of_first_answer": 2.449207305908203, "lex_sim": 1.0}
{"question": "who sold the most records elvis or the beatles", "answer": ["The Beatles CHAPTER 7: THE SPIDER"], "scores": [[0.37353515625, 1.0, 1.0, 0.0, 0.275390625, 0.0301513671875, 0.404296875, 0.0255126953125, 0.01027679443359375, 0.026885986328125, 0.9921875]], "normalized_score": [0.0], "tokens": [["\u2581The", "\u2581Beat", "les", "\u2581CHAPTER", "\u2581", "7", ":", "\u2581THE", "\u2581SP", "ID", "ER"]], "entropy": [[1.130859375, 0.0008463859558105469, 4.470348358154297e-05, 1.3037109375, 2.34375, 1.7216796875, 2.4140625, 3.048828125, 4.2890625, 2.576171875, 0.0533447265625]], "avg_entropy": [1.716578256000172], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The Beatles", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4055109347653111, "std_of_first_answer": 0.4055109347653111, "avg_entropy_of_first_answer": 1.716578256000172, "lex_sim": 1.0}
{"question": "when was the last time new england had a hurricane", "answer": ["1991 (Hurricane Bob)"], "scores": [[0.2249755859375, 0.94482421875, 1.0, 0.76171875, 0.99853515625, 0.27587890625, 0.288818359375, 1.0, 1.0, 0.9990234375, 0.99267578125]], "normalized_score": [0.6727471947669983], "tokens": [["\u2581", "1", "9", "9", "1", "\u2581(", "H", "urr", "icane", "\u2581Bob", ")"]], "entropy": [[1.19921875, 0.2164306640625, 0.0021209716796875, 0.80224609375, 0.0141143798828125, 1.744140625, 0.8486328125, 0.0014171600341796875, 2.8431415557861328e-05, 0.0089569091796875, 0.05181884765625]], "avg_entropy": [0.4444659677418796], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Hurricane Hanna", "score_of_biggest_cluster": 0.6727471947669983, "score_of_first_answer": 0.6727471947669983, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.2249755859375, "avg_score": 0.6727471947669983, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.31856426215713707, "std_of_first_answer": 0.31856426215713707, "avg_entropy_of_first_answer": 0.4444659677418796, "lex_sim": 1.0}
{"question": "who sings love me tender in princess diaries 2", "answer": ["Elvis Presley"], "scores": [[0.65771484375, 0.998046875, 0.99560546875, 0.99951171875]], "normalized_score": [0.8990129232406616], "tokens": [["\u2581El", "vis", "\u2581Pres", "ley"]], "entropy": [[2.0078125, 0.0167236328125, 0.033905029296875, 0.0039825439453125]], "avg_entropy": [0.5156059265136719], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Norah Jones", "score_of_biggest_cluster": 0.8990129232406616, "score_of_first_answer": 0.8990129232406616, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.65771484375, "avg_score": 0.8990129232406616, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.14723375010891676, "std_of_first_answer": 0.14723375010891676, "avg_entropy_of_first_answer": 0.5156059265136719, "lex_sim": 1.0}
{"question": "where in the bible can i find the lord's prayer", "answer": ["In Matthew 6:9-13 and Luke 11:2-4 #61 - Narcissistic Personality Disorder in Law Enforcement"], "scores": [[0.0186767578125, 0.253173828125, 0.9873046875, 1.0, 0.99609375, 0.99951171875, 0.99853515625, 1.0, 1.0, 0.41796875, 0.98291015625, 1.0, 1.0, 1.0, 1.0, 0.99755859375, 1.0, 0.9990234375, 1.1920928955078125e-07, 2.8848648071289062e-05, 0.0833740234375, 0.0017719268798828125, 0.00037384033203125, 2.562999725341797e-05, 0.96435546875, 0.44384765625, 0.04791259765625, 0.9970703125, 0.71240234375, 0.99951171875, 0.0036449432373046875, 1.9669532775878906e-06, 0.3720703125, 0.99951171875, 0.99951171875]], "normalized_score": [0.09093141555786133], "tokens": [["\u2581In", "\u2581Matthew", "\u2581", "6", ":", "9", "-", "1", "3", "\u2581and", "\u2581Luke", "\u2581", "1", "1", ":", "2", "-", "4", "\u2581#", "6", "1", "\u2581-", "\u2581N", "arc", "iss", "istic", "\u2581Person", "ality", "\u2581Dis", "order", "\u2581in", "\u2581Law", "\u2581En", "for", "cement"]], "entropy": [[0.7646484375, 0.65625, 0.086181640625, 0.0005526542663574219, 0.0347900390625, 0.004856109619140625, 0.01119232177734375, 0.0005240440368652344, 0.00160980224609375, 1.857421875, 0.10235595703125, 0.0019159317016601562, 9.304285049438477e-05, 0.00208282470703125, 0.0013418197631835938, 0.0192413330078125, 0.00012385845184326172, 0.00954437255859375, 1.3212890625, 1.69140625, 3.541015625, 2.830078125, 3.85546875, 0.5361328125, 0.229248046875, 1.4814453125, 5.10546875, 0.025390625, 1.1826171875, 0.005100250244140625, 2.37109375, 2.24609375, 1.7509765625, 0.005889892578125, 0.004367828369140625]], "avg_entropy": [0.9067945327077593], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the Gospel of Matthew", "score_of_biggest_cluster": 0.09093141555786133, "score_of_first_answer": 0.09093141555786133, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.09093141555786133, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43938195286418225, "std_of_first_answer": 0.43938195286418225, "avg_entropy_of_first_answer": 0.9067945327077593, "lex_sim": 1.0}
{"question": "who does eric end up with in that 70s show", "answer": ["Donna Pinciotti"], "scores": [[0.89306640625, 1.0, 0.7666015625, 0.9990234375, 1.0]], "normalized_score": [0.9268422722816467], "tokens": [["\u2581Don", "na", "\u2581P", "inci", "otti"]], "entropy": [[0.5966796875, 3.731250762939453e-05, 0.76318359375, 0.01181793212890625, 0.0014190673828125]], "avg_entropy": [0.27462751865386964], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Donna", "score_of_biggest_cluster": 0.9268422722816467, "score_of_first_answer": 0.9268422722816467, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.7666015625, "avg_score": 0.9268422722816467, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.09231713442316908, "std_of_first_answer": 0.09231713442316908, "avg_entropy_of_first_answer": 0.27462751865386964, "lex_sim": 1.0}
{"question": "who appoints the chief election commissioner of india", "answer": ["President of India ######"], "scores": [[0.43115234375, 0.9814453125, 1.0, 0.0, 0.4716796875]], "normalized_score": [0.0], "tokens": [["\u2581President", "\u2581of", "\u2581India", "\u2581#####", "#"]], "entropy": [[0.96875, 0.11236572265625, 0.0007352828979492188, 1.4013671875, 2.3828125]], "avg_entropy": [0.9732061386108398], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "President of India", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.3762440201293643, "std_of_first_answer": 0.3762440201293643, "avg_entropy_of_first_answer": 0.9732061386108398, "lex_sim": 1.0}
{"question": "when did earth's atmosphere change due to living organisms", "answer": ["The atmosphere has been continuously changing for billions of years as a result of natural processes and the presence of living organisms."], "scores": [[0.178466796875, 0.1802978515625, 0.70751953125, 0.81494140625, 0.0021495819091796875, 1.0, 0.99462890625, 0.432861328125, 0.84912109375, 1.0, 0.99951171875, 0.99951171875, 0.1226806640625, 0.99267578125, 1.0, 1.0, 0.326904296875, 0.9638671875, 0.448486328125, 0.53076171875, 0.2264404296875, 0.99853515625, 0.99267578125, 1.0, 0.99951171875, 0.95703125, 0.303466796875, 0.57568359375, 0.16845703125, 0.9990234375, 0.10498046875, 0.50146484375, 0.9931640625, 0.02020263671875, 0.5126953125, 0.3984375, 0.99951171875, 0.27734375, 0.0487060546875, 0.3896484375, 0.6376953125, 0.5166015625, 5.960464477539063e-08, 2.682209014892578e-06, 0.8681640625]], "normalized_score": [0.23429572582244873], "tokens": [["\u2581The", "\u2581atmosphere", "\u2581has", "\u2581been", "\u2581continu", "ously", "\u2581changing", "\u2581for", "\u2581bill", "ions", "\u2581of", "\u2581years", "\u2581as", "\u2581a", "\u2581result", "\u2581of", "\u2581natural", "\u2581processes", "\u2581and", "\u2581the", "\u2581presence", "\u2581of", "\u2581living", "\u2581organ", "isms", ".", "\u2581The", "\u2581exact", "\u2581tim", "eline", "\u2581is", "\u2581complex", "\u2581and", "\u2581can", "\u2581be", "\u2581attributed", "\u2581to", "\u2581various", "\u2581events", "\u2581and", "\u2581factors", ".", "\u2581###", "\u2581Sum", "mary"]], "entropy": [[3.6328125, 1.2822265625, 0.92822265625, 0.62548828125, 0.222900390625, 0.00039696693420410156, 0.03857421875, 1.5, 0.67724609375, 0.0003724098205566406, 0.005115509033203125, 0.005161285400390625, 1.109375, 0.053466796875, 0.0026760101318359375, 0.0011577606201171875, 1.3818359375, 0.218017578125, 1.2490234375, 1.3203125, 1.81640625, 0.01255035400390625, 0.04620361328125, 0.0003657341003417969, 0.0034351348876953125, 0.2305908203125, 1.71484375, 1.9853515625, 1.435546875, 0.00916290283203125, 0.767578125, 1.46875, 0.04620361328125, 3.095703125, 1.21484375, 1.1865234375, 0.005741119384765625, 1.546875, 0.408935546875, 1.8076171875, 1.6357421875, 1.4931640625, 0.689453125, 5.734375, 0.68505859375]], "avg_entropy": [0.9621200614505344], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "around 2.45\u00a0billion years ago", "score_of_biggest_cluster": 0.23429572582244873, "score_of_first_answer": 0.23429572582244873, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.23429572582244873, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.36909052685613, "std_of_first_answer": 0.36909052685613, "avg_entropy_of_first_answer": 0.9621200614505344, "lex_sim": 1.0}
{"question": "french film pioneer who introduced newsreel in 1910", "answer": ["Charles Path\u00e9"], "scores": [[0.1551513671875, 0.857421875, 0.990234375]], "normalized_score": [0.5088183283805847], "tokens": [["\u2581Charles", "\u2581Path", "\u00e9"]], "entropy": [[1.9111328125, 0.64599609375, 0.070556640625]], "avg_entropy": [0.8758951822916666], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Charles Path\u00e9", "score_of_biggest_cluster": 0.5088183283805847, "score_of_first_answer": 0.5088183283805847, "max_score_of_first_answer": 0.990234375, "min_score_of_first_answer": 0.1551513671875, "avg_score": 0.5088183283805847, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.36639181459753173, "std_of_first_answer": 0.36639181459753173, "avg_entropy_of_first_answer": 0.8758951822916666, "lex_sim": 1.0}
{"question": "who developed the first printing press in 1430s", "answer": ["Johannes Gutenberg #115 \u2013 The Best Thing I Ever Ate"], "scores": [[0.95556640625, 0.99951171875, 0.99853515625, 0.9990234375, 7.748603820800781e-07, 0.08209228515625, 0.035552978515625, 0.08087158203125, 8.785724639892578e-05, 0.0200653076171875, 0.0007123947143554688, 0.0015401840209960938, 0.978515625, 0.0020809173583984375, 0.66064453125, 0.77685546875, 0.9462890625]], "normalized_score": [0.03632185235619545], "tokens": [["\u2581Johannes", "\u2581G", "uten", "berg", "\u2581#", "1", "1", "5", "\u2581\u2013", "\u2581The", "\u2581Best", "\u2581Th", "ing", "\u2581I", "\u2581Ever", "\u2581A", "te"]], "entropy": [[0.219970703125, 0.0035076141357421875, 0.0111083984375, 0.0065155029296875, 0.88818359375, 5.5703125, 3.02734375, 2.9765625, 2.638671875, 4.13671875, 4.171875, 3.642578125, 0.1436767578125, 2.294921875, 1.47265625, 0.92724609375, 0.33056640625]], "avg_entropy": [1.9095538644229664], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Johannes Gutenberg", "score_of_biggest_cluster": 0.03632185235619545, "score_of_first_answer": 0.03632185235619545, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 7.748603820800781e-07, "avg_score": 0.03632185235619545, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.45197124070054534, "std_of_first_answer": 0.45197124070054534, "avg_entropy_of_first_answer": 1.9095538644229664, "lex_sim": 1.0}
{"question": "where does the paraguay river start and end", "answer": ["The Paraguay River starts in the Brazilian highlands and runs through Brazil, Bolivia, Paraguay, and Argentina, emptying into the Parana River."], "scores": [[0.603515625, 0.990234375, 0.99560546875, 1.0, 0.89306640625, 0.78271484375, 0.97216796875, 0.93994140625, 0.35693359375, 0.99951171875, 0.6962890625, 0.9990234375, 0.93798828125, 0.1092529296875, 0.9736328125, 0.97216796875, 0.994140625, 0.640625, 1.0, 0.9970703125, 0.95068359375, 1.0, 1.0, 0.9296875, 0.9990234375, 0.99755859375, 0.390869140625, 0.269775390625, 0.99951171875, 0.99853515625, 1.0, 0.79345703125, 0.4560546875, 0.95849609375, 0.66796875, 8.344650268554688e-07, 0.00012600421905517578, 5.334615707397461e-05, 0.0114898681640625, 0.0004031658172607422, 0.007476806640625, 0.69091796875, 0.10699462890625, 0.1456298828125, 0.004917144775390625, 4.023313522338867e-05, 0.01399993896484375, 0.83447265625]], "normalized_score": [0.17596426606178284], "tokens": [["\u2581The", "\u2581Par", "agu", "ay", "\u2581River", "\u2581starts", "\u2581in", "\u2581the", "\u2581Brazil", "ian", "\u2581high", "lands", "\u2581and", "\u2581runs", "\u2581through", "\u2581Brazil", ",", "\u2581Boliv", "ia", ",", "\u2581Par", "agu", "ay", ",", "\u2581and", "\u2581Argentina", ",", "\u2581empty", "ing", "\u2581into", "\u2581the", "\u2581Par", "ana", "\u2581River", ".", "\u2581#", "Ch", "ap", "ters", "Read", "2", "0", "1", "7", ":", "\u2581Our", "\u2581F", "avor"]], "entropy": [[1.2548828125, 0.08038330078125, 0.032501220703125, 0.0006198883056640625, 0.342041015625, 0.79736328125, 0.133544921875, 0.324462890625, 1.4013671875, 0.0029277801513671875, 0.73974609375, 0.006717681884765625, 0.3037109375, 1.2998046875, 0.1739501953125, 0.198974609375, 0.041473388671875, 0.77783203125, 8.755922317504883e-05, 0.0230560302734375, 0.201171875, 0.0012998580932617188, 0.0006856918334960938, 0.25830078125, 0.00815582275390625, 0.0240020751953125, 1.171875, 2.150390625, 0.0024089813232421875, 0.01146697998046875, 0.0017480850219726562, 0.955078125, 1.03515625, 0.2025146484375, 1.1142578125, 0.6435546875, 3.474609375, 1.0634765625, 3.619140625, 2.787109375, 2.576171875, 1.4912109375, 2.046875, 1.849609375, 1.3876953125, 2.298828125, 6.07421875, 0.662109375]], "avg_entropy": [0.9385118645926317], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Paran\u00e1 River", "score_of_biggest_cluster": 0.17596426606178284, "score_of_first_answer": 0.17596426606178284, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 8.344650268554688e-07, "avg_score": 0.17596426606178284, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39861937488203014, "std_of_first_answer": 0.39861937488203014, "avg_entropy_of_first_answer": 0.9385118645926317, "lex_sim": 1.0}
{"question": "what was the emperor name in star wars", "answer": ["Palpatine #8: The Ultimatum"], "scores": [[0.91162109375, 1.0, 1.0, 5.841255187988281e-06, 0.001888275146484375, 0.0060577392578125, 0.07623291015625, 0.0006995201110839844, 0.0001195669174194336, 0.99951171875]], "normalized_score": [0.014417959377169609], "tokens": [["\u2581Pal", "pat", "ine", "\u2581#", "8", ":", "\u2581The", "\u2581Ult", "imat", "um"]], "entropy": [[0.492919921875, 0.0004086494445800781, 3.5643577575683594e-05, 1.07421875, 4.55859375, 2.96484375, 3.76171875, 1.744140625, 0.0032329559326171875, 0.0033054351806640625]], "avg_entropy": [1.4603418231010437], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Darth Sidious", "score_of_biggest_cluster": 0.014417959377169609, "score_of_first_answer": 0.014417959377169609, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.841255187988281e-06, "avg_score": 0.014417959377169609, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.47318263828201235, "std_of_first_answer": 0.47318263828201235, "avg_entropy_of_first_answer": 1.4603418231010437, "lex_sim": 1.0}
{"question": "who is the first prime minister of france", "answer": ["Jean-Pierre Raffarin #BookReview: The Wives by Tarryn Fisher @TarrynFisher @GalleryBooks"], "scores": [[0.2939453125, 0.95166015625, 0.450439453125, 0.99462890625, 1.0, 1.0, 5.781650543212891e-06, 0.00017976760864257812, 0.00995635986328125, 0.58984375, 0.1500244140625, 0.1121826171875, 0.007030487060546875, 0.0144195556640625, 0.072509765625, 0.826171875, 0.912109375, 0.8076171875, 0.97705078125, 0.99951171875, 0.13330078125, 0.7685546875, 0.99951171875, 0.99951171875, 0.998046875, 0.9189453125, 0.9990234375, 0.327880859375, 0.0139312744140625, 0.93701171875, 0.998046875, 0.99951171875]], "normalized_score": [0.19600547850131989], "tokens": [["\u2581Jean", "-", "Pierre", "\u2581R", "aff", "arin", "\u2581#", "Book", "Re", "view", ":", "\u2581The", "\u2581W", "ives", "\u2581by", "\u2581Tar", "ry", "n", "\u2581Fish", "er", "\u2581@", "T", "ar", "ry", "n", "F", "isher", "\u2581@", "G", "allery", "Book", "s"]], "entropy": [[2.568359375, 0.366455078125, 0.9658203125, 0.052734375, 0.0003476142883300781, 0.0021495819091796875, 0.640625, 5.7578125, 4.80859375, 0.76220703125, 2.703125, 3.53515625, 6.0234375, 3.55859375, 0.736328125, 1.0966796875, 0.54541015625, 0.609375, 0.16552734375, 0.0036411285400390625, 2.33984375, 1.0478515625, 0.00319671630859375, 0.00513458251953125, 0.01448822021484375, 0.455810546875, 0.009124755859375, 1.72265625, 4.56640625, 0.42529296875, 0.0165557861328125, 0.0035686492919921875]], "avg_entropy": [1.4222596436738968], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Michel Debr\u00e9", "score_of_biggest_cluster": 0.19600547850131989, "score_of_first_answer": 0.19600547850131989, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.781650543212891e-06, "avg_score": 0.19600547850131989, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4154808068323654, "std_of_first_answer": 0.4154808068323654, "avg_entropy_of_first_answer": 1.4222596436738968, "lex_sim": 1.0}
{"question": "when was the last time the crows were in the grand final", "answer": ["The last time the Crows won the AFL Grand Final was in 1998."], "scores": [[0.202392578125, 0.50341796875, 0.9990234375, 0.99462890625, 0.476318359375, 0.99951171875, 0.25927734375, 0.99755859375, 0.91064453125, 0.99755859375, 0.9296875, 0.9990234375, 0.99853515625, 0.99755859375, 0.97509765625, 0.32421875, 1.0, 0.9990234375, 0.95263671875, 0.94921875, 6.556510925292969e-07, 1.8656253814697266e-05, 0.0303802490234375, 0.0011510848999023438, 0.00257110595703125, 0.541015625, 0.031341552734375, 2.3365020751953125e-05, 0.289794921875, 0.99951171875, 0.52978515625, 0.002574920654296875, 0.07659912109375, 0.0582275390625, 0.64697265625, 0.8681640625, 0.142822265625, 0.9599609375, 0.87353515625]], "normalized_score": [0.13584846258163452], "tokens": [["\u2581The", "\u2581last", "\u2581time", "\u2581the", "\u2581C", "rows", "\u2581won", "\u2581the", "\u2581A", "FL", "\u2581Grand", "\u2581Final", "\u2581was", "\u2581in", "\u2581", "1", "9", "9", "8", ".", "\u2581#", "7", "1", ":", "\u2581What", "\u2581is", "\u2581a", "\u2581Sales", "\u2581F", "unnel", "?", "\u2581And", "\u2581Why", "\u2581You", "\u2581Need", "\u2581One", "\u2581for", "\u2581Your", "\u2581Business"]], "entropy": [[1.763671875, 1.794921875, 0.0075836181640625, 0.04595947265625, 2.044921875, 0.004070281982421875, 1.4130859375, 0.0197296142578125, 0.3720703125, 0.0198516845703125, 0.322509765625, 0.0091552734375, 0.01375579833984375, 0.0182342529296875, 0.12030029296875, 0.6298828125, 7.092952728271484e-06, 0.0093994140625, 0.19189453125, 0.26318359375, 0.84033203125, 1.9638671875, 3.990234375, 4.1875, 5.1328125, 2.46484375, 1.4423828125, 5.796875, 3.455078125, 0.0033416748046875, 1.958984375, 2.794921875, 3.53515625, 1.9775390625, 1.060546875, 0.497802734375, 3.123046875, 0.3408203125, 0.70849609375]], "avg_entropy": [1.3933018277852962], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2017", "score_of_biggest_cluster": 0.13584846258163452, "score_of_first_answer": 0.13584846258163452, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 6.556510925292969e-07, "avg_score": 0.13584846258163452, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4130147762386289, "std_of_first_answer": 0.4130147762386289, "avg_entropy_of_first_answer": 1.3933018277852962, "lex_sim": 1.0}
{"question": "what do you call a person who officiates a wedding", "answer": ["minister, priest, rabbi, justice of the peace, etc."], "scores": [[0.0183563232421875, 0.1275634765625, 0.41748046875, 0.94384765625, 0.4404296875, 1.0, 0.939453125, 0.1845703125, 0.99951171875, 0.99951171875, 1.0, 0.54541015625, 0.69189453125, 0.98291015625, 5.960464477539063e-08, 0.004779815673828125, 0.057373046875, 0.0005235671997070312, 0.06396484375, 0.0523681640625, 0.01074981689453125, 0.33447265625, 0.026947021484375, 0.87744140625, 0.94384765625, 0.95947265625, 0.95751953125, 0.00821685791015625]], "normalized_score": [0.10554693639278412], "tokens": [["\u2581minister", ",", "\u2581priest", ",", "\u2581ra", "bbi", ",", "\u2581justice", "\u2581of", "\u2581the", "\u2581peace", ",", "\u2581etc", ".", "\u2581#", "9", "1", "\u2581", "2", "8", "-", "0", "1", "-", "2", "0", "2", "0"]], "entropy": [[1.201171875, 1.51953125, 2.06640625, 0.253173828125, 1.08203125, 0.002193450927734375, 0.292236328125, 1.6279296875, 0.0038013458251953125, 0.004749298095703125, 0.00047969818115234375, 1.1171875, 1.11328125, 0.10296630859375, 0.77294921875, 5.4375, 2.73828125, 2.375, 3.642578125, 2.978515625, 3.255859375, 2.837890625, 1.375, 0.662109375, 0.30078125, 0.2666015625, 0.2130126953125, 0.7392578125]], "avg_entropy": [1.3565170083727156], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "vow master", "score_of_biggest_cluster": 0.10554693639278412, "score_of_first_answer": 0.10554693639278412, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.10554693639278412, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42084807983219574, "std_of_first_answer": 0.42084807983219574, "avg_entropy_of_first_answer": 1.3565170083727156, "lex_sim": 1.0}
{"question": "how long did the democrats control the house and senate", "answer": ["The Democrats controlled the House of Representatives from 2007 to 2011 and the Senate from 2007 to 2015."], "scores": [[0.31201171875, 0.57470703125, 1.0, 0.36474609375, 0.99462890625, 0.99169921875, 0.88916015625, 0.99951171875, 0.86181640625, 0.791015625, 1.0, 1.0, 0.9541015625, 0.99755859375, 0.732421875, 0.99853515625, 1.0, 1.0, 1.0, 0.99951171875, 0.6435546875, 0.8369140625, 0.9755859375, 0.99853515625, 0.9990234375, 1.0, 1.0, 0.990234375, 0.1331787109375, 0.994140625, 0.99853515625, 1.0, 1.0, 0.99951171875, 0.998046875, 0.9462890625, 1.5497207641601562e-06, 0.0009069442749023438, 6.151199340820312e-05, 0.02325439453125, 0.00030112266540527344, 0.00433349609375, 0.88671875, 0.21533203125, 0.0012302398681640625, 0.00318145751953125, 0.8271484375, 0.06341552734375]], "normalized_score": [0.22884562611579895], "tokens": [["\u2581The", "\u2581Democr", "ats", "\u2581controlled", "\u2581the", "\u2581House", "\u2581of", "\u2581Representatives", "\u2581from", "\u2581", "2", "0", "0", "7", "\u2581to", "\u2581", "2", "0", "1", "1", "\u2581and", "\u2581the", "\u2581Senate", "\u2581from", "\u2581", "2", "0", "0", "7", "\u2581to", "\u2581", "2", "0", "1", "5", ".", "\u2581#", "4", "\u2581\u2013", "\u2581The", "\u2581W", "onders", "\u2581of", "\u2581the", "\u2581Deep", "\u2581Blue", "\u2581Sea", ":"]], "entropy": [[2.330078125, 0.9833984375, 0.0001266002655029297, 1.892578125, 0.0362548828125, 0.061309814453125, 0.435546875, 0.004581451416015625, 0.57080078125, 0.64111328125, 0.002017974853515625, 0.00028824806213378906, 0.1868896484375, 0.01873779296875, 0.615234375, 0.00995635986328125, 3.6776065826416016e-05, 0.0003833770751953125, 0.0005035400390625, 0.005405426025390625, 0.77294921875, 0.79736328125, 0.143798828125, 0.01274871826171875, 0.00685882568359375, 0.00011521577835083008, 9.119510650634766e-06, 0.054718017578125, 0.461181640625, 0.03936767578125, 0.0099029541015625, 2.855062484741211e-05, 0.0001347064971923828, 0.00592803955078125, 0.0184326171875, 0.30810546875, 0.8447265625, 2.5, 3.177734375, 3.431640625, 2.7109375, 2.828125, 0.64599609375, 3.287109375, 2.2890625, 3.607421875, 1.23046875, 3.09765625]], "avg_entropy": [0.8349534099300703], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "57 yrs", "score_of_biggest_cluster": 0.22884562611579895, "score_of_first_answer": 0.22884562611579895, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.5497207641601562e-06, "avg_score": 0.22884562611579895, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3953392199594994, "std_of_first_answer": 0.3953392199594994, "avg_entropy_of_first_answer": 0.8349534099300703, "lex_sim": 1.0}
{"question": "who began the age of exploration in portugal", "answer": ["Henry the Navigator #664: The Ballad of Janis Joplin by Big Brother and the Holding Company"], "scores": [[0.53515625, 0.9990234375, 0.9990234375, 0.99853515625, 1.7881393432617188e-07, 0.0015039443969726562, 0.0709228515625, 0.047515869140625, 0.00029778480529785156, 0.0228271484375, 8.344650268554688e-07, 0.9013671875, 0.984375, 0.00038909912109375, 0.08795166015625, 0.36083984375, 1.0, 0.99951171875, 0.0151519775390625, 0.1700439453125, 0.99853515625, 0.99951171875, 0.978515625, 0.9921875, 0.99755859375, 1.0, 0.99609375]], "normalized_score": [0.07032564282417297], "tokens": [["\u2581Henry", "\u2581the", "\u2581N", "avigator", "\u2581#", "6", "6", "4", ":", "\u2581The", "\u2581Ball", "ad", "\u2581of", "\u2581Jan", "is", "\u2581J", "op", "lin", "\u2581by", "\u2581Big", "\u2581Bro", "ther", "\u2581and", "\u2581the", "\u2581Hold", "ing", "\u2581Company"]], "entropy": [[1.02734375, 0.00794219970703125, 0.0100555419921875, 0.013641357421875, 0.892578125, 5.06640625, 3.365234375, 2.2421875, 2.666015625, 4.3828125, 2.666015625, 0.7197265625, 0.10699462890625, 3.326171875, 4.625, 2.490234375, 0.0024814605712890625, 0.0035800933837890625, 3.05859375, 4.4375, 0.01445770263671875, 0.0042877197265625, 0.1376953125, 0.059051513671875, 0.02313232421875, 3.540515899658203e-05, 0.03363037109375]], "avg_entropy": [1.5326965164255213], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "King Dinis of Portugal", "score_of_biggest_cluster": 0.07032564282417297, "score_of_first_answer": 0.07032564282417297, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.07032564282417297, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.45752061129265365, "std_of_first_answer": 0.45752061129265365, "avg_entropy_of_first_answer": 1.5326965164255213, "lex_sim": 1.0}
{"question": "when does season 13 of america's got talent premiere", "answer": ["I do not have the latest information."], "scores": [[0.241455078125, 0.1297607421875, 0.99951171875, 0.794921875, 0.08258056640625, 0.0268096923828125, 0.94287109375, 0.102294921875, 0.0726318359375, 0.52880859375, 0.86279296875, 0.9990234375, 0.93212890625, 0.62255859375, 0.7919921875, 0.91357421875, 0.76318359375, 0.257568359375, 0.2215576171875, 0.93603515625, 0.85693359375, 0.287841796875, 1.0, 0.99658203125, 0.478271484375, 0.5302734375, 0.998046875, 1.0, 0.99853515625, 0.99951171875, 1.0, 0.381591796875, 2.5033950805664062e-06, 0.0009660720825195312, 0.02569580078125, 0.99169921875, 0.00241851806640625, 0.04974365234375, 0.0106353759765625]], "normalized_score": [0.2122919112443924], "tokens": [["\u2581I", "\u2581do", "\u2581not", "\u2581have", "\u2581the", "\u2581latest", "\u2581information", ".", "\u2581It", "\u2581is", "\u2581best", "\u2581to", "\u2581check", "\u2581the", "\u2581official", "\u2581website", "\u2581or", "\u2581other", "\u2581sources", "\u2581for", "\u2581the", "\u2581premi", "ere", "\u2581date", "\u2581of", "\u2581America", "'", "s", "\u2581Got", "\u2581Tal", "ent", ".", "\u2581#", "M", "ov", "ies", "Music", "and", "More"]], "entropy": [[2.451171875, 1.2265625, 0.005184173583984375, 0.5166015625, 1.2373046875, 1.90234375, 0.37939453125, 1.4072265625, 2.197265625, 1.30859375, 0.599609375, 0.00930023193359375, 0.343017578125, 1.2255859375, 0.98681640625, 0.498291015625, 0.7060546875, 1.8671875, 0.83251953125, 0.30078125, 0.8095703125, 1.5595703125, 6.884336471557617e-05, 0.024688720703125, 0.72265625, 1.310546875, 0.01617431640625, 0.00014829635620117188, 0.01100921630859375, 0.0024662017822265625, 0.0008301734924316406, 1.1513671875, 0.75048828125, 4.515625, 3.587890625, 0.06951904296875, 1.7431640625, 2.7265625, 0.82421875]], "avg_entropy": [1.0212148076448686], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "May 29, 2018", "score_of_biggest_cluster": 0.2122919112443924, "score_of_first_answer": 0.2122919112443924, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.5033950805664062e-06, "avg_score": 0.2122919112443924, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39734741385834316, "std_of_first_answer": 0.39734741385834316, "avg_entropy_of_first_answer": 1.0212148076448686, "lex_sim": 1.0}
{"question": "where are antibodies made and by what type of lymphocyte", "answer": ["Antibodies are made by a type of lymphocyte called B cells."], "scores": [[0.95166015625, 0.99951171875, 0.99951171875, 1.0, 0.99853515625, 0.75634765625, 0.974609375, 0.0751953125, 0.98779296875, 0.99951171875, 0.319091796875, 1.0, 1.0, 1.0, 0.97900390625, 0.9873046875, 0.9365234375, 0.951171875, 0.90673828125, 0.82763671875, 0.99365234375, 0.888671875, 0.89013671875, 0.297607421875, 0.99951171875, 0.74951171875, 0.302490234375, 0.92919921875, 0.9912109375, 1.0, 0.337158203125, 0.79541015625, 0.87451171875, 0.99951171875, 0.5146484375, 0.2666015625, 0.93603515625, 0.8203125, 0.99951171875, 0.986328125, 0.95166015625, 0.96337890625, 0.93798828125, 0.99951171875, 0.94140625, 0.347900390625, 1.0, 0.99462890625, 1.0, 0.12066650390625]], "normalized_score": [0.745887815952301], "tokens": [["\u2581Ant", "ib", "od", "ies", "\u2581are", "\u2581made", "\u2581by", "\u2581a", "\u2581type", "\u2581of", "\u2581l", "ym", "ph", "ocy", "te", "\u2581called", "\u2581B", "\u2581cells", ".", "\u2581They", "\u2581are", "\u2581produced", "\u2581in", "\u2581response", "\u2581to", "\u2581an", "\u2581inv", "ading", "\u2581path", "ogen", "\u2581or", "\u2581foreign", "\u2581subst", "ance", "\u2581and", "\u2581help", "\u2581to", "\u2581neutral", "ize", "\u2581or", "\u2581destroy", "\u2581the", "\u2581path", "ogen", ".", "\u2581Ant", "ib", "od", "ies", "\u2581can"]], "entropy": [[0.259521484375, 0.004390716552734375, 0.0032787322998046875, 5.900859832763672e-06, 0.01172637939453125, 0.642578125, 0.1251220703125, 0.6650390625, 0.0714111328125, 0.0038890838623046875, 1.0380859375, 1.4007091522216797e-05, 7.05718994140625e-05, 0.0009937286376953125, 0.10296630859375, 0.071044921875, 0.262451171875, 0.2049560546875, 0.4658203125, 0.6357421875, 0.042572021484375, 0.47216796875, 0.388671875, 0.77783203125, 0.00455474853515625, 0.7939453125, 1.2626953125, 0.258544921875, 0.06488037109375, 0.0006866455078125, 1.13671875, 0.79541015625, 0.407470703125, 0.00247955322265625, 1.3134765625, 1.6337890625, 0.333740234375, 0.771484375, 0.004337310791015625, 0.08892822265625, 0.234130859375, 0.1876220703125, 0.346435546875, 0.005901336669921875, 0.282958984375, 1.3720703125, 0.001590728759765625, 0.0341796875, 7.748603820800781e-06, 0.380615234375]], "avg_entropy": [0.35938013076782227], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "B cells", "score_of_biggest_cluster": 0.745887815952301, "score_of_first_answer": 0.745887815952301, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0751953125, "avg_score": 0.745887815952301, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.26696099624717984, "std_of_first_answer": 0.26696099624717984, "avg_entropy_of_first_answer": 0.35938013076782227, "lex_sim": 1.0}
{"question": "who's opening for foo fighters at fenway", "answer": ["There is no specific opening act currently announced for Foo Fighters at Fenway."], "scores": [[0.00211334228515625, 0.1138916015625, 0.9521484375, 0.02349853515625, 0.26806640625, 0.96044921875, 0.0275115966796875, 0.748046875, 0.97802734375, 0.70849609375, 0.99951171875, 1.0, 1.0, 0.5087890625, 0.99951171875, 1.0, 0.53369140625, 2.384185791015625e-07, 4.291534423828125e-05, 0.0029201507568359375, 0.336181640625, 0.01505279541015625, 0.67529296875, 0.024658203125]], "normalized_score": [0.08358003944158554], "tokens": [["\u2581There", "\u2581is", "\u2581no", "\u2581specific", "\u2581opening", "\u2581act", "\u2581currently", "\u2581announced", "\u2581for", "\u2581Foo", "\u2581F", "igh", "ters", "\u2581at", "\u2581Fen", "way", ".", "\u2581Proof", "\u2581That", "\u2581There", "\u2581Is", "\u2581a", "\u2581God", "!"]], "entropy": [[2.576171875, 0.67919921875, 0.26220703125, 1.130859375, 0.94140625, 0.1905517578125, 1.705078125, 0.81689453125, 0.138671875, 0.64306640625, 0.0025348663330078125, 0.00035262107849121094, 0.00013577938079833984, 0.73486328125, 0.0031719207763671875, 0.00127410888671875, 0.9833984375, 1.4619140625, 2.091796875, 3.033203125, 1.490234375, 1.9326171875, 2.279296875, 3.1484375]], "avg_entropy": [1.0936390608549118], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "N/A", "score_of_biggest_cluster": 0.08358003944158554, "score_of_first_answer": 0.08358003944158554, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.08358003944158554, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4166518674368703, "std_of_first_answer": 0.4166518674368703, "avg_entropy_of_first_answer": 1.0936390608549118, "lex_sim": 1.0}
{"question": "who owned the colts when they left baltimore", "answer": ["Robert Irsay"], "scores": [[0.06634521484375, 0.99951171875, 1.0, 1.0]], "normalized_score": [0.5074571371078491], "tokens": [["\u2581Robert", "\u2581I", "rs", "ay"]], "entropy": [[0.95703125, 0.003696441650390625, 0.0005540847778320312, 5.900859832763672e-06]], "avg_entropy": [0.24032191932201385], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Robert Irsay", "score_of_biggest_cluster": 0.5074571371078491, "score_of_first_answer": 0.5074571371078491, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.06634521484375, "avg_score": 0.5074571371078491, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4042139529800476, "std_of_first_answer": 0.4042139529800476, "avg_entropy_of_first_answer": 0.24032191932201385, "lex_sim": 1.0}
{"question": "which battle ended britain's support for the south", "answer": ["Battle of Gettysburg"], "scores": [[0.23486328125, 0.99951171875, 0.0058441162109375, 0.98681640625, 0.99951171875, 0.9990234375]], "normalized_score": [0.3325219452381134], "tokens": [["\u2581Battle", "\u2581of", "\u2581G", "ett", "ys", "burg"]], "entropy": [[1.3408203125, 0.00627899169921875, 3.58203125, 0.1025390625, 0.002471923828125, 0.00832366943359375]], "avg_entropy": [0.8404108683268229], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Battle of Antietam", "score_of_biggest_cluster": 0.3325219452381134, "score_of_first_answer": 0.3325219452381134, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.0058441162109375, "avg_score": 0.3325219452381134, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4181683847312603, "std_of_first_answer": 0.4181683847312603, "avg_entropy_of_first_answer": 0.8404108683268229, "lex_sim": 1.0}
{"question": "when does season 8 of vampire diaries come out", "answer": ["Season 8 of The Vampire Diaries has already aired, it aired from October 2016 to March 2017."], "scores": [[0.0254974365234375, 0.99951171875, 0.99951171875, 0.9482421875, 0.78759765625, 0.99951171875, 1.0, 1.0, 0.9990234375, 1.0, 0.8408203125, 0.99951171875, 0.892578125, 1.0, 0.32470703125, 0.9677734375, 0.63671875, 1.0, 0.85986328125, 0.485595703125, 0.958984375, 0.9970703125, 0.8935546875, 1.0, 1.0, 0.986328125, 0.9931640625, 0.99951171875, 1.0, 1.0, 1.0, 1.0, 0.9951171875, 1.7881393432617188e-07, 3.975629806518555e-05, 0.7392578125, 0.99951171875, 0.07904052734375, 0.00469970703125, 0.0007572174072265625, 0.2352294921875, 0.7314453125, 0.9970703125, 0.2080078125, 0.74658203125, 0.998046875, 0.04913330078125, 0.246826171875]], "normalized_score": [0.3113221824169159], "tokens": [["\u2581Season", "\u2581", "8", "\u2581of", "\u2581The", "\u2581V", "amp", "ire", "\u2581Di", "aries", "\u2581has", "\u2581already", "\u2581a", "ired", ",", "\u2581it", "\u2581a", "ired", "\u2581from", "\u2581October", "\u2581", "2", "0", "1", "6", "\u2581to", "\u2581March", "\u2581", "2", "0", "1", "7", ".", "\u2581#", "Me", "To", "o", "\u2581movement", ":", "\u2581M", "J", "\u2581Ak", "bar", "\u2581res", "ign", "s", "\u2581amid", "\u2581sexual"]], "entropy": [[2.37890625, 0.00325775146484375, 0.003238677978515625, 0.258544921875, 0.73828125, 0.0031223297119140625, 0.000797271728515625, 0.00025773048400878906, 0.0077362060546875, 0.0015077590942382812, 0.71923828125, 0.0033473968505859375, 0.5, 0.000339508056640625, 1.0546875, 0.1708984375, 0.97802734375, 1.0728836059570312e-05, 0.440185546875, 0.83447265625, 0.188232421875, 0.023345947265625, 0.4111328125, 0.00020384788513183594, 0.0009222030639648438, 0.0888671875, 0.045379638671875, 0.004146575927734375, 2.7179718017578125e-05, 0.0003180503845214844, 0.00036907196044921875, 0.00037217140197753906, 0.035675048828125, 0.9873046875, 4.1015625, 1.6728515625, 0.005786895751953125, 2.396484375, 3.6796875, 4.859375, 3.833984375, 1.6552734375, 0.0249176025390625, 3.37109375, 0.65283203125, 0.019287109375, 1.431640625, 2.021484375]], "avg_entropy": [0.8251961568991343], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "October 21, 2016", "score_of_biggest_cluster": 0.3113221824169159, "score_of_first_answer": 0.3113221824169159, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.3113221824169159, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.3667417231476036, "std_of_first_answer": 0.3667417231476036, "avg_entropy_of_first_answer": 0.8251961568991343, "lex_sim": 1.0}
{"question": "when did the movie peter pan come out", "answer": ["February 5, 2003 #SundayReads: What\u2019s in my Facebook feed?"], "scores": [[0.163330078125, 0.9970703125, 0.9814453125, 0.93310546875, 0.9990234375, 0.287841796875, 1.0, 0.986328125, 0.99951171875, 6.556510925292969e-07, 0.0049591064453125, 0.305419921875, 0.998046875, 0.0003948211669921875, 0.028564453125, 0.0052490234375, 0.01052093505859375, 0.020782470703125, 0.994140625, 0.0214691162109375, 0.04583740234375, 0.0005106925964355469, 0.14794921875, 0.630859375]], "normalized_score": [0.06433658301830292], "tokens": [["\u2581February", "\u2581", "5", ",", "\u2581", "2", "0", "0", "3", "\u2581#", "S", "und", "ay", "Read", "s", ":", "\u2581What", "\u2019", "s", "\u2581in", "\u2581my", "\u2581Facebook", "\u2581feed", "?"]], "entropy": [[0.9921875, 0.024017333984375, 0.106689453125, 0.2666015625, 0.0089874267578125, 0.6005859375, 0.0001074671745300293, 0.08038330078125, 0.0033397674560546875, 0.53857421875, 4.96875, 1.9833984375, 0.0184173583984375, 3.888671875, 0.50439453125, 1.498046875, 4.046875, 4.15625, 0.0478515625, 3.015625, 2.01171875, 5.53125, 4.62109375, 1.7568359375]], "avg_entropy": [1.6946105435490608], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2003", "score_of_biggest_cluster": 0.06433658301830292, "score_of_first_answer": 0.06433658301830292, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 6.556510925292969e-07, "avg_score": 0.06433658301830292, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4453732719216748, "std_of_first_answer": 0.4453732719216748, "avg_entropy_of_first_answer": 1.6946105435490608, "lex_sim": 1.0}
{"question": "who proposed that electrons behave like waves and particles", "answer": ["Louis de Broglie"], "scores": [[0.9853515625, 0.8857421875, 0.99853515625, 1.0, 1.0]], "normalized_score": [0.97286456823349], "tokens": [["\u2581Louis", "\u2581de", "\u2581Bro", "g", "lie"]], "entropy": [[0.11004638671875, 0.431884765625, 0.014434814453125, 0.00015413761138916016, 0.0006117820739746094]], "avg_entropy": [0.11142637729644775], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Einstein", "score_of_biggest_cluster": 0.97286456823349, "score_of_first_answer": 0.97286456823349, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.8857421875, "avg_score": 0.97286456823349, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.0444347741944847, "std_of_first_answer": 0.0444347741944847, "avg_entropy_of_first_answer": 0.11142637729644775, "lex_sim": 1.0}
{"question": "who came out first batman or spider man", "answer": ["Batman (created in 1939), Spider-Man (created in 1962)."], "scores": [[0.95703125, 1.0, 0.1221923828125, 0.2978515625, 0.998046875, 0.99951171875, 1.0, 1.0, 1.0, 1.0, 0.2462158203125, 0.99462890625, 0.99755859375, 1.0, 0.99951171875, 0.9990234375, 0.99951171875, 0.99951171875, 1.0, 1.0, 1.0, 1.0, 0.360107421875, 1.6689300537109375e-06, 0.002574920654296875, 0.032379150390625, 0.08551025390625, 0.01094818115234375, 0.01308441162109375, 8.51750373840332e-05, 0.79150390625, 0.990234375, 1.7464160919189453e-05, 0.001789093017578125, 0.00041675567626953125, 0.1173095703125, 0.98583984375, 0.0155487060546875, 0.97705078125, 1.0]], "normalized_score": [0.1325843632221222], "tokens": [["\u2581Bat", "man", "\u2581(", "created", "\u2581in", "\u2581", "1", "9", "3", "9", "),", "\u2581Spider", "-", "Man", "\u2581(", "created", "\u2581in", "\u2581", "1", "9", "6", "2", ").", "\u2581#", "0", "5", "6", ":", "\u2581The", "\u2581Import", "ance", "\u2581of", "\u2581Rest", "\u2581Days", "\u2581with", "\u2581Dr", ".", "\u2581Stuart", "\u2581McG", "ill"]], "entropy": [[0.239013671875, 0.0005693435668945312, 1.603515625, 1.6318359375, 0.0167694091796875, 0.006351470947265625, 4.4465065002441406e-05, 0.0002453327178955078, 0.0004432201385498047, 0.0008249282836914062, 1.037109375, 0.041046142578125, 0.018829345703125, 0.0014028549194335938, 0.005764007568359375, 0.0092926025390625, 0.002941131591796875, 0.00565338134765625, 1.0371208190917969e-05, 0.00014972686767578125, 0.00034332275390625, 0.001407623291015625, 0.703125, 0.209716796875, 3.98828125, 2.818359375, 2.607421875, 2.830078125, 4.875, 4.21875, 0.5322265625, 0.06463623046875, 2.16796875, 2.48046875, 2.9140625, 5.84765625, 0.151123046875, 4.62109375, 0.197998046875, 0.0015840530395507812]], "avg_entropy": [1.146327841281891], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Batman", "score_of_biggest_cluster": 0.1325843632221222, "score_of_first_answer": 0.1325843632221222, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.6689300537109375e-06, "avg_score": 0.1325843632221222, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.45060995462847575, "std_of_first_answer": 0.45060995462847575, "avg_entropy_of_first_answer": 1.146327841281891, "lex_sim": 1.0}
{"question": "what nfl player has the most nfl rings", "answer": ["Tom Brady (6)"], "scores": [[0.85888671875, 1.0, 1.0, 0.2174072265625, 0.67431640625, 0.67041015625]], "normalized_score": [0.6623217463493347], "tokens": [["\u2581Tom", "\u2581Br", "ady", "\u2581(", "6", ")"]], "entropy": [[0.7333984375, 0.0015001296997070312, 6.020069122314453e-06, 1.857421875, 1.009765625, 1.0576171875]], "avg_entropy": [0.7766182124614716], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Charles Haley", "score_of_biggest_cluster": 0.6623217463493347, "score_of_first_answer": 0.6623217463493347, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.2174072265625, "avg_score": 0.6623217463493347, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2681834890304755, "std_of_first_answer": 0.2681834890304755, "avg_entropy_of_first_answer": 0.7766182124614716, "lex_sim": 1.0}
{"question": "what happens when iron reacts with oxygen and water", "answer": ["Iron oxide is formed, also known as rust."], "scores": [[0.331787109375, 0.646484375, 0.7158203125, 0.12200927734375, 0.91259765625, 0.2327880859375, 0.1082763671875, 0.98583984375, 0.99853515625, 0.9970703125, 0.6689453125, 0.0, 1.1920928955078125e-07, 0.0316162109375, 0.0017347335815429688, 0.99365234375, 1.0]], "normalized_score": [0.0], "tokens": [["\u2581Iron", "\u2581ox", "ide", "\u2581is", "\u2581formed", ",", "\u2581also", "\u2581known", "\u2581as", "\u2581rust", ".", "\u2581#####", "\u2581SY", "N", "OP", "S", "IS"]], "entropy": [[1.4560546875, 1.1484375, 0.61962890625, 1.0537109375, 0.3173828125, 1.39453125, 1.7666015625, 0.10113525390625, 0.01282501220703125, 0.024688720703125, 0.85009765625, 0.630859375, 1.0556640625, 0.1429443359375, 0.44970703125, 0.044769287109375, 0.0004839897155761719]], "avg_entropy": [0.651148375342874], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Rust", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.40960849184213477, "std_of_first_answer": 0.40960849184213477, "avg_entropy_of_first_answer": 0.651148375342874, "lex_sim": 1.0}
{"question": "where did you go to drink during prohibition", "answer": ["I am an AI research assistant and do not have the ability to drink."], "scores": [[0.09393310546875, 0.6298828125, 0.9384765625, 0.82373046875, 1.0, 0.2471923828125, 0.99853515625, 0.81396484375, 0.66259765625, 0.99951171875, 0.74560546875, 0.7548828125, 0.89208984375, 0.9990234375, 0.50732421875, 0.6318359375, 0.33544921875, 0.99951171875, 1.0, 0.5888671875, 0.97607421875, 0.72021484375, 0.97412109375, 0.97119140625, 0.9970703125, 1.0, 0.57275390625, 0.99951171875, 1.0, 1.0, 0.99951171875, 1.0, 0.9052734375, 0.99853515625, 1.0, 1.0, 1.0, 1.0, 0.904296875, 0.998046875, 0.422119140625, 0.98388671875, 0.315185546875, 0.953125, 0.9921875, 0.99853515625, 0.9990234375, 0.99951171875, 0.99853515625, 1.0]], "normalized_score": [0.7894976139068604], "tokens": [["\u2581I", "\u2581am", "\u2581an", "\u2581A", "I", "\u2581research", "\u2581assistant", "\u2581and", "\u2581do", "\u2581not", "\u2581have", "\u2581the", "\u2581ability", "\u2581to", "\u2581drink", ".", "\u2581Pro", "hib", "ition", "\u2581was", "\u2581a", "\u2581period", "\u2581in", "\u2581the", "\u2581United", "\u2581States", "\u2581from", "\u2581", "1", "9", "2", "0", "\u2581to", "\u2581", "1", "9", "3", "3", "\u2581when", "\u2581the", "\u2581production", ",", "\u2581transport", "ation", ",", "\u2581and", "\u2581sale", "\u2581of", "\u2581alco", "hol"]], "entropy": [[1.697265625, 1.201171875, 0.31591796875, 0.487060546875, 0.0001697540283203125, 1.1572265625, 0.012054443359375, 0.53173828125, 1.0234375, 0.005035400390625, 0.77880859375, 0.80322265625, 0.376953125, 0.00792694091796875, 1.216796875, 1.001953125, 1.7802734375, 0.0030269622802734375, 0.00030541419982910156, 1.1962890625, 0.137451171875, 0.6396484375, 0.12274169921875, 0.154541015625, 0.020172119140625, 0.0022029876708984375, 1.216796875, 0.003383636474609375, 7.092952728271484e-06, 2.1338462829589844e-05, 0.0027179718017578125, 0.0004725456237792969, 0.318115234375, 0.01110076904296875, 3.6776065826416016e-05, 3.731250762939453e-05, 9.500980377197266e-05, 0.00016498565673828125, 0.43994140625, 0.01354217529296875, 0.787109375, 0.0902099609375, 1.3515625, 0.2152099609375, 0.05084228515625, 0.010406494140625, 0.0095977783203125, 0.0030117034912109375, 0.011474609375, 5.227327346801758e-05]], "avg_entropy": [0.38418603301048276], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Speakeasies", "score_of_biggest_cluster": 0.7894976139068604, "score_of_first_answer": 0.7894976139068604, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.09393310546875, "avg_score": 0.7894976139068604, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.23437831546027885, "std_of_first_answer": 0.23437831546027885, "avg_entropy_of_first_answer": 0.38418603301048276, "lex_sim": 1.0}
{"question": "where was percy jackson and the olympians filmed", "answer": ["It was filmed in various locations in North America, including British Columbia and Ontario, Canada, and New York and New York City in the United States."], "scores": [[0.11468505859375, 0.99951171875, 0.89306640625, 1.0, 0.978515625, 0.5888671875, 0.99853515625, 0.84765625, 0.028472900390625, 0.96533203125, 0.89794921875, 0.96630859375, 0.042633056640625, 1.0, 0.05511474609375, 0.59375, 0.697265625, 0.99951171875, 0.47998046875, 0.93359375, 0.4599609375, 0.9921875, 0.322021484375, 0.62255859375, 0.00011175870895385742, 0.99658203125, 0.63232421875, 1.0, 0.99560546875, 0.99951171875, 0.99462890625, 2.384185791015625e-07, 0.0007691383361816406, 0.0009183883666992188, 0.98828125, 0.00012409687042236328, 0.112060546875, 0.0017614364624023438, 0.33056640625, 1.0, 1.0, 0.88720703125, 0.50341796875, 0.0019292831420898438, 0.97412109375, 0.99560546875, 0.9521484375, 0.0227508544921875]], "normalized_score": [0.16874437034130096], "tokens": [["\u2581It", "\u2581was", "\u2581fil", "med", "\u2581in", "\u2581various", "\u2581locations", "\u2581in", "\u2581North", "\u2581America", ",", "\u2581including", "\u2581British", "\u2581Columbia", "\u2581and", "\u2581Ontario", ",", "\u2581Canada", ",", "\u2581and", "\u2581New", "\u2581York", "\u2581and", "\u2581New", "\u2581York", "\u2581City", "\u2581in", "\u2581the", "\u2581United", "\u2581States", ".", "\u2581#", "A", "pol", "lo", "5", "0", ":", "\u2581C", "ele", "br", "ating", "\u2581the", "\u2581Gi", "ant", "\u2581Le", "ap", "\u2581That"]], "entropy": [[2.853515625, 0.0067138671875, 0.443359375, 1.055002212524414e-05, 0.1380615234375, 1.3349609375, 0.01143646240234375, 0.64794921875, 1.9033203125, 0.1715087890625, 0.446044921875, 0.1986083984375, 2.802734375, 0.0006532669067382812, 0.28515625, 1.7138671875, 0.7080078125, 0.003231048583984375, 0.91748046875, 0.2705078125, 1.615234375, 0.052093505859375, 1.1103515625, 1.30859375, 0.75, 0.030853271484375, 0.7353515625, 0.00200653076171875, 0.0305328369140625, 0.00246429443359375, 0.04034423828125, 0.79296875, 3.056640625, 1.8251953125, 0.0933837890625, 2.623046875, 3.03125, 2.45703125, 3.4453125, 0.00263214111328125, 0.0020427703857421875, 0.36376953125, 1.5908203125, 1.6044921875, 0.12310791015625, 0.0389404296875, 0.2003173828125, 3.29296875]], "avg_entropy": [0.9391432218253613], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Vancouver", "score_of_biggest_cluster": 0.16874437034130096, "score_of_first_answer": 0.16874437034130096, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.16874437034130096, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4058901955594545, "std_of_first_answer": 0.4058901955594545, "avg_entropy_of_first_answer": 0.9391432218253613, "lex_sim": 1.0}
{"question": "what is the final season of downton abbey", "answer": ["Season 6"], "scores": [[0.337890625, 0.99853515625, 1.0]], "normalized_score": [0.6961665749549866], "tokens": [["\u2581Season", "\u2581", "6"]], "entropy": [[1.841796875, 0.012908935546875, 0.0012884140014648438]], "avg_entropy": [0.6186647415161133], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the sixth", "score_of_biggest_cluster": 0.6961665749549866, "score_of_first_answer": 0.6961665749549866, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.337890625, "avg_score": 0.6961665749549866, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.3117766591827901, "std_of_first_answer": 0.3117766591827901, "avg_entropy_of_first_answer": 0.6186647415161133, "lex_sim": 1.0}
{"question": "who played ricky in secret life of the american teenager", "answer": ["Daren Kagasoff #OurMission: Nestle Waters Canada\u2019s Commitment to Responsible Water Management"], "scores": [[0.63720703125, 1.0, 0.9990234375, 0.99951171875, 0.9990234375, 1.1920928955078125e-07, 0.000812530517578125, 0.01201629638671875, 0.03533935546875, 0.026519775390625, 0.034759521484375, 0.0001666545867919922, 0.0009064674377441406, 0.9423828125, 0.005794525146484375, 0.99755859375, 0.01812744140625, 0.0013446807861328125, 0.99951171875, 0.0002837181091308594, 0.998046875, 0.98486328125, 0.8173828125, 0.048797607421875, 0.9921875, 0.99951171875, 0.95068359375, 0.6494140625, 0.86083984375]], "normalized_score": [0.05945867300033569], "tokens": [["\u2581Dar", "en", "\u2581K", "agas", "off", "\u2581#", "O", "ur", "M", "ission", ":", "\u2581N", "est", "le", "\u2581W", "aters", "\u2581Canada", "\u2019", "s", "\u2581Comm", "it", "ment", "\u2581to", "\u2581Res", "p", "ons", "ible", "\u2581Water", "\u2581Management"]], "entropy": [[1.2041015625, 0.0002238750457763672, 0.011962890625, 0.00402069091796875, 0.0089111328125, 0.4677734375, 5.74609375, 4.87890625, 4.34375, 3.58203125, 2.0, 3.3515625, 2.306640625, 0.348388671875, 3.544921875, 0.02606201171875, 3.2734375, 2.87109375, 0.00528717041015625, 1.9248046875, 0.01641845703125, 0.08123779296875, 1.021484375, 3.015625, 0.048553466796875, 0.0028171539306640625, 0.23681640625, 1.712890625, 0.576171875]], "avg_entropy": [1.6073099580304375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Daren Maxwell Kagasoff", "score_of_biggest_cluster": 0.05945867300033569, "score_of_first_answer": 0.05945867300033569, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.05945867300033569, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.46247421125052746, "std_of_first_answer": 0.46247421125052746, "avg_entropy_of_first_answer": 1.6073099580304375, "lex_sim": 1.0}
{"question": "when did britain set up east indian trading company", "answer": ["1600"], "scores": [[0.90966796875, 0.99951171875, 0.9990234375, 0.99951171875, 1.0]], "normalized_score": [0.980859637260437], "tokens": [["\u2581", "1", "6", "0", "0"]], "entropy": [[0.4541015625, 0.0035552978515625, 0.010650634765625, 0.0050506591796875, 0.0015020370483398438]], "avg_entropy": [0.09497203826904296], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "31 December 1600", "score_of_biggest_cluster": 0.980859637260437, "score_of_first_answer": 0.980859637260437, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.90966796875, "avg_score": 0.980859637260437, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.035938826826729345, "std_of_first_answer": 0.035938826826729345, "avg_entropy_of_first_answer": 0.09497203826904296, "lex_sim": 1.0}
{"question": "who played jason in friday the 13th the final chapter", "answer": ["Corey Feldman #007: \u201cThe Unforgivable Curses\u201d \u2013 Harry Potter and the Cursed Child"], "scores": [[0.2481689453125, 1.0, 0.97412109375, 1.0, 1.7881393432617188e-07, 0.00594329833984375, 0.1824951171875, 0.06524658203125, 0.0028858184814453125, 0.0009775161743164062, 0.085205078125, 4.166364669799805e-05, 0.08245849609375, 0.96533203125, 0.0151519775390625, 0.974609375, 0.0980224609375, 0.93798828125, 0.9501953125, 0.775390625, 0.0119476318359375, 0.064697265625, 0.98193359375, 1.0, 0.1358642578125, 0.9931640625, 0.07379150390625, 1.0, 1.0, 1.0]], "normalized_score": [0.08753641694784164], "tokens": [["\u2581Core", "y", "\u2581Feld", "man", "\u2581#", "0", "0", "7", ":", "\u2581\u201c", "The", "\u2581Un", "f", "org", "iv", "able", "\u2581C", "urs", "es", "\u201d", "\u2581\u2013", "\u2581Harry", "\u2581Pot", "ter", "\u2581and", "\u2581the", "\u2581C", "urs", "ed", "\u2581Child"]], "entropy": [[2.015625, 0.0001804828643798828, 0.14990234375, 0.0009288787841796875, 0.69189453125, 4.390625, 3.46875, 2.583984375, 2.673828125, 3.970703125, 3.501953125, 2.546875, 3.494140625, 0.1922607421875, 0.278564453125, 0.16845703125, 4.15234375, 0.41748046875, 0.2822265625, 1.3046875, 2.787109375, 4.91015625, 0.163818359375, 0.0022716522216796875, 2.7421875, 0.053924560546875, 1.388671875, 0.0015668869018554688, 6.854534149169922e-05, 0.0026836395263671875]], "avg_entropy": [1.611262325445811], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ted White", "score_of_biggest_cluster": 0.08753641694784164, "score_of_first_answer": 0.08753641694784164, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.08753641694784164, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4540981419919951, "std_of_first_answer": 0.4540981419919951, "avg_entropy_of_first_answer": 1.611262325445811, "lex_sim": 1.0}
{"question": "who was the first british team to win the european cup", "answer": ["Manchester United (1968) #12."], "scores": [[0.70849609375, 0.99658203125, 0.248291015625, 0.86767578125, 1.0, 1.0, 0.81494140625, 0.99609375, 8.940696716308594e-07, 0.0335693359375, 0.03729248046875, 0.006053924560546875, 3.403425216674805e-05, 0.005237579345703125, 0.0002884864807128906]], "normalized_score": [0.032278694212436676], "tokens": [["\u2581Manchester", "\u2581United", "\u2581(", "1", "9", "6", "8", ")", "\u2581#", "1", "2", ".", "\u2581G", "iving", "\u2581Back"]], "entropy": [[1.21484375, 0.0256805419921875, 1.4423828125, 0.5732421875, 4.0590763092041016e-05, 0.0009112358093261719, 0.479736328125, 0.031158447265625, 0.4638671875, 4.18359375, 3.072265625, 3.212890625, 1.3701171875, 4.1640625, 2.412109375]], "avg_entropy": [1.509793476263682], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Celtic", "score_of_biggest_cluster": 0.032278694212436676, "score_of_first_answer": 0.032278694212436676, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 8.940696716308594e-07, "avg_score": 0.032278694212436676, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44443832119830656, "std_of_first_answer": 0.44443832119830656, "avg_entropy_of_first_answer": 1.509793476263682, "lex_sim": 1.0}
{"question": "the legend of heroes trails in the sky the 3rd vita", "answer": ["release date has not been announced yet."], "scores": [[0.04595947265625, 0.93212890625, 0.1517333984375, 0.97900390625, 0.87158203125, 0.59375, 0.64697265625, 0.77978515625, 1.1920928955078125e-07, 0.0005970001220703125, 7.665157318115234e-05, 0.0258941650390625, 1.0, 0.8427734375, 5.5849552154541016e-05]], "normalized_score": [0.029481424018740654], "tokens": [["\u2581release", "\u2581date", "\u2581has", "\u2581not", "\u2581been", "\u2581announced", "\u2581yet", ".", "\u2581_", "An", "\u2581Ex", "cer", "pt", "\u2581from", "_"]], "entropy": [[3.453125, 0.388427734375, 2.47265625, 0.11474609375, 0.38916015625, 0.7578125, 1.1015625, 0.86669921875, 1.21875, 3.623046875, 4.2265625, 2.53125, 0.0013895034790039062, 0.58984375, 1.908203125]], "avg_entropy": [1.576215680440267], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "July 14, 2016", "score_of_biggest_cluster": 0.029481424018740654, "score_of_first_answer": 0.029481424018740654, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.029481424018740654, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41275275129301475, "std_of_first_answer": 0.41275275129301475, "avg_entropy_of_first_answer": 1.576215680440267, "lex_sim": 1.0}
{"question": "who plays ser davos in game of thrones", "answer": ["Liam Cunningham #VeteranOfTheDay Johnnie E. Roberts Jr."], "scores": [[0.98193359375, 1.0, 1.0, 1.0, 1.0, 1.9073486328125e-06, 0.00044918060302734375, 0.0034580230712890625, 0.97021484375, 0.0007300376892089844, 0.04193115234375, 0.002285003662109375, 0.00019407272338867188, 0.00675201416015625, 0.0213165283203125, 0.96875, 0.01190185546875, 0.03857421875, 0.75732421875]], "normalized_score": [0.027239946648478508], "tokens": [["\u2581Li", "am", "\u2581C", "unning", "ham", "\u2581#", "V", "eter", "an", "Of", "The", "Day", "\u2581John", "nie", "\u2581E", ".", "\u2581Roberts", "\u2581Jr", "."]], "entropy": [[0.1341552734375, 0.0002951622009277344, 0.000965118408203125, 0.0015239715576171875, 0.00024390220642089844, 0.7353515625, 4.140625, 3.2578125, 0.165283203125, 1.8642578125, 0.66552734375, 2.3515625, 1.5947265625, 4.65625, 3.83984375, 0.28369140625, 4.05859375, 3.037109375, 1.00390625]], "avg_entropy": [1.6732486549176668], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Liam Cunningham", "score_of_biggest_cluster": 0.027239946648478508, "score_of_first_answer": 0.027239946648478508, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.9073486328125e-06, "avg_score": 0.027239946648478508, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4709760258775789, "std_of_first_answer": 0.4709760258775789, "avg_entropy_of_first_answer": 1.6732486549176668, "lex_sim": 1.0}
{"question": "during the first world war against which country germany did not fight", "answer": ["the United States of America #TheDress Appropriation & Cultural Misappropriation"], "scores": [[0.16796875, 0.76953125, 0.99853515625, 0.322998046875, 0.99951171875, 2.980232238769531e-07, 0.002941131591796875, 0.00687408447265625, 0.0012760162353515625, 1.6927719116210938e-05, 0.1842041015625, 0.174072265625, 0.0004286766052246094, 0.06695556640625, 0.1427001953125, 0.89990234375, 1.0, 0.99951171875]], "normalized_score": [0.03085000440478325], "tokens": [["\u2581the", "\u2581United", "\u2581States", "\u2581of", "\u2581America", "\u2581#", "The", "D", "ress", "\u2581App", "ropri", "ation", "\u2581&", "\u2581Cultural", "\u2581Mis", "app", "ropri", "ation"]], "entropy": [[2.501953125, 0.9453125, 0.01381683349609375, 1.3125, 0.00293731689453125, 1.14453125, 5.88671875, 2.826171875, 2.484375, 1.6748046875, 2.0859375, 0.95751953125, 2.666015625, 5.26953125, 2.115234375, 0.44287109375, 0.0025501251220703125, 0.006771087646484375]], "avg_entropy": [1.7966417736477323], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Austria-Hungary", "score_of_biggest_cluster": 0.03085000440478325, "score_of_first_answer": 0.03085000440478325, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.03085000440478325, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4147937954777425, "std_of_first_answer": 0.4147937954777425, "avg_entropy_of_first_answer": 1.7966417736477323, "lex_sim": 1.0}
{"question": "who was the father of the princes in the tower", "answer": ["Edward IV"], "scores": [[0.95263671875, 0.990234375]], "normalized_score": [0.9712536334991455], "tokens": [["\u2581Edward", "\u2581IV"]], "entropy": [[0.2362060546875, 0.07275390625]], "avg_entropy": [0.15447998046875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Edward IV of England", "score_of_biggest_cluster": 0.9712536334991455, "score_of_first_answer": 0.9712536334991455, "max_score_of_first_answer": 0.990234375, "min_score_of_first_answer": 0.95263671875, "avg_score": 0.9712536334991455, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.018798828125, "std_of_first_answer": 0.018798828125, "avg_entropy_of_first_answer": 0.15447998046875, "lex_sim": 1.0}
{"question": "what is the multiplication sign on the computer", "answer": ["7 (when the numbers are one line above the bottom number)"], "scores": [[0.022918701171875, 0.818359375, 0.0142059326171875, 0.007572174072265625, 0.08172607421875, 0.36328125, 0.43115234375, 0.0006570816040039062, 0.0177001953125, 0.051544189453125, 0.49755859375, 0.01432037353515625, 0.07818603515625, 0.751953125]], "normalized_score": [0.0591946505010128], "tokens": [["\u2581", "7", "\u2581(", "when", "\u2581the", "\u2581numbers", "\u2581are", "\u2581one", "\u2581line", "\u2581above", "\u2581the", "\u2581bottom", "\u2581number", ")"]], "entropy": [[2.2734375, 1.181640625, 1.2001953125, 3.24609375, 3.02734375, 2.68359375, 1.4404296875, 2.1796875, 1.7509765625, 2.404296875, 0.853515625, 3.5078125, 0.6162109375, 1.056640625]], "avg_entropy": [1.9587053571428572], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "a rotationally symmetric saltire", "score_of_biggest_cluster": 0.0591946505010128, "score_of_first_answer": 0.0591946505010128, "max_score_of_first_answer": 0.818359375, "min_score_of_first_answer": 0.0006570816040039062, "avg_score": 0.0591946505010128, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2813318981392424, "std_of_first_answer": 0.2813318981392424, "avg_entropy_of_first_answer": 1.9587053571428572, "lex_sim": 1.0}
{"question": "what was the religion in the virginia colony", "answer": ["Christianity"], "scores": [[0.67578125, 0.99267578125]], "normalized_score": [0.8190431594848633], "tokens": [["\u2581Christian", "ity"]], "entropy": [[1.1025390625, 0.0543212890625]], "avg_entropy": [0.57843017578125], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Anglican church", "score_of_biggest_cluster": 0.8190431594848633, "score_of_first_answer": 0.8190431594848633, "max_score_of_first_answer": 0.99267578125, "min_score_of_first_answer": 0.67578125, "avg_score": 0.8190431594848633, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.158447265625, "std_of_first_answer": 0.158447265625, "avg_entropy_of_first_answer": 0.57843017578125, "lex_sim": 1.0}
{"question": "when is season 7 race to the edge coming out", "answer": ["I do not have access to release dates for future episodes or seasons of the television show Race to the Edge."], "scores": [[0.382080078125, 0.1387939453125, 0.99951171875, 0.90380859375, 0.02484130859375, 0.99951171875, 0.20458984375, 0.73974609375, 0.6708984375, 0.3935546875, 0.028594970703125, 0.326171875, 0.99560546875, 0.6318359375, 0.055999755859375, 0.056488037109375, 0.82763671875, 0.062408447265625, 0.9951171875, 0.99951171875, 0.99853515625, 0.91455078125, 0.0, 0.0816650390625, 0.08892822265625, 0.00016021728515625, 0.00024962425231933594, 0.99658203125, 0.84033203125, 0.43310546875, 0.09954833984375, 0.99609375, 0.8662109375]], "normalized_score": [0.0], "tokens": [["\u2581I", "\u2581do", "\u2581not", "\u2581have", "\u2581access", "\u2581to", "\u2581release", "\u2581dates", "\u2581for", "\u2581future", "\u2581episodes", "\u2581or", "\u2581seasons", "\u2581of", "\u2581the", "\u2581television", "\u2581show", "\u2581Race", "\u2581to", "\u2581the", "\u2581Edge", ".", "\u2581Proof", "\u2581of", "\u2581the", "\u2581R", "eli", "ability", "\u2581of", "\u2581the", "\u2581Q", "ur", "an"]], "entropy": [[2.59375, 1.1962890625, 0.0028705596923828125, 0.323974609375, 1.23828125, 0.00445556640625, 2.23828125, 0.91259765625, 1.2724609375, 1.9287109375, 0.716796875, 1.2646484375, 0.035980224609375, 0.87548828125, 2.275390625, 1.23046875, 0.50732421875, 0.63623046875, 0.031524658203125, 0.0032558441162109375, 0.01302337646484375, 0.383544921875, 2.306640625, 2.134765625, 4.359375, 3.85546875, 3.306640625, 0.0304412841796875, 0.93359375, 3.078125, 4.99609375, 0.03814697265625, 0.489501953125]], "avg_entropy": [1.3701255104758523], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "February 16, 2018", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4022584662805554, "std_of_first_answer": 0.4022584662805554, "avg_entropy_of_first_answer": 1.3701255104758523, "lex_sim": 1.0}
{"question": "where does the red river start and end in louisiana", "answer": ["Start: Northwest Minnesota, End: At the Atchafalaya River near Krotz Springs, Louisiana."], "scores": [[0.00997161865234375, 0.93310546875, 0.3681640625, 0.1787109375, 0.0220184326171875, 0.41552734375, 0.96875, 0.99658203125, 0.81787109375, 0.58154296875, 0.292724609375, 1.0, 0.99951171875, 1.0, 1.0, 0.98681640625, 0.362060546875, 0.01141357421875, 0.92626953125, 1.0, 0.99365234375, 1.0, 0.79296875, 0.98974609375, 0.40185546875, 2.384185791015625e-07, 0.005863189697265625, 5.805492401123047e-05, 0.9892578125, 0.5625, 0.9873046875, 1.1920928955078125e-07, 0.0025653839111328125, 0.309814453125, 0.03790283203125, 0.005619049072265625, 0.417236328125, 0.9990234375, 0.556640625, 0.1826171875, 0.78955078125, 0.9990234375]], "normalized_score": [0.1274753361940384], "tokens": [["\u2581Start", ":", "\u2581North", "west", "\u2581Minnesota", ",", "\u2581End", ":", "\u2581At", "\u2581the", "\u2581At", "ch", "af", "al", "aya", "\u2581River", "\u2581near", "\u2581K", "rot", "z", "\u2581Spr", "ings", ",", "\u2581Louisiana", ".", "\u2581#", "W", "om", "ens", "M", "arch", "\u2581Se", "eks", "\u2581to", "\u2581Keep", "\u2581Women", "\u2019", "s", "\u2581Rights", "\u2581at", "\u2581Fore", "front"]], "entropy": [[1.0439453125, 0.338134765625, 3.6328125, 1.89453125, 1.8232421875, 1.2470703125, 0.17333984375, 0.0260772705078125, 0.8466796875, 1.091796875, 1.119140625, 0.000331878662109375, 0.002666473388671875, 0.0007610321044921875, 0.0007791519165039062, 0.07513427734375, 1.3046875, 1.9697265625, 0.468505859375, 5.2809715270996094e-05, 0.03765869140625, 0.00033354759216308594, 0.669921875, 0.06890869140625, 1.1064453125, 0.50146484375, 4.703125, 2.552734375, 0.07598876953125, 1.7109375, 0.08343505859375, 1.4482421875, 2.537109375, 3.32421875, 4.27734375, 3.044921875, 1.9013671875, 0.0107879638671875, 1.5791015625, 2.427734375, 0.68310546875, 0.0102691650390625]], "avg_entropy": [1.1860612261862982], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the Texas Panhandle", "score_of_biggest_cluster": 0.1274753361940384, "score_of_first_answer": 0.1274753361940384, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.1274753361940384, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40430722234537936, "std_of_first_answer": 0.40430722234537936, "avg_entropy_of_first_answer": 1.1860612261862982, "lex_sim": 1.0}
{"question": "when did the granite mountain hotshots get certified", "answer": ["I'm sorry, I don't have information on the Granite Mountain Hotshots."], "scores": [[0.5224609375, 0.650390625, 0.99951171875, 0.97119140625, 0.9873046875, 0.83203125, 0.416015625, 0.9951171875, 1.0, 0.921875, 0.425048828125, 0.5751953125, 0.328857421875, 0.5087890625, 0.99951171875, 0.9951171875, 0.98681640625, 0.99853515625, 1.0, 0.59912109375, 0.4775390625, 0.94921875, 0.465087890625, 0.89794921875, 0.94580078125, 0.9892578125, 0.00727081298828125, 0.11151123046875, 0.99609375, 0.669921875, 0.56494140625, 0.99462890625, 0.99462890625, 8.928775787353516e-05, 2.014636993408203e-05, 0.183349609375, 0.269775390625, 0.16552734375, 0.142578125, 0.0008397102355957031, 1.430511474609375e-05, 6.210803985595703e-05, 0.1307373046875, 0.93994140625, 0.03759765625, 0.0006418228149414062, 0.434326171875, 0.8408203125]], "normalized_score": [0.17239777743816376], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581I", "\u2581don", "'", "t", "\u2581have", "\u2581information", "\u2581on", "\u2581the", "\u2581Gran", "ite", "\u2581Mountain", "\u2581Hot", "sh", "ots", ".", "\u2581Can", "\u2581you", "\u2581please", "\u2581provide", "\u2581more", "\u2581context", "\u2581for", "\u2581me", "\u2581to", "\u2581better", "\u2581assist", "\u2581you", "?", "\u2581I", "\u2581received", "\u2581the", "\u2581following", "\u2581message", "\u2581from", "\u2581T", "LC", "\u2581Book", "\u2581T", "ours", "\u2581and", "\u2581knew", "\u2581I", "\u2581had"]], "entropy": [[1.9794921875, 1.3369140625, 0.00266265869140625, 0.1497802734375, 0.07958984375, 0.60986328125, 1.4306640625, 0.035552978515625, 0.00037860870361328125, 0.29833984375, 1.5498046875, 0.826171875, 1.3310546875, 1.326171875, 0.00563812255859375, 0.032318115234375, 0.0802001953125, 0.01265716552734375, 3.534555435180664e-05, 1.6484375, 1.4462890625, 0.2086181640625, 0.791015625, 0.46142578125, 0.274169921875, 0.0687255859375, 0.54248046875, 0.78662109375, 0.0283660888671875, 1.076171875, 0.822265625, 0.03680419921875, 0.04241943359375, 0.338623046875, 2.076171875, 2.6484375, 2.744140625, 3.181640625, 2.0390625, 2.380859375, 5.20703125, 3.294921875, 3.71875, 0.31103515625, 2.826171875, 3.810546875, 2.068359375, 0.76611328125]], "avg_entropy": [1.1819367818534374], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2008", "score_of_biggest_cluster": 0.17239777743816376, "score_of_first_answer": 0.17239777743816376, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.430511474609375e-05, "avg_score": 0.17239777743816376, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38188633393065485, "std_of_first_answer": 0.38188633393065485, "avg_entropy_of_first_answer": 1.1819367818534374, "lex_sim": 1.0}
{"question": "who has the most all ireland hurling medals", "answer": ["Christy Dunne and Brendan Daly have won 6 All-Ireland Hurling titles each."], "scores": [[0.8447265625, 1.0, 0.0059814453125, 0.74658203125, 0.08758544921875, 0.004802703857421875, 1.0, 1.0, 0.1522216796875, 0.7177734375, 0.286376953125, 0.490966796875, 0.7734375, 0.1708984375, 0.90625, 0.97509765625, 1.0, 1.0, 0.689453125, 1.0, 0.1287841796875, 0.71337890625, 0.8896484375, 1.430511474609375e-06, 0.06103515625, 0.0003833770751953125, 0.12030029296875, 0.701171875, 0.000873565673828125, 0.002384185791015625, 8.857250213623047e-05, 0.896484375, 0.016387939453125, 0.8134765625, 0.256591796875, 0.9970703125]], "normalized_score": [0.11664694547653198], "tokens": [["\u2581Christ", "y", "\u2581Dun", "ne", "\u2581and", "\u2581Br", "end", "an", "\u2581Dal", "y", "\u2581have", "\u2581won", "\u2581", "6", "\u2581All", "-", "I", "reland", "\u2581Hur", "ling", "\u2581titles", "\u2581each", ".", "\u2581#", "I", "am", "S", "cience", ":", "\u2581S", "ae", "ed", "\u2581Hass", "an", "p", "our"]], "entropy": [[1.0341796875, 0.0011873245239257812, 0.34130859375, 0.8671875, 2.05078125, 2.373046875, 0.0007944107055664062, 0.0004582405090332031, 2.8515625, 0.7294921875, 1.8896484375, 1.142578125, 0.92724609375, 1.4619140625, 0.3681640625, 0.11798095703125, 0.0004572868347167969, 0.00042057037353515625, 0.99365234375, 0.0006971359252929688, 1.470703125, 0.99462890625, 0.50146484375, 0.3759765625, 4.4140625, 0.6396484375, 4.83984375, 1.775390625, 1.6123046875, 4.52734375, 2.001953125, 0.755859375, 4.4609375, 0.72119140625, 3.7421875, 0.022247314453125]], "avg_entropy": [1.3891250292460124], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Henry Shefflin", "score_of_biggest_cluster": 0.11664694547653198, "score_of_first_answer": 0.11664694547653198, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.430511474609375e-06, "avg_score": 0.11664694547653198, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40523057878959023, "std_of_first_answer": 0.40523057878959023, "avg_entropy_of_first_answer": 1.3891250292460124, "lex_sim": 1.0}
{"question": "an object that moves around an external axis is said to be", "answer": ["rotating THE WITCHES REUNITED"], "scores": [[0.54150390625, 0.86572265625, 0.0, 0.00921630859375, 0.0002396106719970703, 0.0198822021484375, 0.025390625, 0.0013360977172851562, 0.00274658203125, 0.15869140625, 0.97509765625]], "normalized_score": [0.0], "tokens": [["\u2581rot", "ating", "\u2581THE", "\u2581W", "IT", "CH", "ES", "\u2581RE", "UN", "IT", "ED"]], "entropy": [[2.314453125, 0.437744140625, 0.943359375, 2.24609375, 0.6865234375, 0.57861328125, 3.021484375, 3.427734375, 1.248046875, 0.59375, 0.1644287109375]], "avg_entropy": [1.4238392223011365], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "revolution or orbital revolution", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.97509765625, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.35743673470285253, "std_of_first_answer": 0.35743673470285253, "avg_entropy_of_first_answer": 1.4238392223011365, "lex_sim": 1.0}
{"question": "phase change from gas to solid is called", "answer": ["condensation #ELTchat Summary 21/08/2017 \u2013 Teaching listening skills"], "scores": [[0.163330078125, 1.0, 1.0, 2.384185791015625e-07, 0.00031447410583496094, 0.00020420551300048828, 0.00021278858184814453, 0.0, 0.7265625, 0.052703857421875, 0.391357421875, 0.007251739501953125, 0.314697265625, 0.7080078125, 0.0175018310546875, 0.95458984375, 0.98583984375, 0.99755859375, 0.0335693359375, 0.0517578125, 0.00250244140625, 0.07427978515625, 0.98095703125, 0.0189361572265625, 0.79150390625]], "normalized_score": [0.0], "tokens": [["\u2581cond", "ens", "ation", "\u2581#", "E", "LT", "chat", "\u2581Sum", "mary", "\u2581", "2", "1", "/", "0", "8", "/", "2", "0", "1", "7", "\u2581\u2013", "\u2581Te", "aching", "\u2581listening", "\u2581skills"]], "entropy": [[1.4580078125, 0.0018243789672851562, 0.0002009868621826172, 1.0625, 4.8203125, 2.87109375, 3.427734375, 0.78515625, 0.923828125, 2.10546875, 1.9013671875, 0.91748046875, 2.05859375, 1.0400390625, 1.4912109375, 0.26611328125, 0.07489013671875, 0.018951416015625, 0.1510009765625, 0.85498046875, 1.162109375, 4.65234375, 0.11663818359375, 4.8671875, 1.1171875]], "avg_entropy": [1.5258488368988037], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Deposition", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41702996474665516, "std_of_first_answer": 0.41702996474665516, "avg_entropy_of_first_answer": 1.5258488368988037, "lex_sim": 1.0}
{"question": "who has won the most f1 grand prix", "answer": ["Sebastian Vettel #2435538 - 02/07/20 08:53 AM Re: The Mueller Report: The Great Travesty [Re: pdxjim"], "scores": [[0.004302978515625, 1.0, 1.0, 1.0, 1.5497207641601562e-06, 0.049560546875, 0.0218048095703125, 0.1534423828125, 0.023712158203125, 0.054107666015625, 0.0509033203125, 0.042022705078125, 0.0013580322265625, 0.428466796875, 0.03131103515625, 0.044708251953125, 0.80419921875, 0.27294921875, 0.1231689453125, 0.98291015625, 0.98388671875, 0.9765625, 0.0003204345703125, 0.470703125, 0.10302734375, 0.984375, 0.1573486328125, 0.1009521484375, 0.094482421875, 0.00018489360809326172, 0.8154296875, 0.01126861572265625, 5.1856040954589844e-05, 0.97705078125, 0.96337890625, 0.1273193359375, 0.0748291015625, 0.0572509765625, 0.00043272972106933594, 0.8779296875, 0.99951171875, 0.5078125, 0.9990234375, 0.99951171875, 0.00428009033203125, 0.0296173095703125, 0.032806396484375, 0.8818359375]], "normalized_score": [0.0703389123082161], "tokens": [["\u2581Sebastian", "\u2581V", "ett", "el", "\u2581#", "2", "4", "3", "5", "5", "3", "8", "\u2581-", "\u2581", "0", "2", "/", "0", "7", "/", "2", "0", "\u2581", "0", "8", ":", "5", "3", "\u2581AM", "\u2581Re", ":", "\u2581The", "\u2581Mu", "eller", "\u2581Report", ":", "\u2581The", "\u2581Great", "\u2581Tra", "vest", "y", "\u2581[", "Re", ":", "\u2581p", "dx", "j", "im"]], "entropy": [[0.087890625, 0.0022144317626953125, 0.0006780624389648438, 0.0005393028259277344, 1.5126953125, 3.3359375, 2.64453125, 3.23046875, 2.9375, 3.095703125, 3.509765625, 3.42578125, 3.037109375, 4.0859375, 1.59375, 2.44921875, 0.990234375, 1.224609375, 2.177734375, 0.11724853515625, 0.1024169921875, 0.151123046875, 0.083984375, 1.1083984375, 2.267578125, 0.11273193359375, 1.7958984375, 2.310546875, 2.49609375, 1.8994140625, 0.8232421875, 4.83203125, 5.83203125, 0.140869140625, 0.26904296875, 3.16796875, 4.23046875, 4.84765625, 2.783203125, 0.64892578125, 0.006191253662109375, 1.927734375, 0.00740814208984375, 0.00554656982421875, 5.5, 1.9912109375, 1.251953125, 0.671875]], "avg_entropy": [1.890106091896693], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Michael Schumacher", "score_of_biggest_cluster": 0.0703389123082161, "score_of_first_answer": 0.0703389123082161, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.5497207641601562e-06, "avg_score": 0.0703389123082161, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42019748410263547, "std_of_first_answer": 0.42019748410263547, "avg_entropy_of_first_answer": 1.890106091896693, "lex_sim": 1.0}
{"question": "how many characters are present in icd-10 codes", "answer": ["7 characters #Syria #Turkey #ISIS: #Turkey\u2019s Dirty War #TheBlogProphet @dieter_winkel"], "scores": [[0.701171875, 0.442626953125, 0.5625, 1.7881393432617188e-07, 0.00206756591796875, 0.02117919921875, 0.03228759765625, 0.055206298828125, 0.0316162109375, 0.9130859375, 0.99365234375, 0.880859375, 0.047088623046875, 0.9365234375, 6.824731826782227e-05, 0.0295257568359375, 0.028045654296875, 0.91064453125, 0.9794921875, 0.0312347412109375, 0.9931640625, 0.0093841552734375, 0.0029087066650390625, 0.56396484375, 0.07208251953125, 0.021759033203125, 0.0015039443969726562, 0.0022525787353515625, 0.006366729736328125, 0.0726318359375, 0.98779296875, 0.027313232421875, 0.00341796875, 0.213134765625, 0.2362060546875, 0.060394287109375, 0.0178680419921875]], "normalized_score": [0.041597601026296616], "tokens": [["\u2581", "7", "\u2581characters", "\u2581#", "S", "y", "ria", "\u2581#", "T", "ur", "key", "\u2581#", "IS", "IS", ":", "\u2581#", "T", "ur", "key", "\u2019", "s", "\u2581D", "irty", "\u2581War", "\u2581#", "The", "B", "log", "Pro", "ph", "et", "\u2581@", "di", "eter", "_", "w", "inkel"]], "entropy": [[1.623046875, 0.93896484375, 1.578125, 1.1748046875, 5.1640625, 4.28125, 3.94140625, 1.234375, 5.015625, 0.61328125, 0.04705810546875, 0.5107421875, 3.55078125, 0.33447265625, 0.3564453125, 4.79296875, 3.365234375, 0.52587890625, 0.1470947265625, 4.953125, 0.060943603515625, 4.625, 0.69189453125, 1.2666015625, 2.80859375, 3.7734375, 4.9140625, 2.484375, 2.615234375, 3.25390625, 0.0732421875, 1.7734375, 4.49609375, 3.26953125, 3.953125, 4.18359375, 3.50390625]], "avg_entropy": [2.4836681469066724], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "7", "score_of_biggest_cluster": 0.041597601026296616, "score_of_first_answer": 0.041597601026296616, "max_score_of_first_answer": 0.99365234375, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.041597601026296616, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38444432165049014, "std_of_first_answer": 0.38444432165049014, "avg_entropy_of_first_answer": 2.4836681469066724, "lex_sim": 1.0}
{"question": "do you need a permit or license to own a gun in florida", "answer": ["Yes, to carry a concealed weapon, you need a permit."], "scores": [[0.401123046875, 0.74072265625, 0.034515380859375, 0.169921875, 0.99609375, 0.99072265625, 1.0, 0.98291015625, 0.413818359375, 0.209228515625, 0.54931640625, 0.859375, 0.52392578125, 0.201171875, 0.6123046875, 0.10052490234375, 0.9384765625, 0.52294921875, 0.99951171875, 0.1492919921875, 0.9970703125, 0.67236328125, 1.0, 0.9296875, 1.0, 0.99169921875, 0.9931640625, 0.8251953125, 0.7255859375, 0.99951171875, 0.96728515625, 1.0, 0.6181640625, 0.7529296875, 0.99755859375, 0.0391845703125, 0.1048583984375, 0.0614013671875, 0.8896484375, 0.9228515625, 0.9970703125, 1.0, 0.97900390625, 1.0, 0.88916015625, 0.037445068359375, 0.880859375, 0.99853515625, 0.9052734375, 0.1702880859375]], "normalized_score": [0.5174638628959656], "tokens": [["\u2581Yes", ",", "\u2581to", "\u2581carry", "\u2581a", "\u2581conce", "aled", "\u2581weapon", ",", "\u2581you", "\u2581need", "\u2581a", "\u2581permit", ".", "\u2581To", "\u2581purchase", "\u2581a", "\u2581hand", "gun", "\u2581from", "\u2581a", "\u2581lic", "ensed", "\u2581deal", "er", ",", "\u2581you", "\u2581must", "\u2581pass", "\u2581a", "\u2581background", "\u2581check", "\u2581and", "\u2581obtain", "\u2581a", "\u2581permit", "\u2581or", "\u2581pass", "\u2581a", "\u2581three", "-", "day", "\u2581waiting", "\u2581period", ".", "\u2581For", "\u2581long", "\u2581guns", ",", "\u2581such"]], "entropy": [[2.48046875, 0.8935546875, 1.7138671875, 1.5673828125, 0.0295257568359375, 0.06231689453125, 1.627206802368164e-05, 0.09490966796875, 1.08203125, 0.7421875, 1.2998046875, 0.40869140625, 1.232421875, 1.3349609375, 1.5703125, 1.23828125, 0.30908203125, 1.1376953125, 0.003604888916015625, 0.46240234375, 0.0193023681640625, 0.66748046875, 7.903575897216797e-05, 0.303466796875, 0.0004699230194091797, 0.059783935546875, 0.05023193359375, 0.568359375, 0.74267578125, 0.0026836395263671875, 0.1751708984375, 0.001220703125, 0.99462890625, 1.09375, 0.01715087890625, 2.8671875, 1.2939453125, 1.564453125, 0.457275390625, 0.475341796875, 0.02215576171875, 0.000476837158203125, 0.104248046875, 0.0003936290740966797, 0.468994140625, 2.466796875, 0.5693359375, 0.01171112060546875, 0.388916015625, 1.455078125]], "avg_entropy": [0.6901256453990936], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "No", "score_of_biggest_cluster": 0.5174638628959656, "score_of_first_answer": 0.5174638628959656, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.034515380859375, "avg_score": 0.5174638628959656, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3482166651296453, "std_of_first_answer": 0.3482166651296453, "avg_entropy_of_first_answer": 0.6901256453990936, "lex_sim": 1.0}
{"question": "who translated the play neel darpan into english", "answer": ["Suresh Desai"], "scores": [[0.1025390625, 0.086669921875, 1.0, 0.1485595703125, 0.7314453125]], "normalized_score": [0.24944111704826355], "tokens": [["\u2581S", "ures", "h", "\u2581Des", "ai"]], "entropy": [[3.83984375, 1.5859375, 0.0004260540008544922, 3.625, 0.77490234375]], "avg_entropy": [1.965221929550171], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Michael Madhusudan Dutta", "score_of_biggest_cluster": 0.24944111704826355, "score_of_first_answer": 0.24944111704826355, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.086669921875, "avg_score": 0.24944111704826355, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3791513998849655, "std_of_first_answer": 0.3791513998849655, "avg_entropy_of_first_answer": 1.965221929550171, "lex_sim": 1.0}
{"question": "who has most followers on instagram in world", "answer": ["Cristiano Ronaldo #5750469, By SausageMonster PSP2 is Officially announced today."], "scores": [[0.6884765625, 0.9990234375, 0.99951171875, 1.0, 1.0, 3.2782554626464844e-06, 0.0013360977172851562, 0.03070068359375, 0.0295867919921875, 0.43310546875, 0.093994140625, 0.0810546875, 0.092041015625, 1.233816146850586e-05, 1.3530254364013672e-05, 0.0003936290740966797, 6.9141387939453125e-06, 0.08746337890625, 0.0003018379211425781, 0.9619140625, 9.715557098388672e-05, 1.1920928955078125e-05, 0.00511932373046875, 6.699562072753906e-05, 5.4836273193359375e-05, 0.0300750732421875, 0.0002872943878173828, 0.0004982948303222656, 0.07623291015625]], "normalized_score": [0.004830514546483755], "tokens": [["\u2581Crist", "iano", "\u2581R", "onal", "do", "\u2581#", "5", "7", "5", "0", "4", "6", "9", ",", "\u2581By", "\u2581S", "aus", "age", "Mon", "ster", "\u2581P", "SP", "2", "\u2581is", "\u2581Official", "ly", "\u2581announced", "\u2581today", "."]], "entropy": [[1.373046875, 0.00702667236328125, 0.00335693359375, 0.0008711814880371094, 0.0007314682006835938, 1.103515625, 2.5, 3.021484375, 3.240234375, 2.28125, 2.28515625, 2.30078125, 2.275390625, 2.271484375, 3.65625, 1.853515625, 5.26953125, 1.619140625, 4.765625, 0.2156982421875, 3.345703125, 3.421875, 5.16796875, 2.271484375, 3.22265625, 3.625, 4.31640625, 3.94921875, 3.953125]], "avg_entropy": [2.5281906292356293], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Instagram's own account", "score_of_biggest_cluster": 0.004830514546483755, "score_of_first_answer": 0.004830514546483755, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 3.2782554626464844e-06, "avg_score": 0.004830514546483755, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3767723301658634, "std_of_first_answer": 0.3767723301658634, "avg_entropy_of_first_answer": 2.5281906292356293, "lex_sim": 1.0}
{"question": "when was the canadian pacific railway started and finished", "answer": ["The Canadian Pacific Railway began construction in 1881 and was completed in 1885."], "scores": [[0.36962890625, 0.87109375, 0.9990234375, 0.99951171875, 0.053375244140625, 0.91943359375, 0.98876953125, 0.99951171875, 1.0, 1.0, 0.9794921875, 0.99951171875, 0.9921875, 0.99462890625, 0.9853515625, 0.9970703125, 1.0, 1.0, 1.0, 1.0, 0.99951171875, 0.96826171875, 1.1920928955078125e-06, 0.0016469955444335938, 2.5987625122070312e-05, 0.99755859375, 0.716796875, 0.9921875, 9.143352508544922e-05, 0.0175628662109375, 0.002475738525390625, 0.35009765625, 0.25537109375, 0.9990234375, 0.0029048919677734375, 0.00028824806213378906, 0.0013132095336914062]], "normalized_score": [0.12284594774246216], "tokens": [["\u2581The", "\u2581Canadian", "\u2581Pacific", "\u2581Railway", "\u2581began", "\u2581construction", "\u2581in", "\u2581", "1", "8", "8", "1", "\u2581and", "\u2581was", "\u2581completed", "\u2581in", "\u2581", "1", "8", "8", "5", ".", "\u2581#", "A", "to", "Z", "Ch", "allenge", "\u2581\u2013", "\u2581\u201c", "K", "\u201d", "\u2581is", "\u2581for", "\u2581K", "ud", "zu"]], "entropy": [[1.830078125, 0.412353515625, 0.00930023193359375, 0.0035037994384765625, 0.947265625, 0.296875, 0.0631103515625, 0.00727081298828125, 0.00031828880310058594, 0.0005326271057128906, 0.1025390625, 0.0029735565185546875, 0.0494384765625, 0.043304443359375, 0.0885009765625, 0.02069091796875, 0.001079559326171875, 6.413459777832031e-05, 9.685754776000977e-05, 4.774332046508789e-05, 0.0034503936767578125, 0.1810302734375, 0.724609375, 1.55859375, 0.7451171875, 0.0233612060546875, 1.373046875, 0.051605224609375, 1.05859375, 2.681640625, 1.2958984375, 1.1845703125, 2.2734375, 0.00820159912109375, 1.0283203125, 4.2890625, 0.0215911865234375]], "avg_entropy": [0.6049047193011722], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "between 1881 and 1885", "score_of_biggest_cluster": 0.12284594774246216, "score_of_first_answer": 0.12284594774246216, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-06, "avg_score": 0.12284594774246216, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4370960095715996, "std_of_first_answer": 0.4370960095715996, "avg_entropy_of_first_answer": 0.6049047193011722, "lex_sim": 1.0}
{"question": "who was it that described the structure of dna", "answer": ["James Watson and Francis Crick ### What are the different types of clouds?"], "scores": [[0.82666015625, 0.98095703125, 0.97900390625, 0.9970703125, 0.99951171875, 1.0, 0.0, 8.755922317504883e-05, 0.065673828125, 0.58837890625, 0.0111236572265625, 0.5341796875, 0.99267578125, 0.0276336669921875, 0.355712890625]], "normalized_score": [0.0], "tokens": [["\u2581James", "\u2581Watson", "\u2581and", "\u2581Francis", "\u2581Cr", "ick", "\u2581###", "\u2581What", "\u2581are", "\u2581the", "\u2581different", "\u2581types", "\u2581of", "\u2581clouds", "?"]], "entropy": [[0.56298828125, 0.098388671875, 0.12298583984375, 0.02362060546875, 0.00531005859375, 6.687641143798828e-05, 0.9453125, 2.10546875, 3.07421875, 2.265625, 5.12890625, 2.705078125, 0.058837890625, 6.3984375, 2.11328125]], "avg_entropy": [1.707235089937846], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "James Watson and Francis Crick", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4233294165670079, "std_of_first_answer": 0.4233294165670079, "avg_entropy_of_first_answer": 1.707235089937846, "lex_sim": 1.0}
{"question": "who sings so come and dance with me jai ho", "answer": ["Sukhwinder Singh and A.R."], "scores": [[0.8056640625, 0.998046875, 0.95703125, 1.0, 1.0, 0.14453125, 0.0308074951171875, 0.8447265625, 0.323974609375, 0.99755859375, 0.94873046875, 1.0]], "normalized_score": [0.5567750930786133], "tokens": [["\u2581Su", "kh", "w", "inder", "\u2581Singh", "\u2581and", "\u2581A", ".", "R", ".", "\u2581Rah", "man"]], "entropy": [[1.1865234375, 0.015380859375, 0.181884765625, 0.00047850608825683594, 0.0018873214721679688, 1.365234375, 2.83984375, 0.712890625, 0.6376953125, 0.0201263427734375, 0.259765625, 0.0008611679077148438]], "avg_entropy": [0.6018810073534647], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Mahalaxmi Iyer", "score_of_biggest_cluster": 0.5567750930786133, "score_of_first_answer": 0.5567750930786133, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0308074951171875, "avg_score": 0.5567750930786133, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3499821901589941, "std_of_first_answer": 0.3499821901589941, "avg_entropy_of_first_answer": 0.6018810073534647, "lex_sim": 1.0}
{"question": "in what state was the united states center of population gravity located during the period 1790", "answer": ["Maryland"], "scores": [[0.105224609375]], "normalized_score": [0.1052246242761612], "tokens": [["\u2581Maryland"]], "entropy": [[1.39453125]], "avg_entropy": [1.39453125], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Maryland", "score_of_biggest_cluster": 0.1052246242761612, "score_of_first_answer": 0.1052246242761612, "max_score_of_first_answer": 0.105224609375, "min_score_of_first_answer": 0.105224609375, "avg_score": 0.1052246242761612, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.0, "std_of_first_answer": 0.0, "avg_entropy_of_first_answer": 1.39453125, "lex_sim": 1.0}
{"question": "where does blonde hair green eyes come from", "answer": ["Blonde hair and green eyes can occur naturally in people from different geographic regions."], "scores": [[0.0211334228515625, 0.99072265625, 1.0, 0.99267578125, 0.986328125, 1.0, 0.0560302734375, 0.23828125, 0.55712890625, 0.69091796875, 0.354248046875, 0.493408203125, 0.1861572265625, 0.216552734375, 0.88671875, 0.74609375, 0.294189453125, 0.1644287109375, 0.97216796875, 0.99072265625, 0.41845703125, 0.79833984375, 0.414794921875, 0.5849609375, 0.364013671875, 0.9130859375, 0.98291015625, 0.755859375, 0.99951171875, 0.6005859375, 0.484130859375, 0.0699462890625, 0.978515625, 1.7881393432617188e-06, 0.1558837890625, 0.08526611328125, 0.07269287109375, 0.004863739013671875, 0.054351806640625, 0.0003905296325683594, 0.0008420944213867188, 0.61572265625, 0.00040340423583984375, 0.0004787445068359375]], "normalized_score": [0.145846426486969], "tokens": [["\u2581Bl", "onde", "\u2581hair", "\u2581and", "\u2581green", "\u2581eyes", "\u2581can", "\u2581occur", "\u2581naturally", "\u2581in", "\u2581people", "\u2581from", "\u2581different", "\u2581ge", "ographic", "\u2581regions", ".", "\u2581There", "\u2581is", "\u2581no", "\u2581one", "\u2581specific", "\u2581location", "\u2581where", "\u2581this", "\u2581combination", "\u2581of", "\u2581tra", "its", "\u2581origin", "ated", "\u2581from", ".", "\u2581#", "1", "9", "5", ":", "\u2581The", "\u2581In", "j", "ury", "\u2581Thread", "?"]], "entropy": [[2.4453125, 0.0557861328125, 0.0018835067749023438, 0.057159423828125, 0.07275390625, 0.00243377685546875, 1.0654296875, 1.291015625, 1.1337890625, 1.0126953125, 1.9716796875, 1.2294921875, 1.494140625, 1.61328125, 0.355224609375, 0.78271484375, 1.1904296875, 1.9541015625, 0.16162109375, 0.06146240234375, 1.06640625, 0.86669921875, 1.3984375, 1.03125, 0.84765625, 0.477294921875, 0.10577392578125, 0.84326171875, 0.00423431396484375, 0.88916015625, 0.6953125, 0.309814453125, 0.11993408203125, 1.517578125, 4.32421875, 2.48828125, 2.70703125, 2.5625, 5.890625, 4.3984375, 3.060546875, 1.3232421875, 3.62109375, 2.806640625]], "avg_entropy": [1.3933599428697065], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "a low concentration in pigmentation", "score_of_biggest_cluster": 0.145846426486969, "score_of_first_answer": 0.145846426486969, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-06, "avg_score": 0.145846426486969, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3759431565154796, "std_of_first_answer": 0.3759431565154796, "avg_entropy_of_first_answer": 1.3933599428697065, "lex_sim": 1.0}
{"question": "winner of the women's royal rumble match", "answer": ["Charlotte Flair"], "scores": [[0.12939453125, 0.99951171875, 1.0, 1.0]], "normalized_score": [0.5996887683868408], "tokens": [["\u2581Charlotte", "\u2581F", "la", "ir"]], "entropy": [[1.322265625, 0.004650115966796875, 0.0001424551010131836, 2.0682811737060547e-05]], "avg_entropy": [0.3317697197198868], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Asuka", "score_of_biggest_cluster": 0.5996887683868408, "score_of_first_answer": 0.5996887683868408, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.12939453125, "avg_score": 0.5996887683868408, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37691280169082897, "std_of_first_answer": 0.37691280169082897, "avg_entropy_of_first_answer": 0.3317697197198868, "lex_sim": 1.0}
{"question": "what is the second book in the alchemyst series", "answer": ["The Magician"], "scores": [[0.99072265625, 0.9765625, 0.99658203125]], "normalized_score": [0.9879198670387268], "tokens": [["\u2581The", "\u2581Mag", "ician"]], "entropy": [[0.0679931640625, 0.18359375, 0.02630615234375]], "avg_entropy": [0.09263102213541667], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The Magician", "score_of_biggest_cluster": 0.9879198670387268, "score_of_first_answer": 0.9879198670387268, "max_score_of_first_answer": 0.99658203125, "min_score_of_first_answer": 0.9765625, "avg_score": 0.9879198670387268, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.0084038610959802, "std_of_first_answer": 0.0084038610959802, "avg_entropy_of_first_answer": 0.09263102213541667, "lex_sim": 1.0}
{"question": "which player won the pga championship by the most shots", "answer": ["Tiger Woods \\_-T^TZ ^T^T^ '^^^T^"], "scores": [[0.92822265625, 0.9990234375, 0.9951171875, 1.0, 8.404254913330078e-06, 0.0007257461547851562, 0.008056640625, 0.0001804828643798828, 0.0010137557983398438, 0.154541015625, 8.046627044677734e-06, 0.03863525390625, 0.1341552734375, 0.1829833984375, 0.417724609375, 0.05914306640625, 0.00041675567626953125, 0.008056640625, 0.126220703125, 0.198486328125, 0.224609375]], "normalized_score": [0.02075524814426899], "tokens": [["\u2581T", "iger", "\u2581Wood", "s", "\u2581\\", "_", "-", "T", "^", "T", "Z", "\u2581^", "T", "^", "T", "^", "\u2581'", "^^", "^", "T", "^"]], "entropy": [[0.5322265625, 0.00934600830078125, 0.033660888671875, 0.0023479461669921875, 1.5498046875, 0.82958984375, 5.09765625, 1.4638671875, 1.734375, 2.796875, 1.9716796875, 3.375, 3.529296875, 2.875, 2.623046875, 3.0078125, 1.9248046875, 4.046875, 3.748046875, 3.466796875, 3.01953125]], "avg_entropy": [2.268459047589983], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Rory McIlroy", "score_of_biggest_cluster": 0.02075524814426899, "score_of_first_answer": 0.02075524814426899, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 8.046627044677734e-06, "avg_score": 0.02075524814426899, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.36397510657848, "std_of_first_answer": 0.36397510657848, "avg_entropy_of_first_answer": 2.268459047589983, "lex_sim": 1.0}
{"question": "what type of car is a g wagon", "answer": ["G-Class (Mercedes-Benz) #9 \u2013 Rivers of London by Ben Aaronovitch"], "scores": [[0.0499267578125, 0.88720703125, 0.3740234375, 0.06463623046875, 0.52001953125, 0.99951171875, 0.9990234375, 1.0, 1.0, 0.90380859375, 9.5367431640625e-07, 1.0192394256591797e-05, 9.196996688842773e-05, 0.00022721290588378906, 0.00026869773864746094, 0.029693603515625, 0.0034503936767578125, 0.092041015625, 0.99951171875, 0.99853515625, 0.9716796875, 0.9990234375, 0.99755859375]], "normalized_score": [0.04671696200966835], "tokens": [["\u2581G", "-", "Class", "\u2581(", "Mer", "cedes", "-", "B", "enz", ")", "\u2581#", "9", "\u2581\u2013", "\u2581R", "ivers", "\u2581of", "\u2581London", "\u2581by", "\u2581Ben", "\u2581A", "aron", "ov", "itch"]], "entropy": [[0.93701171875, 0.446533203125, 1.0869140625, 1.10546875, 1.966796875, 0.0034122467041015625, 0.0106658935546875, 0.00022602081298828125, 9.429454803466797e-05, 0.4677734375, 0.30224609375, 1.173828125, 2.927734375, 3.296875, 3.296875, 1.46875, 3.8515625, 2.560546875, 0.006099700927734375, 0.01270294189453125, 0.1929931640625, 0.0099945068359375, 0.0195465087890625]], "avg_entropy": [1.093245708424112], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Mercedes-Benz", "score_of_biggest_cluster": 0.04671696200966835, "score_of_first_answer": 0.04671696200966835, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 9.5367431640625e-07, "avg_score": 0.04671696200966835, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4574972136128931, "std_of_first_answer": 0.4574972136128931, "avg_entropy_of_first_answer": 1.093245708424112, "lex_sim": 1.0}
{"question": "who is the actor that plays saul on grace and frankie", "answer": ["Martin Sheen"], "scores": [[0.443603515625, 0.953125, 1.0]], "normalized_score": [0.7505534291267395], "tokens": [["\u2581Martin", "\u2581She", "en"]], "entropy": [[1.3408203125, 0.269775390625, 0.0015859603881835938]], "avg_entropy": [0.5373938878377279], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Sam Waterston", "score_of_biggest_cluster": 0.7505534291267395, "score_of_first_answer": 0.7505534291267395, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.443603515625, "avg_score": 0.7505534291267395, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.25196702969713297, "std_of_first_answer": 0.25196702969713297, "avg_entropy_of_first_answer": 0.5373938878377279, "lex_sim": 1.0}
{"question": "where is the extensor pollicis longus tendon located", "answer": ["it is located on the dorsal aspect of the hand, originating from the lateral epicondyle of the humerus and inserting into the radial side of the thumb ## What is an IPA?"], "scores": [[0.11212158203125, 0.7060546875, 0.98291015625, 0.7587890625, 0.99169921875, 0.46484375, 1.0, 0.31396484375, 0.362060546875, 0.9951171875, 0.99951171875, 0.65966796875, 0.7275390625, 0.330810546875, 0.947265625, 0.89013671875, 0.99951171875, 0.8798828125, 1.0, 0.978515625, 1.0, 1.0, 1.0, 0.99853515625, 1.0, 0.99267578125, 1.0, 1.0, 0.80419921875, 0.9150390625, 0.70556640625, 1.0, 0.45849609375, 0.75146484375, 1.0, 1.0, 0.24560546875, 0.0, 0.0004253387451171875, 0.54833984375, 0.00606536865234375, 0.0006275177001953125, 0.4814453125, 0.261474609375]], "normalized_score": [0.0], "tokens": [["\u2581it", "\u2581is", "\u2581located", "\u2581on", "\u2581the", "\u2581d", "ors", "al", "\u2581aspect", "\u2581of", "\u2581the", "\u2581hand", ",", "\u2581origin", "ating", "\u2581from", "\u2581the", "\u2581later", "al", "\u2581ep", "ic", "ond", "yle", "\u2581of", "\u2581the", "\u2581hum", "er", "us", "\u2581and", "\u2581inserting", "\u2581into", "\u2581the", "\u2581radial", "\u2581side", "\u2581of", "\u2581the", "\u2581thumb", "\u2581##", "\u2581What", "\u2581is", "\u2581an", "\u2581IP", "A", "?"]], "entropy": [[2.814453125, 1.064453125, 0.121337890625, 0.783203125, 0.052947998046875, 1.4404296875, 8.225440979003906e-06, 0.62451171875, 1.4091796875, 0.034423828125, 0.00341033935546875, 0.9384765625, 1.08984375, 3.0, 0.2120361328125, 0.454833984375, 0.0042572021484375, 0.662109375, 4.4286251068115234e-05, 0.1385498046875, 0.00018298625946044922, 0.0001506805419921875, 0.00017714500427246094, 0.01233673095703125, 0.0008654594421386719, 0.0560302734375, 0.002628326416015625, 0.0001042485237121582, 0.626953125, 0.48388671875, 0.79736328125, 0.0006132125854492188, 2.03125, 1.3740234375, 0.0016527175903320312, 0.0002655982971191406, 2.189453125, 1.4716796875, 4.54296875, 2.6015625, 1.369140625, 2.640625, 1.669921875, 2.583984375]], "avg_entropy": [0.8933256756175648], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "dorsally on the forearm", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.34187436742944666, "std_of_first_answer": 0.34187436742944666, "avg_entropy_of_first_answer": 0.8933256756175648, "lex_sim": 1.0}
{"question": "when does star trek discovery season 1 end", "answer": ["May 18, 2018 ## The 091 Labs Open House was a great success!"], "scores": [[0.232666015625, 0.99658203125, 0.84912109375, 0.338134765625, 0.6220703125, 0.9970703125, 0.99365234375, 1.0, 0.73095703125, 0.34765625, 0.0, 0.0019893646240234375, 0.004253387451171875, 0.00263214111328125, 0.056243896484375, 0.012451171875, 0.0036449432373046875, 0.00826263427734375, 0.00893402099609375, 0.00885772705078125, 0.12841796875, 0.81591796875, 0.53759765625, 0.8154296875, 0.630859375, 0.2939453125, 0.01163482666015625, 0.427978515625, 0.0009064674377441406, 0.93798828125, 0.98388671875, 0.040283203125, 0.50537109375, 0.74462890625, 0.99951171875, 1.0, 0.55810546875, 0.99951171875, 0.041534423828125, 1.0, 0.99951171875, 0.95361328125, 0.342041015625, 0.00616455078125, 0.5888671875, 0.9990234375, 0.724609375, 0.8916015625]], "normalized_score": [0.0], "tokens": [["\u2581May", "\u2581", "1", "8", ",", "\u2581", "2", "0", "1", "8", "\u2581##", "\u2581The", "\u2581", "0", "9", "1", "\u2581L", "abs", "\u2581Open", "\u2581House", "\u2581was", "\u2581a", "\u2581great", "\u2581success", "!", "\u2581We", "\u2581celebrated", "\u2581the", "\u2581renov", "ation", "\u2581of", "\u2581the", "\u2581", "0", "9", "1", "\u2581L", "abs", "\u2581cow", "ork", "ing", "\u2581space", "\u2581in", "\u2581Sh", "ored", "itch", ",", "\u2581London"]], "entropy": [[2.6328125, 0.0299224853515625, 0.446044921875, 1.28125, 0.8212890625, 0.0221710205078125, 0.038177490234375, 5.519390106201172e-05, 0.6806640625, 0.71142578125, 1.048828125, 6.34765625, 4.671875, 1.140625, 3.326171875, 2.669921875, 2.978515625, 1.0166015625, 3.853515625, 3.19140625, 3.703125, 0.96875, 2.3671875, 0.7568359375, 1.2578125, 2.841796875, 1.583984375, 1.7021484375, 3.173828125, 0.270751953125, 0.09942626953125, 0.361328125, 2.48828125, 1.04296875, 0.004581451416015625, 0.000396728515625, 2.771484375, 0.0035800933837890625, 2.109375, 0.00020742416381835938, 0.00441741943359375, 0.2607421875, 1.5390625, 5.01171875, 1.431640625, 0.00896453857421875, 0.89501953125, 0.6396484375]], "avg_entropy": [1.5459998721877735], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "February\u00a011,\u00a02018", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3999911701711715, "std_of_first_answer": 0.3999911701711715, "avg_entropy_of_first_answer": 1.5459998721877735, "lex_sim": 1.0}
{"question": "where did the book small steps take place", "answer": ["Earth's Moon #Bonas alumnus to present paper at prestigious international conference"], "scores": [[0.1357421875, 0.0919189453125, 1.0, 0.343505859375, 0.0, 0.00492095947265625, 2.3186206817626953e-05, 5.602836608886719e-06, 0.53271484375, 0.00139617919921875, 0.010528564453125, 0.019500732421875, 0.0049591064453125, 0.6875, 0.014617919921875, 1.0, 0.9990234375, 0.059722900390625, 0.483642578125]], "normalized_score": [0.0], "tokens": [["\u2581Earth", "'", "s", "\u2581Moon", "\u2581#", "B", "onas", "\u2581al", "umn", "us", "\u2581to", "\u2581present", "\u2581paper", "\u2581at", "\u2581pr", "estig", "ious", "\u2581international", "\u2581conference"]], "entropy": [[3.875, 1.333984375, 5.4955482482910156e-05, 1.3359375, 0.87353515625, 4.08203125, 4.34765625, 4.90625, 2.09765625, 0.0290069580078125, 3.716796875, 3.408203125, 3.943359375, 0.97509765625, 2.17578125, 0.0017518997192382812, 0.00814056396484375, 2.880859375, 2.048828125]], "avg_entropy": [2.2126279441933883], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Austin, Texas", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3705395989165544, "std_of_first_answer": 0.3705395989165544, "avg_entropy_of_first_answer": 2.2126279441933883, "lex_sim": 1.0}
{"question": "who did dwight howard play for last year", "answer": ["Washington Wizards."], "scores": [[0.031341552734375, 0.99951171875, 0.99951171875, 1.0, 0.04937744140625, 4.172325134277344e-07, 0.00794219970703125, 0.9833984375, 0.0287322998046875, 0.99951171875, 0.99853515625, 0.00125885009765625, 0.004558563232421875, 0.0010051727294921875, 0.003154754638671875, 0.043914794921875, 0.403564453125, 0.019927978515625, 1.0, 1.0, 1.0, 0.75048828125]], "normalized_score": [0.058290403336286545], "tokens": [["\u2581Washington", "\u2581W", "iz", "ards", ".", "\u2581#", "Throw", "back", "Th", "urs", "day", ":", "\u2581\u201c", "Where", "\u2581Have", "\u2581All", "\u2581The", "\u2581Flow", "ers", "\u2581G", "one", "?\u201d"]], "entropy": [[2.01171875, 0.0036945343017578125, 0.005634307861328125, 0.0014543533325195312, 0.9208984375, 0.273193359375, 4.796875, 0.11328125, 2.1328125, 0.004161834716796875, 0.01235198974609375, 1.822265625, 3.509765625, 3.9140625, 2.615234375, 0.308837890625, 0.7373046875, 2.3203125, 0.001495361328125, 0.0023097991943359375, 6.937980651855469e-05, 0.93505859375]], "avg_entropy": [1.2019451206380671], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Atlanta Hawks", "score_of_biggest_cluster": 0.058290403336286545, "score_of_first_answer": 0.058290403336286545, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.058290403336286545, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4694087326879349, "std_of_first_answer": 0.4694087326879349, "avg_entropy_of_first_answer": 1.2019451206380671, "lex_sim": 1.0}
{"question": "who rebuilt the temple after the babylonian captivity", "answer": ["Zerubbabel"], "scores": [[0.6953125, 1.0, 1.0, 0.99853515625]], "normalized_score": [0.9128214716911316], "tokens": [["\u2581Z", "er", "ub", "babel"]], "entropy": [[1.23828125, 0.000705718994140625, 0.00033354759216308594, 0.0131378173828125]], "avg_entropy": [0.31311458349227905], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Herod", "score_of_biggest_cluster": 0.9128214716911316, "score_of_first_answer": 0.9128214716911316, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.6953125, "avg_score": 0.9128214716911316, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.13172348312616602, "std_of_first_answer": 0.13172348312616602, "avg_entropy_of_first_answer": 0.31311458349227905, "lex_sim": 1.0}
{"question": "when did the movie the post begin filming", "answer": ["Filming began in October 2017."], "scores": [[0.08526611328125, 0.99951171875, 0.57666015625, 0.72314453125, 0.50146484375, 0.99267578125, 1.0, 1.0, 1.0, 0.9736328125, 0.8056640625, 7.152557373046875e-07, 0.00016927719116210938, 0.98974609375, 1.0, 0.11920166015625, 1.0, 0.0070953369140625, 8.696317672729492e-05, 0.00331878662109375, 0.006282806396484375, 0.0285186767578125, 0.1015625, 0.044281005859375, 0.0009307861328125, 0.01580810546875, 0.7041015625, 0.99853515625, 0.015289306640625, 0.0582275390625, 0.6240234375, 0.059356689453125, 0.86376953125, 0.18212890625, 0.007297515869140625, 0.6376953125, 0.966796875, 0.921875, 0.9990234375, 0.986328125, 0.221435546875, 0.99267578125]], "normalized_score": [0.10678737610578537], "tokens": [["\u2581Fil", "ming", "\u2581began", "\u2581in", "\u2581October", "\u2581", "2", "0", "1", "7", ".", "\u2581#", "Me", "To", "o", "\u2581Mov", "ement", ":", "\u2581India", "\u2581Has", "\u2581", "9", "9", "9", "\u2581Report", "ed", "\u2581C", "ases", "\u2581In", "\u2581The", "\u2581Last", "\u2581Two", "\u2581Years", ",", "\u2581Ministry", "\u2581Of", "\u2581Women", "\u2581And", "\u2581Child", "\u2581Development", "\u2581S", "ays"]], "entropy": [[2.7578125, 0.005870819091796875, 0.79248046875, 0.6103515625, 1.626953125, 0.0489501953125, 0.0003180503845214844, 0.0007824897766113281, 1.7940998077392578e-05, 0.123291015625, 0.6962890625, 0.8505859375, 1.6103515625, 0.08447265625, 0.002349853515625, 3.0703125, 0.0023193359375, 3.458984375, 4.64453125, 4.26953125, 3.515625, 1.93359375, 3.140625, 2.400390625, 3.78125, 1.5361328125, 1.0224609375, 0.01322174072265625, 1.6640625, 1.66015625, 1.2646484375, 1.5224609375, 0.6259765625, 3.505859375, 4.44140625, 1.17578125, 0.2100830078125, 0.373291015625, 0.00818634033203125, 0.10565185546875, 3.462890625, 0.04669189453125]], "avg_entropy": [1.4777857647055672], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "May 2017", "score_of_biggest_cluster": 0.10678737610578537, "score_of_first_answer": 0.10678737610578537, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 7.152557373046875e-07, "avg_score": 0.10678737610578537, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43242164476588935, "std_of_first_answer": 0.43242164476588935, "avg_entropy_of_first_answer": 1.4777857647055672, "lex_sim": 1.0}
{"question": "who won the men's ice skating 2018", "answer": ["Nathan Chen"], "scores": [[0.6103515625, 0.9951171875]], "normalized_score": [0.7793403267860413], "tokens": [["\u2581Nathan", "\u2581Chen"]], "entropy": [[0.93408203125, 0.036773681640625]], "avg_entropy": [0.4854278564453125], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Yuzuru Hanyu", "score_of_biggest_cluster": 0.7793403267860413, "score_of_first_answer": 0.7793403267860413, "max_score_of_first_answer": 0.9951171875, "min_score_of_first_answer": 0.6103515625, "avg_score": 0.7793403267860413, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.1923828125, "std_of_first_answer": 0.1923828125, "avg_entropy_of_first_answer": 0.4854278564453125, "lex_sim": 1.0}
{"question": "who sings the theme song for the tv show cops", "answer": ["Rick Shapiro and Glenn Frey #GivingTuesday is a global giving movement that has been built by individuals, families, organizations, businesses, and communities in countries around the world."], "scores": [[0.020843505859375, 0.01544952392578125, 0.01438140869140625, 1.0, 0.08135986328125, 0.0019245147705078125, 0.98779296875, 0.82958984375, 0.99951171875, 1.7881393432617188e-07, 0.0096588134765625, 0.002918243408203125, 0.00787353515625, 0.98291015625, 0.998046875, 0.01496124267578125, 0.54345703125, 0.429931640625, 0.1507568359375, 0.9912109375, 0.60107421875, 0.990234375, 1.0, 1.0, 0.9912109375, 0.133056640625, 0.99755859375, 0.998046875, 0.98974609375, 0.99560546875, 0.990234375, 0.99951171875, 1.0, 0.90087890625, 0.984375, 0.99169921875, 0.98583984375, 0.11572265625, 0.99072265625, 0.994140625, 0.99609375, 0.98486328125, 0.0406494140625, 0.99853515625, 0.99658203125, 0.99658203125, 0.85888671875, 0.9970703125]], "normalized_score": [0.2427622377872467], "tokens": [["\u2581Rick", "\u2581Sh", "api", "ro", "\u2581and", "\u2581Gl", "enn", "\u2581Fre", "y", "\u2581#", "G", "iving", "T", "ues", "day", "\u2581is", "\u2581a", "\u2581global", "\u2581giving", "\u2581movement", "\u2581that", "\u2581has", "\u2581been", "\u2581built", "\u2581by", "\u2581individuals", ",", "\u2581families", ",", "\u2581organizations", ",", "\u2581business", "es", ",", "\u2581and", "\u2581communities", "\u2581in", "\u2581countries", "\u2581around", "\u2581the", "\u2581world", ".", "\u2581Mill", "ions", "\u2581of", "\u2581people", "\u2581have", "\u2581come"]], "entropy": [[4.47265625, 4.953125, 3.498046875, 0.0006155967712402344, 1.1181640625, 3.931640625, 0.06646728515625, 1.298828125, 0.006015777587890625, 1.0478515625, 4.90625, 2.2265625, 1.951171875, 0.130615234375, 0.0178680419921875, 3.75, 2.44921875, 2.599609375, 1.1845703125, 0.06817626953125, 1.2353515625, 0.08575439453125, 0.0017833709716796875, 0.002010345458984375, 0.0550537109375, 2.00390625, 0.018402099609375, 0.0153045654296875, 0.06158447265625, 0.03729248046875, 0.057586669921875, 0.003177642822265625, 0.0001246929168701172, 0.360595703125, 0.0911865234375, 0.07366943359375, 0.09320068359375, 0.60498046875, 0.058837890625, 0.03778076171875, 0.0308685302734375, 0.11083984375, 1.880859375, 0.01239776611328125, 0.022857666015625, 0.032867431640625, 0.414306640625, 0.0254058837890625]], "avg_entropy": [0.9813633412122726], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Inner Circle", "score_of_biggest_cluster": 0.2427622377872467, "score_of_first_answer": 0.2427622377872467, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.2427622377872467, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42469471274466813, "std_of_first_answer": 0.42469471274466813, "avg_entropy_of_first_answer": 0.9813633412122726, "lex_sim": 1.0}
{"question": "who plays jack skellington in nightmare before christmas", "answer": ["Tim Burton"], "scores": [[0.23486328125, 0.99951171875, 1.0]], "normalized_score": [0.616880476474762], "tokens": [["\u2581Tim", "\u2581Bur", "ton"]], "entropy": [[4.17578125, 0.00716400146484375, 0.0016050338745117188]], "avg_entropy": [1.3948500951131184], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Danny Elfman", "score_of_biggest_cluster": 0.616880476474762, "score_of_first_answer": 0.616880476474762, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.23486328125, "avg_score": 0.616880476474762, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.36057387434928523, "std_of_first_answer": 0.36057387434928523, "avg_entropy_of_first_answer": 1.3948500951131184, "lex_sim": 1.0}
{"question": "what does aa on a license plate mean", "answer": ["Anti-theft #LATAM News"], "scores": [[0.262451171875, 0.9912109375, 0.91552734375, 1.0, 5.364418029785156e-07, 1.71661376953125e-05, 9.560585021972656e-05, 0.049041748046875, 2.8192996978759766e-05]], "normalized_score": [0.0040450068190693855], "tokens": [["\u2581Anti", "-", "the", "ft", "\u2581#", "L", "AT", "AM", "\u2581News"]], "entropy": [[1.837890625, 0.07147216796875, 0.45947265625, 7.295608520507812e-05, 1.1962890625, 0.77587890625, 1.1767578125, 3.046875, 2.84765625]], "avg_entropy": [1.2680406040615506], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "cars of the royal family", "score_of_biggest_cluster": 0.0040450068190693855, "score_of_first_answer": 0.0040450068190693855, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.364418029785156e-07, "avg_score": 0.0040450068190693855, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4398351766656597, "std_of_first_answer": 0.4398351766656597, "avg_entropy_of_first_answer": 1.2680406040615506, "lex_sim": 1.0}
{"question": "love yourself by justin bieber is about who", "answer": ["a breakup with someone he was in a relationship with, and the introspection and learning to love oneself that followed."], "scores": [[0.0054931640625, 0.0124664306640625, 0.904296875, 0.5322265625, 0.00444793701171875, 0.260009765625, 0.74951171875, 0.83203125, 0.9384765625, 0.7841796875, 0.998046875, 0.0660400390625, 0.314453125, 0.171630859375, 0.019805908203125, 0.88232421875, 0.5712890625, 0.0176544189453125, 0.435302734375, 0.9677734375, 0.9775390625, 1.0, 0.9697265625, 0.277099609375, 0.77099609375, 2.3245811462402344e-06, 0.0020694732666015625, 0.057647705078125, 0.00019681453704833984, 0.005268096923828125, 0.0001285076141357422, 0.08428955078125, 0.0262298583984375, 0.00014150142669677734, 0.97705078125, 0.86181640625, 0.002552032470703125, 0.029052734375, 0.478515625, 0.99462890625, 0.10870361328125, 0.0255279541015625, 0.86962890625, 0.9990234375, 0.47509765625]], "normalized_score": [0.08388600498437881], "tokens": [["\u2581a", "\u2581break", "up", "\u2581with", "\u2581someone", "\u2581he", "\u2581was", "\u2581in", "\u2581a", "\u2581relationship", "\u2581with", ",", "\u2581and", "\u2581the", "\u2581intros", "pection", "\u2581and", "\u2581learning", "\u2581to", "\u2581love", "\u2581ones", "elf", "\u2581that", "\u2581followed", ".", "\u2581#", "4", "9", ")", "\u2581The", "\u2581In", "cred", "ible", "\u2581Import", "ance", "\u2581of", "\u2581M", "ent", "or", "ship", "\u2581in", "\u2581Le", "ad", "ership", "\u2581Development"]], "entropy": [[2.21484375, 2.52734375, 0.3935546875, 1.525390625, 1.0576171875, 2.21875, 1.033203125, 0.75244140625, 0.2330322265625, 0.7587890625, 0.01514434814453125, 1.4912109375, 3.029296875, 2.974609375, 2.626953125, 0.36279296875, 0.80712890625, 1.3125, 1.21484375, 0.2181396484375, 0.12939453125, 0.0015478134155273438, 0.1925048828125, 1.1533203125, 0.69189453125, 0.413818359375, 3.603515625, 2.876953125, 2.833984375, 1.60546875, 4.00390625, 3.66015625, 0.1600341796875, 2.228515625, 0.1317138671875, 0.50341796875, 2.943359375, 1.9267578125, 1.48828125, 0.056427001953125, 3.322265625, 3.462890625, 0.548828125, 0.00899505615234375, 2.474609375]], "avg_entropy": [1.493114365471734], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Rihanna", "score_of_biggest_cluster": 0.08388600498437881, "score_of_first_answer": 0.08388600498437881, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.3245811462402344e-06, "avg_score": 0.08388600498437881, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40416054169780613, "std_of_first_answer": 0.40416054169780613, "avg_entropy_of_first_answer": 1.493114365471734, "lex_sim": 1.0}
{"question": "who was originally cast as phoebe on charmed", "answer": ["Jane Krakowski"], "scores": [[0.006496429443359375, 0.4443359375, 0.99951171875]], "normalized_score": [0.142361119389534], "tokens": [["\u2581Jane", "\u2581Krak", "owski"]], "entropy": [[2.990234375, 3.419921875, 0.00531768798828125]], "avg_entropy": [2.1384913126627603], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Lori Rom", "score_of_biggest_cluster": 0.142361119389534, "score_of_first_answer": 0.142361119389534, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.006496429443359375, "avg_score": 0.142361119389534, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40633906855380714, "std_of_first_answer": 0.40633906855380714, "avg_entropy_of_first_answer": 2.1384913126627603, "lex_sim": 1.0}
{"question": "who was assassinated during a visit to sarajevo in bosnia", "answer": ["Archduke Franz Ferdinand of Austria."], "scores": [[0.9873046875, 0.99951171875, 1.0, 0.99658203125, 0.99951171875, 0.88623046875, 0.99951171875, 0.08636474609375, 2.384185791015625e-06, 0.00040841102600097656, 0.004543304443359375, 5.358457565307617e-05, 0.0, 0.81884765625, 1.0, 0.006580352783203125, 1.0, 0.9990234375, 0.030120849609375, 0.0027256011962890625, 0.99755859375, 0.98388671875, 0.99755859375, 0.9853515625, 0.99609375]], "normalized_score": [0.0], "tokens": [["\u2581Arch", "du", "ke", "\u2581Franz", "\u2581Ferdinand", "\u2581of", "\u2581Austria", ".", "\u2581#", "Re", "view", "\u2581A", "\u2581Knight", "'", "s", "\u2581Ven", "ge", "ance", "\u2581by", "\u2581Kath", "ry", "n", "\u2581Le", "\u2581Ve", "que"]], "entropy": [[0.074951171875, 0.004451751708984375, 1.6033649444580078e-05, 0.0277557373046875, 0.0039215087890625, 0.44091796875, 0.004283905029296875, 1.2138671875, 0.256103515625, 5.00390625, 2.85546875, 4.21484375, 2.107421875, 0.724609375, 6.878376007080078e-05, 1.1376953125, 0.0007863044738769531, 0.00766754150390625, 1.283203125, 3.265625, 0.022308349609375, 0.0855712890625, 0.019500732421875, 0.09112548828125, 0.032928466796875]], "avg_entropy": [0.9151599669456482], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Archduke Franz Ferdinand of Austria", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.46438325338121134, "std_of_first_answer": 0.46438325338121134, "avg_entropy_of_first_answer": 0.9151599669456482, "lex_sim": 1.0}
{"question": "who was toot toot in the green mile", "answer": ["red"], "scores": [[0.0209808349609375]], "normalized_score": [0.02098083682358265], "tokens": [["\u2581red"]], "entropy": [[3.509765625]], "avg_entropy": [3.509765625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "A trustee", "score_of_biggest_cluster": 0.02098083682358265, "score_of_first_answer": 0.02098083682358265, "max_score_of_first_answer": 0.0209808349609375, "min_score_of_first_answer": 0.0209808349609375, "avg_score": 0.02098083682358265, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.0, "std_of_first_answer": 0.0, "avg_entropy_of_first_answer": 3.509765625, "lex_sim": 1.0}
{"question": "where was the remake of dirty dancing filmed", "answer": ["The remake of \"Dirty Dancing\" was filmed in Australia and Ireland."], "scores": [[0.1016845703125, 0.89599609375, 1.0, 0.99609375, 0.305908203125, 1.0, 1.0, 1.0, 1.0, 0.99951171875, 0.9658203125, 0.97412109375, 1.0, 0.9931640625, 0.14453125, 0.082275390625, 0.13720703125, 0.95751953125, 3.5762786865234375e-07, 0.001140594482421875, 1.2934207916259766e-05, 0.14306640625, 0.0007901191711425781, 0.15380859375, 0.222900390625, 0.058074951171875, 0.05523681640625, 0.48828125, 0.0689697265625, 0.248291015625, 0.29443359375, 0.55029296875, 1.0, 0.89208984375]], "normalized_score": [0.13569021224975586], "tokens": [["\u2581The", "\u2581re", "make", "\u2581of", "\u2581\"", "Dir", "ty", "\u2581Dan", "cing", "\"", "\u2581was", "\u2581fil", "med", "\u2581in", "\u2581Australia", "\u2581and", "\u2581Ireland", ".", "\u2581#", "I", "WS", "G", ":", "\u2581What", "\u2581are", "\u2581the", "\u2581benefits", "\u2581of", "\u2581writing", "\u2581in", "\u2581different", "\u2581gen", "res", "?"]], "entropy": [[3.669921875, 0.669921875, 0.001079559326171875, 0.0265045166015625, 0.83203125, 0.002109527587890625, 0.00010031461715698242, 0.001972198486328125, 0.00018322467803955078, 0.004703521728515625, 0.1943359375, 0.1285400390625, 1.0132789611816406e-06, 0.050262451171875, 4.14453125, 0.68896484375, 3.0078125, 0.1983642578125, 0.54052734375, 2.8359375, 1.138671875, 3.537109375, 1.3515625, 4.0546875, 2.369140625, 1.0146484375, 2.203125, 0.74658203125, 3.7265625, 3.251953125, 1.5390625, 1.365234375, 0.0006046295166015625, 0.52685546875]], "avg_entropy": [1.2889295570990618], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "High Hampton Inn in Cashiers", "score_of_biggest_cluster": 0.13569021224975586, "score_of_first_answer": 0.13569021224975586, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 3.5762786865234375e-07, "avg_score": 0.13569021224975586, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4226257892165973, "std_of_first_answer": 0.4226257892165973, "avg_entropy_of_first_answer": 1.2889295570990618, "lex_sim": 1.0}
{"question": "who sang it's a mean old world", "answer": ["BB King"], "scores": [[0.002407073974609375, 0.99853515625]], "normalized_score": [0.049025990068912506], "tokens": [["\u2581BB", "\u2581King"]], "entropy": [[2.39453125, 0.01291656494140625]], "avg_entropy": [1.2037239074707031], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "T-Bone Walker", "score_of_biggest_cluster": 0.049025990068912506, "score_of_first_answer": 0.049025990068912506, "max_score_of_first_answer": 0.99853515625, "min_score_of_first_answer": 0.002407073974609375, "avg_score": 0.049025990068912506, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4980640411376953, "std_of_first_answer": 0.4980640411376953, "avg_entropy_of_first_answer": 1.2037239074707031, "lex_sim": 1.0}
{"question": "where do the maple leafs play hockey in toronto", "answer": ["Scotiabank Arena (previously known as Air Canada Centre) #MondayMotivation: Overcoming Adversity"], "scores": [[0.71044921875, 0.99951171875, 1.0, 1.0, 0.9990234375, 0.32763671875, 0.041717529296875, 1.0, 0.73095703125, 1.0, 0.480224609375, 1.0, 1.0, 0.88720703125, 1.1920928955078125e-07, 0.007648468017578125, 0.007015228271484375, 0.99072265625, 0.8056640625, 0.9931640625, 0.99951171875, 0.99951171875, 0.01540374755859375, 0.0016012191772460938, 0.43798828125, 0.047332763671875, 1.0, 0.9921875]], "normalized_score": [0.19132950901985168], "tokens": [["\u2581Scot", "i", "ab", "ank", "\u2581Arena", "\u2581(", "pre", "viously", "\u2581known", "\u2581as", "\u2581Air", "\u2581Canada", "\u2581Centre", ")", "\u2581#", "M", "ond", "ay", "M", "ot", "iv", "ation", ":", "\u2581Over", "coming", "\u2581Ad", "vers", "ity"]], "entropy": [[0.9248046875, 0.00254058837890625, 0.000255584716796875, 7.152557373046875e-05, 0.010589599609375, 1.1357421875, 0.55908203125, 3.534555435180664e-05, 0.6650390625, 0.0009245872497558594, 0.6982421875, 0.0006265640258789062, 0.0023365020751953125, 0.462158203125, 0.327880859375, 2.818359375, 3.216796875, 0.056396484375, 1.005859375, 0.060638427734375, 0.00429534912109375, 0.004791259765625, 1.7548828125, 4.296875, 1.1845703125, 3.283203125, 0.0011949539184570312, 0.051605224609375]], "avg_entropy": [0.8046356460877827], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Air Canada Centre", "score_of_biggest_cluster": 0.19132950901985168, "score_of_first_answer": 0.19132950901985168, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.19132950901985168, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.41262827726447304, "std_of_first_answer": 0.41262827726447304, "avg_entropy_of_first_answer": 0.8046356460877827, "lex_sim": 1.0}
{"question": "how many tornado planes does the uk have", "answer": ["I do not have information on the exact number of Tornado planes in the UK."], "scores": [[0.379150390625, 0.12078857421875, 0.99951171875, 0.95458984375, 0.6181640625, 0.60400390625, 0.87939453125, 0.0745849609375, 0.99658203125, 0.9912109375, 0.07220458984375, 1.0, 1.0, 0.966796875, 1.0, 0.08544921875, 0.98291015625, 0.9853515625, 0.7431640625, 1.1920928955078125e-06, 0.04693603515625, 0.043548583984375, 0.057403564453125, 0.0004208087921142578, 0.088623046875, 0.41650390625, 0.0283050537109375, 0.197265625, 0.1279296875, 0.015380859375, 8.404254913330078e-06, 0.056182861328125]], "normalized_score": [0.10523287206888199], "tokens": [["\u2581I", "\u2581do", "\u2581not", "\u2581have", "\u2581information", "\u2581on", "\u2581the", "\u2581exact", "\u2581number", "\u2581of", "\u2581T", "orn", "ado", "\u2581plan", "es", "\u2581in", "\u2581the", "\u2581UK", ".", "\u2581#", "1", "5", "6", "\u2581-", "\u2581", "1", "2", "0", "0", "\u2581W", "\u2581Georgia", "\u2581St"]], "entropy": [[2.19921875, 1.205078125, 0.00290679931640625, 0.190185546875, 1.4189453125, 0.8818359375, 0.5966796875, 1.298828125, 0.028533935546875, 0.06292724609375, 0.30712890625, 0.0009746551513671875, 0.0008592605590820312, 0.1834716796875, 1.710653305053711e-05, 1.0751953125, 0.10833740234375, 0.07940673828125, 0.837890625, 1.9384765625, 5.484375, 2.73828125, 2.958984375, 3.232421875, 5.1875, 1.87109375, 2.287109375, 3.53125, 4.1796875, 3.849609375, 0.591796875, 1.3974609375]], "avg_entropy": [1.5539521258324385], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "138", "score_of_biggest_cluster": 0.10523287206888199, "score_of_first_answer": 0.10523287206888199, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-06, "avg_score": 0.10523287206888199, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42038617092572805, "std_of_first_answer": 0.42038617092572805, "avg_entropy_of_first_answer": 1.5539521258324385, "lex_sim": 1.0}
{"question": "when was the last time michigan won the championship", "answer": ["Michigan has won several championships in various sports, with the most recent one being the Michigan Wolverines football team winning the College Football Playoff National Championship in January 2021."], "scores": [[0.10223388671875, 0.61279296875, 0.57177734375, 0.223876953125, 0.94482421875, 1.0, 0.8193359375, 0.5126953125, 0.99951171875, 0.42724609375, 0.0022678375244140625, 0.99658203125, 0.8779296875, 0.9990234375, 0.398681640625, 0.97021484375, 0.5439453125, 0.47314453125, 0.99609375, 1.0, 0.99951171875, 0.56689453125, 0.99951171875, 0.9140625, 0.99951171875, 0.091552734375, 0.9990234375, 0.9892578125, 1.0, 0.99755859375, 1.0, 0.9794921875, 0.0660400390625, 0.970703125, 1.0, 1.0, 0.98193359375, 0.9931640625, 0.98291015625, 1.4901161193847656e-06, 2.9802322387695312e-06, 0.90283203125, 0.0298004150390625, 0.998046875, 0.998046875, 0.00070953369140625, 0.0007319450378417969, 0.0003733634948730469]], "normalized_score": [0.2179258167743683], "tokens": [["\u2581Michigan", "\u2581has", "\u2581won", "\u2581several", "\u2581champion", "ships", "\u2581in", "\u2581various", "\u2581sports", ",", "\u2581with", "\u2581the", "\u2581most", "\u2581recent", "\u2581one", "\u2581being", "\u2581the", "\u2581Michigan", "\u2581Wol", "ver", "ines", "\u2581football", "\u2581team", "\u2581winning", "\u2581the", "\u2581College", "\u2581Football", "\u2581Play", "off", "\u2581National", "\u2581Championship", "\u2581in", "\u2581January", "\u2581", "2", "0", "2", "1", ".", "\u2581#", "Throw", "back", "Th", "urs", "day", ":", "\u2581S", "ens"]], "entropy": [[1.6884765625, 1.4814453125, 0.818359375, 1.923828125, 0.254150390625, 0.00012034177780151367, 0.73486328125, 0.78125, 0.005462646484375, 1.38671875, 1.986328125, 0.030364990234375, 0.431884765625, 0.008697509765625, 1.2236328125, 0.1827392578125, 0.81591796875, 1.4013671875, 0.03118896484375, 0.0008707046508789062, 0.0026397705078125, 1.11328125, 0.005802154541015625, 0.417236328125, 0.005878448486328125, 1.5908203125, 0.0094451904296875, 0.06365966796875, 0.00136566162109375, 0.0182952880859375, 0.0017414093017578125, 0.11932373046875, 0.85791015625, 0.1414794921875, 0.0015325546264648438, 0.0013484954833984375, 0.0914306640625, 0.04510498046875, 0.115234375, 1.1396484375, 0.2509765625, 0.537109375, 2.328125, 0.01971435546875, 0.0168304443359375, 2.25390625, 3.880859375, 2.916015625]], "avg_entropy": [0.6902996338903904], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1989", "score_of_biggest_cluster": 0.2179258167743683, "score_of_first_answer": 0.2179258167743683, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.4901161193847656e-06, "avg_score": 0.2179258167743683, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3903534447341292, "std_of_first_answer": 0.3903534447341292, "avg_entropy_of_first_answer": 0.6902996338903904, "lex_sim": 1.0}
{"question": "who owns the crown plaza hotel in chicago illinois", "answer": ["I am not able to provide information on the current ownership of specific properties."], "scores": [[0.255859375, 0.11651611328125, 0.4462890625, 0.3349609375, 0.99951171875, 0.1932373046875, 0.405029296875, 0.59521484375, 0.544921875, 0.72021484375, 0.5400390625, 0.953125, 0.791015625, 0.1912841796875, 0.63916015625, 0.0716552734375, 0.3681640625, 0.84423828125, 0.89990234375, 0.9443359375, 0.405029296875, 0.7431640625, 0.4091796875, 1.0, 1.0, 0.71240234375, 0.9794921875, 0.0305328369140625, 0.9248046875, 0.99072265625, 0.0, 0.66015625, 0.03912353515625, 0.485595703125, 0.00917816162109375, 1.6927719116210938e-05, 0.038421630859375, 0.0009603500366210938, 0.77294921875, 0.57421875]], "normalized_score": [0.0], "tokens": [["\u2581I", "\u2581am", "\u2581not", "\u2581able", "\u2581to", "\u2581provide", "\u2581information", "\u2581on", "\u2581the", "\u2581current", "\u2581ownership", "\u2581of", "\u2581specific", "\u2581properties", ".", "\u2581Please", "\u2581check", "\u2581with", "\u2581the", "\u2581hotel", "\u2581or", "\u2581a", "\u2581re", "put", "able", "\u2581source", "\u2581for", "\u2581more", "\u2581information", ".", "\u2581Chapter", "\u2581", "6", ":", "\u2581", "\u300a", "The", "\u2581Dark", "\u2581Knight", "\u300b"]], "entropy": [[1.046875, 1.5908203125, 1.259765625, 1.267578125, 0.00553131103515625, 1.58984375, 1.7978515625, 0.7255859375, 1.208984375, 0.85693359375, 0.8251953125, 0.204833984375, 0.814453125, 1.0673828125, 1.0732421875, 2.392578125, 1.4267578125, 0.685546875, 0.390625, 0.333984375, 1.2900390625, 1.2060546875, 1.33203125, 0.0009112358093261719, 0.0002372264862060547, 0.98486328125, 0.10833740234375, 1.599609375, 0.345458984375, 0.057403564453125, 0.69775390625, 2.0390625, 1.50390625, 2.23046875, 5.29296875, 2.0234375, 6.234375, 6.11328125, 1.1669921875, 1.0791015625]], "avg_entropy": [1.396766573190689], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "InterContinental Hotels Group", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3441079357421839, "std_of_first_answer": 0.3441079357421839, "avg_entropy_of_first_answer": 1.396766573190689, "lex_sim": 1.0}
{"question": "when was national service abolished in the uk", "answer": ["1960 #007 - \"The Evolution of a Podcast\" - Nicole Rodrigues"], "scores": [[0.9765625, 0.99169921875, 1.0, 0.99951171875, 0.1414794921875, 1.1920928955078125e-07, 0.0008997917175292969, 0.2493896484375, 0.03692626953125, 0.0006508827209472656, 0.005611419677734375, 0.08154296875, 0.002902984619140625, 0.14599609375, 0.9140625, 0.01473236083984375, 0.0002372264862060547, 0.68603515625, 0.53955078125, 0.17724609375, 0.0035495758056640625, 0.0159149169921875, 0.0052642822265625, 0.9404296875, 0.98388671875]], "normalized_score": [0.03628552332520485], "tokens": [["\u2581", "1", "9", "6", "0", "\u2581#", "0", "0", "7", "\u2581-", "\u2581\"", "The", "\u2581E", "volution", "\u2581of", "\u2581a", "\u2581Pod", "cast", "\"", "\u2581-", "\u2581N", "icole", "\u2581Rod", "rig", "ues"]], "entropy": [[0.1741943359375, 0.04754638671875, 0.000514984130859375, 0.00469207763671875, 0.634765625, 1.3720703125, 5.27734375, 3.15625, 1.55859375, 3.072265625, 5.48828125, 4.6015625, 5.7421875, 3.0703125, 0.5859375, 2.732421875, 4.78125, 1.4462890625, 2.30859375, 2.83984375, 5.5546875, 2.564453125, 2.64453125, 0.278076171875, 0.084228515625]], "avg_entropy": [2.4008357238769533], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1960", "score_of_biggest_cluster": 0.03628552332520485, "score_of_first_answer": 0.03628552332520485, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.03628552332520485, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4171785547277923, "std_of_first_answer": 0.4171785547277923, "avg_entropy_of_first_answer": 2.4008357238769533, "lex_sim": 1.0}
{"question": "what features of muscle contraction can be determined from an emg (electromyogram)", "answer": ["The electromyogram (EMG) measures the electrical activity of muscles during contraction and relaxation."], "scores": [[0.259033203125, 0.00373077392578125, 0.9072265625, 1.0, 0.990234375, 0.94580078125, 0.99951171875, 1.0, 0.99951171875, 0.69091796875, 0.9619140625, 0.99560546875, 1.0, 0.99853515625, 0.1988525390625, 0.98486328125, 0.7373046875, 0.1279296875, 0.97216796875, 0.97021484375, 0.57421875, 0.783203125, 1.0, 0.8916015625, 0.392333984375, 0.66650390625, 0.99951171875, 1.0, 0.96240234375, 0.343994140625, 0.77294921875, 0.99169921875, 0.93896484375, 0.9990234375, 1.0, 0.99951171875, 0.998046875, 0.99951171875, 0.99951171875, 0.9990234375, 0.99951171875]], "normalized_score": [0.6891182065010071], "tokens": [["\u2581The", "\u2581elect", "rom", "y", "ogram", "\u2581(", "EM", "G", ")", "\u2581measures", "\u2581the", "\u2581elect", "rical", "\u2581activity", "\u2581of", "\u2581mus", "cles", "\u2581during", "\u2581contra", "ction", "\u2581and", "\u2581relax", "ation", ".", "\u2581From", "\u2581an", "\u2581EM", "G", ",", "\u2581the", "\u2581following", "\u2581features", "\u2581of", "\u2581mus", "cle", "\u2581contra", "ction", "\u2581can", "\u2581be", "\u2581determined", ":"]], "entropy": [[2.5234375, 1.5771484375, 0.311279296875, 0.0003943443298339844, 0.05780029296875, 0.29931640625, 0.004852294921875, 0.0017547607421875, 0.0064849853515625, 0.9453125, 0.1885986328125, 0.03900146484375, 0.00015783309936523438, 0.01444244384765625, 0.97705078125, 0.08868408203125, 0.576171875, 1.1689453125, 0.167236328125, 0.1368408203125, 0.98388671875, 0.6455078125, 0.0009379386901855469, 0.407958984375, 1.744140625, 0.97900390625, 0.00460052490234375, 0.0006895065307617188, 0.21533203125, 1.8994140625, 0.80126953125, 0.0599365234375, 0.2371826171875, 0.007228851318359375, 0.0005707740783691406, 0.0037097930908203125, 0.01456451416015625, 0.006103515625, 0.004550933837890625, 0.00959014892578125, 0.00693511962890625]], "avg_entropy": [0.4175128006353611], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "electric potential generated", "score_of_biggest_cluster": 0.6891182065010071, "score_of_first_answer": 0.6891182065010071, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.00373077392578125, "avg_score": 0.6891182065010071, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.27738518314012944, "std_of_first_answer": 0.27738518314012944, "avg_entropy_of_first_answer": 0.4175128006353611, "lex_sim": 1.0}
{"question": "what country shares borders with both belarus and romania", "answer": ["Moldova"], "scores": [[0.6796875, 0.99951171875]], "normalized_score": [0.8242303133010864], "tokens": [["\u2581Mold", "ova"]], "entropy": [[0.7001953125, 0.00525665283203125]], "avg_entropy": [0.3527259826660156], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ukraine", "score_of_biggest_cluster": 0.8242303133010864, "score_of_first_answer": 0.8242303133010864, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.6796875, "avg_score": 0.8242303133010864, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.159912109375, "std_of_first_answer": 0.159912109375, "avg_entropy_of_first_answer": 0.3527259826660156, "lex_sim": 1.0}
{"question": "how does the cash cab guy read the questions", "answer": ["The Cash Cab guy reads the questions through a microphone that is not visible to the passengers in the car."], "scores": [[0.278076171875, 0.91943359375, 1.0, 0.9990234375, 0.35888671875, 1.0, 0.91064453125, 0.99169921875, 0.99853515625, 0.31201171875, 0.86865234375, 0.4482421875, 1.0, 0.26171875, 0.98583984375, 0.1444091796875, 0.9326171875, 0.91796875, 0.9912109375, 0.619140625, 0.7646484375, 0.99853515625, 0.1273193359375, 0.9892578125, 0.01136016845703125, 0.004638671875, 0.79296875, 0.99951171875, 0.09185791015625, 1.0, 0.99755859375, 0.8876953125, 0.277099609375, 1.0, 0.6123046875, 0.98193359375, 0.9873046875, 0.984375, 5.960464477539062e-07, 0.0002397298812866211, 0.05169677734375, 0.00174713134765625, 0.00994110107421875, 0.0027923583984375, 0.003498077392578125, 0.09490966796875, 0.0098114013671875, 0.004627227783203125]], "normalized_score": [0.16747356951236725], "tokens": [["\u2581The", "\u2581C", "ash", "\u2581Cab", "\u2581gu", "y", "\u2581reads", "\u2581the", "\u2581questions", "\u2581through", "\u2581a", "\u2581micro", "phone", "\u2581that", "\u2581is", "\u2581not", "\u2581visible", "\u2581to", "\u2581the", "\u2581passengers", "\u2581in", "\u2581the", "\u2581car", ".", "\u2581This", "\u2581adds", "\u2581to", "\u2581the", "\u2581element", "\u2581of", "\u2581surprise", "\u2581and", "\u2581t", "ension", "\u2581during", "\u2581the", "\u2581game", ".", "\u2581#", "4", "5", "\u2581-", "\u2581\"", "W", "ar", "hol", "\u2581and", "\u2581Super"]], "entropy": [[1.9169921875, 0.400146484375, 0.0004911422729492188, 0.01087188720703125, 1.474609375, 2.9921531677246094e-05, 0.5244140625, 0.04949951171875, 0.01070404052734375, 2.064453125, 0.457763671875, 2.158203125, 0.0010356903076171875, 2.10546875, 0.1075439453125, 1.87890625, 0.329833984375, 0.29931640625, 0.055084228515625, 1.37109375, 0.5966796875, 0.01190948486328125, 0.7001953125, 0.0654296875, 1.095703125, 0.89306640625, 0.607421875, 0.004673004150390625, 2.529296875, 0.0009202957153320312, 0.0215301513671875, 0.427001953125, 1.7265625, 0.0007338523864746094, 1.2275390625, 0.1002197265625, 0.078369140625, 0.09820556640625, 0.411376953125, 2.43359375, 3.033203125, 3.1796875, 3.716796875, 2.814453125, 3.42578125, 3.625, 3.783203125, 4.75]], "avg_entropy": [1.1786461447676022], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "walkie-talkie and earpiece", "score_of_biggest_cluster": 0.16747356951236725, "score_of_first_answer": 0.16747356951236725, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539062e-07, "avg_score": 0.16747356951236725, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42130204927541287, "std_of_first_answer": 0.42130204927541287, "avg_entropy_of_first_answer": 1.1786461447676022, "lex_sim": 1.0}
{"question": "who plays elsa's aunt in once upon a time", "answer": ["Catherine Elizabeth Arapovic Hughes"], "scores": [[0.0007767677307128906, 0.21435546875, 0.0018138885498046875, 0.046295166015625, 0.92724609375, 0.88720703125, 0.0022678375244140625, 1.0]], "normalized_score": [0.04753904789686203], "tokens": [["\u2581Catherine", "\u2581Elizabeth", "\u2581A", "rap", "ov", "ic", "\u2581Hugh", "es"]], "entropy": [[1.82421875, 3.873046875, 2.2109375, 5.03515625, 0.4501953125, 0.48876953125, 3.6328125, 0.00197601318359375]], "avg_entropy": [2.189639091491699], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Elizabeth Mitchell", "score_of_biggest_cluster": 0.04753904789686203, "score_of_first_answer": 0.04753904789686203, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0007767677307128906, "avg_score": 0.04753904789686203, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4343459515859603, "std_of_first_answer": 0.4343459515859603, "avg_entropy_of_first_answer": 2.189639091491699, "lex_sim": 1.0}
{"question": "when did hollywood video go out of business", "answer": ["April 11, 2018"], "scores": [[0.02618408203125, 0.99365234375, 0.462890625, 0.1268310546875, 0.93603515625, 0.99853515625, 1.0, 1.0, 0.99951171875, 0.73193359375]], "normalized_score": [0.5033720135688782], "tokens": [["\u2581April", "\u2581", "1", "1", ",", "\u2581", "2", "0", "1", "8"]], "entropy": [[0.68212890625, 0.0435791015625, 1.5615234375, 2.052734375, 0.261474609375, 0.01325225830078125, 1.5020370483398438e-05, 1.0132789611816406e-05, 0.002590179443359375, 1.021484375]], "avg_entropy": [0.5638792395591736], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2005.", "score_of_biggest_cluster": 0.5033720135688782, "score_of_first_answer": 0.5033720135688782, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.02618408203125, "avg_score": 0.5033720135688782, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.36509887104325156, "std_of_first_answer": 0.36509887104325156, "avg_entropy_of_first_answer": 0.5638792395591736, "lex_sim": 1.0}
{"question": "who won the first medal in olympics for india", "answer": ["Norman Pritchard"], "scores": [[0.84130859375, 0.98681640625, 0.9794921875, 1.0, 1.0]], "normalized_score": [0.9594857692718506], "tokens": [["\u2581Norman", "\u2581P", "rit", "ch", "ard"]], "entropy": [[1.021484375, 0.10321044921875, 0.181396484375, 0.0004086494445800781, 0.00015616416931152344]], "avg_entropy": [0.26133122444152834], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Norman Pritchard", "score_of_biggest_cluster": 0.9594857692718506, "score_of_first_answer": 0.9594857692718506, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.84130859375, "avg_score": 0.9594857692718506, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.06062196075057405, "std_of_first_answer": 0.06062196075057405, "avg_entropy_of_first_answer": 0.26133122444152834, "lex_sim": 1.0}
{"question": "which financial statement involves all aspects of the accounting\u200b equation", "answer": ["Balance sheet Tags: AS | Sports | Olympics | Australia"], "scores": [[0.791015625, 1.0, 0.52978515625, 0.0, 0.99560546875, 4.172325134277344e-07, 5.644559860229492e-05, 6.556510925292969e-07, 0.63232421875, 0.003009796142578125, 0.90283203125, 0.00396728515625]], "normalized_score": [0.0], "tokens": [["\u2581Bal", "ance", "\u2581sheet", "\u2581Tags", ":", "\u2581AS", "\u2581|", "\u2581Sports", "\u2581|", "\u2581Olympics", "\u2581|", "\u2581Australia"]], "entropy": [[0.6884765625, 0.0001474618911743164, 0.71630859375, 0.88818359375, 0.0400390625, 3.025390625, 0.22998046875, 2.546875, 2.04296875, 5.76171875, 0.56103515625, 5.4609375]], "avg_entropy": [1.8301717936992645], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "balance sheet", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.42282865531129876, "std_of_first_answer": 0.42282865531129876, "avg_entropy_of_first_answer": 1.8301717936992645, "lex_sim": 1.0}
{"question": "who owns the biggest house in beverly hills", "answer": ["I'm sorry, I don't have that information."], "scores": [[0.54345703125, 0.615234375, 1.0, 0.88134765625, 0.9912109375, 0.87939453125, 0.493896484375, 0.99853515625, 1.0, 0.91650390625, 0.3955078125, 0.9970703125, 0.96923828125, 1.1920928955078125e-07, 0.00022876262664794922, 0.260009765625]], "normalized_score": [0.16543009877204895], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581I", "\u2581don", "'", "t", "\u2581have", "\u2581that", "\u2581information", ".", "\u2581###", "\u2581General", "\u2581Information"]], "entropy": [[2.587890625, 1.2294921875, 0.0016317367553710938, 0.38623046875, 0.0579833984375, 0.483154296875, 0.98828125, 0.01430511474609375, 0.0012607574462890625, 0.292724609375, 1.3408203125, 0.0252227783203125, 0.1961669921875, 1.1015625, 5.25390625, 1.79296875]], "avg_entropy": [0.9846001267433167], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Anthony Pritzker", "score_of_biggest_cluster": 0.16543009877204895, "score_of_first_answer": 0.16543009877204895, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.16543009877204895, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.35023157039523684, "std_of_first_answer": 0.35023157039523684, "avg_entropy_of_first_answer": 0.9846001267433167, "lex_sim": 1.0}
{"question": "when does sam realize he is jim in ghost whisperer", "answer": ["Season 1, Episode 13"], "scores": [[0.369384765625, 0.99853515625, 0.11822509765625, 0.2744140625, 0.955078125, 1.0, 0.99951171875, 0.8095703125, 0.06585693359375]], "normalized_score": [0.43927645683288574], "tokens": [["\u2581Season", "\u2581", "1", ",", "\u2581E", "pisode", "\u2581", "1", "3"]], "entropy": [[2.5, 0.0160369873046875, 0.93505859375, 0.935546875, 0.1949462890625, 0.0002899169921875, 0.0029087066650390625, 0.740234375, 2.189453125]], "avg_entropy": [0.834941652086046], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Leap of Faith", "score_of_biggest_cluster": 0.43927645683288574, "score_of_first_answer": 0.43927645683288574, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.06585693359375, "avg_score": 0.43927645683288574, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38311733923584573, "std_of_first_answer": 0.38311733923584573, "avg_entropy_of_first_answer": 0.834941652086046, "lex_sim": 1.0}
{"question": "who is new prime minister of italy 2018", "answer": ["Giuseppe Conte #4556665, By T_A_Wilde Rising fuel prices?"], "scores": [[0.99365234375, 0.99853515625, 1.0, 1.1920928955078125e-07, 0.01068878173828125, 0.04266357421875, 0.00705718994140625, 0.081298828125, 0.051666259765625, 0.15576171875, 0.025848388671875, 0.002613067626953125, 1.7702579498291016e-05, 0.0007328987121582031, 0.00017082691192626953, 5.936622619628906e-05, 0.82421875, 0.880859375, 2.467632293701172e-05, 5.53131103515625e-05, 0.00011801719665527344, 1.5437602996826172e-05, 0.77294921875, 0.004840850830078125, 0.006740570068359375, 0.465576171875, 0.99853515625, 0.28271484375, 0.0009889602661132812, 0.83349609375, 0.96826171875, 0.013397216796875]], "normalized_score": [0.010109378956258297], "tokens": [["\u2581Giuseppe", "\u2581Con", "te", "\u2581#", "4", "5", "5", "6", "6", "6", "5", ",", "\u2581By", "\u2581T", "_", "A", "_", "W", "ilde", "\u2581R", "ising", "\u2581fuel", "\u2581prices", "?", "\u2581Here", "'", "s", "\u2581a", "\u2581mod", "est", "\u2581proposal", "..."]], "entropy": [[0.05902099609375, 0.0141448974609375, 0.00010097026824951172, 0.94677734375, 4.78125, 3.03515625, 2.54296875, 2.912109375, 3.021484375, 2.6640625, 2.587890625, 2.8125, 2.33984375, 4.3125, 4.59765625, 0.20556640625, 1.35546875, 0.71875, 2.958984375, 3.779296875, 3.638671875, 5.140625, 1.22265625, 3.005859375, 5.1171875, 1.3349609375, 0.01386260986328125, 2.0390625, 4.47265625, 0.78515625, 0.268798828125, 2.083984375]], "avg_entropy": [2.3365316949784756], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "TBD", "score_of_biggest_cluster": 0.010109378956258297, "score_of_first_answer": 0.010109378956258297, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.010109378956258297, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40406014585494154, "std_of_first_answer": 0.40406014585494154, "avg_entropy_of_first_answer": 2.3365316949784756, "lex_sim": 1.0}
{"question": "who was the first woman to win who wants to be a millionaire", "answer": ["Chris Tarrant was the host of \"Who Wants to Be a Millionaire?\""], "scores": [[0.65869140625, 0.3447265625, 1.0, 0.99609375, 0.016265869140625, 0.92724609375, 0.91357421875, 0.9482421875, 0.067138671875, 0.99755859375, 1.0, 1.0, 0.95751953125, 0.9521484375, 0.99951171875, 1.0, 1.0, 1.0, 0.57470703125, 0.056243896484375, 0.77880859375, 0.99267578125, 0.7607421875, 0.748046875, 0.634765625, 0.6416015625, 0.7646484375, 0.14892578125, 0.73681640625, 1.0, 0.9970703125, 0.978515625, 0.9833984375, 0.98291015625, 0.99951171875, 0.72216796875, 0.81787109375, 0.9716796875, 0.99951171875, 0.9560546875, 0.49609375, 0.88330078125, 0.97607421875, 0.47216796875, 1.0, 0.61279296875, 1.0, 1.0, 1.0, 1.0]], "normalized_score": [0.6838722229003906], "tokens": [["\u2581Chris", "\u2581T", "arr", "ant", "\u2581was", "\u2581the", "\u2581host", "\u2581of", "\u2581\"", "Who", "\u2581W", "ants", "\u2581to", "\u2581Be", "\u2581a", "\u2581Mill", "ion", "aire", "?\"", "\u2581when", "\u2581the", "\u2581first", "\u2581woman", "\u2581won", ".", "\u2581The", "\u2581first", "\u2581female", "\u2581contest", "ant", "\u2581to", "\u2581win", "\u2581the", "\u2581top", "\u2581prize", "\u2581was", "\u2581Jud", "ith", "\u2581Ke", "ppel", ",", "\u2581who", "\u2581won", "\u2581\u00a3", "1", ",", "0", "0", "0", ","]], "entropy": [[1.515625, 2.541015625, 0.0020160675048828125, 0.028076171875, 1.6650390625, 0.363525390625, 0.406005859375, 0.3203125, 0.89404296875, 0.0200347900390625, 0.0003325939178466797, 0.0012960433959960938, 0.1761474609375, 0.1943359375, 0.004146575927734375, 0.0021820068359375, 0.00039505958557128906, 0.0009660720825195312, 1.4091796875, 2.44921875, 1.1220703125, 0.056396484375, 0.57568359375, 0.77392578125, 0.86962890625, 1.73828125, 1.0146484375, 0.47705078125, 0.63916015625, 0.0002727508544921875, 0.0232696533203125, 0.1141357421875, 0.10772705078125, 0.1160888671875, 0.00433349609375, 0.6396484375, 1.2265625, 0.1630859375, 0.0038738250732421875, 0.2218017578125, 1.083984375, 0.47607421875, 0.148193359375, 1.26171875, 0.0011157989501953125, 0.69287109375, 4.029273986816406e-05, 0.00017559528350830078, 0.0002422332763671875, 0.00046253204345703125]], "avg_entropy": [0.5109283518791199], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Judith Cynthia Aline Keppel", "score_of_biggest_cluster": 0.6838722229003906, "score_of_first_answer": 0.6838722229003906, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.016265869140625, "avg_score": 0.6838722229003906, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.27379728886712845, "std_of_first_answer": 0.27379728886712845, "avg_entropy_of_first_answer": 0.5109283518791199, "lex_sim": 1.0}
{"question": "how long is a prime minister term in uk", "answer": ["5 years"], "scores": [[0.7744140625, 0.99951171875, 0.99755859375]], "normalized_score": [0.9174164533615112], "tokens": [["\u2581", "5", "\u2581years"]], "entropy": [[1.19921875, 0.005828857421875, 0.023468017578125]], "avg_entropy": [0.4095052083333333], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "At Her Majesty's pleasure", "score_of_biggest_cluster": 0.9174164533615112, "score_of_first_answer": 0.9174164533615112, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.7744140625, "avg_score": 0.9174164533615112, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.105654705618134, "std_of_first_answer": 0.105654705618134, "avg_entropy_of_first_answer": 0.4095052083333333, "lex_sim": 1.0}
{"question": "where is the white castle that harold and kumar go to", "answer": ["Neil Patrick Harris's house #OscarsSoWhite: 7 Black Actors Who Should Have Been Nominated For An Oscar"], "scores": [[0.0826416015625, 0.86474609375, 0.99951171875, 0.364013671875, 0.5458984375, 0.94873046875, 4.172325134277344e-07, 3.993511199951172e-06, 0.004833221435546875, 1.0, 0.044036865234375, 0.93408203125, 0.0016765594482421875, 0.033447265625, 0.0465087890625, 0.000522613525390625, 0.197509765625, 0.890625, 0.8974609375, 0.1729736328125, 0.7333984375, 0.97998046875, 1.0, 0.99169921875, 0.99951171875, 1.0, 0.0019893646240234375, 0.316650390625, 0.884765625]], "normalized_score": [0.08409973233938217], "tokens": [["\u2581Neil", "\u2581Patrick", "\u2581Harris", "'", "s", "\u2581house", "\u2581#", "O", "sc", "ars", "So", "White", ":", "\u2581", "7", "\u2581Black", "\u2581Act", "ors", "\u2581Who", "\u2581Should", "\u2581Have", "\u2581Be", "en", "\u2581N", "omin", "ated", "\u2581For", "\u2581An", "\u2581Oscar"]], "entropy": [[3.642578125, 0.65087890625, 0.003810882568359375, 1.4638671875, 0.8759765625, 0.32470703125, 1.35546875, 1.853515625, 3.20703125, 0.002864837646484375, 2.29296875, 0.478271484375, 2.349609375, 3.796875, 2.099609375, 4.5625, 3.52734375, 0.39306640625, 0.69189453125, 1.4921875, 1.0400390625, 0.1298828125, 0.00197601318359375, 0.0634765625, 0.00386810302734375, 0.001972198486328125, 3.248046875, 1.6640625, 0.50341796875]], "avg_entropy": [1.4386816353633487], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "in Cherry Hill", "score_of_biggest_cluster": 0.08409973233938217, "score_of_first_answer": 0.08409973233938217, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.08409973233938217, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42748555205600797, "std_of_first_answer": 0.42748555205600797, "avg_entropy_of_first_answer": 1.4386816353633487, "lex_sim": 1.0}
{"question": "when does the first nba basketball game start", "answer": ["October 23, 2018 #16 Post by Gort \u00bb Mon Jan 08, 2007 11:45 am"], "scores": [[0.200439453125, 0.86865234375, 0.99560546875, 0.0250396728515625, 0.359375, 0.994140625, 0.947265625, 1.0, 0.109619140625, 0.59228515625, 5.960464477539062e-07, 0.0340576171875, 0.0203399658203125, 1.6093254089355469e-06, 0.0026340484619140625, 0.00838470458984375, 0.00984954833984375, 0.2364501953125, 0.1387939453125, 0.034576416015625, 0.998046875, 0.311767578125, 0.265380859375, 0.9990234375, 0.99658203125, 0.99951171875, 1.0, 0.00013768672943115234, 0.91796875, 0.9873046875, 0.3994140625, 0.262451171875, 0.99853515625, 0.150390625, 0.10321044921875, 0.478271484375]], "normalized_score": [0.09438005834817886], "tokens": [["\u2581October", "\u2581", "2", "3", ",", "\u2581", "2", "0", "1", "8", "\u2581#", "1", "6", "\u2581Post", "\u2581by", "\u2581G", "ort", "\u2581\u00bb", "\u2581Mon", "\u2581Jan", "\u2581", "0", "8", ",", "\u2581", "2", "0", "0", "7", "\u2581", "1", "1", ":", "4", "5", "\u2581am"]], "entropy": [[2.025390625, 0.53271484375, 0.03173828125, 0.99658203125, 1.15234375, 0.047637939453125, 0.2069091796875, 0.0002713203430175781, 0.3525390625, 0.96875, 1.4052734375, 5.609375, 3.322265625, 3.759765625, 0.7587890625, 5.9453125, 5.27734375, 3.072265625, 2.232421875, 1.7265625, 0.0159149169921875, 1.12109375, 1.4052734375, 0.00945281982421875, 0.026458740234375, 0.0030803680419921875, 0.001804351806640625, 0.00197601318359375, 0.288330078125, 0.1043701171875, 1.9189453125, 1.39453125, 0.01206207275390625, 1.7958984375, 2.3046875, 0.734375]], "avg_entropy": [1.4045140610800848], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "October 17, 2017", "score_of_biggest_cluster": 0.09438005834817886, "score_of_first_answer": 0.09438005834817886, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539062e-07, "avg_score": 0.09438005834817886, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41461417841832204, "std_of_first_answer": 0.41461417841832204, "avg_entropy_of_first_answer": 1.4045140610800848, "lex_sim": 1.0}
{"question": "how many different kinds of pokemon cards are there", "answer": ["over 900"], "scores": [[0.1396484375, 0.99072265625, 0.12060546875, 0.99462890625, 0.99951171875]], "normalized_score": [0.4405151605606079], "tokens": [["\u2581over", "\u2581", "9", "0", "0"]], "entropy": [[2.763671875, 0.06427001953125, 1.2314453125, 0.042572021484375, 0.00395965576171875]], "avg_entropy": [0.8211837768554687], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "eleven", "score_of_biggest_cluster": 0.4405151605606079, "score_of_first_answer": 0.4405151605606079, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.12060546875, "avg_score": 0.4405151605606079, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4237291521103363, "std_of_first_answer": 0.4237291521103363, "avg_entropy_of_first_answer": 0.8211837768554687, "lex_sim": 1.0}
{"question": "who wants a heart in the wizard of oz", "answer": ["Tinman #ClimateChange #COP21 #ParisAgreement"], "scores": [[0.033447265625, 0.98046875, 0.0196533203125, 1.9073486328125e-06, 0.000278472900390625, 3.349781036376953e-05, 0.0109710693359375, 0.09033203125, 0.0726318359375, 0.018646240234375, 0.9755859375, 0.99755859375, 0.0458984375, 0.433837890625, 0.55078125, 0.9990234375, 0.9912109375, 1.0, 1.0]], "normalized_score": [0.049582988023757935], "tokens": [["\u2581T", "in", "man", "\u2581#", "C", "lim", "ate", "Change", "\u2581#", "CO", "P", "2", "1", "\u2581#", "Par", "is", "A", "gre", "ement"]], "entropy": [[0.7509765625, 0.11468505859375, 0.6494140625, 0.90283203125, 2.28125, 3.861328125, 0.38037109375, 1.9365234375, 2.03125, 3.78125, 0.13525390625, 0.0208892822265625, 0.5009765625, 1.6083984375, 2.19140625, 0.0082550048828125, 0.06982421875, 0.00010251998901367188, 0.0024013519287109375]], "avg_entropy": [1.1172309423747815], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Tin Woodman", "score_of_biggest_cluster": 0.049582988023757935, "score_of_first_answer": 0.049582988023757935, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.9073486328125e-06, "avg_score": 0.049582988023757935, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.449637484230872, "std_of_first_answer": 0.449637484230872, "avg_entropy_of_first_answer": 1.1172309423747815, "lex_sim": 1.0}
{"question": "who designed the earth day flag in 1969", "answer": ["Howard Bunt"], "scores": [[0.059356689453125, 0.904296875, 0.30712890625]], "normalized_score": [0.2545074224472046], "tokens": [["\u2581Howard", "\u2581B", "unt"]], "entropy": [[4.39453125, 0.76416015625, 2.98046875]], "avg_entropy": [2.7130533854166665], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "John McConnell", "score_of_biggest_cluster": 0.2545074224472046, "score_of_first_answer": 0.2545074224472046, "max_score_of_first_answer": 0.904296875, "min_score_of_first_answer": 0.059356689453125, "avg_score": 0.2545074224472046, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.35463981281003437, "std_of_first_answer": 0.35463981281003437, "avg_entropy_of_first_answer": 2.7130533854166665, "lex_sim": 1.0}
{"question": "when is the last time wisconsin missed the ncaa tournament", "answer": ["2013 #SocEnt #GlobalDev Making Every Drop of Water Count: Innovations for Water Scarcity #AskTheExpert"], "scores": [[0.861328125, 0.08148193359375, 0.99951171875, 0.9814453125, 0.9072265625, 3.5762786865234375e-06, 0.0018758773803710938, 9.894371032714844e-06, 0.0016889572143554688, 0.268798828125, 0.00023698806762695312, 0.23046875, 4.2438507080078125e-05, 0.00428009033203125, 0.0012559890747070312, 0.007648468017578125, 0.01129913330078125, 0.65087890625, 0.998046875, 0.329833984375, 0.021331787109375, 0.96240234375, 0.79833984375, 0.1798095703125, 0.1456298828125, 0.3212890625, 0.923828125, 1.0, 0.3828125, 0.0172271728515625, 0.1033935546875, 0.037261962890625, 0.87646484375, 0.7373046875]], "normalized_score": [0.047341518104076385], "tokens": [["\u2581", "2", "0", "1", "3", "\u2581#", "S", "oc", "Ent", "\u2581#", "Global", "Dev", "\u2581M", "aking", "\u2581Every", "\u2581Drop", "\u2581of", "\u2581Water", "\u2581Count", ":", "\u2581In", "nov", "ations", "\u2581for", "\u2581Water", "\u2581Sc", "arc", "ity", "\u2581#", "A", "sk", "The", "Ex", "pert"]], "entropy": [[0.8212890625, 0.2841796875, 0.0040740966796875, 0.10540771484375, 0.418212890625, 0.9208984375, 5.33984375, 2.70703125, 5.5, 1.5458984375, 4.5703125, 2.380859375, 0.970703125, 3.037109375, 4.0703125, 0.82470703125, 0.09051513671875, 1.306640625, 0.0202178955078125, 3.291015625, 4.21875, 0.283447265625, 0.60205078125, 0.81298828125, 1.8115234375, 1.8203125, 0.28662109375, 0.0003008842468261719, 2.83984375, 4.66015625, 2.29296875, 4.54296875, 0.923828125, 0.576171875]], "avg_entropy": [1.8788576546837301], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1997\u201398", "score_of_biggest_cluster": 0.047341518104076385, "score_of_first_answer": 0.047341518104076385, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 3.5762786865234375e-06, "avg_score": 0.047341518104076385, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3978092572792341, "std_of_first_answer": 0.3978092572792341, "avg_entropy_of_first_answer": 1.8788576546837301, "lex_sim": 1.0}
{"question": "what is the lead singers name of staind", "answer": ["Aaron Lewis #AskVidasAndAuke 129: How to Practice Sight-reading for Organists?"], "scores": [[0.99951171875, 1.0, 1.0, 2.384185791015625e-07, 0.08758544921875, 0.441162109375, 0.0004761219024658203, 0.006221771240234375, 0.86181640625, 0.061187744140625, 0.31591796875, 0.8916015625, 0.0019989013671875, 0.005962371826171875, 0.090576171875, 0.03216552734375, 0.0064544677734375, 0.1634521484375, 0.426513671875, 0.0380859375, 0.98876953125, 0.09619140625, 0.0369873046875, 0.966796875, 0.07647705078125, 0.11151123046875, 0.1942138671875, 0.81640625, 0.744140625]], "normalized_score": [0.0723085105419159], "tokens": [["\u2581A", "aron", "\u2581Lewis", "\u2581#", "A", "sk", "V", "idas", "And", "A", "u", "ke", "\u2581", "1", "2", "9", ":", "\u2581How", "\u2581to", "\u2581Pract", "ice", "\u2581S", "ight", "-", "reading", "\u2581for", "\u2581Organ", "ists", "?"]], "entropy": [[0.0036449432373046875, 0.00217437744140625, 0.0021572113037109375, 0.76123046875, 3.443359375, 1.818359375, 4.62109375, 3.546875, 0.81884765625, 0.9443359375, 2.341796875, 0.5927734375, 0.765625, 0.6337890625, 3.13671875, 3.095703125, 1.74609375, 3.400390625, 1.599609375, 4.5859375, 0.0775146484375, 3.25390625, 0.234130859375, 0.1953125, 0.43017578125, 1.9833984375, 1.0078125, 0.77783203125, 1.19921875]], "avg_entropy": [1.6213730121481007], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Aaron Lewis", "score_of_biggest_cluster": 0.0723085105419159, "score_of_first_answer": 0.0723085105419159, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.0723085105419159, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3933431926748607, "std_of_first_answer": 0.3933431926748607, "avg_entropy_of_first_answer": 1.6213730121481007, "lex_sim": 1.0}
{"question": "who did us fight in world war 1", "answer": ["Germany and Austria-Hungary \\r\\nA graduate of Columbia Journalism School, she has written for the New York Times, Salon, Slate, Time Out New York, Forward, The Village Voice,"], "scores": [[0.76025390625, 0.0234527587890625, 0.69775390625, 0.99609375, 1.0, 0.99951171875, 1.0, 5.960464477539063e-08, 6.079673767089844e-06, 0.07220458984375, 0.99462890625, 0.008026123046875, 1.9669532775878906e-06, 0.98095703125, 0.2239990234375, 0.01058197021484375, 0.042999267578125, 1.0, 0.9736328125, 0.438232421875, 0.04437255859375, 0.50048828125, 0.1324462890625, 0.7041015625, 0.062255859375, 0.61279296875, 0.9658203125, 0.6484375, 0.9619140625, 0.0013475418090820312, 1.0, 0.97314453125, 0.078857421875, 1.0, 0.9560546875, 0.01319122314453125, 0.10418701171875, 0.9140625, 0.9970703125, 0.89794921875, 0.01412200927734375, 0.035125732421875, 0.9541015625, 0.06256103515625, 0.09539794921875, 0.9814453125, 1.0, 0.91650390625]], "normalized_score": [0.11808465421199799], "tokens": [["\u2581Germany", "\u2581and", "\u2581Austria", "-", "H", "ung", "ary", "\u2581\\", "r", "\\", "n", "A", "\u2581gradu", "ate", "\u2581of", "\u2581Columbia", "\u2581Journal", "ism", "\u2581School", ",", "\u2581she", "\u2581has", "\u2581written", "\u2581for", "\u2581the", "\u2581New", "\u2581York", "\u2581Times", ",", "\u2581Sal", "on", ",", "\u2581S", "late", ",", "\u2581Time", "\u2581Out", "\u2581New", "\u2581York", ",", "\u2581For", "ward", ",", "\u2581The", "\u2581Village", "\u2581Vo", "ice", ","]], "entropy": [[1.1376953125, 0.314697265625, 0.9931640625, 0.0311737060546875, 0.0006008148193359375, 0.0029544830322265625, 0.0002353191375732422, 1.3193359375, 0.16162109375, 1.2568359375, 0.044525146484375, 3.025390625, 3.9921875, 0.1104736328125, 2.1953125, 3.67578125, 1.375, 0.0004372596740722656, 0.1890869140625, 2.203125, 4.82421875, 2.576171875, 3.142578125, 1.2021484375, 3.296875, 2.15234375, 0.255126953125, 1.251953125, 0.2359619140625, 2.91796875, 0.002338409423828125, 0.1607666015625, 2.60546875, 0.0012712478637695312, 0.2178955078125, 2.1484375, 1.017578125, 0.410888671875, 0.0233001708984375, 0.410888671875, 2.431640625, 0.1585693359375, 0.251220703125, 2.359375, 3.447265625, 0.1097412109375, 0.0002092123031616211, 0.337646484375]], "avg_entropy": [1.2495725477735202], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Germany", "score_of_biggest_cluster": 0.11808465421199799, "score_of_first_answer": 0.11808465421199799, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.11808465421199799, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4318122022704648, "std_of_first_answer": 0.4318122022704648, "avg_entropy_of_first_answer": 1.2495725477735202, "lex_sim": 1.0}
{"question": "what tectonic setting is responsible for the folded mountains of pennsylvania and the high himalaya", "answer": ["Convergent \\ Activation keys / E-Sketch Pro - Design Software 2020"], "scores": [[0.022064208984375, 0.99365234375, 0.9970703125, 3.5762786865234375e-07, 8.225440979003906e-06, 0.88623046875, 1.1920928955078125e-07, 0.0010232925415039062, 0.0012693405151367188, 0.06280517578125, 0.0001462697982788086, 0.08978271484375, 0.0545654296875, 0.0123748779296875, 0.0006642341613769531, 0.021453857421875, 0.00800323486328125, 0.35009765625, 0.31982421875, 0.8203125, 0.06475830078125]], "normalized_score": [0.0076215737499296665], "tokens": [["\u2581Con", "ver", "gent", "\u2581\\", "\u2581Activ", "ation", "\u2581keys", "\u2581/", "\u2581E", "-", "Sk", "etch", "\u2581Pro", "\u2581-", "\u2581Design", "\u2581Software", "\u2581", "2", "0", "2", "0"]], "entropy": [[3.05078125, 0.057037353515625, 0.0201416015625, 1.91015625, 1.400390625, 0.486572265625, 2.78515625, 1.951171875, 6.359375, 4.17578125, 1.2978515625, 3.048828125, 4.5546875, 2.66015625, 5.734375, 4.0546875, 3.43359375, 1.4453125, 1.1162109375, 0.69970703125, 1.3095703125]], "avg_entropy": [2.454835437593006], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "a convergent plate boundary", "score_of_biggest_cluster": 0.0076215737499296665, "score_of_first_answer": 0.0076215737499296665, "max_score_of_first_answer": 0.9970703125, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.0076215737499296665, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3539148927078686, "std_of_first_answer": 0.3539148927078686, "avg_entropy_of_first_answer": 2.454835437593006, "lex_sim": 1.0}
{"question": "what type of bridge is the charles bridge", "answer": ["stone bridge #517563 - 09/25/07 12:42 PM Re: NCL Breakaway - What Do You Think?"], "scores": [[0.580078125, 0.0762939453125, 2.980232238769531e-07, 0.0008039474487304688, 0.047607421875, 0.0665283203125, 0.11492919921875, 0.0936279296875, 0.043304443359375, 0.0010318756103515625, 0.0295867919921875, 0.25439453125, 0.00894927978515625, 0.1427001953125, 0.31640625, 0.09490966796875, 0.9931640625, 0.018463134765625, 0.09051513671875, 0.20849609375, 0.53564453125, 0.1527099609375, 0.96630859375, 0.1444091796875, 0.09918212890625, 0.215576171875, 0.00022017955780029297, 0.1527099609375, 0.0005078315734863281, 0.005786895751953125, 0.000713348388671875, 0.970703125, 0.455322265625, 0.006786346435546875, 0.0054779052734375, 0.90869140625, 0.6318359375, 0.70263671875, 0.2039794921875, 0.9921875, 0.9990234375, 0.006069183349609375, 0.269287109375, 0.388671875, 0.0002963542938232422, 0.978515625]], "normalized_score": [0.05173926427960396], "tokens": [["\u2581stone", "\u2581bridge", "\u2581#", "5", "1", "7", "5", "6", "3", "\u2581-", "\u2581", "0", "9", "/", "2", "5", "/", "0", "7", "\u2581", "1", "2", ":", "4", "2", "\u2581PM", "\u2581Re", ":", "\u2581N", "CL", "\u2581Break", "away", "\u2581-", "\u2581What", "\u2581Do", "\u2581You", "\u2581Think", "?", "\u2581[", "Re", ":", "\u2581c", "ath", "ies", "place", "]"]], "entropy": [[0.7822265625, 1.767578125, 0.88720703125, 3.57421875, 3.349609375, 3.1171875, 2.701171875, 2.640625, 3.171875, 2.650390625, 3.484375, 2.130859375, 2.666015625, 3.35546875, 1.2373046875, 2.298828125, 0.05621337890625, 1.0029296875, 2.21875, 2.59765625, 1.47265625, 2.267578125, 0.243408203125, 1.7998046875, 2.3203125, 2.087890625, 3.828125, 2.94140625, 4.11328125, 5.13671875, 6.10546875, 0.230712890625, 3.44140625, 5.35546875, 2.8515625, 0.5234375, 1.3271484375, 1.509765625, 3.892578125, 0.07257080078125, 0.00922393798828125, 5.90625, 4.421875, 2.626953125, 4.16015625, 0.173583984375]], "avg_entropy": [2.4893442236858867], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "a bow bridge", "score_of_biggest_cluster": 0.05173926427960396, "score_of_first_answer": 0.05173926427960396, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.05173926427960396, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.34149841288310656, "std_of_first_answer": 0.34149841288310656, "avg_entropy_of_first_answer": 2.4893442236858867, "lex_sim": 1.0}
{"question": "when did 10 shilling note go out of circulation", "answer": ["I'm sorry, but a 10 shilling note is not a valid currency in the countries I am familiar #Fantasy #Mystery #Adventure #Romance #Druids #Gargoyles"], "scores": [[0.3447265625, 0.48779296875, 0.9990234375, 0.93603515625, 0.97705078125, 0.1868896484375, 0.0097198486328125, 0.935546875, 1.0, 1.0, 0.98681640625, 0.9990234375, 0.9990234375, 0.48876953125, 0.4306640625, 0.7978515625, 0.1986083984375, 0.97314453125, 0.86279296875, 0.06011962890625, 0.33203125, 0.5673828125, 0.68408203125, 0.57958984375, 0.0, 0.0004696846008300781, 0.0008854866027832031, 0.496337890625, 0.1348876953125, 0.11956787109375, 0.1624755859375, 0.9833984375, 0.50537109375, 0.0654296875, 1.0, 0.99951171875, 0.398193359375, 0.267333984375, 0.98291015625, 0.99658203125, 0.56201171875, 0.0034961700439453125, 8.630752563476562e-05, 0.08917236328125, 0.7138671875, 0.0123138427734375, 0.0347900390625, 0.99755859375]], "normalized_score": [0.0], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581but", "\u2581a", "\u2581", "1", "0", "\u2581sh", "illing", "\u2581note", "\u2581is", "\u2581not", "\u2581a", "\u2581valid", "\u2581currency", "\u2581in", "\u2581the", "\u2581countries", "\u2581I", "\u2581am", "\u2581familiar", "\u2581#", "F", "ant", "asy", "\u2581#", "M", "yst", "ery", "\u2581#", "Ad", "vent", "ure", "\u2581#", "R", "om", "ance", "\u2581#", "D", "ru", "ids", "\u2581#", "G", "argo", "yles"]], "entropy": [[2.232421875, 1.6103515625, 0.0072174072265625, 0.279052734375, 0.12744140625, 0.94482421875, 0.91015625, 0.32373046875, 0.00011932849884033203, 0.00011992454528808594, 0.07891845703125, 0.00646209716796875, 0.01055145263671875, 1.72265625, 1.4716796875, 0.75732421875, 2.34375, 0.1556396484375, 0.7021484375, 1.373046875, 2.494140625, 1.1220703125, 0.9111328125, 1.0966796875, 0.024261474609375, 4.234375, 5.140625, 1.0986328125, 2.830078125, 4.30078125, 1.767578125, 0.10308837890625, 1.6396484375, 3.123046875, 0.001850128173828125, 0.004241943359375, 1.744140625, 3.22265625, 0.11138916015625, 0.0264129638671875, 1.501953125, 2.755859375, 0.371826171875, 0.53125, 0.9326171875, 2.287109375, 1.5439453125, 0.0164642333984375]], "avg_entropy": [1.249905563890934], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "22 November 1970", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38851886621345594, "std_of_first_answer": 0.38851886621345594, "avg_entropy_of_first_answer": 1.249905563890934, "lex_sim": 1.0}
{"question": "where does no game no life anime end", "answer": ["The anime series \"No Game No Life\" ends with its 14th episode, which is the final episode of its first season."], "scores": [[0.16455078125, 0.72900390625, 1.0, 0.533203125, 0.53173828125, 0.99951171875, 1.0, 0.9921875, 0.9990234375, 1.0, 0.09271240234375, 0.77783203125, 0.167236328125, 0.79638671875, 0.99755859375, 0.01055145263671875, 1.0, 0.98974609375, 0.333251953125, 0.2568359375, 0.8642578125, 0.626953125, 0.8037109375, 0.99658203125, 0.90380859375, 0.82177734375, 0.96240234375, 0.99951171875, 0.99462890625, 1.0728836059570312e-06, 0.003307342529296875, 0.0860595703125, 3.5762786865234375e-07, 0.008697509765625, 0.0006566047668457031, 0.0006556510925292969, 0.0024738311767578125, 0.88232421875, 0.7548828125, 0.95166015625, 0.99951171875, 1.0, 0.2279052734375, 0.6904296875]], "normalized_score": [0.15976375341415405], "tokens": [["\u2581The", "\u2581an", "ime", "\u2581series", "\u2581\"", "No", "\u2581Game", "\u2581No", "\u2581Life", "\"", "\u2581ends", "\u2581with", "\u2581its", "\u2581", "1", "4", "th", "\u2581episode", ",", "\u2581which", "\u2581is", "\u2581the", "\u2581final", "\u2581episode", "\u2581of", "\u2581its", "\u2581first", "\u2581season", ".", "\u2581#", "8", "9", "\u2581\u2013", "\u2581The", "\u2581Best", "\u2581Books", "\u2581We", "\u2581Read", "\u2581in", "\u2581", "2", "0", "1", "9"]], "entropy": [[2.8125, 1.3193359375, 0.00012433528900146484, 1.314453125, 0.9150390625, 0.004680633544921875, 0.0017309188842773438, 0.046905517578125, 0.00920867919921875, 0.0013446807861328125, 1.4580078125, 0.826171875, 1.62109375, 0.87255859375, 0.018463134765625, 0.278564453125, 0.0011272430419921875, 0.06048583984375, 1.330078125, 2.083984375, 0.67529296875, 1.134765625, 0.826171875, 0.025390625, 0.369140625, 0.51025390625, 0.2041015625, 0.0037288665771484375, 0.041717529296875, 1.126953125, 4.0546875, 2.8125, 2.392578125, 2.56640625, 4.59375, 2.419921875, 2.80078125, 0.615234375, 0.8115234375, 0.339599609375, 0.0034351348876953125, 0.0014619827270507812, 0.546875, 0.986328125]], "avg_entropy": [1.0190558514811776], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the Elkia Federation", "score_of_biggest_cluster": 0.15976375341415405, "score_of_first_answer": 0.15976375341415405, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 3.5762786865234375e-07, "avg_score": 0.15976375341415405, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39882126380527794, "std_of_first_answer": 0.39882126380527794, "avg_entropy_of_first_answer": 1.0190558514811776, "lex_sim": 1.0}
{"question": "where did maria work in west side story", "answer": ["Maria worked at the store."], "scores": [[0.2081298828125, 0.93896484375, 0.460205078125, 0.7724609375, 0.007228851318359375, 0.1478271484375, 1.1920928955078125e-06, 7.18235969543457e-05, 0.9921875, 0.02044677734375, 0.99951171875, 0.99951171875, 0.0002613067626953125, 0.0024013519287109375, 0.037200927734375, 0.0014123916625976562, 0.00405120849609375, 9.632110595703125e-05, 0.9931640625, 0.99951171875, 0.01027679443359375, 0.0006465911865234375, 0.001949310302734375, 0.0247955322265625, 0.26416015625, 0.27392578125, 0.99951171875, 0.85791015625, 0.9990234375]], "normalized_score": [0.031661175191402435], "tokens": [["\u2581Maria", "\u2581worked", "\u2581at", "\u2581the", "\u2581store", ".", "\u2581#", "Throw", "back", "Th", "urs", "day", ":", "\u2581Remember", "ing", "\u2581The", "\u2581'", "9", "0", "s", "\u2581K", "-", "d", "rama", "\u2581That", "\u2581Start", "ed", "\u2581It", "\u2581All"]], "entropy": [[3.373046875, 0.306640625, 1.0478515625, 0.70556640625, 4.0546875, 2.501953125, 0.343994140625, 4.39453125, 0.046630859375, 1.7958984375, 0.0030193328857421875, 0.004650115966796875, 1.2099609375, 4.09375, 1.83203125, 1.2841796875, 3.45703125, 0.1578369140625, 0.055755615234375, 0.0036716461181640625, 3.50390625, 0.06640625, 1.0703125, 0.11669921875, 2.7109375, 3.236328125, 0.00357818603515625, 0.595703125, 0.0088043212890625]], "avg_entropy": [1.4477711381583378], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the dress shop", "score_of_biggest_cluster": 0.031661175191402435, "score_of_first_answer": 0.031661175191402435, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 1.1920928955078125e-06, "avg_score": 0.031661175191402435, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.43225508681696206, "std_of_first_answer": 0.43225508681696206, "avg_entropy_of_first_answer": 1.4477711381583378, "lex_sim": 1.0}
{"question": "who played solomon in little house on the prairie", "answer": ["Kenneth Johnson"], "scores": [[0.0181427001953125, 0.03155517578125]], "normalized_score": [0.02392689138650894], "tokens": [["\u2581Kenneth", "\u2581Johnson"]], "entropy": [[4.23828125, 1.53125]], "avg_entropy": [2.884765625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Todd Bridges", "score_of_biggest_cluster": 0.02392689138650894, "score_of_first_answer": 0.02392689138650894, "max_score_of_first_answer": 0.03155517578125, "min_score_of_first_answer": 0.0181427001953125, "avg_score": 0.02392689138650894, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.00670623779296875, "std_of_first_answer": 0.00670623779296875, "avg_entropy_of_first_answer": 2.884765625, "lex_sim": 1.0}
{"question": "where is the hero golf challenge being played", "answer": ["Celtic Manor Resort, Wales"], "scores": [[0.0022640228271484375, 0.7021484375, 0.99609375, 0.99951171875, 1.0, 0.98583984375, 1.0, 0.4501953125, 0.33740234375]], "normalized_score": [0.39554402232170105], "tokens": [["\u2581C", "elt", "ic", "\u2581Man", "or", "\u2581Res", "ort", ",", "\u2581Wales"]], "entropy": [[4.41015625, 1.8212890625, 0.0256500244140625, 0.00475311279296875, 5.78761100769043e-05, 0.10076904296875, 0.0019550323486328125, 1.3369140625, 0.94482421875]], "avg_entropy": [0.9607076313760545], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The Bahamas", "score_of_biggest_cluster": 0.39554402232170105, "score_of_first_answer": 0.39554402232170105, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0022640228271484375, "avg_score": 0.39554402232170105, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.35220886643584326, "std_of_first_answer": 0.35220886643584326, "avg_entropy_of_first_answer": 0.9607076313760545, "lex_sim": 1.0}
{"question": "when does ellen's new game show start", "answer": ["I'm sorry, I do not have the latest information on television schedules."], "scores": [[0.14697265625, 0.65869140625, 0.99951171875, 0.92822265625, 0.9892578125, 0.84814453125, 0.42236328125, 0.9990234375, 0.94677734375, 0.103515625, 0.039306640625, 0.98193359375, 0.6611328125, 0.033111572265625, 0.53466796875, 0.9921875, 0.9521484375, 2.384185791015625e-07, 0.00078582763671875, 0.12115478515625, 0.99609375, 0.32470703125, 0.97265625, 1.0, 0.9990234375, 0.0255126953125, 0.01357269287109375, 4.3332576751708984e-05, 0.681640625, 0.0151519775390625, 0.85107421875, 0.00737762451171875, 0.560546875, 0.966796875]], "normalized_score": [0.1374719887971878], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581I", "\u2581do", "\u2581not", "\u2581have", "\u2581the", "\u2581latest", "\u2581information", "\u2581on", "\u2581television", "\u2581sched", "ules", ".", "\u2581#", "M", "ond", "ay", "M", "ot", "iv", "ation", ":", "\u2581The", "\u2581Per", "fect", "\u2581Work", "out", "\u2581Music", "\u2581Play", "list"]], "entropy": [[2.640625, 1.0302734375, 0.00324249267578125, 0.27490234375, 0.0736083984375, 0.65869140625, 1.107421875, 0.00785064697265625, 0.2147216796875, 1.140625, 1.9033203125, 0.13232421875, 0.94873046875, 1.859375, 1.3544921875, 0.046417236328125, 0.2685546875, 2.1953125, 4.77734375, 3.087890625, 0.026763916015625, 2.712890625, 0.1949462890625, 0.002513885498046875, 0.00826263427734375, 2.078125, 3.84765625, 4.05859375, 1.3193359375, 4.92578125, 0.8583984375, 2.802734375, 1.8046875, 0.1546630859375]], "avg_entropy": [1.4270904765409582], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "December 18, 2017", "score_of_biggest_cluster": 0.1374719887971878, "score_of_first_answer": 0.1374719887971878, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.1374719887971878, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4133180201794038, "std_of_first_answer": 0.4133180201794038, "avg_entropy_of_first_answer": 1.4270904765409582, "lex_sim": 1.0}
{"question": "the vast interior rural area of australia is known as the", "answer": ["Outback ######"], "scores": [[0.8466796875, 1.0, 0.0, 0.476318359375]], "normalized_score": [0.0], "tokens": [["\u2581Out", "back", "\u2581#####", "#"]], "entropy": [[0.486083984375, 0.00014543533325195312, 1.0556640625, 1.65234375]], "avg_entropy": [0.798559308052063], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The Outback", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.38557285020360393, "std_of_first_answer": 0.38557285020360393, "avg_entropy_of_first_answer": 0.798559308052063, "lex_sim": 1.0}
{"question": "who was the aztec ruler when the spanish arrived", "answer": ["Montezuma II #89: 2017 Honda Civic Type R \u2013 The Hell Yeah, Damn Right Wagon!"], "scores": [[0.100341796875, 0.99951171875, 0.99951171875, 0.9765625, 5.960464477539063e-08, 0.00917816162109375, 0.0214080810546875, 0.0006117820739746094, 0.03619384765625, 0.10601806640625, 0.278076171875, 0.095458984375, 0.0660400390625, 0.001300811767578125, 0.09136962890625, 0.54052734375, 0.98681640625, 0.99951171875, 0.9638671875, 0.99462890625, 0.059783935546875, 0.1337890625, 0.0003676414489746094, 0.10626220703125, 0.00307464599609375, 0.00933837890625, 0.9736328125, 0.295166015625, 0.001007080078125, 0.478271484375, 0.259033203125]], "normalized_score": [0.05111400783061981], "tokens": [["\u2581Monte", "z", "uma", "\u2581II", "\u2581#", "8", "9", ":", "\u2581", "2", "0", "1", "7", "\u2581H", "onda", "\u2581C", "iv", "ic", "\u2581Type", "\u2581R", "\u2581\u2013", "\u2581The", "\u2581Hell", "\u2581Yeah", ",", "\u2581Dam", "n", "\u2581Right", "\u2581W", "agon", "!"]], "entropy": [[0.439208984375, 0.0028972625732421875, 0.004108428955078125, 0.1356201171875, 0.92333984375, 5.1484375, 1.6767578125, 2.052734375, 5.171875, 1.2041015625, 3.255859375, 3.671875, 2.166015625, 2.87109375, 3.826171875, 1.9248046875, 0.07403564453125, 0.0049591064453125, 0.22119140625, 0.038970947265625, 3.314453125, 5.421875, 1.7275390625, 3.16015625, 1.7841796875, 3.392578125, 0.13623046875, 2.671875, 1.2451171875, 1.0693359375, 3.173828125]], "avg_entropy": [1.9971363313736454], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Moctezuma II", "score_of_biggest_cluster": 0.05111400783061981, "score_of_first_answer": 0.05111400783061981, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.05111400783061981, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4018404645320485, "std_of_first_answer": 0.4018404645320485, "avg_entropy_of_first_answer": 1.9971363313736454, "lex_sim": 1.0}
{"question": "who wrote the poem for whom the bell tolls", "answer": ["The poem you are referring to is \"For Whom the Bell Tolls\" and it was written by Ernest Hemingway."], "scores": [[0.0168914794921875, 0.62158203125, 0.015960693359375, 0.65625, 0.8291015625, 0.9990234375, 0.974609375, 0.489990234375, 0.86767578125, 0.99755859375, 0.99951171875, 0.9892578125, 0.99658203125, 1.0, 0.99853515625, 1.0, 0.634765625, 0.7529296875, 0.98779296875, 0.99755859375, 0.998046875, 0.99951171875, 0.1514892578125, 1.0, 1.0, 1.0, 0.9814453125]], "normalized_score": [0.620970606803894], "tokens": [["\u2581The", "\u2581poem", "\u2581you", "\u2581are", "\u2581referring", "\u2581to", "\u2581is", "\u2581\"", "For", "\u2581Wh", "om", "\u2581the", "\u2581Bell", "\u2581T", "oll", "s", "\"", "\u2581and", "\u2581it", "\u2581was", "\u2581written", "\u2581by", "\u2581Ernest", "\u2581Hem", "ing", "way", "."]], "entropy": [[1.0908203125, 1.8798828125, 1.4658203125, 1.06640625, 0.66259765625, 0.009063720703125, 0.1572265625, 1.5537109375, 0.6123046875, 0.019378662109375, 0.005184173583984375, 0.059539794921875, 0.024444580078125, 0.0005078315734863281, 0.0118560791015625, 5.2809715270996094e-05, 0.9248046875, 0.701171875, 0.07867431640625, 0.017547607421875, 0.016326904296875, 0.005096435546875, 1.326171875, 0.0012111663818359375, 0.0015172958374023438, 0.0002970695495605469, 0.10650634765625]], "avg_entropy": [0.43696750976421217], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ernest Hemingway", "score_of_biggest_cluster": 0.620970606803894, "score_of_first_answer": 0.620970606803894, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.015960693359375, "avg_score": 0.620970606803894, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.30285388323322243, "std_of_first_answer": 0.30285388323322243, "avg_entropy_of_first_answer": 0.43696750976421217, "lex_sim": 1.0}
{"question": "what is the name of the muslim dress", "answer": ["The Muslim dress is called \"Hijab\" or \"Burqa\"."], "scores": [[0.1275634765625, 0.267578125, 0.990234375, 0.98095703125, 0.44287109375, 0.0472412109375, 0.7041015625, 0.9892578125, 1.0, 0.62109375, 0.6982421875, 0.98974609375, 0.286376953125, 0.9521484375, 0.8515625, 0.50146484375, 9.5367431640625e-07, 0.0032367706298828125, 0.044342041015625, 0.11102294921875, 1.1920928955078125e-07, 0.01088714599609375, 0.0038242340087890625, 0.0164947509765625, 0.0018548965454101562, 0.00994110107421875, 0.025115966796875, 0.86669921875, 0.004375457763671875, 0.447265625, 0.06298828125, 0.00955963134765625, 0.9296875, 0.50830078125, 0.0760498046875, 0.029876708984375, 0.00307464599609375, 0.05389404296875]], "normalized_score": [0.05590400472283363], "tokens": [["\u2581The", "\u2581Muslim", "\u2581dress", "\u2581is", "\u2581called", "\u2581\"", "H", "ij", "ab", "\"", "\u2581or", "\u2581\"", "B", "ur", "qa", "\".", "\u2581#", "1", "8", "0", "\u2581Jeff", "\u2581S", "ass", "\u2581-", "\u2581Re", "venue", "\u2581Oper", "ations", "\u2581Str", "ategy", ",", "\u2581A", "I", ",", "\u2581and", "\u2581the", "\u2581Digital", "\u2581Future"]], "entropy": [[2.91015625, 2.2890625, 0.0731201171875, 0.130615234375, 1.0888671875, 0.87451171875, 0.791015625, 0.07373046875, 0.001964569091796875, 0.96630859375, 1.0859375, 0.07916259765625, 1.2587890625, 0.2288818359375, 0.435546875, 1.0078125, 0.4345703125, 1.4130859375, 3.068359375, 3.005859375, 2.525390625, 4.76171875, 2.267578125, 4.96875, 5.32421875, 3.34765625, 4.70703125, 0.5576171875, 3.24609375, 0.96630859375, 3.669921875, 4.515625, 0.50390625, 2.712890625, 4.6796875, 4.94921875, 3.53515625, 3.69140625]], "avg_entropy": [2.16177719517758], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "hijab", "score_of_biggest_cluster": 0.05590400472283363, "score_of_first_answer": 0.05590400472283363, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.05590400472283363, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38756210170790967, "std_of_first_answer": 0.38756210170790967, "avg_entropy_of_first_answer": 2.16177719517758, "lex_sim": 1.0}
{"question": "what's the largest city park in the united states", "answer": ["Central Park in New York City"], "scores": [[0.0107269287109375, 0.9990234375, 0.357421875, 0.99560546875, 1.0, 0.99609375]], "normalized_score": [0.39500564336776733], "tokens": [["\u2581Central", "\u2581Park", "\u2581in", "\u2581New", "\u2581York", "\u2581City"]], "entropy": [[3.130859375, 0.008758544921875, 1.4970703125, 0.03338623046875, 0.00179290771484375, 0.0321044921875]], "avg_entropy": [0.7839953104654948], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Franklin Mountains State Park", "score_of_biggest_cluster": 0.39500564336776733, "score_of_first_answer": 0.39500564336776733, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0107269287109375, "avg_score": 0.39500564336776733, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39638356140640935, "std_of_first_answer": 0.39638356140640935, "avg_entropy_of_first_answer": 0.7839953104654948, "lex_sim": 1.0}
{"question": "who sings find out who your friends are with tracy lawrence", "answer": ["Tim McGraw"], "scores": [[0.01837158203125, 0.9990234375, 1.0]], "normalized_score": [0.26377931237220764], "tokens": [["\u2581Tim", "\u2581McG", "raw"]], "entropy": [[1.0458984375, 0.0111083984375, 0.00019824504852294922]], "avg_entropy": [0.35240169366200763], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Kenny Chesney", "score_of_biggest_cluster": 0.26377931237220764, "score_of_first_answer": 0.26377931237220764, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.01837158203125, "avg_score": 0.26377931237220764, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.46251406780676524, "std_of_first_answer": 0.46251406780676524, "avg_entropy_of_first_answer": 0.35240169366200763, "lex_sim": 1.0}
{"question": "who invented the transtheoretical model of behavior change", "answer": ["Prochaska and DiClemente"], "scores": [[0.10797119140625, 0.9990234375, 0.9990234375, 0.921875, 0.9931640625, 0.998046875, 0.99951171875, 0.99951171875]], "normalized_score": [0.7483587861061096], "tokens": [["\u2581Pro", "ch", "aska", "\u2581and", "\u2581Di", "C", "lement", "e"]], "entropy": [[0.476318359375, 0.01285552978515625, 0.00858306884765625, 0.376953125, 0.055023193359375, 0.017791748046875, 0.004119873046875, 0.00499725341796875]], "avg_entropy": [0.11958026885986328], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "colleagues", "score_of_biggest_cluster": 0.7483587861061096, "score_of_first_answer": 0.7483587861061096, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.10797119140625, "avg_score": 0.7483587861061096, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.29183955882167, "std_of_first_answer": 0.29183955882167, "avg_entropy_of_first_answer": 0.11958026885986328, "lex_sim": 1.0}
{"question": "why was the plague that struck athens so devastating", "answer": ["The plague that struck Athens in the 5th century BCE is considered to be one of the most devastating pandemics in human history."], "scores": [[0.56787109375, 0.8046875, 1.0, 0.8349609375, 0.99853515625, 0.98486328125, 1.0, 0.521484375, 0.0924072265625, 0.91796875, 0.99853515625, 0.99951171875, 0.9990234375, 0.74267578125, 0.98974609375, 0.04901123046875, 0.018463134765625, 0.269775390625, 0.56396484375, 0.912109375, 0.99560546875, 0.998046875, 0.6875, 0.99169921875, 1.0, 1.0, 0.51123046875, 1.0, 1.0, 0.99853515625, 0.8427734375, 1.0, 0.92724609375, 0.52734375, 0.6513671875, 0.81103515625, 0.30712890625, 0.9990234375, 0.7841796875, 0.370361328125, 0.99951171875, 1.0, 0.935546875, 1.0, 0.81591796875, 0.293212890625, 0.0018186569213867188, 0.43701171875, 0.8134765625, 1.0]], "normalized_score": [0.5799881815910339], "tokens": [["\u2581The", "\u2581pl", "ague", "\u2581that", "\u2581struck", "\u2581Ath", "ens", "\u2581in", "\u2581the", "\u2581", "5", "th", "\u2581century", "\u2581B", "CE", "\u2581is", "\u2581considered", "\u2581to", "\u2581be", "\u2581one", "\u2581of", "\u2581the", "\u2581most", "\u2581dev", "ast", "ating", "\u2581pan", "dem", "ics", "\u2581in", "\u2581human", "\u2581history", ".", "\u2581The", "\u2581disease", ",", "\u2581believed", "\u2581to", "\u2581be", "\u2581b", "ub", "onic", "\u2581pl", "ague", ",", "\u2581was", "\u2581a", "\u2581highly", "\u2581cont", "ag"]], "entropy": [[1.2275390625, 0.78271484375, 0.00128173828125, 0.7412109375, 0.01126861572265625, 0.083251953125, 0.0008101463317871094, 1.216796875, 0.334228515625, 0.3974609375, 0.01061248779296875, 0.0032749176025390625, 0.00949859619140625, 0.62060546875, 0.0572509765625, 0.6875, 1.5107421875, 0.70458984375, 0.70947265625, 0.390625, 0.0301971435546875, 0.0148468017578125, 0.7919921875, 0.06109619140625, 0.00030303001403808594, 0.0005006790161132812, 1.3759765625, 0.0013790130615234375, 3.159046173095703e-06, 0.01399993896484375, 0.55322265625, 0.0005288124084472656, 0.283935546875, 1.0322265625, 1.2138671875, 0.67626953125, 1.671875, 0.006427764892578125, 0.53076171875, 1.3916015625, 0.002696990966796875, 2.562999725341797e-05, 0.27783203125, 0.00015783309936523438, 0.52783203125, 1.822265625, 1.859375, 2.251953125, 0.58056640625, 8.875131607055664e-05]], "avg_entropy": [0.5294908046722412], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "close quarters and poor hygiene", "score_of_biggest_cluster": 0.5799881815910339, "score_of_first_answer": 0.5799881815910339, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0018186569213867188, "avg_score": 0.5799881815910339, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.30451102449713696, "std_of_first_answer": 0.30451102449713696, "avg_entropy_of_first_answer": 0.5294908046722412, "lex_sim": 1.0}
{"question": "where was the movie strangers prey at night filmed", "answer": ["filmed in Albuquerque, New Mexico, USA ### Rethinking Education"], "scores": [[0.0030460357666015625, 1.0, 0.87109375, 0.0024585723876953125, 0.96484375, 0.9970703125, 1.0, 0.94775390625, 0.98779296875, 0.99951171875, 0.5341796875, 0.493896484375, 0.0, 0.00010722875595092773, 0.00577545166015625, 0.72412109375, 1.329183578491211e-05]], "normalized_score": [0.0], "tokens": [["\u2581fil", "med", "\u2581in", "\u2581Al", "bu", "quer", "que", ",", "\u2581New", "\u2581Mexico", ",", "\u2581USA", "\u2581###", "\u2581R", "eth", "inking", "\u2581Education"]], "entropy": [[3.29296875, 0.0018310546875, 0.64794921875, 3.0625, 0.1932373046875, 0.023101806640625, 0.00043487548828125, 0.263916015625, 0.08740234375, 0.00403594970703125, 1.2998046875, 0.95751953125, 1.1591796875, 2.337890625, 3.173828125, 0.7607421875, 3.96875]], "avg_entropy": [1.2491230684168197], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Covington, Kentucky", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4383312501102856, "std_of_first_answer": 0.4383312501102856, "avg_entropy_of_first_answer": 1.2491230684168197, "lex_sim": 1.0}
{"question": "when was the last time the womens hockey team won gold", "answer": ["2018"], "scores": [[0.849609375, 0.9990234375, 1.0, 0.99658203125, 0.99951171875]], "normalized_score": [0.9669837951660156], "tokens": [["\u2581", "2", "0", "1", "8"]], "entropy": [[0.78515625, 0.01006317138671875, 0.0027008056640625, 0.025848388671875, 0.006832122802734375]], "avg_entropy": [0.16612014770507813], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2018", "score_of_biggest_cluster": 0.9669837951660156, "score_of_first_answer": 0.9669837951660156, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.849609375, "avg_score": 0.9669837951660156, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.05967955531427631, "std_of_first_answer": 0.05967955531427631, "avg_entropy_of_first_answer": 0.16612014770507813, "lex_sim": 1.0}
{"question": "when did congress passes legislation to fund the national cancer institute", "answer": ["June 10, 1937 (National Cancer Institute Act)"], "scores": [[0.007770538330078125, 0.99462890625, 0.0176544189453125, 0.08392333984375, 0.966796875, 0.99658203125, 0.99951171875, 1.0, 0.9912109375, 0.9990234375, 0.011322021484375, 0.21435546875, 0.99853515625, 1.0, 0.962890625, 0.806640625, 0.9755859375]], "normalized_score": [0.35252222418785095], "tokens": [["\u2581June", "\u2581", "1", "0", ",", "\u2581", "1", "9", "3", "7", "\u2581(", "National", "\u2581Can", "cer", "\u2581Institute", "\u2581Act", ")"]], "entropy": [[1.44921875, 0.03802490234375, 0.11627197265625, 2.158203125, 0.16064453125, 0.026397705078125, 0.00446319580078125, 3.874301910400391e-06, 0.06256103515625, 0.00783538818359375, 1.083984375, 2.40625, 0.01421356201171875, 1.239776611328125e-05, 0.186279296875, 0.935546875, 0.164794921875]], "avg_entropy": [0.5185121122528525], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "August 5, 1937", "score_of_biggest_cluster": 0.35252222418785095, "score_of_first_answer": 0.35252222418785095, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.007770538330078125, "avg_score": 0.35252222418785095, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4179039825100001, "std_of_first_answer": 0.4179039825100001, "avg_entropy_of_first_answer": 0.5185121122528525, "lex_sim": 1.0}
{"question": "who are the judges on the fisa court", "answer": ["I do not have access to current information."], "scores": [[0.1142578125, 0.1376953125, 0.99951171875, 0.9560546875, 0.1591796875, 0.9990234375, 0.45654296875, 0.966796875, 0.1763916015625, 0.1512451171875, 0.11865234375, 0.13623046875, 0.484130859375, 0.96484375, 0.99951171875, 0.99951171875, 1.0, 0.98828125, 0.61474609375, 0.0, 4.76837158203125e-06, 0.0020084381103515625, 0.01467132568359375, 0.0007266998291015625, 0.00136566162109375, 0.9599609375, 0.99560546875, 0.9814453125, 0.97265625, 0.99755859375, 0.96923828125, 1.0, 0.73974609375, 0.11572265625, 0.07574462890625, 0.0017681121826171875, 0.0999755859375, 0.057861328125, 0.10003662109375, 0.07171630859375, 0.08038330078125, 0.1080322265625, 0.978515625]], "normalized_score": [0.0], "tokens": [["\u2581I", "\u2581do", "\u2581not", "\u2581have", "\u2581access", "\u2581to", "\u2581current", "\u2581information", ".", "\u2581Please", "\u2581consult", "\u2581an", "\u2581up", "-", "to", "-", "date", "\u2581source", ".", "\u2581#####", "\u2581Can", "cel", "\u2581#", "<", "Book", ":", "0", "x", "0", "0", "0", "0", "7", "fa", "6", "fc", "0", "c", "8", "2", "f", "8", ">"]], "entropy": [[2.955078125, 1.705078125, 0.0052947998046875, 0.2086181640625, 1.74609375, 0.01062774658203125, 1.7822265625, 0.221435546875, 1.8876953125, 2.20703125, 1.6513671875, 0.7685546875, 1.0654296875, 0.1607666015625, 0.004528045654296875, 0.005702972412109375, 0.0005412101745605469, 0.09185791015625, 0.74365234375, 0.46728515625, 1.1484375, 1.521484375, 1.7353515625, 0.6708984375, 5.359375, 0.1900634765625, 0.049774169921875, 0.1197509765625, 0.1793212890625, 0.0200042724609375, 0.14599609375, 0.0006785392761230469, 0.76318359375, 1.8798828125, 2.548828125, 3.240234375, 2.529296875, 3.22265625, 2.57421875, 2.921875, 2.822265625, 0.355224609375, 0.1368408203125]], "avg_entropy": [1.2052211096120435], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Thomas Russell", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43221852617251627, "std_of_first_answer": 0.43221852617251627, "avg_entropy_of_first_answer": 1.2052211096120435, "lex_sim": 1.0}
{"question": "when was the last time lebron scored 50 points", "answer": ["December 25, 2020 #032 - Favorite Film - Die Hard"], "scores": [[0.119384765625, 0.99755859375, 0.59716796875, 0.05047607421875, 0.69189453125, 0.9990234375, 0.99755859375, 1.0, 0.85888671875, 0.1541748046875, 4.76837158203125e-07, 0.002918243408203125, 0.0252838134765625, 0.06829833984375, 0.0015926361083984375, 0.0009131431579589844, 0.003391265869140625, 0.88916015625, 0.0005645751953125, 0.0322265625, 0.0026416778564453125, 0.994140625]], "normalized_score": [0.039884038269519806], "tokens": [["\u2581December", "\u2581", "2", "5", ",", "\u2581", "2", "0", "2", "0", "\u2581#", "0", "3", "2", "\u2581-", "\u2581F", "avor", "ite", "\u2581Film", "\u2581-", "\u2581Die", "\u2581Hard"]], "entropy": [[2.439453125, 0.0176239013671875, 0.97314453125, 1.2763671875, 0.67236328125, 0.006908416748046875, 0.0181121826171875, 0.0002620220184326172, 0.41259765625, 0.498046875, 1.4365234375, 5.015625, 3.849609375, 2.96875, 2.576171875, 4.44140625, 4.72265625, 0.73046875, 5.7265625, 3.974609375, 5.12890625, 0.050933837890625]], "avg_entropy": [2.13350463997234], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "March 5, 2008", "score_of_biggest_cluster": 0.039884038269519806, "score_of_first_answer": 0.039884038269519806, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.76837158203125e-07, "avg_score": 0.039884038269519806, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43237828968824005, "std_of_first_answer": 0.43237828968824005, "avg_entropy_of_first_answer": 2.13350463997234, "lex_sim": 1.0}
{"question": "who laid foundation stone of islamia college peshawar", "answer": ["Sir Syed Ahmad Khan"], "scores": [[0.86767578125, 0.396484375, 1.0, 0.939453125, 0.99951171875, 1.0, 1.0]], "normalized_score": [0.8509271144866943], "tokens": [["\u2581Sir", "\u2581Sy", "ed", "\u2581A", "hm", "ad", "\u2581Khan"]], "entropy": [[0.85302734375, 2.591796875, 0.001483917236328125, 0.2310791015625, 0.0028171539306640625, 0.0019121170043945312, 0.0020999908447265625]], "avg_entropy": [0.5263166427612305], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Haji Sahib", "score_of_biggest_cluster": 0.8509271144866943, "score_of_first_answer": 0.8509271144866943, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.396484375, "avg_score": 0.8509271144866943, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.20517981318631984, "std_of_first_answer": 0.20517981318631984, "avg_entropy_of_first_answer": 0.5263166427612305, "lex_sim": 1.0}
{"question": "who were the two mathematicians that invented calculus", "answer": ["Sir Isaac Newton and Gottfried Wilhelm Leibniz"], "scores": [[0.67578125, 0.97509765625, 1.0, 0.98681640625, 0.62255859375, 1.0, 0.99462890625, 0.9951171875, 1.0, 1.0, 1.0]], "normalized_score": [0.9202196002006531], "tokens": [["\u2581Sir", "\u2581Isaac", "\u2581Newton", "\u2581and", "\u2581Gott", "fried", "\u2581Wilhelm", "\u2581Le", "ib", "n", "iz"]], "entropy": [[0.8896484375, 0.1195068359375, 0.0007171630859375, 0.08892822265625, 0.7880859375, 0.00039958953857421875, 0.034423828125, 0.033111572265625, 8.32676887512207e-05, 0.0008950233459472656, 0.0007872581481933594]], "avg_entropy": [0.1778715577992526], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Gottfried Leibniz", "score_of_biggest_cluster": 0.9202196002006531, "score_of_first_answer": 0.9202196002006531, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.62255859375, "avg_score": 0.9202196002006531, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.13392334094262015, "std_of_first_answer": 0.13392334094262015, "avg_entropy_of_first_answer": 0.1778715577992526, "lex_sim": 1.0}
{"question": "total goals scored by ronaldo in la liga", "answer": ["311"], "scores": [[0.8779296875, 0.783203125, 0.990234375, 0.9970703125]], "normalized_score": [0.9077149629592896], "tokens": [["\u2581", "3", "1", "1"]], "entropy": [[0.74560546875, 0.65966796875, 0.07147216796875, 0.0272064208984375]], "avg_entropy": [0.3759880065917969], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "309", "score_of_biggest_cluster": 0.9077149629592896, "score_of_first_answer": 0.9077149629592896, "max_score_of_first_answer": 0.9970703125, "min_score_of_first_answer": 0.783203125, "avg_score": 0.9077149629592896, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.0881858107244854, "std_of_first_answer": 0.0881858107244854, "avg_entropy_of_first_answer": 0.3759880065917969, "lex_sim": 1.0}
{"question": "what grade was arnold from hey arnold in", "answer": ["3rd grade"], "scores": [[0.69140625, 0.95263671875, 1.0, 0.6845703125]], "normalized_score": [0.8194447159767151], "tokens": [["\u2581", "3", "rd", "\u2581grade"]], "entropy": [[1.3017578125, 0.255859375, 0.0019741058349609375, 0.89208984375]], "avg_entropy": [0.6129202842712402], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "fourth", "score_of_biggest_cluster": 0.8194447159767151, "score_of_first_answer": 0.8194447159767151, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.6845703125, "avg_score": 0.8194447159767151, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.1451544342912953, "std_of_first_answer": 0.1451544342912953, "avg_entropy_of_first_answer": 0.6129202842712402, "lex_sim": 1.0}
{"question": "the first permanent european settlement on future united states soil was located where", "answer": ["Jamestown, Virginia #040 - Lance Eaton"], "scores": [[0.7490234375, 1.0, 1.0, 0.98291015625, 0.99658203125, 1.1920928955078125e-07, 0.00658416748046875, 0.0657958984375, 0.12249755859375, 0.0007958412170410156, 0.00086212158203125, 0.0002237558364868164, 0.0024261474609375, 0.02484130859375]], "normalized_score": [0.015419336035847664], "tokens": [["\u2581Jam", "est", "own", ",", "\u2581Virginia", "\u2581#", "0", "4", "0", "\u2581-", "\u2581L", "ance", "\u2581E", "aton"]], "entropy": [[0.87353515625, 3.0338764190673828e-05, 0.00010848045349121094, 0.10968017578125, 0.0288848876953125, 1.20703125, 4.55078125, 2.521484375, 2.57421875, 2.748046875, 4.06640625, 3.369140625, 4.6171875, 3.52734375]], "avg_entropy": [2.156705690281732], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Jamestown", "score_of_biggest_cluster": 0.015419336035847664, "score_of_first_answer": 0.015419336035847664, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.015419336035847664, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44628224272979433, "std_of_first_answer": 0.44628224272979433, "avg_entropy_of_first_answer": 2.156705690281732, "lex_sim": 1.0}
{"question": "what was the code name of the us program to develop an atomic bomb", "answer": ["The Manhattan Project #404: Rush for the Door"], "scores": [[0.490478515625, 0.99951171875, 1.0, 0.99853515625, 1.1920928955078125e-07, 0.003543853759765625, 0.00677490234375, 0.43994140625, 0.00051116943359375, 0.0005164146423339844, 0.0011692047119140625, 0.01119232177734375, 0.9853515625, 3.463029861450195e-05, 0.99951171875]], "normalized_score": [0.01330671925097704], "tokens": [["\u2581The", "\u2581Manh", "attan", "\u2581Project", "\u2581#", "4", "0", "4", ":", "\u2581R", "ush", "\u2581for", "\u2581the", "\u2581Do", "or"]], "entropy": [[1.013671875, 0.0038166046142578125, 5.245208740234375e-05, 0.01190948486328125, 0.54248046875, 4.9921875, 0.5087890625, 2.2890625, 2.337890625, 5.296875, 4.328125, 3.162109375, 0.1458740234375, 1.556640625, 0.00611114501953125]], "avg_entropy": [1.7463730494181315], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Manhattan", "score_of_biggest_cluster": 0.01330671925097704, "score_of_first_answer": 0.01330671925097704, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.01330671925097704, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.450955918346221, "std_of_first_answer": 0.450955918346221, "avg_entropy_of_first_answer": 1.7463730494181315, "lex_sim": 1.0}
{"question": "when does the sword art online movie take place", "answer": ["The movie Sword Art Online: Ordinal Scale takes place after the events of the Aincrad arc of the original Sword Art Online light novel series."], "scores": [[0.09619140625, 0.403076171875, 0.08642578125, 0.98583984375, 1.0, 0.99951171875, 0.9755859375, 0.93603515625, 0.9990234375, 0.99951171875, 1.0, 0.69140625, 0.99951171875, 0.1463623046875, 0.9990234375, 0.896484375, 0.99853515625, 0.986328125, 0.366455078125, 0.94970703125, 0.9765625, 0.7353515625, 0.245361328125, 1.0, 0.294189453125, 0.51611328125, 0.99951171875, 1.0, 0.99853515625, 0.884765625, 0.908203125, 0.98681640625, 0.8330078125, 1.8477439880371094e-06, 0.0247344970703125, 0.1533203125, 0.09368896484375, 8.344650268554688e-07, 0.0055694580078125, 0.003421783447265625, 0.00342559814453125, 0.8701171875, 0.9658203125, 0.99951171875, 0.031463623046875, 0.036468505859375, 0.908203125, 0.0034942626953125]], "normalized_score": [0.19815397262573242], "tokens": [["\u2581The", "\u2581movie", "\u2581S", "word", "\u2581Art", "\u2581Online", ":", "\u2581Ord", "inal", "\u2581Sc", "ale", "\u2581takes", "\u2581place", "\u2581after", "\u2581the", "\u2581events", "\u2581of", "\u2581the", "\u2581A", "inc", "rad", "\u2581arc", "\u2581of", "\u2581the", "\u2581original", "\u2581S", "word", "\u2581Art", "\u2581Online", "\u2581light", "\u2581novel", "\u2581series", ".", "\u2581#", "1", "0", "6", "\u2581Post", "\u2581by", "\u2581d", "da", "1", "9", "9", "6", "a", "\u2581\u00bb", "\u2581Sat"]], "entropy": [[3.533203125, 2.37890625, 1.3662109375, 0.076171875, 0.0007143020629882812, 0.003620147705078125, 0.1363525390625, 0.289794921875, 0.007476806640625, 0.0035915374755859375, 0.00011056661605834961, 0.7265625, 0.004085540771484375, 1.3486328125, 0.01153564453125, 0.447265625, 0.01385498046875, 0.0928955078125, 2.21875, 0.2344970703125, 0.1171875, 0.7255859375, 1.427734375, 0.0019741058349609375, 1.2275390625, 1.2060546875, 0.00460052490234375, 0.0005035400390625, 0.01317596435546875, 0.474365234375, 0.3076171875, 0.08538818359375, 0.56982421875, 1.255859375, 2.984375, 2.779296875, 2.435546875, 2.396484375, 2.904296875, 5.26171875, 4.8984375, 0.73291015625, 0.159912109375, 0.006744384765625, 1.619140625, 1.138671875, 0.5966796875, 0.407470703125]], "avg_entropy": [1.013194341212511], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2026", "score_of_biggest_cluster": 0.19815397262573242, "score_of_first_answer": 0.19815397262573242, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 8.344650268554688e-07, "avg_score": 0.19815397262573242, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41504671240426194, "std_of_first_answer": 0.41504671240426194, "avg_entropy_of_first_answer": 1.013194341212511, "lex_sim": 1.0}
{"question": "who played zoe hart on hart of dixie", "answer": ["Rachel Bilson #28 \u2013 Be Kind to Yourself: On Failure, Setbacks, and Self-Compassion in Writing and Publishing"], "scores": [[0.99951171875, 0.99951171875, 0.99951171875, 1.0, 4.172325134277344e-07, 0.0034923553466796875, 0.0352783203125, 8.434057235717773e-05, 0.0006470680236816406, 0.006916046142578125, 0.09991455078125, 0.032379150390625, 0.2418212890625, 0.09124755859375, 0.0013256072998046875, 0.0015573501586914062, 0.41162109375, 0.2344970703125, 0.003993988037109375, 0.9990234375, 0.99365234375, 0.85986328125, 0.93115234375, 0.01491546630859375, 0.97216796875, 0.53759765625, 1.0, 1.0, 0.00711822509765625, 0.018218994140625, 0.099365234375, 0.0352783203125]], "normalized_score": [0.0504494234919548], "tokens": [["\u2581Rach", "el", "\u2581Bil", "son", "\u2581#", "2", "8", "\u2581\u2013", "\u2581Be", "\u2581Kind", "\u2581to", "\u2581Your", "self", ":", "\u2581On", "\u2581Fail", "ure", ",", "\u2581Set", "back", "s", ",", "\u2581and", "\u2581Self", "-", "Com", "pass", "ion", "\u2581in", "\u2581Writing", "\u2581and", "\u2581Publishing"]], "entropy": [[0.006267547607421875, 0.0030040740966796875, 0.0030117034912109375, 0.00030159950256347656, 0.6025390625, 5.015625, 3.34765625, 3.55078125, 5.046875, 4.03515625, 2.45703125, 1.501953125, 2.958984375, 2.94921875, 4.7578125, 4.55859375, 0.72607421875, 2.138671875, 4.73828125, 0.00901031494140625, 0.0438232421875, 0.5009765625, 0.505859375, 4.12890625, 0.1705322265625, 1.3046875, 0.00015056133270263672, 0.0024509429931640625, 2.8359375, 3.279296875, 3.00390625, 1.8837890625]], "avg_entropy": [2.064598921686411], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Rachel Sarah Bilson", "score_of_biggest_cluster": 0.0504494234919548, "score_of_first_answer": 0.0504494234919548, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.0504494234919548, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4384661462335988, "std_of_first_answer": 0.4384661462335988, "avg_entropy_of_first_answer": 2.064598921686411, "lex_sim": 1.0}
{"question": "who won la liga in the last 10 years", "answer": ["Over the past 10 years, the La Liga winners are:"], "scores": [[0.0002346038818359375, 0.9970703125, 0.490478515625, 0.9033203125, 0.99951171875, 0.99951171875, 0.9853515625, 0.94921875, 0.411865234375, 0.0208587646484375, 0.998046875, 0.1326904296875, 1.0, 0.286376953125, 0.29736328125]], "normalized_score": [0.29162248969078064], "tokens": [["\u2581Over", "\u2581the", "\u2581past", "\u2581", "1", "0", "\u2581years", ",", "\u2581the", "\u2581La", "\u2581Liga", "\u2581w", "inners", "\u2581are", ":"]], "entropy": [[1.736328125, 0.0267791748046875, 0.71630859375, 0.38671875, 0.004894256591796875, 0.00421905517578125, 0.0811767578125, 0.26123046875, 1.884765625, 1.3759765625, 0.0160064697265625, 1.87109375, 2.4437904357910156e-05, 1.033203125, 0.6142578125]], "avg_entropy": [0.6675321976343791], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Real Madrid", "score_of_biggest_cluster": 0.29162248969078064, "score_of_first_answer": 0.29162248969078064, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0002346038818359375, "avg_score": 0.29162248969078064, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3910474494256582, "std_of_first_answer": 0.3910474494256582, "avg_entropy_of_first_answer": 0.6675321976343791, "lex_sim": 1.0}
{"question": "when was the latest version of chrome released", "answer": ["Chrome 83"], "scores": [[0.10980224609375, 0.98681640625, 0.513671875, 0.028900146484375]], "normalized_score": [0.2002665400505066], "tokens": [["\u2581Chrome", "\u2581", "8", "3"]], "entropy": [[2.353515625, 0.07916259765625, 1.0029296875, 1.7001953125]], "avg_entropy": [1.2839508056640625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2018-01-22", "score_of_biggest_cluster": 0.2002665400505066, "score_of_first_answer": 0.2002665400505066, "max_score_of_first_answer": 0.98681640625, "min_score_of_first_answer": 0.028900146484375, "avg_score": 0.2002665400505066, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3804013177661704, "std_of_first_answer": 0.3804013177661704, "avg_entropy_of_first_answer": 1.2839508056640625, "lex_sim": 1.0}
{"question": "what is the legal age for marriage in australia", "answer": ["18 years old #WeWantEqualPay: What\u2019s The Status Of FIFA\u2019s Investigation On The USWNT Equal Pay Fight?"], "scores": [[0.96484375, 1.0, 0.9990234375, 0.37841796875, 0.93603515625, 2.384185791015625e-07, 0.00021517276763916016, 0.01056671142578125, 0.08782958984375, 0.001773834228515625, 0.0145416259765625, 9.02414321899414e-05, 0.005031585693359375, 0.004154205322265625, 0.99951171875, 0.005748748779296875, 0.017425537109375, 0.442138671875, 2.0384788513183594e-05, 0.5478515625, 0.99658203125, 0.01317596435546875, 0.99658203125, 0.01184844970703125, 0.367919921875, 0.29833984375, 0.5849609375, 0.99853515625, 0.01305389404296875, 0.9990234375, 0.99853515625, 0.0777587890625, 0.96826171875]], "normalized_score": [0.04507867619395256], "tokens": [["\u2581", "1", "8", "\u2581years", "\u2581old", "\u2581#", "We", "W", "ant", "Equal", "Pay", ":", "\u2581What", "\u2019", "s", "\u2581The", "\u2581Status", "\u2581Of", "\u2581FIFA", "\u2019", "s", "\u2581Investig", "ation", "\u2581On", "\u2581The", "\u2581US", "WN", "T", "\u2581Equ", "al", "\u2581Pay", "\u2581Fight", "?"]], "entropy": [[0.206298828125, 0.00010770559310913086, 0.0075225830078125, 1.595703125, 0.29296875, 1.73046875, 5.15234375, 3.37109375, 1.3251953125, 3.255859375, 1.3701171875, 1.1689453125, 4.73828125, 3.33984375, 0.003574371337890625, 2.0859375, 4.3125, 1.8115234375, 0.6416015625, 1.564453125, 0.0225982666015625, 3.119140625, 0.027313232421875, 1.0048828125, 2.931640625, 2.2890625, 0.77392578125, 0.014434814453125, 0.53369140625, 0.0090179443359375, 0.013336181640625, 1.3447265625, 0.2353515625]], "avg_entropy": [1.5240442951520283], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "18", "score_of_biggest_cluster": 0.04507867619395256, "score_of_first_answer": 0.04507867619395256, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.04507867619395256, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43414470546230555, "std_of_first_answer": 0.43414470546230555, "avg_entropy_of_first_answer": 1.5240442951520283, "lex_sim": 1.0}
{"question": "who won the fountain of youth stakes at gulfstream park", "answer": ["Vekoma ### 1938-1980: El retorno del mal"], "scores": [[0.01216888427734375, 0.0139312744140625, 0.99267578125, 0.0, 0.02288818359375, 0.265380859375, 0.06402587890625, 0.03289794921875, 0.05145263671875, 0.227783203125, 0.2183837890625, 0.036407470703125, 0.1094970703125, 0.058441162109375, 0.0005898475646972656, 0.0003521442413330078, 8.940696716308594e-06, 0.953125, 0.354248046875, 0.044769287109375]], "normalized_score": [0.0], "tokens": [["\u2581V", "ek", "oma", "\u2581###", "\u2581", "1", "9", "3", "8", "-", "1", "9", "8", "0", ":", "\u2581El", "\u2581ret", "orno", "\u2581del", "\u2581mal"]], "entropy": [[4.21484375, 3.271484375, 0.06732177734375, 1.5693359375, 5.41015625, 2.14453125, 3.005859375, 2.78125, 2.884765625, 2.900390625, 1.8984375, 1.5244140625, 1.583984375, 2.2265625, 1.6064453125, 5.375, 4.625, 0.302978515625, 2.23828125, 5.41015625]], "avg_entropy": [2.7520599365234375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Gunnevera", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.99267578125, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2844762312990109, "std_of_first_answer": 0.2844762312990109, "avg_entropy_of_first_answer": 2.7520599365234375, "lex_sim": 1.0}
{"question": "what goes on the bottom of shepherd's pie", "answer": ["mashed potatoes or a layer of fried mashed potatoes called \"crumbs\""], "scores": [[0.53857421875, 0.99755859375, 1.0, 0.97412109375, 0.1119384765625, 0.6162109375, 0.1915283203125, 0.99951171875, 0.0005507469177246094, 0.92138671875, 0.395263671875, 0.99755859375, 0.99951171875, 0.93701171875, 0.0298004150390625, 0.83154296875, 0.14306640625, 0.006366729736328125, 0.9267578125, 0.93017578125]], "normalized_score": [0.2951675057411194], "tokens": [["\u2581m", "ashed", "\u2581pot", "atoes", "\u2581or", "\u2581a", "\u2581layer", "\u2581of", "\u2581f", "ried", "\u2581m", "ashed", "\u2581pot", "atoes", "\u2581called", "\u2581\"", "cr", "umb", "s", "\""]], "entropy": [[1.99609375, 0.0171356201171875, 0.0026683807373046875, 0.12005615234375, 1.4013671875, 1.86328125, 2.140625, 0.0026378631591796875, 1.1904296875, 0.421875, 2.3046875, 0.01922607421875, 0.00576019287109375, 0.23486328125, 2.0, 0.87939453125, 2.89453125, 0.0654296875, 0.398681640625, 0.309814453125]], "avg_entropy": [0.9134279251098633], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "minced meat", "score_of_biggest_cluster": 0.2951675057411194, "score_of_first_answer": 0.2951675057411194, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0005507469177246094, "avg_score": 0.2951675057411194, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39390222942006, "std_of_first_answer": 0.39390222942006, "avg_entropy_of_first_answer": 0.9134279251098633, "lex_sim": 1.0}
{"question": "genre of diary of a wimpy kid the getaway", "answer": ["Action-adventure"], "scores": [[0.0274200439453125, 0.978515625, 0.258056640625, 1.0, 1.0]], "normalized_score": [0.36988794803619385], "tokens": [["\u2581Action", "-", "ad", "vent", "ure"]], "entropy": [[2.236328125, 0.13916015625, 0.6162109375, 7.56978988647461e-05, 1.0371208190917969e-05]], "avg_entropy": [0.5983570575714111], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Children's novel", "score_of_biggest_cluster": 0.36988794803619385, "score_of_first_answer": 0.36988794803619385, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0274200439453125, "avg_score": 0.36988794803619385, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42287320973618925, "std_of_first_answer": 0.42287320973618925, "avg_entropy_of_first_answer": 0.5983570575714111, "lex_sim": 1.0}
{"question": "the south west wind blows across nigeria between", "answer": ["September and March #TheGoodStuff: A Slice Of Good News For Dec. 13, 2018"], "scores": [[0.03924560546875, 0.9951171875, 0.66259765625, 5.960464477539063e-08, 0.001667022705078125, 0.00046825408935546875, 0.199462890625, 0.9990234375, 0.0006561279296875, 0.01001739501953125, 0.0014781951904296875, 0.0195465087890625, 0.01299285888671875, 0.00205230712890625, 0.94189453125, 0.2313232421875, 0.0002582073211669922, 0.587890625, 0.98876953125, 0.47998046875, 0.10614013671875, 0.430908203125, 0.98193359375, 0.99853515625, 1.0, 0.74267578125, 0.12347412109375]], "normalized_score": [0.042239636182785034], "tokens": [["\u2581September", "\u2581and", "\u2581March", "\u2581#", "The", "Good", "St", "uff", ":", "\u2581A", "\u2581S", "lice", "\u2581Of", "\u2581Good", "\u2581News", "\u2581For", "\u2581Dec", ".", "\u2581", "1", "3", ",", "\u2581", "2", "0", "1", "8"]], "entropy": [[2.458984375, 0.034423828125, 1.064453125, 1.4150390625, 5.21875, 3.337890625, 3.279296875, 0.0089263916015625, 1.0537109375, 4.14453125, 5.3125, 3.134765625, 0.0909423828125, 2.974609375, 0.296875, 3.212890625, 1.35546875, 0.96923828125, 0.08367919921875, 1.76171875, 2.486328125, 1.423828125, 0.1553955078125, 0.01123809814453125, 0.0010099411010742188, 0.5751953125, 0.5546875]], "avg_entropy": [1.7191250765765156], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "till September", "score_of_biggest_cluster": 0.042239636182785034, "score_of_first_answer": 0.042239636182785034, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.042239636182785034, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41096266906014267, "std_of_first_answer": 0.41096266906014267, "avg_entropy_of_first_answer": 1.7191250765765156, "lex_sim": 1.0}
{"question": "mainland greece is a body of land with water on three sides called", "answer": ["Peninsula #89: Dr. Aiden Goggins \u2013 The Power of Nitrates & Nitrites 0"], "scores": [[0.015869140625, 0.9990234375, 0.98974609375, 5.960464477539063e-08, 0.0030956268310546875, 0.049163818359375, 0.0016870498657226562, 1.2099742889404297e-05, 0.3369140625, 0.01401519775390625, 4.744529724121094e-05, 0.005512237548828125, 0.0037841796875, 0.6552734375, 0.90576171875, 0.00528717041015625, 0.039306640625, 0.00514984130859375, 0.9267578125, 0.00782012939453125, 0.006786346435546875, 0.116455078125, 0.8115234375, 0.0184173583984375, 0.80859375, 0.9990234375, 0.9931640625, 0.99951171875, 0.008514404296875, 0.03155517578125]], "normalized_score": [0.023625822737812996], "tokens": [["\u2581Pen", "ins", "ula", "\u2581#", "8", "9", ":", "\u2581Dr", ".", "\u2581A", "iden", "\u2581G", "og", "g", "ins", "\u2581\u2013", "\u2581The", "\u2581Power", "\u2581of", "\u2581N", "it", "r", "ates", "\u2581&", "\u2581N", "it", "rit", "es", "\u2581", "0"]], "entropy": [[2.427734375, 0.0082550048828125, 0.0640869140625, 0.81689453125, 5.3515625, 3.693359375, 2.796875, 4.79296875, 3.068359375, 5.46484375, 1.2880859375, 4.58984375, 2.939453125, 1.3095703125, 0.53466796875, 3.013671875, 5.9609375, 6.4140625, 0.458984375, 5.21484375, 1.7529296875, 0.485107421875, 0.662109375, 2.927734375, 1.416015625, 0.0115966796875, 0.053558349609375, 0.0036487579345703125, 2.57421875, 1.5029296875]], "avg_entropy": [2.386630312601725], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "peninsula", "score_of_biggest_cluster": 0.023625822737812996, "score_of_first_answer": 0.023625822737812996, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.023625822737812996, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4219580919970931, "std_of_first_answer": 0.4219580919970931, "avg_entropy_of_first_answer": 2.386630312601725, "lex_sim": 1.0}
{"question": "where is the ucla usc game being played", "answer": ["The location of the UCLA-USC football game changes yearly and is determined by a rotation between the two universities' home fields and a neutral site."], "scores": [[0.194580078125, 0.411376953125, 0.966796875, 0.9990234375, 0.9189453125, 1.0, 0.9677734375, 0.99951171875, 1.0, 0.3193359375, 0.99951171875, 0.41796875, 0.0125579833984375, 0.55712890625, 0.1300048828125, 0.763671875, 0.3525390625, 0.9912109375, 0.0204315185546875, 0.70458984375, 0.83349609375, 0.98779296875, 0.96923828125, 0.1396484375, 1.0, 0.84619140625, 0.81591796875, 0.135986328125, 0.19482421875, 0.32275390625, 0.9306640625, 0.9833984375, 0.94091796875, 0.5322265625, 0.51953125, 0.81787109375, 0.6318359375, 0.818359375, 0.56884765625, 0.79296875, 0.9931640625, 0.93408203125, 0.99951171875, 0.9716796875, 0.99951171875, 1.0, 1.0, 0.258056640625, 0.9423828125]], "normalized_score": [0.551131546497345], "tokens": [["\u2581The", "\u2581location", "\u2581of", "\u2581the", "\u2581U", "CLA", "-", "US", "C", "\u2581football", "\u2581game", "\u2581changes", "\u2581year", "ly", "\u2581and", "\u2581is", "\u2581determined", "\u2581by", "\u2581a", "\u2581rotation", "\u2581between", "\u2581the", "\u2581two", "\u2581univers", "ities", "'", "\u2581home", "\u2581fields", "\u2581and", "\u2581a", "\u2581neutral", "\u2581site", ".", "\u2581The", "\u2581most", "\u2581recent", "\u2581game", "\u2581was", "\u2581played", "\u2581at", "\u2581the", "\u2581Los", "\u2581Angeles", "\u2581Memorial", "\u2581Col", "ise", "um", "\u2581on", "\u2581November"]], "entropy": [[2.06640625, 1.41796875, 0.16552734375, 0.00958251953125, 0.375732421875, 0.0004184246063232422, 0.184326171875, 0.00482177734375, 1.9073486328125e-05, 0.66015625, 0.00600433349609375, 1.3359375, 0.99609375, 0.94384765625, 1.244140625, 1.0517578125, 1.8740234375, 0.07257080078125, 0.2447509765625, 1.2333984375, 0.71875, 0.08306884765625, 0.1917724609375, 1.267578125, 3.457069396972656e-05, 0.52294921875, 0.7294921875, 0.43505859375, 1.32421875, 1.3544921875, 0.358642578125, 0.1075439453125, 0.3291015625, 1.9287109375, 1.70703125, 0.6337890625, 1.3701171875, 0.80078125, 0.76904296875, 0.5693359375, 0.051422119140625, 0.302490234375, 0.0067901611328125, 0.12890625, 0.00275421142578125, 0.00041484832763671875, 0.00010567903518676758, 1.3818359375, 0.2802734375]], "avg_entropy": [0.6376324247340767], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "UCLA", "score_of_biggest_cluster": 0.551131546497345, "score_of_first_answer": 0.551131546497345, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0125579833984375, "avg_score": 0.551131546497345, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3243985268468205, "std_of_first_answer": 0.3243985268468205, "avg_entropy_of_first_answer": 0.6376324247340767, "lex_sim": 1.0}
{"question": "chris cornell she's going to change the world", "answer": ["The lyrics you have provided are from a song named \"Black Hole Sun\" by Soundgarden, not Chris Cornell's solo song \"She's Going to Change the World\"."], "scores": [[0.0257110595703125, 0.45166015625, 1.0, 0.2142333984375, 0.326416015625, 0.55126953125, 0.94677734375, 0.982421875, 0.029266357421875, 0.99609375, 0.0230865478515625, 0.9912109375, 0.1798095703125, 0.99658203125, 0.986328125, 1.0, 0.96533203125, 0.8837890625, 0.244140625, 0.99853515625, 0.99951171875, 0.8125, 0.295166015625, 0.31005859375, 0.9990234375, 1.0, 0.1375732421875, 1.0, 0.78759765625, 0.321044921875, 0.84619140625, 0.994140625, 1.0, 1.0, 0.9951171875, 1.0, 0.87548828125, 0.99951171875, 0.998046875, 1.0, 0.646484375, 0.1812744140625, 0.01187896728515625, 0.96728515625, 1.0, 0.31689453125, 0.8408203125, 0.9345703125, 0.99609375, 1.0]], "normalized_score": [0.5202093720436096], "tokens": [["\u2581The", "\u2581lyr", "ics", "\u2581you", "\u2581have", "\u2581provided", "\u2581are", "\u2581from", "\u2581a", "\u2581song", "\u2581named", "\u2581\"", "Black", "\u2581H", "ole", "\u2581Sun", "\"", "\u2581by", "\u2581Sound", "g", "arden", ",", "\u2581not", "\u2581Chris", "\u2581Corn", "ell", "'", "s", "\u2581solo", "\u2581song", "\u2581\"", "She", "'", "s", "\u2581Go", "ing", "\u2581to", "\u2581Change", "\u2581the", "\u2581World", "\".", "\u2581The", "\u2581actual", "\u2581lyr", "ics", "\u2581to", "\u2581\"", "She", "'", "s"]], "entropy": [[3.9375, 1.1884765625, 9.745359420776367e-05, 1.380859375, 1.548828125, 1.19921875, 0.329833984375, 0.1220703125, 0.1441650390625, 0.035552978515625, 0.83984375, 0.07232666015625, 2.669921875, 0.03082275390625, 0.07696533203125, 0.00035309791564941406, 0.189453125, 0.54345703125, 0.5849609375, 0.01016998291015625, 0.00621795654296875, 0.56787109375, 1.5537109375, 1.208984375, 0.00970458984375, 0.00029754638671875, 0.890625, 0.00064849853515625, 0.7548828125, 1.1669921875, 0.54541015625, 0.048309326171875, 0.0009622573852539062, 0.0006566047668457031, 0.036407470703125, 0.001277923583984375, 0.37939453125, 0.004261016845703125, 0.01470184326171875, 0.001247406005859375, 0.7744140625, 1.587890625, 1.19921875, 0.1956787109375, 0.0003483295440673828, 1.5498046875, 0.57470703125, 0.2479248046875, 0.0260009765625, 0.0010814666748046875]], "avg_entropy": [0.5650902020931244], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Can't Change Me", "score_of_biggest_cluster": 0.5202093720436096, "score_of_first_answer": 0.5202093720436096, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.01187896728515625, "avg_score": 0.5202093720436096, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.35665911218298213, "std_of_first_answer": 0.35665911218298213, "avg_entropy_of_first_answer": 0.5650902020931244, "lex_sim": 1.0}
{"question": "who was the first signatory of the israeli declaration of independence", "answer": ["Chaim Weizmann #NewRelease THE AURORA CONTRACT by @KatDeFalcoAuthor"], "scores": [[0.8369140625, 1.0, 0.99560546875, 0.99853515625, 0.9990234375, 2.980232238769531e-07, 0.0002949237823486328, 3.874301910400391e-06, 6.9141387939453125e-06, 0.04254150390625, 0.0028362274169921875, 0.07855224609375, 0.98193359375, 0.0037441253662109375, 0.63330078125, 0.05889892578125, 0.99951171875, 0.214111328125, 0.1214599609375, 0.015625, 0.0025730133056640625, 0.0002582073211669922, 0.205078125, 0.498291015625, 0.998046875, 0.03314208984375]], "normalized_score": [0.025042204186320305], "tokens": [["\u2581Cha", "im", "\u2581We", "iz", "mann", "\u2581#", "New", "Release", "\u2581THE", "\u2581A", "U", "RO", "RA", "\u2581CON", "T", "RA", "CT", "\u2581by", "\u2581@", "K", "at", "De", "F", "al", "co", "Author"]], "entropy": [[0.98779296875, 4.5239925384521484e-05, 0.035858154296875, 0.01102447509765625, 0.008270263671875, 0.82958984375, 5.234375, 5.015625, 2.552734375, 4.0703125, 2.953125, 1.2470703125, 0.11676025390625, 1.662109375, 1.013671875, 0.53271484375, 0.004665374755859375, 3.236328125, 4.42578125, 5.3125, 3.990234375, 4.01953125, 1.279296875, 0.9775390625, 0.0236663818359375, 3.384765625]], "avg_entropy": [2.0355918384515324], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "David Ben-Gurion", "score_of_biggest_cluster": 0.025042204186320305, "score_of_first_answer": 0.025042204186320305, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.025042204186320305, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42863502634163836, "std_of_first_answer": 0.42863502634163836, "avg_entropy_of_first_answer": 2.0355918384515324, "lex_sim": 1.0}
{"question": "who created separation of powers and checks and balances", "answer": ["James Madison #68 \u2013 Rethinking Mental Illness with Dr. Dan Gottlieb"], "scores": [[0.9541015625, 0.99951171875, 1.0, 1.5497207641601562e-06, 0.01061248779296875, 0.056365966796875, 8.440017700195312e-05, 0.0003902912139892578, 0.002521514892578125, 0.83984375, 0.0008139610290527344, 0.0174560546875, 0.337646484375, 0.99951171875, 0.036590576171875, 0.335693359375, 0.9912109375, 0.023712158203125, 0.0145263671875, 0.958984375, 1.0]], "normalized_score": [0.03758490830659866], "tokens": [["\u2581James", "\u2581Mad", "ison", "\u2581#", "6", "8", "\u2581\u2013", "\u2581R", "eth", "inking", "\u2581M", "ental", "\u2581Ill", "ness", "\u2581with", "\u2581Dr", ".", "\u2581Dan", "\u2581Gott", "lie", "b"]], "entropy": [[0.30859375, 0.005817413330078125, 0.0005235671997070312, 1.4580078125, 4.2734375, 3.494140625, 2.947265625, 4.4453125, 4.484375, 0.546875, 3.615234375, 3.822265625, 2.42578125, 0.003662109375, 3.310546875, 3.923828125, 0.09539794921875, 4.79296875, 3.517578125, 0.1724853515625, 0.0017805099487304688]], "avg_entropy": [2.268851325625465], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Montesquieu in the Enlightenment", "score_of_biggest_cluster": 0.03758490830659866, "score_of_first_answer": 0.03758490830659866, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.5497207641601562e-06, "avg_score": 0.03758490830659866, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4494999737888445, "std_of_first_answer": 0.4494999737888445, "avg_entropy_of_first_answer": 2.268851325625465, "lex_sim": 1.0}
{"question": "when does wentworth season 6 start in australia", "answer": ["I am not familiar with the exact date, as my knowledge cutoff is 2021 and Wentworth season 6 might have started after that time."], "scores": [[0.1605224609375, 0.1514892578125, 0.41943359375, 0.0074005126953125, 0.99951171875, 0.75, 0.083984375, 0.72900390625, 0.38037109375, 0.067626953125, 0.791015625, 0.4609375, 0.82470703125, 0.45068359375, 0.99755859375, 0.7333984375, 1.0, 1.0, 1.0, 0.9990234375, 0.442626953125, 0.08392333984375, 0.99951171875, 1.0, 0.4521484375, 0.99755859375, 0.93310546875, 0.1561279296875, 0.463134765625, 0.326416015625, 0.83642578125, 0.96533203125, 0.050140380859375, 0.97216796875, 0.07415771484375, 0.50634765625, 0.82958984375, 0.99951171875, 0.9609375, 0.178955078125, 0.464599609375, 0.1827392578125, 1.0, 0.60546875, 0.030731201171875, 0.6162109375, 0.0207672119140625, 0.9306640625, 0.8603515625, 0.07037353515625]], "normalized_score": [0.3783191740512848], "tokens": [["\u2581I", "\u2581am", "\u2581not", "\u2581familiar", "\u2581with", "\u2581the", "\u2581exact", "\u2581date", ",", "\u2581as", "\u2581my", "\u2581knowledge", "\u2581cut", "off", "\u2581is", "\u2581", "2", "0", "2", "1", "\u2581and", "\u2581W", "ent", "worth", "\u2581season", "\u2581", "6", "\u2581might", "\u2581have", "\u2581started", "\u2581after", "\u2581that", "\u2581time", ".", "\u2581It", "\u2581is", "\u2581best", "\u2581to", "\u2581check", "\u2581local", "\u2581TV", "\u2581list", "ings", "\u2581or", "\u2581an", "\u2581online", "\u2581resource", "\u2581for", "\u2581the", "\u2581latest"]], "entropy": [[2.654296875, 1.2685546875, 1.201171875, 1.2509765625, 0.006793975830078125, 1.0849609375, 1.9951171875, 1.07421875, 1.681640625, 1.2705078125, 0.68359375, 0.751953125, 0.634765625, 1.0703125, 0.0199432373046875, 0.78857421875, 0.0010290145874023438, 0.0009427070617675781, 0.0026226043701171875, 0.00792694091796875, 1.0673828125, 1.947265625, 0.00299072265625, 0.0001354217529296875, 1.01953125, 0.0226287841796875, 0.267578125, 2.173828125, 0.85107421875, 1.7333984375, 0.8154296875, 0.17822265625, 0.97119140625, 0.1549072265625, 2.19921875, 1.1240234375, 0.66796875, 0.004459381103515625, 0.2139892578125, 1.96875, 1.2802734375, 1.1455078125, 2.092123031616211e-05, 0.81884765625, 2.248046875, 1.06640625, 0.94482421875, 0.34423828125, 0.73583984375, 0.83251953125]], "avg_entropy": [0.8850080382823944], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2019", "score_of_biggest_cluster": 0.3783191740512848, "score_of_first_answer": 0.3783191740512848, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0074005126953125, "avg_score": 0.3783191740512848, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.36322455869528153, "std_of_first_answer": 0.36322455869528153, "avg_entropy_of_first_answer": 0.8850080382823944, "lex_sim": 1.0}
{"question": "how much is the united states in debt to china", "answer": ["$1.4 trillion #OTD in 1913 \u2013 James Larkin is arrested in Dublin for incitement on \"Bloody Sunday\" (the murder of a worker during an industrial dispute) the day"], "scores": [[0.150634765625, 0.98828125, 0.974609375, 0.1575927734375, 0.8623046875, 1.0, 1.0, 1.1920928955078125e-07, 0.00028228759765625, 0.1422119140625, 0.1776123046875, 0.9091796875, 0.0018377304077148438, 0.37744140625, 0.0284271240234375, 0.135986328125, 0.0005331039428710938, 0.0005135536193847656, 0.0035552978515625, 0.1009521484375, 0.97216796875, 0.039825439453125, 0.416748046875, 0.90234375, 0.70263671875, 0.1488037109375, 0.01085662841796875, 0.2392578125, 0.0005640983581542969, 0.01264190673828125, 0.51806640625, 1.0, 1.0, 0.9990234375, 0.30908203125, 0.05633544921875, 0.07305908203125, 0.0005483627319335938, 0.89111328125, 0.0638427734375, 0.0986328125, 0.07568359375, 0.00762176513671875, 0.76171875, 0.99169921875, 0.34814453125, 0.00045371055603027344, 0.475341796875]], "normalized_score": [0.06772274523973465], "tokens": [["\u2581$", "1", ".", "4", "\u2581tr", "ill", "ion", "\u2581#", "OT", "D", "\u2581in", "\u2581", "1", "9", "1", "3", "\u2581\u2013", "\u2581James", "\u2581L", "ark", "in", "\u2581is", "\u2581arrested", "\u2581in", "\u2581Dublin", "\u2581for", "\u2581inc", "itement", "\u2581on", "\u2581\"", "B", "lo", "ody", "\u2581Sunday", "\"", "\u2581(", "the", "\u2581murder", "\u2581of", "\u2581a", "\u2581worker", "\u2581during", "\u2581an", "\u2581industrial", "\u2581dispute", ")", "\u2581the", "\u2581day"]], "entropy": [[2.833984375, 0.0819091796875, 0.1475830078125, 1.046875, 0.71435546875, 0.00016355514526367188, 9.143352508544922e-05, 1.5068359375, 5.41015625, 2.943359375, 2.365234375, 0.5859375, 0.019439697265625, 1.7314453125, 2.376953125, 2.177734375, 2.35546875, 2.689453125, 2.259765625, 1.8515625, 0.2205810546875, 2.00390625, 2.267578125, 0.51708984375, 0.71533203125, 1.37109375, 2.412109375, 0.552734375, 0.424072265625, 3.513671875, 1.736328125, 0.0002574920654296875, 0.00067138671875, 0.0084686279296875, 1.375, 1.78125, 4.171875, 3.984375, 0.440673828125, 3.392578125, 2.14453125, 0.9013671875, 0.67529296875, 1.1396484375, 0.063720703125, 1.373046875, 1.572265625, 2.064453125]], "avg_entropy": [1.5400475139419239], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "$1.06 trillion", "score_of_biggest_cluster": 0.06772274523973465, "score_of_first_answer": 0.06772274523973465, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.06772274523973465, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3959297116770371, "std_of_first_answer": 0.3959297116770371, "avg_entropy_of_first_answer": 1.5400475139419239, "lex_sim": 1.0}
{"question": "when did the prr first begin its passenger service between pittsburgh and philadelphia", "answer": ["1834 #BookReview + #Giveaway: Death on Delos by @KirstenWeissBooks"], "scores": [[0.83740234375, 0.99462890625, 0.990234375, 0.9423828125, 0.6494140625, 5.960464477539062e-07, 2.8789043426513672e-05, 0.0087890625, 0.3232421875, 5.167722702026367e-05, 0.048309326171875, 0.0462646484375, 0.89990234375, 0.99169921875, 0.486328125, 0.004222869873046875, 0.068359375, 0.1669921875, 0.990234375, 0.90478515625, 0.0440673828125, 0.00885009765625, 0.00531768798828125, 0.99267578125, 0.52001953125, 0.90234375, 0.0105438232421875, 0.375]], "normalized_score": [0.06262297928333282], "tokens": [["\u2581", "1", "8", "3", "4", "\u2581#", "Book", "Re", "view", "\u2581+", "\u2581#", "G", "ive", "away", ":", "\u2581Death", "\u2581on", "\u2581Del", "os", "\u2581by", "\u2581@", "K", "irst", "en", "We", "iss", "Book", "s"]], "entropy": [[0.939453125, 0.043212890625, 0.068603515625, 0.2958984375, 0.98291015625, 0.869140625, 5.33984375, 4.4453125, 0.73388671875, 2.9296875, 4.21875, 4.9140625, 0.6640625, 0.06121826171875, 2.27734375, 3.265625, 2.306640625, 1.2529296875, 0.0802001953125, 0.53759765625, 3.53125, 4.69921875, 4.1953125, 0.060882568359375, 2.703125, 0.65869140625, 2.462890625, 2.240234375]], "avg_entropy": [2.027785164969308], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "by 1854", "score_of_biggest_cluster": 0.06262297928333282, "score_of_first_answer": 0.06262297928333282, "max_score_of_first_answer": 0.99462890625, "min_score_of_first_answer": 5.960464477539062e-07, "avg_score": 0.06262297928333282, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4156800592972152, "std_of_first_answer": 0.4156800592972152, "avg_entropy_of_first_answer": 2.027785164969308, "lex_sim": 1.0}
{"question": "who has the most catches in nfl history", "answer": ["Jerry Rice ONE Championship signs multi-year media rights deal with OSN and FOX Sports"], "scores": [[0.99462890625, 0.99951171875, 1.0, 0.0, 0.61669921875, 0.000995635986328125, 4.410743713378906e-06, 0.056671142578125, 0.9853515625, 0.95361328125, 0.01611328125, 0.76416015625, 0.82177734375, 0.984375, 0.045867919921875, 0.99267578125, 0.0144500732421875, 0.22705078125, 1.0, 0.56396484375]], "normalized_score": [0.0], "tokens": [["\u2581Jerry", "\u2581R", "ice", "\u2581ON", "E", "\u2581Championship", "\u2581signs", "\u2581multi", "-", "year", "\u2581media", "\u2581rights", "\u2581deal", "\u2581with", "\u2581OS", "N", "\u2581and", "\u2581FO", "X", "\u2581Sports"]], "entropy": [[0.0499267578125, 0.004486083984375, 0.00011354684829711914, 0.904296875, 2.169921875, 3.044921875, 2.318359375, 4.171875, 0.10040283203125, 0.3037109375, 1.890625, 0.73828125, 0.55322265625, 0.101806640625, 3.09765625, 0.050262451171875, 2.310546875, 3.888671875, 0.0018110275268554688, 1.8291015625]], "avg_entropy": [1.3765000373125076], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Jerry Rice", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43279334818334037, "std_of_first_answer": 0.43279334818334037, "avg_entropy_of_first_answer": 1.3765000373125076, "lex_sim": 1.0}
{"question": "who has the world's largest standing army", "answer": ["China Tags: Crime, Houston, Local, Fort Bend County"], "scores": [[0.90771484375, 0.0, 0.96240234375, 4.172325134277344e-07, 0.263427734375, 5.424022674560547e-06, 0.79931640625, 0.01025390625, 0.422607421875, 0.000392913818359375, 0.96728515625, 1.0, 0.66943359375]], "normalized_score": [0.0], "tokens": [["\u2581China", "\u2581Tags", ":", "\u2581Crime", ",", "\u2581Houston", ",", "\u2581Local", ",", "\u2581Fort", "\u2581B", "end", "\u2581County"]], "entropy": [[0.453369140625, 0.80029296875, 0.274658203125, 3.974609375, 2.326171875, 4.921875, 1.09765625, 4.09375, 1.923828125, 2.775390625, 0.239990234375, 0.0007677078247070312, 1.0380859375]], "avg_entropy": [1.8400342647845929], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "China", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.415941615745901, "std_of_first_answer": 0.415941615745901, "avg_entropy_of_first_answer": 1.8400342647845929, "lex_sim": 1.0}
{"question": "what is the name of governor of maharashtra", "answer": ["Uddhav Thackeray (as of February 2023) produced from scanned images of public domain material at Google Books.)"], "scores": [[0.8486328125, 0.994140625, 0.99951171875, 0.990234375, 0.9970703125, 1.0, 0.0982666015625, 0.89404296875, 0.998046875, 0.0092315673828125, 0.99169921875, 0.98583984375, 0.998046875, 1.0, 0.53369140625, 0.9521484375, 0.0, 0.01145172119140625, 0.0012063980102539062, 0.00037026405334472656, 0.002201080322265625, 0.425537109375, 0.0019817352294921875, 0.055572509765625, 0.10394287109375, 0.00018167495727539062, 0.059112548828125, 0.425048828125, 0.0009713172912597656]], "normalized_score": [0.0], "tokens": [["\u2581U", "dd", "hav", "\u2581Th", "acker", "ay", "\u2581(", "as", "\u2581of", "\u2581February", "\u2581", "2", "0", "2", "3", ")", "\u2581produced", "\u2581from", "\u2581sc", "anned", "\u2581images", "\u2581of", "\u2581public", "\u2581domain", "\u2581material", "\u2581at", "\u2581Google", "\u2581Books", ".)"]], "entropy": [[0.62255859375, 0.03680419921875, 0.0032367706298828125, 0.082763671875, 0.0215911865234375, 0.00016498565673828125, 0.76904296875, 0.59814453125, 0.018646240234375, 1.0302734375, 0.049163818359375, 0.0762939453125, 0.0173797607421875, 0.0013437271118164062, 1.0107421875, 0.2347412109375, 0.314208984375, 0.939453125, 4.984375, 0.4208984375, 4.4765625, 2.18359375, 3.04296875, 1.9599609375, 2.0078125, 0.5849609375, 3.83984375, 1.2265625, 2.1015625]], "avg_entropy": [1.1260570657664333], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Chennamaneni Vidyasagar Rao", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4503188361337913, "std_of_first_answer": 0.4503188361337913, "avg_entropy_of_first_answer": 1.1260570657664333, "lex_sim": 1.0}
{"question": "first day collection of mission china assamese film", "answer": ["I'm sorry, I don't have information on the first day collection of a specific Assamese film called \"Mission China\"."], "scores": [[0.6494140625, 0.69580078125, 0.99951171875, 0.99609375, 0.98876953125, 0.857421875, 0.501953125, 0.998046875, 1.0, 0.98046875, 0.311279296875, 0.69384765625, 0.681640625, 0.9462890625, 0.98828125, 0.97021484375, 0.97607421875, 0.52392578125, 0.93017578125, 0.175048828125, 0.9892578125, 1.0, 0.96337890625, 0.2061767578125, 0.875, 0.99658203125, 1.0, 0.99853515625, 0.4482421875, 5.960464477539062e-07, 0.00016546249389648438, 0.990234375, 0.033447265625, 0.9990234375, 0.9970703125, 0.0802001953125, 0.0298919677734375, 0.389892578125, 0.89306640625, 0.0001399517059326172, 0.9990234375, 0.60107421875, 0.88916015625, 0.99951171875, 0.98876953125, 0.82373046875, 0.1021728515625, 0.99365234375]], "normalized_score": [0.32279109954833984], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581I", "\u2581don", "'", "t", "\u2581have", "\u2581information", "\u2581on", "\u2581the", "\u2581first", "\u2581day", "\u2581collection", "\u2581of", "\u2581a", "\u2581specific", "\u2581Ass", "am", "ese", "\u2581film", "\u2581called", "\u2581\"", "M", "ission", "\u2581China", "\".", "\u2581#", "Throw", "back", "Th", "urs", "day", ":", "\u2581I", "'", "m", "\u2581Re", "ady", "\u2581for", "\u2581My", "\u2581Close", "-", "Up", ",", "\u2581Mr"]], "entropy": [[1.78125, 1.00390625, 0.0033016204833984375, 0.0311279296875, 0.0665283203125, 0.52685546875, 1.0205078125, 0.01448822021484375, 0.0006618499755859375, 0.10076904296875, 1.4326171875, 0.6611328125, 0.875, 0.308837890625, 0.06988525390625, 0.1669921875, 0.1162109375, 1.255859375, 0.332763671875, 1.05078125, 0.060699462890625, 0.0009188652038574219, 0.17919921875, 1.689453125, 0.42041015625, 0.0248870849609375, 0.00102996826171875, 0.01378631591796875, 1.0107421875, 2.146484375, 5.1953125, 0.07708740234375, 3.15234375, 0.009185791015625, 0.02606201171875, 2.92578125, 3.888671875, 2.634765625, 0.450439453125, 3.140625, 0.0099334716796875, 1.322265625, 0.5380859375, 0.0028285980224609375, 0.07098388671875, 0.4697265625, 2.03125, 0.060699462890625]], "avg_entropy": [0.8827736675739288], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "\u20b9 39.97 lakh", "score_of_biggest_cluster": 0.32279109954833984, "score_of_first_answer": 0.32279109954833984, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539062e-07, "avg_score": 0.32279109954833984, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3576528191926428, "std_of_first_answer": 0.3576528191926428, "avg_entropy_of_first_answer": 0.8827736675739288, "lex_sim": 1.0}
{"question": "when do we find out luke and leia are siblings", "answer": ["Return of the Jedi #MondayMusings: Taking Stock Of MK Dons' Current Form"], "scores": [[0.016357421875, 1.0, 1.0, 0.9990234375, 1.0, 6.556510925292969e-07, 0.0008339881896972656, 0.0009756088256835938, 0.990234375, 0.00246429443359375, 0.97900390625, 0.00023496150970458984, 0.003871917724609375, 0.0260009765625, 0.08685302734375, 0.025421142578125, 0.001132965087890625, 0.0009822845458984375, 0.00022411346435546875, 0.77685546875, 0.388916015625, 0.049560546875, 0.11517333984375]], "normalized_score": [0.019498666748404503], "tokens": [["\u2581Return", "\u2581of", "\u2581the", "\u2581J", "edi", "\u2581#", "M", "ond", "ay", "Mus", "ings", ":", "\u2581T", "aking", "\u2581Stock", "\u2581Of", "\u2581M", "K", "\u2581D", "ons", "'", "\u2581Current", "\u2581Form"]], "entropy": [[1.0888671875, 0.002185821533203125, 0.002044677734375, 0.009307861328125, 0.0002727508544921875, 1.240234375, 3.6640625, 2.71875, 0.099365234375, 1.3876953125, 0.1209716796875, 1.5322265625, 4.35546875, 2.015625, 3.14453125, 1.421875, 2.9296875, 1.3564453125, 2.484375, 1.6484375, 3.359375, 4.16796875, 2.615234375]], "avg_entropy": [1.7984785826309868], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Return of the Jedi", "score_of_biggest_cluster": 0.019498666748404503, "score_of_first_answer": 0.019498666748404503, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 6.556510925292969e-07, "avg_score": 0.019498666748404503, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43210263245985164, "std_of_first_answer": 0.43210263245985164, "avg_entropy_of_first_answer": 1.7984785826309868, "lex_sim": 1.0}
{"question": "who are the dallas cowboys playing on thanksgiving", "answer": ["The Dallas Cowboys will play against the Buffalo Bills on Thanksgiving this year."], "scores": [[0.28857421875, 0.884765625, 0.99951171875, 0.99951171875, 1.0, 0.255126953125, 0.59814453125, 0.434326171875, 0.99853515625, 0.9287109375, 1.0, 1.0, 1.0, 0.990234375, 0.99462890625, 1.0, 1.0, 0.1434326171875, 1.0, 0.80517578125, 6.973743438720703e-06, 0.00032448768615722656, 0.00010317564010620117, 0.00013494491577148438, 0.0041351318359375, 0.06396484375, 0.26953125, 0.8369140625, 0.143310546875, 0.0022602081298828125, 0.25537109375, 0.1658935546875, 0.98779296875, 0.859375, 0.146728515625, 1.2040138244628906e-05, 0.082763671875, 0.033966064453125, 0.006847381591796875, 0.98046875, 0.99072265625, 0.00013172626495361328, 0.039031982421875, 1.0, 0.99755859375, 0.179931640625, 0.148681640625, 0.468017578125]], "normalized_score": [0.10963843762874603], "tokens": [["\u2581The", "\u2581Dallas", "\u2581Cow", "bo", "ys", "\u2581will", "\u2581play", "\u2581against", "\u2581the", "\u2581Buff", "alo", "\u2581B", "ills", "\u2581on", "\u2581Thanks", "g", "iving", "\u2581this", "\u2581year", ".", "\u2581#", "1", "\u2581|", "\u2581RE", ":", "\u2581", "2", "0", "1", "5", "-", "2", "0", "1", "6", "\u2581Sat", "ellite", "\u2581League", "\u2581Reg", "ular", "\u2581Season", "\u2581Mon", "\u2581A", "pr", "\u2581", "0", "6", ","]], "entropy": [[2.82421875, 0.51611328125, 0.002593994140625, 0.005146026611328125, 2.6881694793701172e-05, 1.2138671875, 0.7353515625, 1.169921875, 0.01605224609375, 0.41357421875, 2.6941299438476562e-05, 0.0006699562072753906, 0.00041103363037109375, 0.0770263671875, 0.038665771484375, 0.0004513263702392578, 0.0002105236053466797, 0.8427734375, 0.0023956298828125, 0.64208984375, 0.65234375, 1.7880859375, 3.234375, 3.21875, 2.638671875, 5.125, 2.533203125, 1.02734375, 0.626953125, 0.314208984375, 3.390625, 1.11328125, 0.09918212890625, 0.5302734375, 0.83203125, 3.416015625, 2.416015625, 4.71484375, 3.681640625, 0.1458740234375, 0.0859375, 3.41015625, 2.193359375, 0.001590728759765625, 0.0232086181640625, 1.513671875, 1.0947265625, 0.80712890625]], "avg_entropy": [1.2318767694135506], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Los Angeles Chargers", "score_of_biggest_cluster": 0.10963843762874603, "score_of_first_answer": 0.10963843762874603, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 6.973743438720703e-06, "avg_score": 0.10963843762874603, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42857337553340363, "std_of_first_answer": 0.42857337553340363, "avg_entropy_of_first_answer": 1.2318767694135506, "lex_sim": 1.0}
{"question": "when was the last year thanksgiving was on the 23rd", "answer": ["1939 #MeToo reaches Bollywood with Tanushree Dutta\u2019s allegations against Nana Patekar"], "scores": [[0.904296875, 0.6923828125, 0.98193359375, 0.4658203125, 0.9736328125, 4.172325134277344e-07, 2.753734588623047e-05, 0.2135009765625, 0.99951171875, 1.1324882507324219e-06, 1.3768672943115234e-05, 0.9990234375, 0.06640625, 0.28564453125, 1.0, 0.99951171875, 0.990234375, 1.0, 0.99951171875, 0.19482421875, 1.0, 0.44287109375, 0.9736328125, 0.69140625, 0.990234375, 1.0, 0.9794921875, 0.9970703125, 0.99658203125]], "normalized_score": [0.1273878961801529], "tokens": [["\u2581", "1", "9", "3", "9", "\u2581#", "Me", "To", "o", "\u2581reaches", "\u2581Bol", "lywood", "\u2581with", "\u2581Tan", "ush", "ree", "\u2581D", "ut", "ta", "\u2019", "s", "\u2581alleg", "ations", "\u2581against", "\u2581N", "ana", "\u2581P", "ate", "kar"]], "entropy": [[0.58984375, 0.6171875, 0.09326171875, 1.19140625, 0.1485595703125, 1.01171875, 5.609375, 3.015625, 0.00415802001953125, 2.404296875, 3.181640625, 0.00691986083984375, 2.630859375, 3.6796875, 0.0013637542724609375, 0.00485992431640625, 0.088134765625, 0.0018949508666992188, 0.005100250244140625, 2.7421875, 0.002349853515625, 2.45703125, 0.1243896484375, 1.2548828125, 0.081298828125, 0.0010843276977539062, 0.1297607421875, 0.0255889892578125, 0.027130126953125]], "avg_entropy": [1.0735033627214103], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2017", "score_of_biggest_cluster": 0.1273878961801529, "score_of_first_answer": 0.1273878961801529, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.1273878961801529, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39614429063184514, "std_of_first_answer": 0.39614429063184514, "avg_entropy_of_first_answer": 1.0735033627214103, "lex_sim": 1.0}
{"question": "the secret of crickley hall how many episodes", "answer": ["three Chapter 27 is not a movie to be taken lightly."], "scores": [[0.007274627685546875, 0.0, 0.03509521484375, 0.1497802734375, 0.0260467529296875, 0.01751708984375, 0.1688232421875, 0.6015625, 0.1741943359375, 0.0002524852752685547, 0.11578369140625, 0.140869140625, 0.908203125, 0.99853515625, 0.45068359375, 0.00318145751953125, 0.75830078125, 0.0214996337890625, 0.2286376953125, 0.1708984375, 0.71435546875, 0.609375, 0.1966552734375, 0.97900390625, 0.22119140625, 0.443359375, 0.97900390625, 0.92626953125, 0.4765625, 0.1710205078125, 0.93310546875, 0.33984375, 0.99072265625, 0.9990234375, 0.79931640625, 0.97509765625, 0.98779296875, 0.9677734375, 0.0128326416015625, 0.86767578125, 0.11322021484375, 0.53955078125, 0.71240234375, 0.990234375, 0.81787109375, 0.05316162109375, 0.6064453125, 0.95263671875]], "normalized_score": [0.0], "tokens": [["\u2581three", "\u2581Chapter", "\u2581", "2", "7", "\u2581is", "\u2581not", "\u2581a", "\u2581movie", "\u2581to", "\u2581be", "\u2581taken", "\u2581light", "ly", ".", "\u2581If", "\u2581you", "\u2581liked", "\u2581the", "\u2581book", ",", "\u2581you", "'", "ll", "\u2581probably", "\u2581like", "\u2581the", "\u2581movie", ".", "\u2581If", "\u2581you", "\u2581didn", "'", "t", "\u2581like", "\u2581the", "\u2581book", ",", "\u2581this", "\u2581movie", "\u2581will", "\u2581not", "\u2581change", "\u2581your", "\u2581mind", "\u2581about", "\u2581it", "."]], "entropy": [[0.284912109375, 0.77099609375, 2.28125, 1.666015625, 3.3984375, 3.55078125, 2.58984375, 2.140625, 3.650390625, 2.7421875, 4.203125, 3.724609375, 0.487548828125, 0.01422119140625, 2.33984375, 2.134765625, 1.4228515625, 2.818359375, 3.271484375, 4.02734375, 1.4052734375, 2.171875, 2.03125, 0.12103271484375, 2.359375, 1.6123046875, 0.149169921875, 0.332763671875, 1.5361328125, 2.951171875, 0.349609375, 2.244140625, 0.0797119140625, 0.0098419189453125, 0.73828125, 0.1566162109375, 0.08673095703125, 0.2440185546875, 1.5, 0.7578125, 2.0390625, 1.8916015625, 1.3603515625, 0.071044921875, 0.62548828125, 0.4560546875, 1.33984375, 0.34375]], "avg_entropy": [1.5934146245320637], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "3", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.38068503853162167, "std_of_first_answer": 0.38068503853162167, "avg_entropy_of_first_answer": 1.5934146245320637, "lex_sim": 1.0}
{"question": "1. what was the precursor to the present day internet", "answer": ["ARPANET"], "scores": [[0.919921875, 0.99609375, 0.99951171875, 0.9921875]], "normalized_score": [0.976356029510498], "tokens": [["\u2581AR", "P", "AN", "ET"]], "entropy": [[0.416015625, 0.0252685546875, 0.004199981689453125, 0.045318603515625]], "avg_entropy": [0.12270069122314453], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the ARPANET project", "score_of_biggest_cluster": 0.976356029510498, "score_of_first_answer": 0.976356029510498, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.919921875, "avg_score": 0.976356029510498, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.03301477302430496, "std_of_first_answer": 0.03301477302430496, "avg_entropy_of_first_answer": 0.12270069122314453, "lex_sim": 1.0}
{"question": "when was the last time university of michigan won a national championship", "answer": ["2018-19 in Men's Gymnastics"], "scores": [[0.57568359375, 0.2305908203125, 0.99951171875, 0.99755859375, 0.78271484375, 0.14111328125, 0.10009765625, 0.99560546875, 0.0308380126953125, 0.328125, 0.99755859375, 1.0, 0.33984375, 0.74267578125, 1.0, 1.0]], "normalized_score": [0.4577186107635498], "tokens": [["\u2581", "2", "0", "1", "8", "-", "1", "9", "\u2581in", "\u2581Men", "'", "s", "\u2581G", "ymn", "ast", "ics"]], "entropy": [[1.80078125, 0.55322265625, 0.00510406494140625, 0.018310546875, 0.73095703125, 2.138671875, 0.61279296875, 0.03240966796875, 2.33984375, 1.5166015625, 0.016937255859375, 7.271766662597656e-06, 1.4833984375, 0.5751953125, 0.002033233642578125, 0.000850677490234375]], "avg_entropy": [0.7391948476433754], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1997", "score_of_biggest_cluster": 0.4577186107635498, "score_of_first_answer": 0.4577186107635498, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0308380126953125, "avg_score": 0.4577186107635498, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3709492160082352, "std_of_first_answer": 0.3709492160082352, "avg_entropy_of_first_answer": 0.7391948476433754, "lex_sim": 1.0}
{"question": "where is cinque terre italy on a map", "answer": ["N/A (request requires a map) #ThrowbackThursday: 2Pac, \"Dear Mama\""], "scores": [[0.0709228515625, 0.17236328125, 1.0, 0.145751953125, 0.001346588134765625, 0.1253662109375, 0.395751953125, 0.7392578125, 0.471435546875, 1.9669532775878906e-06, 0.0001360177993774414, 0.96875, 0.0294647216796875, 0.9970703125, 0.99755859375, 0.01071929931640625, 0.05548095703125, 0.0758056640625, 1.0728836059570312e-05, 0.98876953125, 0.2027587890625, 0.078857421875, 0.82470703125, 1.0, 1.0, 0.99853515625, 0.84619140625]], "normalized_score": [0.0789269506931305], "tokens": [["\u2581N", "/", "A", "\u2581(", "request", "\u2581requires", "\u2581a", "\u2581map", ")", "\u2581#", "Throw", "back", "Th", "urs", "day", ":", "\u2581", "2", "P", "ac", ",", "\u2581\"", "D", "ear", "\u2581M", "ama", "\""]], "entropy": [[3.064453125, 1.109375, 0.0018815994262695312, 1.205078125, 2.599609375, 2.130859375, 2.28515625, 1.072265625, 1.3076171875, 0.16796875, 6.171875, 0.23095703125, 3.048828125, 0.024810791015625, 0.0221405029296875, 1.5673828125, 4.12890625, 1.646484375, 0.60107421875, 0.07525634765625, 3.728515625, 4.05078125, 0.8447265625, 0.0021800994873046875, 0.0019254684448242188, 0.01364898681640625, 0.64892578125]], "avg_entropy": [1.5463956903528284], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Liguria, Italy", "score_of_biggest_cluster": 0.0789269506931305, "score_of_first_answer": 0.0789269506931305, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.9669532775878906e-06, "avg_score": 0.0789269506931305, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42352076752933865, "std_of_first_answer": 0.42352076752933865, "avg_entropy_of_first_answer": 1.5463956903528284, "lex_sim": 1.0}
{"question": "who was the winner of the first indianapolis 500", "answer": ["Ray Harroun"], "scores": [[0.99951171875, 0.9990234375, 1.0]], "normalized_score": [0.9995116591453552], "tokens": [["\u2581Ray", "\u2581Harr", "oun"]], "entropy": [[0.0036907196044921875, 0.00905609130859375, 4.172325134277344e-06]], "avg_entropy": [0.004250327746073405], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ray Harroun", "score_of_biggest_cluster": 0.9995116591453552, "score_of_first_answer": 0.9995116591453552, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.9990234375, "avg_score": 0.9995116591453552, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.00039867997115611623, "std_of_first_answer": 0.00039867997115611623, "avg_entropy_of_first_answer": 0.004250327746073405, "lex_sim": 1.0}
{"question": "where is the tablet of the ten commandments", "answer": ["Mount Sinai, Caucasus mountains, according to the Old Testament of the Bible #Bonas faculty, staff members participate in panel discussions during national diversity, inclusion conference"], "scores": [[0.406005859375, 0.99951171875, 0.9990234375, 1.0, 0.1129150390625, 0.00029730796813964844, 5.120038986206055e-05, 0.99951171875, 0.9951171875, 0.132568359375, 0.27587890625, 0.055694580078125, 1.0, 0.80029296875, 0.12127685546875, 0.99658203125, 0.2220458984375, 0.99853515625, 0.75146484375, 1.1920928955078125e-07, 0.015625, 5.364418029785156e-07, 8.344650268554688e-07, 0.80224609375, 0.03778076171875, 0.421630859375, 0.0020580291748046875, 0.0035037994384765625, 0.90771484375, 0.97216796875, 0.00968170166015625, 0.1884765625, 0.99365234375, 0.00991058349609375, 0.00013327598571777344, 0.0009703636169433594, 0.9990234375, 0.01103973388671875, 0.322509765625, 0.2249755859375]], "normalized_score": [0.03858715295791626], "tokens": [["\u2581Mount", "\u2581S", "ina", "i", ",", "\u2581C", "au", "cas", "us", "\u2581mountains", ",", "\u2581according", "\u2581to", "\u2581the", "\u2581Old", "\u2581Testament", "\u2581of", "\u2581the", "\u2581Bible", "\u2581#", "B", "onas", "\u2581fac", "ulty", ",", "\u2581staff", "\u2581members", "\u2581particip", "ate", "\u2581in", "\u2581panel", "\u2581discuss", "ions", "\u2581during", "\u2581national", "\u2581divers", "ity", ",", "\u2581inclusion", "\u2581conference"]], "entropy": [[1.78515625, 0.004764556884765625, 0.00754547119140625, 0.00011628866195678711, 1.2880859375, 1.2392578125, 1.10546875, 0.00528717041015625, 0.03228759765625, 1.3662109375, 1.880859375, 3.14453125, 0.0023441314697265625, 0.91357421875, 1.953125, 0.0250244140625, 1.7294921875, 0.0146484375, 0.7822265625, 0.79736328125, 4.68359375, 0.55615234375, 2.203125, 1.1181640625, 4.82421875, 3.08984375, 1.484375, 4.3984375, 0.3388671875, 0.239990234375, 5.13671875, 0.9736328125, 0.048583984375, 2.501953125, 4.06640625, 4.8828125, 0.00882720947265625, 1.783203125, 2.080078125, 2.806640625]], "avg_entropy": [1.6325748428702354], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ark of the Covenant", "score_of_biggest_cluster": 0.03858715295791626, "score_of_first_answer": 0.03858715295791626, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.03858715295791626, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.425459586415472, "std_of_first_answer": 0.425459586415472, "avg_entropy_of_first_answer": 1.6325748428702354, "lex_sim": 1.0}
{"question": "how many players have scored 10000 runs in odi", "answer": ["Sachin Tendulkar, Sourav Ganguly, Rahul Dravid, Sanath Jayasuriya, Kumar Sangakkara, Mahela Jayawardene, Ricky Ponting, Jacques Kallis, and"], "scores": [[0.60693359375, 1.0, 0.9970703125, 1.0, 1.0, 1.0, 0.56884765625, 0.453857421875, 1.0, 0.99951171875, 1.0, 0.88916015625, 0.96533203125, 1.0, 1.0, 1.0, 1.0, 0.8759765625, 0.06683349609375, 0.998046875, 1.0, 1.0, 0.98828125, 1.0, 0.87548828125, 0.63232421875, 0.9794921875, 1.0, 1.0, 1.0, 1.0, 0.80615234375, 0.5029296875, 0.9775390625, 0.99072265625, 1.0, 1.0, 0.9677734375, 0.7392578125, 0.87890625, 0.99853515625, 1.0, 1.0, 0.8525390625, 0.7998046875, 1.0, 1.0, 1.0, 0.794921875, 0.703125]], "normalized_score": [0.8549044132232666], "tokens": [["\u2581Sach", "in", "\u2581T", "end", "ul", "kar", ",", "\u2581Sou", "rav", "\u2581Gang", "uly", ",", "\u2581Rah", "ul", "\u2581D", "rav", "id", ",", "\u2581San", "ath", "\u2581Jay", "as", "uri", "ya", ",", "\u2581K", "umar", "\u2581Sang", "ak", "k", "ara", ",", "\u2581Mah", "ela", "\u2581J", "aya", "ward", "ene", ",", "\u2581R", "icky", "\u2581Pont", "ing", ",", "\u2581Jacques", "\u2581K", "all", "is", ",", "\u2581and"]], "entropy": [[1.54296875, 2.1338462829589844e-05, 0.023529052734375, 0.0015401840209960938, 0.0015888214111328125, 0.0007100105285644531, 1.240234375, 1.7294921875, 0.0022640228271484375, 0.0027923583984375, 0.002017974853515625, 0.39697265625, 0.2095947265625, 0.00017559528350830078, 0.0024814605712890625, 0.00021338462829589844, 4.547834396362305e-05, 0.49658203125, 1.908203125, 0.0189971923828125, 0.0016727447509765625, 0.0013456344604492188, 0.0777587890625, 0.00016045570373535156, 0.47216796875, 1.490234375, 0.10137939453125, 0.0009474754333496094, 0.0004291534423828125, 5.78761100769043e-05, 8.13603401184082e-05, 0.6591796875, 1.220703125, 0.10968017578125, 0.055206298828125, 0.0016613006591796875, 0.0005388259887695312, 0.148193359375, 0.9033203125, 0.650390625, 0.01009368896484375, 0.0022830963134765625, 0.00016868114471435547, 0.54736328125, 0.890625, 0.0002422332763671875, 0.00042748451232910156, 4.029273986816406e-05, 0.734375, 1.2744140625]], "avg_entropy": [0.3387113296985626], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "11", "score_of_biggest_cluster": 0.8549044132232666, "score_of_first_answer": 0.8549044132232666, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.06683349609375, "avg_score": 0.8549044132232666, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.186131863126305, "std_of_first_answer": 0.186131863126305, "avg_entropy_of_first_answer": 0.3387113296985626, "lex_sim": 1.0}
{"question": "who used morse code in world war 2", "answer": ["Many people used Morse code during World War II, including military personnel, intelligence agents, and radio operators."], "scores": [[0.297607421875, 0.57177734375, 0.81884765625, 0.9853515625, 1.0, 0.9873046875, 0.916015625, 0.98193359375, 0.99951171875, 0.96337890625, 0.91845703125, 0.97216796875, 0.58349609375, 0.9013671875, 0.5234375, 0.3798828125, 0.6318359375, 0.9990234375, 0.99951171875, 0.43359375, 0.99951171875, 0.99755859375, 0.0, 0.8896484375, 0.3017578125, 0.161865234375, 0.001033782958984375, 0.007183074951171875, 0.017608642578125, 0.1898193359375, 0.00012600421905517578, 0.00916290283203125, 0.07098388671875, 0.986328125, 0.96435546875, 0.99853515625]], "normalized_score": [0.0], "tokens": [["\u2581Many", "\u2581people", "\u2581used", "\u2581Mor", "se", "\u2581code", "\u2581during", "\u2581World", "\u2581War", "\u2581II", ",", "\u2581including", "\u2581military", "\u2581personnel", ",", "\u2581intelligence", "\u2581agents", ",", "\u2581and", "\u2581radio", "\u2581operators", ".", "\u2581Chapter", "\u2581", "1", "1", "1", "6", ":", "\u2581The", "\u2581Path", "\u2581Of", "\u2581Le", "ast", "\u2581Res", "istance"]], "entropy": [[3.125, 1.3134765625, 0.75390625, 0.08282470703125, 0.00025391578674316406, 0.0679931640625, 0.29150390625, 0.09405517578125, 0.00527191162109375, 0.1611328125, 0.403564453125, 0.160400390625, 1.39453125, 0.49267578125, 0.74072265625, 1.75390625, 0.99951171875, 0.00858306884765625, 0.00582122802734375, 1.9072265625, 0.00391387939453125, 0.0215606689453125, 1.41796875, 0.76220703125, 1.9736328125, 2.880859375, 2.45703125, 3.109375, 3.3046875, 5.2578125, 5.5703125, 2.2421875, 3.89453125, 0.11102294921875, 0.2783203125, 0.0115509033203125]], "avg_entropy": [1.3072037763065762], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "naval bases", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3922183144400941, "std_of_first_answer": 0.3922183144400941, "avg_entropy_of_first_answer": 1.3072037763065762, "lex_sim": 1.0}
{"question": "who does the voice of ash in sing", "answer": ["Animation Director, Voice Actor and Writer Carlos Alazraqui"], "scores": [[0.003131866455078125, 0.57275390625, 0.1427001953125, 0.1524658203125, 0.2056884765625, 0.99951171875, 0.33837890625, 1.0, 0.32666015625, 0.304931640625, 1.0, 0.010894775390625, 0.9580078125, 0.97998046875, 1.0, 0.9990234375]], "normalized_score": [0.2918035686016083], "tokens": [["\u2581An", "imation", "\u2581Director", ",", "\u2581Vo", "ice", "\u2581A", "ctor", "\u2581and", "\u2581W", "riter", "\u2581Carlos", "\u2581A", "laz", "ra", "qui"]], "entropy": [[2.71875, 2.30859375, 3.005859375, 2.2890625, 3.470703125, 0.00513458251953125, 1.72265625, 1.245737075805664e-05, 1.3896484375, 2.462890625, 0.000621795654296875, 2.841796875, 0.373779296875, 0.103271484375, 0.0015087127685546875, 0.00795745849609375]], "avg_entropy": [1.4188904203474522], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Scarlett Johansson", "score_of_biggest_cluster": 0.2918035686016083, "score_of_first_answer": 0.2918035686016083, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.003131866455078125, "avg_score": 0.2918035686016083, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39902988770627945, "std_of_first_answer": 0.39902988770627945, "avg_entropy_of_first_answer": 1.4188904203474522, "lex_sim": 1.0}
{"question": "when does the movie jeepers creepers come out", "answer": ["Jeepers Creepers was first released in 2001."], "scores": [[0.057586669921875, 1.0, 1.0, 0.99951171875, 1.0, 1.0, 0.14404296875, 0.007656097412109375, 0.99951171875, 0.81494140625, 0.9892578125, 1.0, 1.0, 1.0, 1.0, 0.556640625, 0.019775390625, 0.998046875, 0.83740234375, 0.73779296875, 0.9931640625, 0.5869140625, 0.6123046875, 0.9990234375, 0.229248046875, 0.3876953125, 0.99462890625, 1.0, 1.0, 1.0, 1.0, 0.99853515625, 0.99951171875, 1.0, 1.0, 0.89892578125, 0.96826171875, 0.26220703125, 0.98876953125, 0.0, 0.00012302398681640625]], "normalized_score": [0.0], "tokens": [["\u2581Je", "ep", "ers", "\u2581C", "ree", "pers", "\u2581was", "\u2581first", "\u2581released", "\u2581in", "\u2581", "2", "0", "0", "1", ".", "\u2581However", ",", "\u2581there", "\u2581have", "\u2581been", "\u2581two", "\u2581sequ", "els", "\u2581released", "\u2581in", "\u2581", "2", "0", "0", "3", "\u2581and", "\u2581", "2", "0", "1", "7", "\u2581respectively", ".", "\u2581##", "Introduction"]], "entropy": [[2.345703125, 0.001125335693359375, 1.0728836059570312e-06, 0.0037899017333984375, 0.0003247261047363281, 0.0018243789672851562, 1.6142578125, 0.08587646484375, 0.002910614013671875, 0.48193359375, 0.06719970703125, 0.0005211830139160156, 0.00010401010513305664, 0.0003681182861328125, 0.0019817352294921875, 1.1103515625, 1.9638671875, 0.0152130126953125, 0.7392578125, 0.94189453125, 0.047088623046875, 1.3359375, 1.08984375, 0.00742340087890625, 1.490234375, 1.60546875, 0.0404052734375, 7.992982864379883e-05, 0.00027751922607421875, 0.0004673004150390625, 0.0015859603881835938, 0.01293182373046875, 0.0030002593994140625, 1.4781951904296875e-05, 3.68952751159668e-05, 0.327392578125, 0.15234375, 1.0478515625, 0.06988525390625, 0.9013671875, 6.55859375]], "avg_entropy": [0.5870911246392785], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "September 26, 2017", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3608431885025407, "std_of_first_answer": 0.3608431885025407, "avg_entropy_of_first_answer": 0.5870911246392785, "lex_sim": 1.0}
{"question": "who has been chosen as the brand ambassador of the campaign 'beti bachao-beti padhao", "answer": ["Madhuri Dixit Nene"], "scores": [[0.374267578125, 0.95166015625, 0.9501953125, 1.0, 0.99951171875, 1.0, 0.89599609375, 0.99951171875]], "normalized_score": [0.8613305687904358], "tokens": [["\u2581Mad", "h", "uri", "\u2581D", "ix", "it", "\u2581N", "ene"]], "entropy": [[2.61328125, 0.2412109375, 0.2266845703125, 0.0019969940185546875, 0.0039043426513671875, 0.00036907196044921875, 0.45703125, 0.0046844482421875]], "avg_entropy": [0.4436453580856323], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Sakshi Malik", "score_of_biggest_cluster": 0.8613305687904358, "score_of_first_answer": 0.8613305687904358, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.374267578125, "avg_score": 0.8613305687904358, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.20040584519421398, "std_of_first_answer": 0.20040584519421398, "avg_entropy_of_first_answer": 0.4436453580856323, "lex_sim": 1.0}
{"question": "what episode of pll does jenna get her sight back", "answer": ["I'm sorry, I am not aware of the exact episode of \"Pretty Little Liars\" where Jenna gets her sight back, as my knowledge cut off is 2021, and the show ended on June 20"], "scores": [[0.185546875, 0.64990234375, 1.0, 0.98583984375, 0.9873046875, 0.78857421875, 0.243896484375, 0.88037109375, 0.120361328125, 0.99853515625, 0.2366943359375, 0.034088134765625, 0.939453125, 0.6455078125, 0.29638671875, 0.97607421875, 1.0, 0.9990234375, 0.99951171875, 1.0, 0.99755859375, 0.52001953125, 0.9912109375, 1.0, 0.79833984375, 0.99951171875, 0.99951171875, 0.99951171875, 0.07159423828125, 0.8681640625, 0.826171875, 0.445556640625, 0.8515625, 0.259033203125, 0.67626953125, 0.7900390625, 1.0, 1.0, 1.0, 0.9990234375, 0.256103515625, 0.78564453125, 0.5205078125, 0.69873046875, 0.84814453125, 0.06298828125, 0.455810546875, 0.98291015625, 0.97998046875, 0.9462890625]], "normalized_score": [0.5965430736541748], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581I", "\u2581am", "\u2581not", "\u2581aware", "\u2581of", "\u2581the", "\u2581exact", "\u2581episode", "\u2581of", "\u2581\"", "Pre", "tty", "\u2581Little", "\u2581Li", "ars", "\"", "\u2581where", "\u2581Jen", "na", "\u2581gets", "\u2581her", "\u2581sight", "\u2581back", ",", "\u2581as", "\u2581my", "\u2581knowledge", "\u2581cut", "\u2581off", "\u2581is", "\u2581", "2", "0", "2", "1", ",", "\u2581and", "\u2581the", "\u2581show", "\u2581ended", "\u2581on", "\u2581June", "\u2581", "2", "0"]], "entropy": [[2.38671875, 1.1064453125, 0.0020580291748046875, 0.083251953125, 0.07525634765625, 0.72509765625, 1.697265625, 0.457275390625, 1.16015625, 0.012603759765625, 1.7333984375, 2.337890625, 0.312255859375, 1.328125, 1.44140625, 0.11993408203125, 7.665157318115234e-05, 0.007465362548828125, 0.0036067962646484375, 0.000431060791015625, 0.0217437744140625, 1.193359375, 0.06903076171875, 0.0010080337524414062, 0.9072265625, 0.0037078857421875, 0.00547027587890625, 0.004962921142578125, 0.6875, 0.666015625, 0.666015625, 0.79931640625, 0.57421875, 1.1025390625, 0.7470703125, 0.7939453125, 0.0002474784851074219, 0.0013980865478515625, 0.0018491744995117188, 0.007488250732421875, 0.9755859375, 1.14453125, 1.7138671875, 0.8447265625, 0.7275390625, 0.4052734375, 0.96533203125, 0.09979248046875, 0.099609375, 0.21142578125]], "avg_entropy": [0.6086503195762635], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "If These Dolls Could Talk", "score_of_biggest_cluster": 0.5965430736541748, "score_of_first_answer": 0.5965430736541748, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.034088134765625, "avg_score": 0.5965430736541748, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.31835405467508293, "std_of_first_answer": 0.31835405467508293, "avg_entropy_of_first_answer": 0.6086503195762635, "lex_sim": 1.0}
{"question": "when was as you like it first performed", "answer": ["1599 #100DaysofCode, Day 54-57: Final Project Ideas and Brainstorming"], "scores": [[0.84619140625, 0.9990234375, 0.994140625, 1.0, 1.0, 5.960464477539063e-08, 0.0166015625, 0.06707763671875, 0.2578125, 0.0006527900695800781, 0.884765625, 1.0, 0.1112060546875, 0.002086639404296875, 0.049407958984375, 0.97802734375, 0.11248779296875, 0.0877685546875, 0.0003314018249511719, 0.2685546875, 0.10845947265625, 0.2232666015625, 0.00414276123046875, 0.64892578125, 0.015625, 0.41943359375, 0.365478515625, 0.024444580078125, 0.998046875, 1.0, 0.99609375]], "normalized_score": [0.08300060778856277], "tokens": [["\u2581", "1", "5", "9", "9", "\u2581#", "1", "0", "0", "Day", "so", "f", "Code", ",", "\u2581Day", "\u2581", "5", "4", "-", "5", "7", ":", "\u2581Final", "\u2581Project", "\u2581Ide", "as", "\u2581and", "\u2581Bra", "inst", "orm", "ing"]], "entropy": [[0.96142578125, 0.0086517333984375, 0.039093017578125, 0.0015611648559570312, 0.002071380615234375, 0.9892578125, 6.125, 2.748046875, 3.21875, 3.115234375, 0.72705078125, 0.001190185546875, 2.388671875, 0.95849609375, 3.638671875, 0.132568359375, 2.224609375, 2.48046875, 1.3330078125, 4.5, 1.60546875, 1.9423828125, 4.94140625, 1.75390625, 3.208984375, 1.0146484375, 2.2421875, 1.3974609375, 0.0156707763671875, 0.0002818107604980469, 0.034881591796875]], "avg_entropy": [1.7339066690014255], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1603", "score_of_biggest_cluster": 0.08300060778856277, "score_of_first_answer": 0.08300060778856277, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.08300060778856277, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4227401787547875, "std_of_first_answer": 0.4227401787547875, "avg_entropy_of_first_answer": 1.7339066690014255, "lex_sim": 1.0}
{"question": "largest state in the us by land mass", "answer": ["Texas"], "scores": [[0.04730224609375]], "normalized_score": [0.04730224609375], "tokens": [["\u2581Texas"]], "entropy": [[0.2169189453125]], "avg_entropy": [0.2169189453125], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Alaska", "score_of_biggest_cluster": 0.04730224609375, "score_of_first_answer": 0.04730224609375, "max_score_of_first_answer": 0.04730224609375, "min_score_of_first_answer": 0.04730224609375, "avg_score": 0.04730224609375, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.0, "std_of_first_answer": 0.0, "avg_entropy_of_first_answer": 0.2169189453125, "lex_sim": 1.0}
{"question": "who has the most restaurants in the world", "answer": ["Subway"], "scores": [[0.86376953125, 0.99755859375]], "normalized_score": [0.9282568097114563], "tokens": [["\u2581Sub", "way"]], "entropy": [[0.533203125, 0.0177154541015625]], "avg_entropy": [0.27545928955078125], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "SUBWAY", "score_of_biggest_cluster": 0.9282568097114563, "score_of_first_answer": 0.9282568097114563, "max_score_of_first_answer": 0.99755859375, "min_score_of_first_answer": 0.86376953125, "avg_score": 0.9282568097114563, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.06689453125, "std_of_first_answer": 0.06689453125, "avg_entropy_of_first_answer": 0.27545928955078125, "lex_sim": 1.0}
{"question": "natural resources can be divided into what two categories", "answer": ["renewable resources and non-renewable resources #BlogTour #Giveaway - Twice in a Lifetime by Annabelle Meyer 3/12/19"], "scores": [[0.204833984375, 1.0, 0.3720703125, 0.98779296875, 0.99951171875, 0.79931640625, 1.0, 1.0, 1.0, 0.99951171875, 0.0, 0.0026454925537109375, 0.0003476142883300781, 0.01708984375, 0.001056671142578125, 0.111083984375, 0.0153656005859375, 0.0450439453125, 0.95263671875, 0.0032176971435546875, 9.721517562866211e-05, 0.1453857421875, 0.04302978515625, 0.99365234375, 0.93896484375, 0.99951171875, 0.99853515625, 0.60693359375, 0.0011081695556640625, 0.171875, 0.8681640625, 0.00020837783813476562, 0.006977081298828125, 0.000701904296875, 0.43408203125, 0.32470703125, 0.07470703125, 0.3359375, 0.001819610595703125, 0.5693359375]], "normalized_score": [0.0], "tokens": [["\u2581renew", "able", "\u2581resources", "\u2581and", "\u2581non", "-", "ren", "ew", "able", "\u2581resources", "\u2581#", "B", "log", "T", "our", "\u2581#", "G", "ive", "away", "\u2581-", "\u2581Tw", "ice", "\u2581in", "\u2581a", "\u2581L", "if", "etime", "\u2581by", "\u2581Ann", "abel", "le", "\u2581Meyer", "\u2581", "3", "/", "1", "2", "/", "1", "9"]], "entropy": [[0.81982421875, 0.0003123283386230469, 0.69873046875, 0.08209228515625, 0.0041656494140625, 0.51220703125, 0.0013875961303710938, 0.0006656646728515625, 0.0005397796630859375, 0.003509521484375, 1.0771484375, 5.84765625, 2.267578125, 3.5546875, 0.75244140625, 3.03515625, 5.08984375, 2.134765625, 0.2607421875, 1.8330078125, 4.484375, 2.306640625, 2.263671875, 0.051300048828125, 0.368408203125, 0.003997802734375, 0.01425933837890625, 1.84375, 2.931640625, 2.525390625, 0.75048828125, 0.1287841796875, 2.845703125, 0.548828125, 3.03125, 1.599609375, 2.6640625, 1.7509765625, 0.039459228515625, 1.416015625]], "avg_entropy": [1.4886268258094788], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Biotic", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4255444426041422, "std_of_first_answer": 0.4255444426041422, "avg_entropy_of_first_answer": 1.4886268258094788, "lex_sim": 1.0}
{"question": "who voiced mewtwo in pokemon the first movie", "answer": ["Jason Cook"], "scores": [[0.314453125, 0.0038928985595703125]], "normalized_score": [0.03498762845993042], "tokens": [["\u2581Jason", "\u2581Cook"]], "entropy": [[3.1796875, 3.615234375]], "avg_entropy": [3.3974609375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Showtaro Morikubo", "score_of_biggest_cluster": 0.03498762845993042, "score_of_first_answer": 0.03498762845993042, "max_score_of_first_answer": 0.314453125, "min_score_of_first_answer": 0.0038928985595703125, "avg_score": 0.03498762845993042, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.15528011322021484, "std_of_first_answer": 0.15528011322021484, "avg_entropy_of_first_answer": 3.3974609375, "lex_sim": 1.0}
{"question": "how long was dark side of the moon number 1", "answer": ["9 weeks"], "scores": [[0.9580078125, 0.95947265625, 0.1934814453125]], "normalized_score": [0.5623590350151062], "tokens": [["\u2581", "9", "\u2581weeks"]], "entropy": [[0.306396484375, 0.20166015625, 1.609375]], "avg_entropy": [0.705810546875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "a week", "score_of_biggest_cluster": 0.5623590350151062, "score_of_first_answer": 0.5623590350151062, "max_score_of_first_answer": 0.95947265625, "min_score_of_first_answer": 0.1934814453125, "avg_score": 0.5623590350151062, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.36074694841638805, "std_of_first_answer": 0.36074694841638805, "avg_entropy_of_first_answer": 0.705810546875, "lex_sim": 1.0}
{"question": "where does a roadrunner live in the desert", "answer": ["The roadrunner, or colloquially as the \"speedster\", native to the desert regions of the Southwestern United States and Northwestern Mexico."], "scores": [[0.41845703125, 0.59033203125, 0.99951171875, 0.0322265625, 0.174072265625, 0.448974609375, 0.01303863525390625, 1.0, 1.0, 1.0, 0.28515625, 0.91015625, 0.93212890625, 0.11065673828125, 0.35986328125, 0.322021484375, 0.002864837646484375, 0.9443359375, 0.9970703125, 0.611328125, 0.1690673828125, 0.9921875, 0.9580078125, 0.315673828125, 0.97705078125, 0.99951171875, 0.99951171875, 0.9716796875, 0.150634765625, 0.99560546875, 0.99560546875, 0.78662109375, 0.1243896484375, 0.460693359375, 0.490966796875, 0.755859375, 0.70361328125, 0.99951171875, 1.0, 1.0, 0.449951171875, 0.97412109375, 0.99853515625, 0.0477294921875, 0.138916015625, 0.379638671875, 0.2406005859375, 0.0127105712890625, 0.86083984375, 0.99951171875]], "normalized_score": [0.3982357680797577], "tokens": [["\u2581The", "\u2581road", "runner", ",", "\u2581or", "\u2581col", "lo", "qu", "ial", "ly", "\u2581as", "\u2581the", "\u2581\"", "speed", "ster", "\",", "\u2581native", "\u2581to", "\u2581the", "\u2581desert", "\u2581regions", "\u2581of", "\u2581the", "\u2581South", "western", "\u2581United", "\u2581States", "\u2581and", "\u2581North", "western", "\u2581Mexico", ".", "\u2581It", "\u2581is", "\u2581a", "\u2581ground", "-", "d", "well", "ing", "\u2581c", "uck", "oo", ",", "\u2581which", "\u2581means", "\u2581that", "\u2581its", "\u2581eggs", "\u2581are"]], "entropy": [[2.181640625, 1.2607421875, 0.00273895263671875, 0.378173828125, 1.2568359375, 2.673828125, 0.765625, 0.0007996559143066406, 0.0004992485046386719, 0.0005426406860351562, 2.041015625, 0.368408203125, 0.4853515625, 4.0390625, 1.5849609375, 0.83203125, 0.400634765625, 0.363037109375, 0.025146484375, 1.3046875, 0.92138671875, 0.0567626953125, 0.2425537109375, 0.83837890625, 0.112060546875, 0.0032215118408203125, 0.0049285888671875, 0.150146484375, 1.3984375, 0.0297088623046875, 0.02923583984375, 0.69775390625, 1.3935546875, 1.9052734375, 1.8671875, 1.16796875, 0.67333984375, 0.004367828369140625, 0.001430511474609375, 0.00142669677734375, 0.73486328125, 0.1953125, 0.01367950439453125, 1.5654296875, 3.0390625, 2.373046875, 0.736328125, 0.376708984375, 0.77783203125, 0.00788116455078125]], "avg_entropy": [0.825700626373291], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "mountainous shrubland", "score_of_biggest_cluster": 0.3982357680797577, "score_of_first_answer": 0.3982357680797577, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.002864837646484375, "avg_score": 0.3982357680797577, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3712585463002085, "std_of_first_answer": 0.3712585463002085, "avg_entropy_of_first_answer": 0.825700626373291, "lex_sim": 1.0}
{"question": "where do red ear slider turtles lay eggs", "answer": ["in the wild, red-eared sliders typically lay their eggs in muddy banks near bodies of water, such as ponds, rivers, or lakes."], "scores": [[0.4853515625, 0.7412109375, 0.9912109375, 0.9912109375, 0.92138671875, 0.91162109375, 0.97314453125, 0.63623046875, 0.99365234375, 0.79052734375, 0.71240234375, 0.93115234375, 1.0, 0.94091796875, 0.001007080078125, 0.28857421875, 0.763671875, 0.437255859375, 0.3916015625, 0.99951171875, 1.0, 0.366455078125, 0.97802734375, 1.0, 0.849609375, 1.0, 0.327392578125, 0.1514892578125, 0.9521484375, 0.429443359375, 0.95654296875, 1.0, 0.947265625, 1.1920928955078125e-07, 0.0015058517456054688, 6.556510925292969e-06, 0.0003082752227783203, 0.2880859375]], "normalized_score": [0.19833862781524658], "tokens": [["\u2581in", "\u2581the", "\u2581wild", ",", "\u2581red", "-", "eared", "\u2581sl", "iders", "\u2581typically", "\u2581lay", "\u2581their", "\u2581eggs", "\u2581in", "\u2581mud", "dy", "\u2581banks", "\u2581near", "\u2581bodies", "\u2581of", "\u2581water", ",", "\u2581such", "\u2581as", "\u2581p", "onds", ",", "\u2581rivers", ",", "\u2581or", "\u2581la", "kes", ".", "\u2581#", "M", "eter", "Ma", "ids"]], "entropy": [[1.662109375, 1.2587890625, 0.07293701171875, 0.0625, 0.37646484375, 0.30517578125, 0.1260986328125, 0.69091796875, 0.038177490234375, 0.89453125, 0.8486328125, 0.253173828125, 0.0008397102355957031, 0.2283935546875, 2.5546875, 1.396484375, 1.0361328125, 1.3916015625, 1.564453125, 0.003177642822265625, 0.0023670196533203125, 1.4453125, 0.161865234375, 0.0014133453369140625, 0.541015625, 3.0159950256347656e-05, 0.81787109375, 0.7626953125, 0.22802734375, 0.69482421875, 0.2330322265625, 6.020069122314453e-06, 0.257568359375, 1.2197265625, 3.962890625, 4.5078125, 0.873046875, 0.67138671875]], "avg_entropy": [0.8196360547291605], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "a hole", "score_of_biggest_cluster": 0.19833862781524658, "score_of_first_answer": 0.19833862781524658, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.19833862781524658, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3608408270933749, "std_of_first_answer": 0.3608408270933749, "avg_entropy_of_first_answer": 0.8196360547291605, "lex_sim": 1.0}
{"question": "what kind of plate boundary is nepal on", "answer": ["convergent boundary CHAPTER TWELVE"], "scores": [[0.58056640625, 1.0, 0.2322998046875, 0.0, 0.0117645263671875, 0.10693359375, 0.0689697265625, 1.0]], "normalized_score": [0.0], "tokens": [["\u2581conver", "gent", "\u2581boundary", "\u2581CHAPTER", "\u2581T", "W", "EL", "VE"]], "entropy": [[1.142578125, 0.0004057884216308594, 1.1171875, 0.93017578125, 1.82421875, 0.79541015625, 0.365234375, 0.00014710426330566406]], "avg_entropy": [0.7719196975231171], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "orogenic belt", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4003045704825652, "std_of_first_answer": 0.4003045704825652, "avg_entropy_of_first_answer": 0.7719196975231171, "lex_sim": 1.0}
{"question": "what kind of metric system does the us use", "answer": ["The United States uses the International System of Units (SI) as its primary system of measurement."], "scores": [[0.90234375, 0.8486328125, 0.99951171875, 0.89697265625, 0.9990234375, 0.06304931640625, 0.99951171875, 0.99951171875, 0.99951171875, 0.98583984375, 0.99951171875, 0.73095703125, 0.2125244140625, 0.97412109375, 0.68212890625, 0.73291015625, 0.99658203125, 0.98388671875, 0.80029296875, 0.0, 0.27294921875, 1.7881393432617188e-05, 0.8388671875, 0.09759521484375, 0.95068359375, 0.33544921875, 0.9599609375, 0.62841796875, 0.99267578125, 0.6943359375, 0.99609375, 0.76123046875, 0.9970703125, 0.83056640625, 0.9970703125, 0.87646484375, 0.9970703125, 0.88330078125, 0.99755859375, 0.88671875, 0.9970703125, 0.884765625, 0.99658203125, 0.88525390625, 0.99609375, 0.89697265625, 0.99560546875, 0.90283203125]], "normalized_score": [0.0], "tokens": [["\u2581The", "\u2581United", "\u2581States", "\u2581uses", "\u2581the", "\u2581International", "\u2581System", "\u2581of", "\u2581Units", "\u2581(", "SI", ")", "\u2581as", "\u2581its", "\u2581primary", "\u2581system", "\u2581of", "\u2581measurement", ".", "\u2581#####", "#", "\u2581#####", "#", "\u2581#####", "#", "\u2581#####", "#", "\u2581#####", "#", "\u2581#####", "#", "\u2581#####", "#", "\u2581#####", "#", "\u2581#####", "#", "\u2581#####", "#", "\u2581#####", "#", "\u2581#####", "#", "\u2581#####", "#", "\u2581#####", "#", "\u2581#####"]], "entropy": [[0.552734375, 0.59716796875, 0.0025615692138671875, 0.513671875, 0.00864410400390625, 2.240234375, 0.00688934326171875, 0.00518035888671875, 0.005558013916015625, 0.08203125, 0.005893707275390625, 0.77001953125, 1.869140625, 0.142578125, 1.0546875, 0.65966796875, 0.0246429443359375, 0.10968017578125, 0.626953125, 1.3740234375, 1.931640625, 1.1298828125, 0.68115234375, 2.134765625, 0.2364501953125, 1.51953125, 0.20751953125, 1.232421875, 0.052581787109375, 1.06640625, 0.0293121337890625, 0.8984375, 0.02154541015625, 0.7138671875, 0.0245513916015625, 0.56640625, 0.02178955078125, 0.53662109375, 0.0197601318359375, 0.5185546875, 0.02081298828125, 0.5224609375, 0.0246124267578125, 0.52587890625, 0.0290069580078125, 0.48974609375, 0.03125, 0.47216796875]], "avg_entropy": [0.5481477975845337], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "international units", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.29259493991086627, "std_of_first_answer": 0.29259493991086627, "avg_entropy_of_first_answer": 0.5481477975845337, "lex_sim": 1.0}
{"question": "how many inches is the iphone 5s screen", "answer": ["4 inches"], "scores": [[0.84912109375, 0.998046875, 0.98095703125]], "normalized_score": [0.9402792453765869], "tokens": [["\u2581", "4", "\u2581inches"]], "entropy": [[0.58642578125, 0.0167236328125, 0.1263427734375]], "avg_entropy": [0.2431640625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "4\u00a0in", "score_of_biggest_cluster": 0.9402792453765869, "score_of_first_answer": 0.9402792453765869, "max_score_of_first_answer": 0.998046875, "min_score_of_first_answer": 0.84912109375, "avg_score": 0.9402792453765869, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.06654293976809776, "std_of_first_answer": 0.06654293976809776, "avg_entropy_of_first_answer": 0.2431640625, "lex_sim": 1.0}
{"question": "where is geothermal energy used the most in the us", "answer": ["California #BookReview #RenegadeSoul by @TheKymGrosso #ParanormalRomance"], "scores": [[0.7578125, 5.364418029785156e-07, 8.344650268554688e-07, 0.0062255859375, 0.392822265625, 0.2364501953125, 0.0121917724609375, 0.03466796875, 0.061309814453125, 0.75146484375, 0.08978271484375, 0.042694091796875, 0.00798797607421875, 0.169189453125, 0.0185089111328125, 0.12060546875, 0.009918212890625, 0.06365966796875, 0.73681640625, 0.9501953125, 0.328125, 0.55224609375, 0.9873046875, 1.0, 0.90966796875, 0.99951171875, 0.99853515625]], "normalized_score": [0.06256680935621262], "tokens": [["\u2581California", "\u2581#", "Book", "Re", "view", "\u2581#", "R", "en", "eg", "ade", "S", "oul", "\u2581by", "\u2581@", "The", "K", "ym", "G", "ros", "so", "\u2581#", "Par", "an", "ormal", "R", "om", "ance"]], "entropy": [[0.84130859375, 1.40234375, 2.328125, 2.7734375, 0.734375, 2.130859375, 4.625, 3.02734375, 1.7724609375, 0.568359375, 3.5859375, 1.552734375, 1.4228515625, 2.51171875, 5.28125, 4.48046875, 4.4375, 2.05078125, 1.0654296875, 0.28662109375, 2.373046875, 1.9970703125, 0.08587646484375, 0.002117156982421875, 0.392333984375, 0.0044403076171875, 0.011016845703125]], "avg_entropy": [1.9164743776674624], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "California", "score_of_biggest_cluster": 0.06256680935621262, "score_of_first_answer": 0.06256680935621262, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.364418029785156e-07, "avg_score": 0.06256680935621262, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.3937880716691354, "std_of_first_answer": 0.3937880716691354, "avg_entropy_of_first_answer": 1.9164743776674624, "lex_sim": 1.0}
{"question": "where was when we first met netflix filmed", "answer": ["Newport Beach, California"], "scores": [[0.289794921875, 0.01493072509765625, 0.5712890625, 0.97705078125, 0.91552734375]], "normalized_score": [0.29439008235931396], "tokens": [["\u2581New", "port", "\u2581Beach", ",", "\u2581California"]], "entropy": [[3.587890625, 0.27294921875, 0.71728515625, 0.13720703125, 0.317626953125]], "avg_entropy": [1.006591796875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "New Orleans", "score_of_biggest_cluster": 0.29439008235931396, "score_of_first_answer": 0.29439008235931396, "max_score_of_first_answer": 0.97705078125, "min_score_of_first_answer": 0.01493072509765625, "avg_score": 0.29439008235931396, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.36616185107274807, "std_of_first_answer": 0.36616185107274807, "avg_entropy_of_first_answer": 1.006591796875, "lex_sim": 1.0}
{"question": "ray charles hit the road jack album name", "answer": ["Yes, indeed!"], "scores": [[9.22083854675293e-05, 0.392822265625, 0.286865234375, 0.69921875, 0.697265625, 0.0654296875, 1.0, 0.1864013671875, 1.0, 0.98681640625, 0.94140625, 0.0496826171875, 0.9990234375, 1.0, 0.96826171875, 1.0, 0.81298828125, 0.9990234375, 0.03485107421875, 0.96240234375, 0.90966796875, 0.9892578125, 1.0, 1.0, 0.99951171875, 0.53564453125, 0.90771484375]], "normalized_score": [0.40900617837905884], "tokens": [["\u2581Yes", ",", "\u2581indeed", "!", "\u2581The", "\u2581name", "\u2581of", "\u2581Ray", "\u2581Charles", "'", "\u2581album", "\u2581\"", "H", "it", "\u2581the", "\u2581Road", "\u2581Jack", "\"", "\u2581was", "\u2581released", "\u2581in", "\u2581", "1", "9", "6", "1", "."]], "entropy": [[0.1644287109375, 1.73828125, 2.61328125, 1.0703125, 1.2392578125, 0.6083984375, 0.002437591552734375, 0.57421875, 0.0011653900146484375, 0.0843505859375, 0.294189453125, 1.763671875, 0.00787353515625, 0.0003552436828613281, 0.142822265625, 0.0006380081176757812, 0.5283203125, 0.010589599609375, 0.2188720703125, 0.263671875, 0.316162109375, 0.07977294921875, 0.0014743804931640625, 0.0001633167266845703, 0.005764007568359375, 0.759765625, 0.451171875]], "avg_entropy": [0.47931151036862973], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ray Charles Greatest Hits", "score_of_biggest_cluster": 0.40900617837905884, "score_of_first_answer": 0.40900617837905884, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 9.22083854675293e-05, "avg_score": 0.40900617837905884, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3639793384612956, "std_of_first_answer": 0.3639793384612956, "avg_entropy_of_first_answer": 0.47931151036862973, "lex_sim": 1.0}
{"question": "what is one element a topographic map shows", "answer": ["contour lines"], "scores": [[0.308837890625, 0.994140625, 0.99365234375]], "normalized_score": [0.6731899380683899], "tokens": [["\u2581cont", "our", "\u2581lines"]], "entropy": [[2.064453125, 0.03717041015625, 0.048675537109375]], "avg_entropy": [0.716766357421875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "relief", "score_of_biggest_cluster": 0.6731899380683899, "score_of_first_answer": 0.6731899380683899, "max_score_of_first_answer": 0.994140625, "min_score_of_first_answer": 0.308837890625, "avg_score": 0.6731899380683899, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.32293977962347437, "std_of_first_answer": 0.32293977962347437, "avg_entropy_of_first_answer": 0.716766357421875, "lex_sim": 1.0}
{"question": "how many cracker barrels in the united states", "answer": ["There are over 700 Cracker Barrel locations in the United States."], "scores": [[0.1544189453125, 0.97509765625, 0.80810546875, 0.99951171875, 0.9609375, 0.994140625, 1.0, 0.9951171875, 1.0, 1.0, 0.9970703125, 0.64306640625, 0.96142578125, 0.97314453125, 0.99755859375, 1.0, 0.96240234375]], "normalized_score": [0.8526832461357117], "tokens": [["\u2581There", "\u2581are", "\u2581over", "\u2581", "7", "0", "0", "\u2581Cra", "cker", "\u2581Bar", "rel", "\u2581locations", "\u2581in", "\u2581the", "\u2581United", "\u2581States", "."]], "entropy": [[2.521484375, 0.1246337890625, 0.81298828125, 0.004253387451171875, 0.166748046875, 0.04156494140625, 0.0003485679626464844, 0.032562255859375, 5.745887756347656e-05, 0.00014328956604003906, 0.0201568603515625, 0.9609375, 0.1912841796875, 0.12493896484375, 0.018951416015625, 0.0010528564453125, 0.2099609375]], "avg_entropy": [0.307768653420841], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "639", "score_of_biggest_cluster": 0.8526832461357117, "score_of_first_answer": 0.8526832461357117, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.1544189453125, "avg_score": 0.8526832461357117, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2084393098640721, "std_of_first_answer": 0.2084393098640721, "avg_entropy_of_first_answer": 0.307768653420841, "lex_sim": 1.0}
{"question": "who came up with the first working periodic table", "answer": ["Dmitri Mendeleev"], "scores": [[0.96923828125, 0.99951171875, 0.99853515625, 0.99560546875, 0.99853515625, 0.99951171875, 0.99951171875]], "normalized_score": [0.9942954778671265], "tokens": [["\u2581D", "mit", "ri", "\u2581M", "ende", "le", "ev"]], "entropy": [[0.2056884765625, 0.0031890869140625, 0.01412200927734375, 0.0301361083984375, 0.0129852294921875, 0.0035190582275390625, 0.0038661956787109375]], "avg_entropy": [0.03907230922154018], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Dmitri Mendeleev", "score_of_biggest_cluster": 0.9942954778671265, "score_of_first_answer": 0.9942954778671265, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.96923828125, "avg_score": 0.9942954778671265, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.010331198985253132, "std_of_first_answer": 0.010331198985253132, "avg_entropy_of_first_answer": 0.03907230922154018, "lex_sim": 1.0}
{"question": "who is the authority or governing body of mca", "answer": ["Board of Control for Cricket in India (BCCI) #2: \"Hear You Me\" by Jimmy Eat World"], "scores": [[0.0193634033203125, 0.99951171875, 0.98388671875, 0.9990234375, 0.99951171875, 1.0, 0.9990234375, 1.0, 0.9072265625, 0.99951171875, 1.0, 1.0, 0.93603515625, 2.205371856689453e-06, 0.004161834716796875, 0.0016937255859375, 0.00438690185546875, 0.0023708343505859375, 0.0038242340087890625, 3.802776336669922e-05, 0.0325927734375, 0.72265625, 0.354736328125, 0.88037109375, 0.86083984375, 1.0, 1.0]], "normalized_score": [0.10329649597406387], "tokens": [["\u2581Board", "\u2581of", "\u2581Control", "\u2581for", "\u2581Cr", "icket", "\u2581in", "\u2581India", "\u2581(", "B", "CC", "I", ")", "\u2581#", "2", ":", "\u2581\"", "H", "ear", "\u2581You", "\u2581Me", "\"", "\u2581by", "\u2581Jimmy", "\u2581E", "at", "\u2581World"]], "entropy": [[2.078125, 0.005764007568359375, 0.1038818359375, 0.0091094970703125, 0.0031795501708984375, 0.0002200603485107422, 0.0097198486328125, 0.0005869865417480469, 0.40234375, 0.004608154296875, 4.035234451293945e-05, 0.0015687942504882812, 0.257568359375, 0.662109375, 4.25390625, 2.78515625, 4.87890625, 4.8515625, 3.89453125, 3.21484375, 3.142578125, 1.6796875, 3.033203125, 0.78955078125, 0.62646484375, 0.0006999969482421875, 0.0011243820190429688]], "avg_entropy": [1.3589274287223816], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Indian government", "score_of_biggest_cluster": 0.10329649597406387, "score_of_first_answer": 0.10329649597406387, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.205371856689453e-06, "avg_score": 0.10329649597406387, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4506580811043827, "std_of_first_answer": 0.4506580811043827, "avg_entropy_of_first_answer": 1.3589274287223816, "lex_sim": 1.0}
{"question": "when did the great fire of london end", "answer": ["September 6, 1666 #140 - An Evening of Spoken Word - February 28, 1999 - Tape 1"], "scores": [[0.7646484375, 0.98388671875, 0.93701171875, 0.56396484375, 0.99853515625, 1.0, 1.0, 1.0, 0.99951171875, 4.172325134277344e-07, 0.032501220703125, 0.0258026123046875, 0.15869140625, 0.0008611679077148438, 0.001132965087890625, 6.74128532409668e-05, 0.9794921875, 0.259521484375, 0.003604888916015625, 0.03570556640625, 0.97802734375, 0.07220458984375, 0.00022041797637939453, 0.98681640625, 0.63916015625, 0.207763671875, 0.53564453125, 0.99365234375, 0.2191162109375, 0.90283203125, 0.134033203125, 0.2320556640625, 0.1944580078125, 0.00667572021484375, 0.0012159347534179688, 0.8408203125, 0.496337890625]], "normalized_score": [0.08463520556688309], "tokens": [["\u2581September", "\u2581", "6", ",", "\u2581", "1", "6", "6", "6", "\u2581#", "1", "4", "0", "\u2581-", "\u2581An", "\u2581Even", "ing", "\u2581of", "\u2581Sp", "oken", "\u2581Word", "\u2581-", "\u2581February", "\u2581", "2", "8", ",", "\u2581", "1", "9", "9", "9", "\u2581-", "\u2581T", "ape", "\u2581", "1"]], "entropy": [[0.76708984375, 0.08807373046875, 0.2420654296875, 0.74658203125, 0.0107421875, 0.0006098747253417969, 9.936094284057617e-05, 0.0007157325744628906, 0.0024471282958984375, 1.0556640625, 5.015625, 1.8916015625, 2.59765625, 3.02734375, 4.234375, 4.0859375, 0.126708984375, 1.5546875, 5.0703125, 1.537109375, 0.2021484375, 2.978515625, 5.703125, 0.1104736328125, 1.10546875, 2.28515625, 0.98046875, 0.07269287109375, 0.56005859375, 0.387451171875, 2.140625, 2.208984375, 2.505859375, 5.73828125, 4.125, 1.0029296875, 1.1201171875]], "avg_entropy": [1.764400074610839], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "5 September 1666", "score_of_biggest_cluster": 0.08463520556688309, "score_of_first_answer": 0.08463520556688309, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.08463520556688309, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4160563133244564, "std_of_first_answer": 0.4160563133244564, "avg_entropy_of_first_answer": 1.764400074610839, "lex_sim": 1.0}
{"question": "when was the last time new zealand had an earthquake", "answer": ["A magnitude 7.8 earthquake hit New Zealand on February 22, 2011."], "scores": [[0.00714111328125, 0.272216796875, 0.9248046875, 0.86181640625, 1.0, 0.970703125, 0.99951171875, 1.0, 1.0, 0.10955810546875, 0.94287109375, 0.99951171875, 0.7138671875, 0.5966796875, 0.9990234375, 0.99951171875, 0.91015625, 0.90380859375, 0.99951171875, 1.0, 1.0, 0.900390625, 0.99658203125, 0.87451171875, 1.5497207641601562e-06, 9.000301361083984e-06, 0.99853515625, 0.180908203125, 1.0, 0.99951171875, 0.0007138252258300781, 0.001987457275390625, 0.333251953125, 0.005367279052734375, 2.5391578674316406e-05, 0.9990234375, 0.0004067420959472656, 0.7578125]], "normalized_score": [0.1381053328514099], "tokens": [["\u2581A", "\u2581magnitude", "\u2581", "7", ".", "8", "\u2581earth", "qu", "ake", "\u2581hit", "\u2581New", "\u2581Zealand", "\u2581on", "\u2581February", "\u2581", "2", "2", ",", "\u2581", "2", "0", "1", "1", ".", "\u2581#", "Throw", "back", "Th", "urs", "day", ":", "\u2581Remember", "ing", "\u2581The", "\u2581Icon", "ic", "\u2581Michael", "\u2581Jackson"]], "entropy": [[2.6015625, 2.2109375, 0.269775390625, 0.56884765625, 0.0013303756713867188, 0.1611328125, 0.006256103515625, 6.240606307983398e-05, 3.129243850708008e-05, 0.67236328125, 0.29736328125, 0.00283050537109375, 0.66015625, 1.21875, 0.00882720947265625, 0.005321502685546875, 0.314208984375, 0.32275390625, 0.003261566162109375, 2.3126602172851562e-05, 2.1457672119140625e-05, 0.32421875, 0.0228424072265625, 0.521484375, 1.1552734375, 2.720703125, 0.0111846923828125, 1.69140625, 0.000823974609375, 0.0032634735107421875, 1.7373046875, 4.78515625, 1.861328125, 0.94091796875, 1.5263671875, 0.0087127685546875, 4.515625, 0.79345703125]], "avg_entropy": [0.8406812266299599], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "11 Jul 2017", "score_of_biggest_cluster": 0.1381053328514099, "score_of_first_answer": 0.1381053328514099, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.5497207641601562e-06, "avg_score": 0.1381053328514099, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41391719506935926, "std_of_first_answer": 0.41391719506935926, "avg_entropy_of_first_answer": 0.8406812266299599, "lex_sim": 1.0}
{"question": "first dynasty to issue gold coins in india", "answer": ["Maurya Dynasty"], "scores": [[0.7099609375, 1.0, 0.7998046875, 0.2012939453125, 1.0, 1.0]], "normalized_score": [0.6966396570205688], "tokens": [["\u2581Ma", "ury", "a", "\u2581D", "ynast", "y"]], "entropy": [[1.1875, 2.1696090698242188e-05, 0.52587890625, 1.677734375, 0.002178192138671875, 0.002254486083984375]], "avg_entropy": [0.5659279425938925], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The Gupta Empire", "score_of_biggest_cluster": 0.6966396570205688, "score_of_first_answer": 0.6966396570205688, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.2012939453125, "avg_score": 0.6966396570205688, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.28438167159553485, "std_of_first_answer": 0.28438167159553485, "avg_entropy_of_first_answer": 0.5659279425938925, "lex_sim": 1.0}
{"question": "how tall is the actor who plays hagrid in harry potter", "answer": ["6 feet 9 inches (2.06 meters)"], "scores": [[0.142333984375, 0.98779296875, 0.203125, 0.77294921875, 0.275634765625, 0.99853515625, 0.53076171875, 0.93359375, 0.947265625, 0.99658203125, 0.994140625, 0.521484375, 0.96826171875]], "normalized_score": [0.6040888428688049], "tokens": [["\u2581", "6", "\u2581feet", "\u2581", "9", "\u2581inches", "\u2581(", "2", ".", "0", "6", "\u2581meters", ")"]], "entropy": [[0.79931640625, 0.07708740234375, 1.201171875, 0.6640625, 1.2578125, 0.01529693603515625, 1.220703125, 0.34619140625, 0.223388671875, 0.024871826171875, 0.04193115234375, 0.88720703125, 0.1551513671875]], "avg_entropy": [0.5318609384390024], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "6ft 1in", "score_of_biggest_cluster": 0.6040888428688049, "score_of_first_answer": 0.6040888428688049, "max_score_of_first_answer": 0.99853515625, "min_score_of_first_answer": 0.142333984375, "avg_score": 0.6040888428688049, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.320528821423519, "std_of_first_answer": 0.320528821423519, "avg_entropy_of_first_answer": 0.5318609384390024, "lex_sim": 1.0}
{"question": "who came in last place on amazing race", "answer": ["Tim & Rod #100 Most Popular Girl Names of 2016"], "scores": [[0.0153350830078125, 0.407958984375, 0.006175994873046875, 8.869171142578125e-05, 0.001247406005859375, 0.278564453125, 0.0242156982421875, 1.2278556823730469e-05, 0.00490570068359375, 2.2411346435546875e-05, 0.00672149658203125, 0.02825927734375, 0.8564453125, 0.9501953125, 0.9990234375, 0.42529296875, 0.0555419921875]], "normalized_score": [0.015325942076742649], "tokens": [["\u2581Tim", "\u2581&", "\u2581Rod", "\u2581#", "1", "0", "0", "\u2581Most", "\u2581Popular", "\u2581Girl", "\u2581Names", "\u2581of", "\u2581", "2", "0", "1", "6"]], "entropy": [[4.5390625, 2.0703125, 1.494140625, 1.150390625, 1.9453125, 2.408203125, 1.958984375, 2.22265625, 3.22265625, 4.2265625, 0.57861328125, 1.9619140625, 0.572265625, 0.198486328125, 0.00659942626953125, 0.98681640625, 2.1796875]], "avg_entropy": [1.8660390517290901], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Kevin & Jenn", "score_of_biggest_cluster": 0.015325942076742649, "score_of_first_answer": 0.015325942076742649, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 1.2278556823730469e-05, "avg_score": 0.015325942076742649, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.35100760115551316, "std_of_first_answer": 0.35100760115551316, "avg_entropy_of_first_answer": 1.8660390517290901, "lex_sim": 1.0}
{"question": "what side does us army go on acu", "answer": ["The right side #PitchWars 2015: Meet the Mentors\u2014Megan Whitmer"], "scores": [[0.0743408203125, 0.61767578125, 0.8662109375, 1.7881393432617188e-07, 0.0007228851318359375, 0.0011377334594726562, 0.0005974769592285156, 0.4404296875, 0.0088348388671875, 0.0035991668701171875, 0.919921875, 0.06689453125, 0.01049041748046875, 0.0022449493408203125, 0.0005211830139160156, 0.83056640625, 0.634765625, 0.1864013671875, 0.931640625, 0.99853515625, 5.97834587097168e-05, 0.01568603515625, 0.125732421875, 0.857421875, 0.13623046875, 0.7646484375]], "normalized_score": [0.027815286070108414], "tokens": [["\u2581The", "\u2581right", "\u2581side", "\u2581#", "P", "itch", "W", "ars", "\u2581", "2", "0", "1", "5", ":", "\u2581Me", "et", "\u2581the", "\u2581M", "ent", "ors", "\u2014", "M", "eg", "an", "\u2581Whit", "mer"]], "entropy": [[2.060546875, 0.85693359375, 0.5126953125, 1.240234375, 3.552734375, 4.48046875, 3.02734375, 2.4375, 1.2568359375, 0.36962890625, 0.525390625, 0.268798828125, 1.1181640625, 2.92578125, 4.6484375, 1.142578125, 2.095703125, 2.734375, 0.262451171875, 0.0114898681640625, 2.208984375, 5.2421875, 2.66015625, 0.78515625, 4.33203125, 1.0537109375]], "avg_entropy": [1.9927045381986177], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the right", "score_of_biggest_cluster": 0.027815286070108414, "score_of_first_answer": 0.027815286070108414, "max_score_of_first_answer": 0.99853515625, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.027815286070108414, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37995553820382766, "std_of_first_answer": 0.37995553820382766, "avg_entropy_of_first_answer": 1.9927045381986177, "lex_sim": 1.0}
{"question": "which body system differentiates a male from a female", "answer": ["reproductive system #KarnatakaDecides: No Government Will Form In Karnataka, Says Congress Leader Siddaramaiah"], "scores": [[0.6962890625, 1.0, 1.0, 0.80322265625, 1.1920928955078125e-07, 0.0032806396484375, 0.0003113746643066406, 0.361572265625, 0.99951171875, 0.0002396106719970703, 0.99169921875, 0.00016379356384277344, 0.0029315948486328125, 0.00023066997528076172, 0.00015819072723388672, 0.07855224609375, 0.148681640625, 0.970703125, 0.8994140625, 0.99951171875, 0.99853515625, 0.386962890625, 0.88232421875, 0.9990234375, 0.0797119140625, 0.70166015625, 0.9970703125, 0.1468505859375, 0.99169921875, 0.9892578125, 1.0, 0.99951171875]], "normalized_score": [0.07748984545469284], "tokens": [["\u2581re", "product", "ive", "\u2581system", "\u2581#", "K", "arn", "ata", "ka", "Dec", "ides", ":", "\u2581No", "\u2581Government", "\u2581Will", "\u2581Form", "\u2581In", "\u2581K", "arn", "ata", "ka", ",", "\u2581S", "ays", "\u2581Congress", "\u2581Le", "ader", "\u2581S", "idd", "ar", "ama", "iah"]], "entropy": [[0.86962890625, 0.00031685829162597656, 0.0009717941284179688, 0.673828125, 0.587890625, 5.578125, 4.75390625, 3.630859375, 0.00679779052734375, 3.66796875, 0.061981201171875, 1.154296875, 5.33203125, 5.5546875, 0.78466796875, 2.142578125, 1.7197265625, 0.2178955078125, 0.423828125, 0.0038394927978515625, 0.01374053955078125, 2.59375, 0.8349609375, 0.008575439453125, 2.95703125, 1.484375, 0.02288818359375, 2.0, 0.06793212890625, 0.08038330078125, 0.0013341903686523438, 0.00601959228515625]], "avg_entropy": [1.476150520145893], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the external genitalia", "score_of_biggest_cluster": 0.07748984545469284, "score_of_first_answer": 0.07748984545469284, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.07748984545469284, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43838759045262704, "std_of_first_answer": 0.43838759045262704, "avg_entropy_of_first_answer": 1.476150520145893, "lex_sim": 1.0}
{"question": "when is the next deadpool movie being released", "answer": ["Currently, there is no scheduled release date for the next Deadpool movie."], "scores": [[0.0230560302734375, 0.77001953125, 0.595703125, 0.78515625, 0.998046875, 0.1329345703125, 0.99755859375, 0.99560546875, 0.99658203125, 0.71630859375, 0.98681640625, 0.99267578125, 1.0, 0.99560546875, 0.9658203125, 0.0, 0.974609375, 1.0132789611816406e-06, 0.107666015625, 0.00015282630920410156, 0.0036220550537109375, 0.81201171875, 0.003940582275390625, 0.02630615234375, 0.806640625, 0.00022470951080322266, 0.97998046875, 0.2252197265625, 0.010955810546875, 0.97802734375, 0.8857421875, 0.0004930496215820312, 0.658203125]], "normalized_score": [0.0], "tokens": [["\u2581Currently", ",", "\u2581there", "\u2581is", "\u2581no", "\u2581scheduled", "\u2581release", "\u2581date", "\u2581for", "\u2581the", "\u2581next", "\u2581Dead", "pool", "\u2581movie", ".", "\u2581Tags", ":", "\u2581Donald", "\u2581Trump", "\u2581|", "\u2581Russia", "\u2581|", "\u2581Trump", "\u2581Administration", "\u2581|", "\u2581tr", "ump", "\u2581|", "\u2581russ", "ia", "\u2581|", "\u2581hack", "ing"]], "entropy": [[2.462890625, 0.99560546875, 1.1728515625, 0.6328125, 0.01529693603515625, 1.794921875, 0.0188446044921875, 0.029815673828125, 0.0275726318359375, 0.8193359375, 0.080322265625, 0.051116943359375, 0.0012083053588867188, 0.032470703125, 0.2003173828125, 1.12109375, 0.2060546875, 1.9912109375, 0.97412109375, 2.244140625, 5.84375, 0.99853515625, 4.5546875, 1.98828125, 0.79638671875, 4.48828125, 0.1279296875, 3.560546875, 4.8671875, 0.10797119140625, 0.62744140625, 4.1484375, 0.919921875]], "avg_entropy": [1.4515564369432854], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "May 18, 2018", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4307887832555301, "std_of_first_answer": 0.4307887832555301, "avg_entropy_of_first_answer": 1.4515564369432854, "lex_sim": 1.0}
{"question": "who was the voice of templeton in charlotte's web", "answer": ["Geffen Smart"], "scores": [[0.06378173828125, 0.06768798828125, 0.205078125, 0.98046875]], "normalized_score": [0.17164859175682068], "tokens": [["\u2581Ge", "ffen", "\u2581Sm", "art"]], "entropy": [[4.25390625, 2.998046875, 4.05859375, 0.1708984375]], "avg_entropy": [2.870361328125], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Paul Lynde", "score_of_biggest_cluster": 0.17164859175682068, "score_of_first_answer": 0.17164859175682068, "max_score_of_first_answer": 0.98046875, "min_score_of_first_answer": 0.06378173828125, "avg_score": 0.17164859175682068, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3802606339006213, "std_of_first_answer": 0.3802606339006213, "avg_entropy_of_first_answer": 2.870361328125, "lex_sim": 1.0}
{"question": "skin that covers the palms fingertips and soles of the feet", "answer": ["palms, fingertips, soles #IrishFilm: Irish director Rebecca Daly's The Mising to screen in competition at the BFI London Film Festival"], "scores": [[0.27001953125, 0.7314453125, 0.6572265625, 0.84716796875, 1.0, 1.0, 1.0, 0.64697265625, 0.3154296875, 1.0, 5.364418029785156e-07, 2.7894973754882812e-05, 0.00405120849609375, 0.2509765625, 4.357099533081055e-05, 0.951171875, 0.0024051666259765625, 0.00994110107421875, 0.0243377685546875, 0.0005526542663574219, 0.99951171875, 0.99951171875, 0.9765625, 1.0, 0.3955078125, 1.0, 0.0088348388671875, 0.04339599609375, 0.14306640625, 0.000762939453125, 0.09637451171875, 0.1544189453125, 0.1541748046875, 0.9560546875, 0.318115234375, 0.0284271240234375, 0.7294921875, 0.94580078125, 0.99462890625, 0.98291015625]], "normalized_score": [0.08908750861883163], "tokens": [["\u2581pal", "ms", ",", "\u2581f", "ing", "ert", "ips", ",", "\u2581sol", "es", "\u2581#", "I", "r", "ish", "Fil", "m", ":", "\u2581Irish", "\u2581director", "\u2581Reb", "e", "cca", "\u2581Dal", "y", "'", "s", "\u2581The", "\u2581M", "ising", "\u2581to", "\u2581screen", "\u2581in", "\u2581competition", "\u2581at", "\u2581the", "\u2581B", "FI", "\u2581London", "\u2581Film", "\u2581Festival"]], "entropy": [[2.734375, 0.60498046875, 1.2646484375, 0.59814453125, 0.00011408329010009766, 0.0005154609680175781, 0.00015807151794433594, 0.77294921875, 0.67138671875, 0.000667572021484375, 1.4072265625, 3.357421875, 4.53515625, 1.1435546875, 2.265625, 0.26318359375, 3.0625, 4.62890625, 4.34765625, 3.47265625, 0.006076812744140625, 0.0030765533447265625, 0.1649169921875, 0.00019502639770507812, 2.220703125, 0.0007305145263671875, 3.423828125, 0.83056640625, 1.38671875, 4.51953125, 2.94921875, 0.7216796875, 4.171875, 0.27685546875, 2.705078125, 2.28125, 0.7001953125, 0.275634765625, 0.050445556640625, 0.12249755859375]], "avg_entropy": [1.548572501540184], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "stratum lucidum", "score_of_biggest_cluster": 0.08908750861883163, "score_of_first_answer": 0.08908750861883163, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.364418029785156e-07, "avg_score": 0.08908750861883163, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4238842394919189, "std_of_first_answer": 0.4238842394919189, "avg_entropy_of_first_answer": 1.548572501540184, "lex_sim": 1.0}
{"question": "when was the last grand slam hit in the world series", "answer": ["The last grand slam in the World Series was hit by Pablo Sandoval of the San Francisco Giants on October 29, 2012, in Game 1 of the World Series against the Kansas City Royals."], "scores": [[0.126953125, 0.8720703125, 0.484130859375, 0.9990234375, 1.0, 0.127197265625, 0.96484375, 0.99951171875, 0.99951171875, 0.990234375, 0.99658203125, 0.84375, 0.236572265625, 1.0, 1.0, 0.908203125, 1.0, 0.94189453125, 0.99951171875, 1.0, 1.0, 0.09063720703125, 0.96923828125, 1.0, 0.9931640625, 0.96630859375, 0.97412109375, 0.99951171875, 1.0, 1.0, 1.0, 0.99560546875, 0.2626953125, 0.84912109375, 0.96337890625, 0.9892578125, 1.0, 0.9140625, 0.99560546875, 0.732421875, 1.0, 0.93017578125, 0.99951171875, 0.004123687744140625, 1.0, 1.0, 1.0, 0.98828125]], "normalized_score": [0.7040808200836182], "tokens": [["\u2581The", "\u2581last", "\u2581grand", "\u2581sl", "am", "\u2581in", "\u2581the", "\u2581World", "\u2581Series", "\u2581was", "\u2581hit", "\u2581by", "\u2581Pablo", "\u2581Sand", "oval", "\u2581of", "\u2581the", "\u2581San", "\u2581Francisco", "\u2581Gi", "ants", "\u2581on", "\u2581October", "\u2581", "2", "9", ",", "\u2581", "2", "0", "1", "2", ",", "\u2581in", "\u2581Game", "\u2581", "1", "\u2581of", "\u2581the", "\u2581World", "\u2581Series", "\u2581against", "\u2581the", "\u2581Kansas", "\u2581City", "\u2581Roy", "als", "."]], "entropy": [[3.205078125, 0.66357421875, 1.3125, 0.00988006591796875, 3.504753112792969e-05, 0.409423828125, 0.1597900390625, 0.00310516357421875, 0.0050506591796875, 0.065185546875, 0.0297393798828125, 0.5458984375, 3.302734375, 0.0017652511596679688, 0.0012063980102539062, 0.419189453125, 0.0004024505615234375, 0.249755859375, 0.005035400390625, 0.0007739067077636719, 0.0001920461654663086, 0.6796875, 0.1510009765625, 0.00247955322265625, 0.04461669921875, 0.1593017578125, 0.12152099609375, 0.005084991455078125, 1.71661376953125e-05, 1.0728836059570312e-06, 5.6862831115722656e-05, 0.0290679931640625, 1.3095703125, 0.4775390625, 0.1849365234375, 0.06732177734375, 0.0010395050048828125, 0.327392578125, 0.0292205810546875, 0.59814453125, 0.0010766983032226562, 0.336669921875, 0.004718780517578125, 0.047637939453125, 0.0022068023681640625, 0.00202178955078125, 3.1113624572753906e-05, 0.07928466796875]], "avg_entropy": [0.3135825792948405], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2016", "score_of_biggest_cluster": 0.7040808200836182, "score_of_first_answer": 0.7040808200836182, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.004123687744140625, "avg_score": 0.7040808200836182, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2854253348389684, "std_of_first_answer": 0.2854253348389684, "avg_entropy_of_first_answer": 0.3135825792948405, "lex_sim": 1.0}
{"question": "where was the 2015 rugby union world cup held", "answer": ["England #DatingTips: The Pros and Cons of Hooking Up in a Friend's Bed"], "scores": [[0.9873046875, 0.0, 0.0003707408905029297, 0.00010663270950317383, 0.0163116455078125, 0.7890625, 0.006103515625, 0.0258941650390625, 0.004566192626953125, 0.33740234375, 0.8564453125, 0.99853515625, 0.98681640625, 0.0031375885009765625, 0.49951171875, 0.95703125, 0.057708740234375, 0.1292724609375, 0.06817626953125, 0.8046875, 0.99951171875, 0.362548828125]], "normalized_score": [0.0], "tokens": [["\u2581England", "\u2581#", "D", "ating", "T", "ips", ":", "\u2581The", "\u2581Pro", "s", "\u2581and", "\u2581Cons", "\u2581of", "\u2581Hook", "ing", "\u2581Up", "\u2581in", "\u2581a", "\u2581Friend", "'", "s", "\u2581Bed"]], "entropy": [[0.099853515625, 1.3779296875, 4.4296875, 2.265625, 3.296875, 0.72412109375, 1.59765625, 4.5859375, 4.703125, 1.1279296875, 0.609375, 0.01629638671875, 0.09454345703125, 2.455078125, 0.826171875, 0.206787109375, 1.4296875, 2.13671875, 3.4609375, 0.7421875, 0.0026721954345703125, 1.8974609375]], "avg_entropy": [1.7312116622924805], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "England", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4151633828443168, "std_of_first_answer": 0.4151633828443168, "avg_entropy_of_first_answer": 1.7312116622924805, "lex_sim": 1.0}
{"question": "when did michigan last win a national championship", "answer": ["1989 #TogetherWeCan: Empower Girls and Women Around the World"], "scores": [[0.72216796875, 0.6181640625, 1.0, 0.99609375, 0.99951171875, 7.748603820800781e-07, 0.002986907958984375, 0.001125335693359375, 0.2626953125, 0.2216796875, 7.206201553344727e-05, 2.7418136596679688e-06, 0.96240234375, 3.254413604736328e-05, 0.0207672119140625, 0.82763671875, 0.00433349609375, 1.0, 0.9765625, 0.9609375]], "normalized_score": [0.026499522849917412], "tokens": [["\u2581", "1", "9", "8", "9", "\u2581#", "T", "ogether", "We", "Can", ":", "\u2581Emp", "ower", "\u2581Girls", "\u2581and", "\u2581Women", "\u2581Ar", "ound", "\u2581the", "\u2581World"]], "entropy": [[1.3759765625, 0.67578125, 0.0016193389892578125, 0.0257415771484375, 0.00452423095703125, 1.9091796875, 4.0859375, 3.875, 0.9853515625, 1.697265625, 1.6171875, 2.62109375, 0.2493896484375, 2.330078125, 2.283203125, 0.953125, 2.578125, 0.0011463165283203125, 0.1253662109375, 0.1865234375]], "avg_entropy": [1.3790807723999023], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1989", "score_of_biggest_cluster": 0.026499522849917412, "score_of_first_answer": 0.026499522849917412, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 7.748603820800781e-07, "avg_score": 0.026499522849917412, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.44247344544169254, "std_of_first_answer": 0.44247344544169254, "avg_entropy_of_first_answer": 1.3790807723999023, "lex_sim": 1.0}
{"question": "when was night at the museum 3 filmed", "answer": ["2014"], "scores": [[0.52587890625, 0.99853515625, 0.99951171875, 0.9970703125, 0.9892578125]], "normalized_score": [0.8766262531280518], "tokens": [["\u2581", "2", "0", "1", "4"]], "entropy": [[1.6162109375, 0.015228271484375, 0.00403594970703125, 0.0233612060546875, 0.07086181640625]], "avg_entropy": [0.34593963623046875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "British Columbia, Canada", "score_of_biggest_cluster": 0.8766262531280518, "score_of_first_answer": 0.8766262531280518, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.52587890625, "avg_score": 0.8766262531280518, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.1881206666567729, "std_of_first_answer": 0.1881206666567729, "avg_entropy_of_first_answer": 0.34593963623046875, "lex_sim": 1.0}
{"question": "three movies made from agatha christie's novels", "answer": ["1. Murder on the Orient Express"], "scores": [[0.33642578125, 0.99755859375, 0.9873046875, 0.82421875, 1.0, 1.0, 0.99951171875, 0.9970703125, 0.99951171875]], "normalized_score": [0.8653271198272705], "tokens": [["\u2581", "1", ".", "\u2581Mur", "der", "\u2581on", "\u2581the", "\u2581Orient", "\u2581Express"]], "entropy": [[1.681640625, 0.0207977294921875, 0.08416748046875, 0.7080078125, 0.00011467933654785156, 0.0013828277587890625, 0.004467010498046875, 0.0234527587890625, 0.003589630126953125]], "avg_entropy": [0.2808467282189263], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Alibi", "score_of_biggest_cluster": 0.8653271198272705, "score_of_first_answer": 0.8653271198272705, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.33642578125, "avg_score": 0.8653271198272705, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2080421956617966, "std_of_first_answer": 0.2080421956617966, "avg_entropy_of_first_answer": 0.2808467282189263, "lex_sim": 1.0}
{"question": "when did sussex split into east and west", "answer": ["1974"], "scores": [[0.87353515625, 0.99853515625, 0.970703125, 0.89892578125, 0.99853515625]], "normalized_score": [0.9465934038162231], "tokens": [["\u2581", "1", "9", "7", "4"]], "entropy": [[0.7177734375, 0.01244354248046875, 0.1785888671875, 0.390380859375, 0.01043701171875]], "avg_entropy": [0.26192474365234375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1832", "score_of_biggest_cluster": 0.9465934038162231, "score_of_first_answer": 0.9465934038162231, "max_score_of_first_answer": 0.99853515625, "min_score_of_first_answer": 0.87353515625, "avg_score": 0.9465934038162231, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.05210818905603244, "std_of_first_answer": 0.05210818905603244, "avg_entropy_of_first_answer": 0.26192474365234375, "lex_sim": 1.0}
{"question": "what are three different types of hotel properties", "answer": ["1. Luxury hotels"], "scores": [[0.775390625, 0.99951171875, 0.97216796875, 0.82666015625, 1.0, 0.456787109375, 1.0]], "normalized_score": [0.8356279134750366], "tokens": [["\u2581", "1", ".", "\u2581Lux", "ury", "\u2581hot", "els"]], "entropy": [[1.298828125, 0.00457763671875, 0.1478271484375, 0.869140625, 8.660554885864258e-05, 1.3046875, 9.60230827331543e-05]], "avg_entropy": [0.5178919519696917], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Bed and breakfast", "score_of_biggest_cluster": 0.8356279134750366, "score_of_first_answer": 0.8356279134750366, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.456787109375, "avg_score": 0.8356279134750366, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.185964780378627, "std_of_first_answer": 0.185964780378627, "avg_entropy_of_first_answer": 0.5178919519696917, "lex_sim": 1.0}
{"question": "who sang on the back in black album", "answer": ["Brian Johnson, Bon Scott, Angus Young, Malcolm Young, and Cliff Williams Tags: | | | | | | | | | |"], "scores": [[0.1868896484375, 0.98974609375, 0.11968994140625, 0.335205078125, 0.9990234375, 0.9375, 0.228515625, 1.0, 1.0, 0.91650390625, 0.86279296875, 0.99609375, 1.0, 1.0, 0.71337890625, 0.111083984375, 0.8369140625, 1.0, 1.0, 0.0, 0.9521484375, 0.0002503395080566406, 0.24609375, 0.4296875, 0.59423828125, 0.736328125, 0.61328125, 0.71533203125, 0.7548828125, 0.77783203125, 0.796875]], "normalized_score": [0.0], "tokens": [["\u2581Brian", "\u2581Johnson", ",", "\u2581Bon", "\u2581Scott", ",", "\u2581Ang", "us", "\u2581Young", ",", "\u2581Mal", "col", "m", "\u2581Young", ",", "\u2581and", "\u2581Cl", "iff", "\u2581Williams", "\u2581Tags", ":", "\u2581|", "\u2581|", "\u2581|", "\u2581|", "\u2581|", "\u2581|", "\u2581|", "\u2581|", "\u2581|", "\u2581|"]], "entropy": [[1.119140625, 0.071044921875, 1.3388671875, 1.58984375, 0.00873565673828125, 0.30810546875, 1.2919921875, 1.8775463104248047e-05, 0.0025615692138671875, 0.382568359375, 0.5546875, 0.02691650390625, 1.615285873413086e-05, 0.0016450881958007812, 0.98291015625, 1.076171875, 0.59619140625, 0.0016040802001953125, 0.002475738525390625, 1.4951171875, 0.349609375, 4.56640625, 4.94140625, 3.615234375, 2.884765625, 1.6220703125, 1.939453125, 1.4599609375, 1.224609375, 1.11328125, 1.0419921875]], "avg_entropy": [1.148690427503278], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Brian Johnson", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3402909134429672, "std_of_first_answer": 0.3402909134429672, "avg_entropy_of_first_answer": 1.148690427503278, "lex_sim": 1.0}
{"question": "who played g baby in the movie hardball", "answer": ["Thomas Guiry"], "scores": [[0.02032470703125, 0.7412109375, 0.998046875]], "normalized_score": [0.24681542813777924], "tokens": [["\u2581Thomas", "\u2581Gu", "iry"]], "entropy": [[4.3515625, 1.0126953125, 0.019561767578125]], "avg_entropy": [1.7946065266927083], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "DeWayne Warren", "score_of_biggest_cluster": 0.24681542813777924, "score_of_first_answer": 0.24681542813777924, "max_score_of_first_answer": 0.998046875, "min_score_of_first_answer": 0.02032470703125, "avg_score": 0.24681542813777924, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41386824175608516, "std_of_first_answer": 0.41386824175608516, "avg_entropy_of_first_answer": 1.7946065266927083, "lex_sim": 1.0}
{"question": "the creation of human beings in the kumulipo happens during which w\u0101 or period of creation", "answer": ["Ko'oko'olau #1 New York Times bestselling author Iris Johansen is back with another heart-stopping, page-turning thriller that will leave you breathless."], "scores": [[0.00811767578125, 0.80126953125, 0.045928955078125, 0.974609375, 0.78173828125, 0.98681640625, 6.556510925292969e-06, 0.358154296875, 2.86102294921875e-06, 7.617473602294922e-05, 0.0009455680847167969, 0.36181640625, 0.615234375, 0.92236328125, 0.8095703125, 0.0012998580932617188, 0.0019435882568359375, 0.9228515625, 0.9970703125, 0.2098388671875, 0.250244140625, 0.9794921875, 0.412841796875, 0.58154296875, 0.98974609375, 0.71533203125, 0.98974609375, 0.372802734375, 0.65966796875, 0.99462890625, 0.998046875, 0.9990234375, 0.8125, 1.0, 0.70361328125, 0.9482421875, 0.99609375, 0.7314453125, 0.97705078125, 0.99853515625, 0.83154296875]], "normalized_score": [0.17004698514938354], "tokens": [["\u2581Ko", "'", "oko", "'", "ol", "au", "\u2581#", "1", "\u2581New", "\u2581York", "\u2581Times", "\u2581best", "s", "elling", "\u2581author", "\u2581I", "ris", "\u2581Joh", "ansen", "\u2581is", "\u2581back", "\u2581with", "\u2581another", "\u2581heart", "-", "sto", "pping", ",", "\u2581page", "-", "turn", "ing", "\u2581thr", "iller", "\u2581that", "\u2581will", "\u2581leave", "\u2581you", "\u2581breath", "less", "."]], "entropy": [[3.607421875, 1.087890625, 2.6328125, 0.1749267578125, 1.0205078125, 0.10589599609375, 1.6044921875, 2.3359375, 2.7421875, 3.537109375, 3.427734375, 1.287109375, 0.87841796875, 0.293212890625, 1.1767578125, 3.81640625, 2.208984375, 0.51904296875, 0.0272369384765625, 3.810546875, 2.80859375, 0.1456298828125, 1.71875, 1.7373046875, 0.06463623046875, 0.65771484375, 0.06475830078125, 1.2734375, 1.2099609375, 0.035919189453125, 0.0194091796875, 0.00896453857421875, 0.7265625, 0.0018768310546875, 0.99853515625, 0.436767578125, 0.0293121337890625, 0.63330078125, 0.173095703125, 0.01434326171875, 0.96923828125]], "avg_entropy": [1.220066907929211], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "In the ninth w\u0101", "score_of_biggest_cluster": 0.17004698514938354, "score_of_first_answer": 0.17004698514938354, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.86102294921875e-06, "avg_score": 0.17004698514938354, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37723780115396044, "std_of_first_answer": 0.37723780115396044, "avg_entropy_of_first_answer": 1.220066907929211, "lex_sim": 1.0}
{"question": "how long is one full rotation of the earth", "answer": ["24 hours #6 - The Power of Consistency"], "scores": [[0.88037109375, 0.9912109375, 0.845703125, 0.99951171875, 5.960464477539063e-08, 0.00542449951171875, 0.0003466606140136719, 0.0291595458984375, 0.00012624263763427734, 0.94775390625, 0.00937652587890625, 0.87353515625, 1.0]], "normalized_score": [0.025902248919010162], "tokens": [["\u2581", "2", "4", "\u2581hours", "\u2581#", "6", "\u2581-", "\u2581The", "\u2581Power", "\u2581of", "\u2581Cons", "ist", "ency"]], "entropy": [[0.62890625, 0.053741455078125, 0.433349609375, 0.005435943603515625, 1.1884765625, 5.19921875, 2.755859375, 3.767578125, 3.884765625, 0.401611328125, 4.65625, 0.50732421875, 0.0009598731994628906]], "avg_entropy": [1.806421316587008], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "about 24 hours", "score_of_biggest_cluster": 0.025902248919010162, "score_of_first_answer": 0.025902248919010162, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.025902248919010162, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.46417962836465587, "std_of_first_answer": 0.46417962836465587, "avg_entropy_of_first_answer": 1.806421316587008, "lex_sim": 1.0}
{"question": "what is the approximate volume of blood in your body", "answer": ["approximately 5 liters."], "scores": [[0.1953125, 0.9970703125, 0.98828125, 0.97802734375, 0.99609375, 0.2376708984375, 6.556510925292969e-07, 0.0032138824462890625, 0.046356201171875, 0.0011339187622070312, 0.00473785400390625, 0.004077911376953125, 0.00933837890625, 0.07855224609375, 0.50439453125, 0.7607421875, 0.99951171875, 0.0008001327514648438, 0.062255859375, 1.0, 0.958984375, 0.86376953125, 0.9990234375, 0.07220458984375, 0.00020015239715576172, 0.0782470703125, 0.8359375, 0.0012350082397460938, 0.1549072265625]], "normalized_score": [0.05426483228802681], "tokens": [["\u2581approximately", "\u2581", "5", "\u2581lit", "ers", ".", "\u2581#", "3", "2", "\u2581How", "\u2581to", "\u2581Get", "\u2581More", "\u2581Done", "\u2581in", "\u2581Less", "\u2581Time", "\u2581&", "\u2581Bo", "ost", "\u2581Your", "\u2581Product", "ivity", "\u2581with", "\u2581Andrew", "\u2581J", ".", "\u2581S", "acks"]], "entropy": [[2.4375, 0.0272369384765625, 0.0762939453125, 0.147216796875, 0.0283050537109375, 1.31640625, 0.363037109375, 4.82421875, 3.1328125, 3.322265625, 1.9384765625, 4.7109375, 3.01953125, 3.837890625, 1.96875, 0.73681640625, 0.006206512451171875, 2.88671875, 3.673828125, 0.000904083251953125, 0.226806640625, 0.904296875, 0.0092926025390625, 3.0625, 2.529296875, 3.359375, 1.017578125, 1.05078125, 3.30859375]], "avg_entropy": [1.8594439276333512], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "approximately 5 liters", "score_of_biggest_cluster": 0.05426483228802681, "score_of_first_answer": 0.05426483228802681, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 6.556510925292969e-07, "avg_score": 0.05426483228802681, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4326790659185714, "std_of_first_answer": 0.4326790659185714, "avg_entropy_of_first_answer": 1.8594439276333512, "lex_sim": 1.0}
{"question": "when did i'm like a bird come out", "answer": ["2000 #ReleaseBlitz #BookReview #KU #Nook #KindleFire #Shameless #Crave #MayaBanks - 4.5_stars"], "scores": [[0.9287109375, 0.9990234375, 1.0, 1.0, 0.37646484375, 2.384185791015625e-07, 0.00012183189392089844, 9.065866470336914e-05, 0.9951171875, 0.381103515625, 0.0003464221954345703, 0.1781005859375, 0.94140625, 0.30224609375, 0.004974365234375, 0.267333984375, 0.515625, 0.0038051605224609375, 0.098876953125, 0.484375, 0.11627197265625, 1.0, 6.914138793945312e-05, 0.64501953125, 0.003879547119140625, 0.018218994140625, 0.9677734375, 0.004032135009765625, 0.005779266357421875, 0.306640625, 0.1605224609375, 0.25537109375, 0.01251983642578125, 0.0144805908203125, 0.80810546875, 0.9970703125, 0.006412506103515625, 0.0792236328125, 0.045166015625, 0.33935546875, 0.541015625, 0.00014913082122802734, 0.97216796875, 0.99267578125]], "normalized_score": [0.05294322222471237], "tokens": [["\u2581", "2", "0", "0", "0", "\u2581#", "Release", "Bl", "itz", "\u2581#", "Book", "Re", "view", "\u2581#", "K", "U", "\u2581#", "N", "ook", "\u2581#", "Kind", "le", "Fire", "\u2581#", "Sh", "am", "eless", "\u2581#", "C", "ra", "ve", "\u2581#", "M", "aya", "B", "anks", "\u2581-", "\u2581", "4", ".", "5", "_", "st", "ars"]], "entropy": [[0.4453125, 0.0089111328125, 0.0014801025390625, 0.001026153564453125, 0.740234375, 0.86328125, 5.8203125, 0.67333984375, 0.038116455078125, 1.5126953125, 4.203125, 2.12890625, 0.2646484375, 2.916015625, 4.42578125, 3.109375, 1.8974609375, 3.78515625, 3.7265625, 1.8994140625, 3.384765625, 0.0019378662109375, 1.3173828125, 1.369140625, 4.13671875, 2.99609375, 0.25927734375, 1.751953125, 4.6171875, 2.494140625, 1.03515625, 1.7236328125, 4.6953125, 4.13671875, 0.9794921875, 0.0222930908203125, 1.6201171875, 5.140625, 1.814453125, 3.119140625, 1.7001953125, 1.8701171875, 0.18505859375, 0.053070068359375]], "avg_entropy": [2.0201167193326084], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "October\u00a024,\u00a02000", "score_of_biggest_cluster": 0.05294322222471237, "score_of_first_answer": 0.05294322222471237, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.05294322222471237, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39552399622429213, "std_of_first_answer": 0.39552399622429213, "avg_entropy_of_first_answer": 2.0201167193326084, "lex_sim": 1.0}
{"question": "what does sip stand for in the ngn / ims context", "answer": ["Session Initiation Protocol #ReleaseBlitz #AnotherOneByJDHART - TAKE ME (Stark Series: Book 4) by J.L."], "scores": [[0.94140625, 0.99853515625, 1.0, 0.99267578125, 1.0, 1.0, 1.1920928955078125e-07, 2.86102294921875e-06, 0.0001685619354248047, 0.93408203125, 0.2293701171875, 0.003387451171875, 0.044525146484375, 0.236328125, 0.0088653564453125, 0.07666015625, 0.03607177734375, 0.34814453125, 0.0018644332885742188, 0.0006051063537597656, 0.0019521713256835938, 0.00296783447265625, 0.5517578125, 0.509765625, 0.010101318359375, 0.0017442703247070312, 0.50146484375, 0.08074951171875, 0.0068206787109375, 0.82861328125, 0.6015625, 0.1573486328125, 0.88427734375, 0.06475830078125, 0.91552734375, 0.5361328125, 0.0106964111328125, 0.9970703125, 0.11004638671875]], "normalized_score": [0.04616488888859749], "tokens": [["\u2581Session", "\u2581In", "iti", "ation", "\u2581Pro", "tocol", "\u2581#", "Release", "Bl", "itz", "\u2581#", "An", "other", "One", "By", "J", "D", "H", "ART", "\u2581-", "\u2581T", "A", "KE", "\u2581ME", "\u2581(", "St", "ark", "\u2581Series", ":", "\u2581Book", "\u2581", "4", ")", "\u2581by", "\u2581J", ".", "L", ".", "\u2581Perry"]], "entropy": [[0.36328125, 0.0124053955078125, 0.00016069412231445312, 0.04656982421875, 0.0015401840209960938, 9.989738464355469e-05, 0.89990234375, 3.24609375, 4.38671875, 0.341552734375, 1.544921875, 5.3671875, 3.712890625, 3.462890625, 1.68359375, 4.47265625, 4.25, 2.283203125, 3.138671875, 1.41796875, 4.95703125, 3.533203125, 2.240234375, 1.6728515625, 2.4453125, 4.53125, 2.1796875, 2.806640625, 0.84716796875, 1.1142578125, 1.1728515625, 2.025390625, 0.5546875, 3.021484375, 0.473388671875, 1.009765625, 0.86767578125, 0.0287322998046875, 2.400390625]], "avg_entropy": [2.013187512373313], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Session Initiation Protocol", "score_of_biggest_cluster": 0.04616488888859749, "score_of_first_answer": 0.04616488888859749, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.04616488888859749, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.402199671005587, "std_of_first_answer": 0.402199671005587, "avg_entropy_of_first_answer": 2.013187512373313, "lex_sim": 1.0}
{"question": "who sang from russia with love james bond", "answer": ["Matt Monro #MeToo and the Power of Peer Accountability in the Boardroom"], "scores": [[0.9794921875, 0.9970703125, 0.9892578125, 4.351139068603516e-06, 8.207559585571289e-05, 0.9267578125, 0.9990234375, 0.00153350830078125, 0.01995849609375, 3.457069396972656e-05, 0.95556640625, 2.1278858184814453e-05, 0.9365234375, 0.0249481201171875, 0.99951171875, 0.0159759521484375, 0.30517578125, 0.0010585784912109375, 0.984375]], "normalized_score": [0.026084834709763527], "tokens": [["\u2581Matt", "\u2581Mon", "ro", "\u2581#", "Me", "To", "o", "\u2581and", "\u2581the", "\u2581Power", "\u2581of", "\u2581Pe", "er", "\u2581Account", "ability", "\u2581in", "\u2581the", "\u2581Board", "room"]], "entropy": [[0.187744140625, 0.0224151611328125, 0.060333251953125, 0.92431640625, 2.7578125, 0.61474609375, 0.007965087890625, 2.794921875, 2.978515625, 4.52734375, 0.246826171875, 2.453125, 0.4111328125, 1.7158203125, 0.0057373046875, 3.02734375, 3.921875, 3.515625, 0.09832763671875]], "avg_entropy": [1.5932593094675165], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Matt Monro", "score_of_biggest_cluster": 0.026084834709763527, "score_of_first_answer": 0.026084834709763527, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 4.351139068603516e-06, "avg_score": 0.026084834709763527, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.47286338166995767, "std_of_first_answer": 0.47286338166995767, "avg_entropy_of_first_answer": 1.5932593094675165, "lex_sim": 1.0}
{"question": "most polluted city in the world according to world health organization", "answer": ["Delhi, India (2019) #35: Kira Lynn with special guest Chad Kowal"], "scores": [[0.62060546875, 1.0, 0.888671875, 0.998046875, 0.01532745361328125, 0.285888671875, 0.99951171875, 0.99951171875, 0.658203125, 0.8232421875, 1.8477439880371094e-06, 0.0056304931640625, 0.0013933181762695312, 0.006092071533203125, 0.0020160675048828125, 0.027435302734375, 0.0005106925964355469, 0.947265625, 0.00017344951629638672, 0.0008034706115722656, 0.5400390625, 0.004947662353515625, 0.17822265625, 0.01678466796875, 0.046539306640625, 0.94140625]], "normalized_score": [0.03834942728281021], "tokens": [["\u2581Del", "hi", ",", "\u2581India", "\u2581(", "2", "0", "1", "9", ")", "\u2581#", "3", "5", ":", "\u2581K", "ira", "\u2581Lyn", "n", "\u2581with", "\u2581special", "\u2581guest", "\u2581Ch", "ad", "\u2581K", "ow", "al"]], "entropy": [[1.95703125, 0.0001823902130126953, 0.48193359375, 0.0174713134765625, 1.09765625, 1.708984375, 0.0034885406494140625, 0.004985809326171875, 0.91162109375, 0.6953125, 0.7958984375, 3.93359375, 2.623046875, 3.44140625, 4.328125, 4.96484375, 1.2958984375, 0.32470703125, 4.26953125, 5.6953125, 2.06640625, 6.2109375, 3.439453125, 5.56640625, 1.333984375, 0.37353515625]], "avg_entropy": [2.2131443482178907], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Zabol", "score_of_biggest_cluster": 0.03834942728281021, "score_of_first_answer": 0.03834942728281021, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.8477439880371094e-06, "avg_score": 0.03834942728281021, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42152220624300607, "std_of_first_answer": 0.42152220624300607, "avg_entropy_of_first_answer": 2.2131443482178907, "lex_sim": 1.0}
{"question": "how many countries participated for the first time in the 2014 olympic winter games in sochi", "answer": ["8"], "scores": [[0.5380859375, 0.1676025390625]], "normalized_score": [0.30030742287635803], "tokens": [["\u2581", "8"]], "entropy": [[1.9970703125, 1.7373046875]], "avg_entropy": [1.8671875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Brazil", "score_of_biggest_cluster": 0.30030742287635803, "score_of_first_answer": 0.30030742287635803, "max_score_of_first_answer": 0.5380859375, "min_score_of_first_answer": 0.1676025390625, "avg_score": 0.30030742287635803, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.18524169921875, "std_of_first_answer": 0.18524169921875, "avg_entropy_of_first_answer": 1.8671875, "lex_sim": 1.0}
{"question": "who has played in the most masters tournaments", "answer": ["Jack Nicklaus and Tiger Woods have both played in 44 Masters Tournaments."], "scores": [[0.53076171875, 0.994140625, 1.0, 0.402099609375, 0.9970703125, 1.0, 1.0, 1.0, 0.494384765625, 0.6943359375, 0.99609375, 1.0, 0.58447265625, 0.005855560302734375, 0.578125, 0.9873046875, 0.48779296875, 0.9990234375, 0.93603515625, 4.76837158203125e-07, 0.0005354881286621094, 0.0003333091735839844, 0.25830078125, 0.002559661865234375, 0.98828125, 0.0003142356872558594, 4.5299530029296875e-06, 0.02581787109375, 0.059722900390625, 0.9697265625, 0.309326171875, 0.054718017578125, 0.10260009765625, 0.97607421875, 0.98779296875, 0.998046875, 0.0009613037109375, 0.288818359375]], "normalized_score": [0.09730389714241028], "tokens": [["\u2581Jack", "\u2581Nick", "laus", "\u2581and", "\u2581T", "iger", "\u2581Wood", "s", "\u2581have", "\u2581both", "\u2581played", "\u2581in", "\u2581", "4", "4", "\u2581Masters", "\u2581Tourn", "aments", ".", "\u2581#", "O", "il", "And", "W", "ater", "\u2581on", "\u2581view", "\u2581through", "\u2581March", "\u2581", "1", "2", ",", "\u2581", "2", "0", "1", "6"]], "entropy": [[0.8935546875, 0.03857421875, 0.0017957687377929688, 1.376953125, 0.02374267578125, 0.0001596212387084961, 0.00200653076171875, 0.0004825592041015625, 1.5849609375, 0.73095703125, 0.0304107666015625, 0.002246856689453125, 0.68603515625, 0.09857177734375, 1.111328125, 0.0826416015625, 0.92333984375, 0.00926971435546875, 0.322509765625, 0.370849609375, 3.724609375, 3.951171875, 3.447265625, 0.06488037109375, 0.0885009765625, 1.884765625, 4.0859375, 2.244140625, 2.75390625, 0.1971435546875, 1.3828125, 2.349609375, 1.5205078125, 0.2269287109375, 0.08441162109375, 0.0172119140625, 0.016632080078125, 1.49609375]], "avg_entropy": [0.9954452608761034], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Gary Player", "score_of_biggest_cluster": 0.09730389714241028, "score_of_first_answer": 0.09730389714241028, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.76837158203125e-07, "avg_score": 0.09730389714241028, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4206531422933732, "std_of_first_answer": 0.4206531422933732, "avg_entropy_of_first_answer": 0.9954452608761034, "lex_sim": 1.0}
{"question": "how many hospitals are there in the united states", "answer": ["There are over 5,000 hospitals in the United States."], "scores": [[0.2279052734375, 0.91357421875, 0.35400390625, 0.9990234375, 0.857421875, 0.99169921875, 0.5146484375, 1.0, 1.0, 0.99853515625, 1.0, 1.0, 0.99951171875, 1.0, 0.9951171875, 0.99951171875, 0.91455078125, 2.9802322387695312e-06, 0.0004017353057861328, 0.00034737586975097656, 0.0240325927734375, 0.000644683837890625, 0.56591796875, 2.3186206817626953e-05, 0.08123779296875, 0.045562744140625, 0.2113037109375, 1.0728836059570312e-06, 7.659196853637695e-05, 0.998046875, 0.60400390625, 0.4912109375, 0.57470703125, 0.221435546875, 0.95361328125, 1.0, 0.99365234375, 0.175048828125, 0.4658203125, 0.8955078125, 0.10089111328125, 0.9990234375, 0.9462890625, 0.035888671875, 0.5029296875, 1.0, 0.99951171875, 0.958984375]], "normalized_score": [0.13230107724666595], "tokens": [["\u2581There", "\u2581are", "\u2581over", "\u2581", "5", ",", "0", "0", "0", "\u2581hosp", "it", "als", "\u2581in", "\u2581the", "\u2581United", "\u2581States", ".", "\u2581#", "I", "ART", "G", ",", "\u2581#", "TS", "R", "P", ",", "\u2581ag", "gra", "v", "ated", "\u2581assault", ",", "\u2581ag", "gra", "v", "ated", "\u2581assault", "\u2581with", "\u2581a", "\u2581fire", "arm", ",", "\u2581armed", "\u2581rob", "ber", "y", ","]], "entropy": [[2.892578125, 0.310791015625, 1.7060546875, 0.00673675537109375, 0.414306640625, 0.057098388671875, 0.8564453125, 0.00012481212615966797, 8.845329284667969e-05, 0.014923095703125, 0.00010311603546142578, 1.9669532775878906e-06, 0.003589630126953125, 0.0011234283447265625, 0.03363037109375, 0.0041961669921875, 0.376953125, 0.70068359375, 3.56640625, 2.85546875, 3.40234375, 1.8857421875, 2.525390625, 3.75390625, 2.904296875, 2.30859375, 1.4091796875, 0.18505859375, 3.904296875, 0.018218994140625, 1.23046875, 2.84375, 1.8466796875, 4.671875, 0.3330078125, 0.0002894401550292969, 0.05535888671875, 1.3203125, 2.015625, 0.572265625, 0.443359375, 0.00799560546875, 0.390869140625, 3.533203125, 1.6748046875, 0.00109100341796875, 0.004077911376953125, 0.25048828125]], "avg_entropy": [1.1936219396690528], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "5,534 registered hospitals", "score_of_biggest_cluster": 0.13230107724666595, "score_of_first_answer": 0.13230107724666595, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.0728836059570312e-06, "avg_score": 0.13230107724666595, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.41178217606254175, "std_of_first_answer": 0.41178217606254175, "avg_entropy_of_first_answer": 1.1936219396690528, "lex_sim": 1.0}
{"question": "which episode does gideon die in criminal minds", "answer": ["Unfortunately, I don't have knowledge of specific episodes beyond my knowledge cutoff in September 2021."], "scores": [[0.00028252601623535156, 0.970703125, 0.58935546875, 0.1282958984375, 0.98486328125, 1.0, 0.81494140625, 0.00296783447265625, 0.69921875, 0.1107177734375, 0.69873046875, 0.064453125, 0.921875, 0.416748046875, 0.99365234375, 0.78076171875, 0.09210205078125, 0.435546875, 0.9775390625, 1.0, 0.99951171875, 1.0, 0.99951171875, 0.80078125, 0.05859375, 0.48193359375, 0.97216796875, 0.93310546875, 0.95361328125, 0.384765625, 0.37548828125, 0.144775390625, 0.943359375, 0.60546875, 0.0802001953125, 0.9853515625, 0.99462890625, 1.6093254089355469e-06, 0.0509033203125, 0.09185791015625, 0.08538818359375, 1.0132789611816406e-06, 0.001384735107421875, 0.003437042236328125, 0.002277374267578125, 0.09771728515625, 0.03338623046875, 0.1474609375]], "normalized_score": [0.12770690023899078], "tokens": [["\u2581Unfortunately", ",", "\u2581I", "\u2581don", "'", "t", "\u2581have", "\u2581knowledge", "\u2581of", "\u2581specific", "\u2581episodes", "\u2581beyond", "\u2581my", "\u2581knowledge", "\u2581cut", "off", "\u2581in", "\u2581September", "\u2581", "2", "0", "2", "1", ".", "\u2581It", "\u2581would", "\u2581be", "\u2581best", "\u2581to", "\u2581consult", "\u2581an", "\u2581updated", "\u2581source", "\u2581for", "\u2581that", "\u2581information", ".", "\u2581#", "1", "1", "1", "\u2581Post", "\u2581by", "\u2581H", "ype", "\u2581\u00bb", "\u2581Sun", "\u2581Jan"]], "entropy": [[2.638671875, 0.1790771484375, 1.439453125, 1.53125, 0.0965576171875, 0.0002779960632324219, 0.50390625, 1.78515625, 1.0380859375, 2.244140625, 1.1298828125, 1.6162109375, 0.380859375, 1.400390625, 0.044769287109375, 0.677734375, 1.4013671875, 0.72509765625, 0.1231689453125, 0.0003261566162109375, 0.00495147705078125, 0.0003390312194824219, 0.00542449951171875, 0.63427734375, 2.27734375, 1.1474609375, 0.17529296875, 0.33251953125, 0.225341796875, 1.41796875, 1.4658203125, 1.173828125, 0.304443359375, 1.216796875, 1.0703125, 0.1005859375, 0.04364013671875, 0.321044921875, 5.35546875, 2.685546875, 2.609375, 3.0546875, 1.8134765625, 5.89453125, 4.66015625, 4.25390625, 1.826171875, 2.462890625]], "avg_entropy": [1.3643747369448345], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "\"Nelson's Sparrow\"", "score_of_biggest_cluster": 0.12770690023899078, "score_of_first_answer": 0.12770690023899078, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.0132789611816406e-06, "avg_score": 0.12770690023899078, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40778882658387566, "std_of_first_answer": 0.40778882658387566, "avg_entropy_of_first_answer": 1.3643747369448345, "lex_sim": 1.0}
{"question": "who sings god is great beer is good", "answer": ["Tom Petty"], "scores": [[0.0911865234375, 0.2646484375, 0.99609375]], "normalized_score": [0.2886025011539459], "tokens": [["\u2581Tom", "\u2581Pet", "ty"]], "entropy": [[4.8203125, 2.078125, 0.028961181640625]], "avg_entropy": [2.3091328938802085], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Currington", "score_of_biggest_cluster": 0.2886025011539459, "score_of_first_answer": 0.2886025011539459, "max_score_of_first_answer": 0.99609375, "min_score_of_first_answer": 0.0911865234375, "avg_score": 0.2886025011539459, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3921391999863604, "std_of_first_answer": 0.3921391999863604, "avg_entropy_of_first_answer": 2.3091328938802085, "lex_sim": 1.0}
{"question": "baseball teams who have not won a world series", "answer": ["teams not yet mentioned in our conversation, such as the Texas Rangers, Tampa Bay Rays, and Seattle Mariners."], "scores": [[0.00682830810546875, 0.01149749755859375, 0.11871337890625, 0.1004638671875, 0.14501953125, 0.265625, 0.90576171875, 0.1337890625, 0.56884765625, 0.99951171875, 0.8994140625, 0.0218353271484375, 1.0, 1.0, 0.810546875, 0.75830078125, 1.0, 1.0, 0.9970703125, 1.0, 0.9873046875, 0.62060546875, 0.181884765625, 1.0, 1.0, 1.0, 0.71923828125, 0.0, 0.72216796875, 3.063678741455078e-05, 0.00016641616821289062, 0.04681396484375]], "normalized_score": [0.0], "tokens": [["\u2581teams", "\u2581not", "\u2581yet", "\u2581mentioned", "\u2581in", "\u2581our", "\u2581conversation", ",", "\u2581such", "\u2581as", "\u2581the", "\u2581Texas", "\u2581R", "angers", ",", "\u2581T", "ampa", "\u2581Bay", "\u2581R", "ays", ",", "\u2581and", "\u2581Seattle", "\u2581Mar", "in", "ers", ".", "\u2581#####", "#", "\u2581P", "REF", "ACE"]], "entropy": [[3.376953125, 2.544921875, 2.193359375, 2.71875, 2.369140625, 1.61328125, 0.480712890625, 2.25, 2.072265625, 0.0027313232421875, 0.52490234375, 2.15625, 0.0022220611572265625, 0.0002486705780029297, 0.62353515625, 0.9990234375, 7.557868957519531e-05, 0.0006270408630371094, 0.01983642578125, 0.0002608299255371094, 0.07379150390625, 1.4814453125, 2.263671875, 0.0004825592041015625, 0.000850677490234375, 5.8770179748535156e-05, 0.9736328125, 0.90625, 1.3720703125, 2.48046875, 1.6708984375, 0.293212890625]], "avg_entropy": [1.1083103604614735], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Washington Nationals", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41823062492507085, "std_of_first_answer": 0.41823062492507085, "avg_entropy_of_first_answer": 1.1083103604614735, "lex_sim": 1.0}
{"question": "when does the new death of superman come out", "answer": ["I'm sorry, but I don't have information on future releases."], "scores": [[0.43798828125, 0.61181640625, 1.0, 0.9423828125, 0.98486328125, 0.148193359375, 0.90234375, 0.369873046875, 0.99755859375, 1.0, 0.9072265625, 0.65478515625, 0.457763671875, 0.055694580078125, 0.5087890625, 0.8271484375, 0.135498046875, 0.53271484375, 0.351318359375, 0.123046875, 0.86865234375, 0.7451171875, 0.2061767578125, 0.86328125, 0.90625, 0.99951171875, 0.99951171875, 0.99951171875, 0.99853515625, 0.96630859375, 1.4901161193847656e-05, 1.430511474609375e-06, 0.2359619140625, 2.5033950805664062e-06, 0.99169921875, 0.96826171875, 0.70654296875, 0.78662109375, 0.99853515625, 0.83154296875, 0.9970703125, 0.998046875, 0.99951171875, 0.99755859375, 0.9970703125, 0.9921875, 0.998046875, 0.92333984375]], "normalized_score": [0.302764892578125], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581but", "\u2581I", "\u2581don", "'", "t", "\u2581have", "\u2581information", "\u2581on", "\u2581future", "\u2581releases", ".", "\u2581My", "\u2581knowledge", "\u2581is", "\u2581up", "\u2581to", "\u2581date", "\u2581only", "\u2581until", "\u2581", "2", "0", "2", "1", ".", "\u2581\"", "For", "\u2581the", "\u2581Son", "\u2581of", "\u2581Man", "\u2581is", "\u2581come", "\u2581to", "\u2581seek", "\u2581and", "\u2581to", "\u2581save", "\u2581that", "\u2581which", "\u2581was", "\u2581lost", ".\""]], "entropy": [[2.138671875, 1.169921875, 0.001834869384765625, 0.239990234375, 0.0904541015625, 0.736328125, 0.5205078125, 1.3662109375, 0.0220794677734375, 0.0013713836669921875, 0.320068359375, 1.3310546875, 0.8056640625, 1.7998046875, 1.068359375, 0.75439453125, 2.34765625, 0.80859375, 0.810546875, 1.443359375, 0.419189453125, 0.6201171875, 0.98046875, 0.57666015625, 0.37451171875, 0.003643035888671875, 0.0037384033203125, 0.0041961669921875, 0.01470947265625, 0.1888427734375, 1.3193359375, 0.361083984375, 3.755859375, 2.15234375, 0.07733154296875, 0.1453857421875, 0.9296875, 0.79443359375, 0.01383209228515625, 0.470703125, 0.0249176025390625, 0.01393890380859375, 0.004566192626953125, 0.0179290771484375, 0.021453857421875, 0.050079345703125, 0.014923095703125, 0.34033203125]], "avg_entropy": [0.6556476354598999], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2019", "score_of_biggest_cluster": 0.302764892578125, "score_of_first_answer": 0.302764892578125, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.430511474609375e-06, "avg_score": 0.302764892578125, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3447953657361118, "std_of_first_answer": 0.3447953657361118, "avg_entropy_of_first_answer": 0.6556476354598999, "lex_sim": 1.0}
{"question": "where's the tv show the crossing filmed", "answer": ["The TV show \"The Crossing\" is an American science fiction drama television series that is filmed on location in Vancouver, Canada."], "scores": [[0.244384765625, 0.2078857421875, 0.99560546875, 0.7666015625, 0.9990234375, 1.0, 1.0, 1.0, 0.133056640625, 0.201904296875, 0.9990234375, 0.763671875, 0.998046875, 0.90283203125, 0.363525390625, 1.0, 0.75244140625, 0.242431640625, 0.720703125, 1.0, 0.07781982421875, 0.9990234375, 0.9990234375, 0.83935546875, 1.0, 0.99951171875, 0.436767578125, 0.97705078125, 1.3709068298339844e-06, 0.0279998779296875, 2.0563602447509766e-05, 0.04095458984375, 0.0338134765625, 0.9892578125, 0.0011701583862304688, 4.082918167114258e-05, 0.0826416015625, 0.006145477294921875, 0.99853515625, 0.1319580078125, 0.325439453125, 0.2027587890625]], "normalized_score": [0.1579362154006958], "tokens": [["\u2581The", "\u2581TV", "\u2581show", "\u2581\"", "The", "\u2581Cross", "ing", "\"", "\u2581is", "\u2581an", "\u2581American", "\u2581science", "\u2581fiction", "\u2581drama", "\u2581television", "\u2581series", "\u2581that", "\u2581is", "\u2581fil", "med", "\u2581on", "\u2581location", "\u2581in", "\u2581V", "ancouver", ",", "\u2581Canada", ".", "\u2581#", "T", "ech", "T", "ues", "day", ":", "\u2581Building", "\u2581the", "\u2581Ult", "imate", "\u2581Home", "\u2581Theater", "\u2581System"]], "entropy": [[1.513671875, 1.2255859375, 0.0312042236328125, 0.61767578125, 0.006832122802734375, 0.0020618438720703125, 2.0742416381835938e-05, 0.0008282661437988281, 0.474853515625, 0.748046875, 0.0091705322265625, 0.97509765625, 0.014495849609375, 0.466796875, 1.1875, 0.0015153884887695312, 0.86669921875, 1.0654296875, 0.869140625, 0.0001621246337890625, 0.300537109375, 0.0084991455078125, 0.00890350341796875, 0.8212890625, 0.0006656646728515625, 0.006511688232421875, 0.703125, 0.1373291015625, 1.060546875, 3.095703125, 0.43212890625, 3.978515625, 1.314453125, 0.07568359375, 0.951171875, 3.416015625, 2.705078125, 4.2734375, 0.01145172119140625, 3.0, 2.2890625, 2.3359375]], "avg_entropy": [0.9762579883847918], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "British Columbia, Canada", "score_of_biggest_cluster": 0.1579362154006958, "score_of_first_answer": 0.1579362154006958, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.3709068298339844e-06, "avg_score": 0.1579362154006958, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4170318140572401, "std_of_first_answer": 0.4170318140572401, "avg_entropy_of_first_answer": 0.9762579883847918, "lex_sim": 1.0}
{"question": "who sings god gave rock and roll to you", "answer": ["Kiss"], "scores": [[0.962890625, 0.8916015625]], "normalized_score": [0.9265606999397278], "tokens": [["\u2581K", "iss"]], "entropy": [[0.2347412109375, 0.345703125]], "avg_entropy": [0.29022216796875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the British band Argent", "score_of_biggest_cluster": 0.9265606999397278, "score_of_first_answer": 0.9265606999397278, "max_score_of_first_answer": 0.962890625, "min_score_of_first_answer": 0.8916015625, "avg_score": 0.9265606999397278, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.03564453125, "std_of_first_answer": 0.03564453125, "avg_entropy_of_first_answer": 0.29022216796875, "lex_sim": 1.0}
{"question": "when do they put the rockefeller tree up", "answer": ["Mid-November ######  ######  ######  ######  ######"], "scores": [[0.0152740478515625, 0.86279296875, 0.99560546875, 1.0, 0.0, 0.207763671875, 0.004444122314453125, 0.0008187294006347656, 0.88720703125, 0.442138671875, 0.5478515625, 0.97119140625, 0.89111328125, 0.8154296875, 0.98828125, 0.9287109375, 0.91455078125, 0.99462890625]], "normalized_score": [0.0], "tokens": [["\u2581Mid", "-", "Nov", "ember", "\u2581#####", "#", "\u2581", "\u2581#####", "#", "\u2581", "\u2581#####", "#", "\u2581", "\u2581#####", "#", "\u2581", "\u2581#####", "#"]], "entropy": [[2.548828125, 0.43994140625, 0.035186767578125, 0.0011625289916992188, 0.8642578125, 2.05859375, 2.515625, 1.9375, 0.6181640625, 2.47265625, 2.5078125, 0.2093505859375, 0.623046875, 1.162109375, 0.0889892578125, 0.415283203125, 0.5859375, 0.043182373046875]], "avg_entropy": [1.0626459651523166], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "mid November", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.39600798995681796, "std_of_first_answer": 0.39600798995681796, "avg_entropy_of_first_answer": 1.0626459651523166, "lex_sim": 1.0}
{"question": "who is covering the winter olympics in canada", "answer": ["NBC"], "scores": [[0.10101318359375, 0.95556640625]], "normalized_score": [0.3106844127178192], "tokens": [["\u2581N", "BC"]], "entropy": [[2.228515625, 0.196044921875]], "avg_entropy": [1.2122802734375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "TLN", "score_of_biggest_cluster": 0.3106844127178192, "score_of_first_answer": 0.3106844127178192, "max_score_of_first_answer": 0.95556640625, "min_score_of_first_answer": 0.10101318359375, "avg_score": 0.3106844127178192, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.427276611328125, "std_of_first_answer": 0.427276611328125, "avg_entropy_of_first_answer": 1.2122802734375, "lex_sim": 1.0}
{"question": "when do primary ossification centers appear in an embryo", "answer": ["during the fetal development stage, typically between 6 and 8 weeks after conception."], "scores": [[0.28173828125, 0.320556640625, 0.2056884765625, 1.0, 0.88330078125, 0.84765625, 0.22314453125, 0.1182861328125, 0.239990234375, 0.615234375, 0.104248046875, 0.450927734375, 0.99853515625, 0.93505859375, 0.99755859375, 0.76708984375, 0.8662109375, 0.54931640625]], "normalized_score": [0.46047163009643555], "tokens": [["\u2581during", "\u2581the", "\u2581f", "etal", "\u2581development", "\u2581stage", ",", "\u2581typically", "\u2581between", "\u2581", "6", "\u2581and", "\u2581", "8", "\u2581weeks", "\u2581after", "\u2581conception", "."]], "entropy": [[2.912109375, 1.314453125, 2.158203125, 0.00044155120849609375, 0.46337890625, 0.7529296875, 1.6552734375, 2.31640625, 1.1357421875, 1.0966796875, 1.51171875, 1.06640625, 0.011383056640625, 0.304931640625, 0.01953125, 0.9375, 0.40087890625, 1.23046875]], "avg_entropy": [1.0715797742207844], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "prenatal development", "score_of_biggest_cluster": 0.46047163009643555, "score_of_first_answer": 0.46047163009643555, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.104248046875, "avg_score": 0.46047163009643555, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.32746236881898433, "std_of_first_answer": 0.32746236881898433, "avg_entropy_of_first_answer": 1.0715797742207844, "lex_sim": 1.0}
{"question": "what is the largest bill in american money", "answer": ["$100 bill (Also known as a \"C-note\" or a \"benjamin\") \\r\\nEileen has written extensively on environmental issues, sustainability, and corporate social responsibility for The Guardian"], "scores": [[0.8125, 1.0, 0.99951171875, 0.966796875, 0.30908203125, 0.041473388671875, 0.08880615234375, 0.88427734375, 1.0, 0.9189453125, 0.34814453125, 0.038330078125, 0.99462890625, 0.83935546875, 0.379638671875, 0.9990234375, 0.88232421875, 0.99951171875, 0.092529296875, 0.9921875, 0.94970703125, 1.7881393432617188e-07, 9.179115295410156e-06, 0.8076171875, 0.9931640625, 0.0005292892456054688, 4.470348358154297e-06, 0.998046875, 4.303455352783203e-05, 0.00284576416015625, 0.0025482177734375, 0.99658203125, 0.642578125, 3.135204315185547e-05, 0.24609375, 0.53125, 0.0218505859375, 1.0, 0.65380859375, 0.85400390625, 0.61376953125, 0.019134521484375, 1.0, 0.75, 0.994140625, 0.08599853515625, 0.0016126632690429688, 0.693359375]], "normalized_score": [0.08994334936141968], "tokens": [["\u2581$", "1", "0", "0", "\u2581bill", "\u2581(", "Also", "\u2581known", "\u2581as", "\u2581a", "\u2581\"", "C", "-", "note", "\"", "\u2581or", "\u2581a", "\u2581\"", "ben", "jamin", "\")", "\u2581\\", "r", "\\", "n", "E", "ile", "en", "\u2581has", "\u2581written", "\u2581extens", "ively", "\u2581on", "\u2581environmental", "\u2581issues", ",", "\u2581sust", "ain", "ability", ",", "\u2581and", "\u2581corpor", "ate", "\u2581social", "\u2581responsibility", "\u2581for", "\u2581The", "\u2581Guardian"]], "entropy": [[0.7197265625, 0.0013723373413085938, 0.002902984619140625, 0.1492919921875, 1.0546875, 0.79296875, 2.5703125, 0.39453125, 0.0007452964782714844, 0.370361328125, 1.0791015625, 0.343505859375, 0.04583740234375, 0.444580078125, 0.90234375, 0.01059722900390625, 0.3662109375, 0.0053253173828125, 0.4130859375, 0.055419921875, 0.25732421875, 0.17822265625, 0.4736328125, 0.7275390625, 0.052490234375, 3.73046875, 3.228515625, 0.0145416259765625, 3.396484375, 4.5703125, 3.736328125, 0.02984619140625, 1.052734375, 3.560546875, 2.72265625, 1.322265625, 3.68359375, 0.0005960464477539062, 0.66064453125, 0.56640625, 2.310546875, 3.705078125, 0.0021076202392578125, 0.748046875, 0.04925537109375, 1.162109375, 2.669921875, 1.8955078125]], "avg_entropy": [1.171471506357193], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "$100", "score_of_biggest_cluster": 0.08994334936141968, "score_of_first_answer": 0.08994334936141968, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.08994334936141968, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4169088835922086, "std_of_first_answer": 0.4169088835922086, "avg_entropy_of_first_answer": 1.171471506357193, "lex_sim": 1.0}
{"question": "the initial unification of upper and lower egypt took place during which period", "answer": ["Narmer (Menes)"], "scores": [[0.0038890838623046875, 1.0, 0.023101806640625, 0.607421875, 0.97509765625, 0.99658203125]], "normalized_score": [0.1938314139842987], "tokens": [["\u2581Nar", "mer", "\u2581(", "M", "enes", ")"]], "entropy": [[1.6005859375, 0.0003266334533691406, 1.6396484375, 1.568359375, 0.18310546875, 0.030059814453125]], "avg_entropy": [0.8370142777760824], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "3000 BC", "score_of_biggest_cluster": 0.1938314139842987, "score_of_first_answer": 0.1938314139842987, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0038890838623046875, "avg_score": 0.1938314139842987, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4370705905938554, "std_of_first_answer": 0.4370705905938554, "avg_entropy_of_first_answer": 0.8370142777760824, "lex_sim": 1.0}
{"question": "who sings the theme song for the proud family", "answer": ["Solange Knowles Proof that Apple is not perfect"], "scores": [[0.55029296875, 0.95458984375, 0.98828125, 1.0, 0.0, 0.0221099853515625, 3.5762786865234375e-07, 0.055145263671875, 0.10577392578125, 0.004039764404296875]], "normalized_score": [0.0], "tokens": [["\u2581Sol", "ange", "\u2581Know", "les", "\u2581Proof", "\u2581that", "\u2581Apple", "\u2581is", "\u2581not", "\u2581perfect"]], "entropy": [[2.369140625, 0.2271728515625, 0.08953857421875, 0.000949859619140625, 0.953125, 1.9462890625, 2.8515625, 3.462890625, 3.916015625, 3.28515625]], "avg_entropy": [1.910184097290039], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Destiny's Child", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43024254636887704, "std_of_first_answer": 0.43024254636887704, "avg_entropy_of_first_answer": 1.910184097290039, "lex_sim": 1.0}
{"question": "what is the most common blood type in sweden", "answer": ["Blood type AB is the most common in Sweden."], "scores": [[0.01313018798828125, 0.634765625, 0.0595703125, 0.59716796875, 0.98779296875, 0.9921875, 0.99658203125, 0.279541015625, 0.99560546875, 0.88037109375, 1.4901161193847656e-06, 9.232759475708008e-05, 0.9951171875, 0.11090087890625, 1.0, 0.9990234375, 0.0026493072509765625, 6.979703903198242e-05, 0.1439208984375, 0.0018911361694335938, 0.8955078125, 0.962890625, 0.01898193359375, 0.994140625, 0.8896484375, 0.9794921875, 0.00518798828125, 0.342529296875, 0.00481414794921875, 0.0216217041015625, 0.318359375, 0.6748046875, 0.99951171875, 1.0]], "normalized_score": [0.09656830877065659], "tokens": [["\u2581Blood", "\u2581type", "\u2581AB", "\u2581is", "\u2581the", "\u2581most", "\u2581common", "\u2581in", "\u2581Sweden", ".", "\u2581#", "Throw", "back", "Th", "urs", "day", ":", "\u2581\u2018", "The", "\u2581Lion", "\u2581King", "\u2019", "\u2581turns", "\u2581", "2", "5", ",", "\u2581still", "\u2581holds", "\u2581magic", "\u2581for", "\u2581aud", "ien", "ces"]], "entropy": [[2.087890625, 1.0400390625, 0.5302734375, 1.04296875, 0.093505859375, 0.05450439453125, 0.028411865234375, 0.63720703125, 0.039794921875, 0.5146484375, 0.351806640625, 3.9296875, 0.0335693359375, 1.896484375, 0.0008029937744140625, 0.007781982421875, 1.7724609375, 3.73046875, 3.998046875, 4.62109375, 0.46044921875, 0.238037109375, 2.94921875, 0.046783447265625, 0.353271484375, 0.127685546875, 1.8828125, 3.927734375, 2.619140625, 3.01953125, 2.748046875, 1.5556640625, 0.00475311279296875, 0.00010448694229125977]], "avg_entropy": [1.3630788343794205], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "A+", "score_of_biggest_cluster": 0.09656830877065659, "score_of_first_answer": 0.09656830877065659, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.4901161193847656e-06, "avg_score": 0.09656830877065659, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43413182734947237, "std_of_first_answer": 0.43413182734947237, "avg_entropy_of_first_answer": 1.3630788343794205, "lex_sim": 1.0}
{"question": "when will the next episode of my next guest needs no introduction", "answer": ["Available dates for new episodes of \"My Next Guest Needs No Introduction with David Letterman\" have not been officially announced by Netflix."], "scores": [[0.0012102127075195312, 0.86767578125, 0.0027923583984375, 0.76904296875, 0.1611328125, 0.9912109375, 0.59423828125, 0.68603515625, 0.794921875, 0.99951171875, 0.99951171875, 1.0, 0.99462890625, 1.0, 0.9990234375, 1.0, 0.3095703125, 1.0, 0.9970703125, 1.0, 1.0, 0.99853515625, 0.473876953125, 0.994140625, 0.82861328125, 0.66552734375, 0.9853515625, 0.147216796875, 0.990234375, 1.0, 1.0, 0.81787109375, 0.15283203125, 0.28369140625, 1.0, 0.85595703125, 0.99951171875, 0.81884765625, 0.205078125, 0.67724609375, 0.94970703125, 0.99951171875, 1.0, 0.91796875, 0.9306640625, 0.994140625, 1.0, 0.380126953125, 0.994140625, 0.5068359375]], "normalized_score": [0.5715113878250122], "tokens": [["\u2581Av", "ailable", "\u2581dates", "\u2581for", "\u2581new", "\u2581episodes", "\u2581of", "\u2581\"", "My", "\u2581Next", "\u2581Gu", "est", "\u2581Ne", "eds", "\u2581No", "\u2581Introduction", "\u2581with", "\u2581David", "\u2581Let", "ter", "man", "\"", "\u2581have", "\u2581not", "\u2581been", "\u2581officially", "\u2581announced", "\u2581by", "\u2581Net", "fli", "x", ".", "\u2581It", "'", "s", "\u2581best", "\u2581to", "\u2581check", "\u2581the", "\u2581official", "\u2581Net", "fli", "x", "\u2581website", "\u2581or", "\u2581social", "\u2581media", "\u2581pages", "\u2581for", "\u2581updates"]], "entropy": [[2.20703125, 0.41064453125, 2.60546875, 1.123046875, 2.46484375, 0.068359375, 1.6884765625, 0.96923828125, 0.76220703125, 0.004825592041015625, 0.005931854248046875, 0.00054168701171875, 0.039794921875, 3.0219554901123047e-05, 0.00775146484375, 0.0019140243530273438, 1.0166015625, 0.002025604248046875, 0.0289764404296875, 0.00019824504852294922, 0.00077056884765625, 0.01444244384765625, 1.63671875, 0.039642333984375, 0.46044921875, 0.7626953125, 0.08978271484375, 1.5126953125, 0.055633544921875, 0.00013971328735351562, 1.1324882507324219e-06, 0.7568359375, 2.1484375, 0.708984375, 7.450580596923828e-06, 0.6064453125, 0.0036754608154296875, 0.63671875, 1.2119140625, 0.9990234375, 0.255615234375, 0.00576019287109375, 3.546476364135742e-05, 0.483642578125, 0.27099609375, 0.04888916015625, 0.0013713836669921875, 1.208984375, 0.04400634765625, 1.287109375]], "avg_entropy": [0.5731866312026977], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "May 31, 2018", "score_of_biggest_cluster": 0.5715113878250122, "score_of_first_answer": 0.5715113878250122, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0012102127075195312, "avg_score": 0.5715113878250122, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.31149786851397887, "std_of_first_answer": 0.31149786851397887, "avg_entropy_of_first_answer": 0.5731866312026977, "lex_sim": 1.0}
{"question": "where was the movie a walk among the tombstones filmed", "answer": ["The movie \"A Walk Among the Tombstones\" was filmed in various locations in New York City, including the Bronx, Brooklyn, and Queens."], "scores": [[0.006839752197265625, 0.94287109375, 0.74169921875, 0.99853515625, 1.0, 0.98828125, 0.994140625, 1.0, 1.0, 0.99951171875, 1.0, 1.0, 0.99560546875, 0.93896484375, 1.0, 0.9267578125, 0.1993408203125, 0.99853515625, 0.79931640625, 0.96826171875, 1.0, 0.99853515625, 0.810546875, 0.91064453125, 0.152587890625, 0.564453125, 1.0, 0.5712890625, 0.50927734375, 1.0, 0.966796875, 0.8056640625, 0.284423828125, 0.9873046875, 1.3113021850585938e-06, 0.00010788440704345703, 0.050018310546875, 0.002422332763671875, 0.000701904296875, 0.0003733634948730469, 0.720703125, 0.0113525390625, 0.37060546875, 0.190185546875, 0.9990234375, 0.0289154052734375, 0.44580078125, 0.99755859375]], "normalized_score": [0.2252195179462433], "tokens": [["\u2581The", "\u2581movie", "\u2581\"", "A", "\u2581Walk", "\u2581Among", "\u2581the", "\u2581T", "omb", "st", "ones", "\"", "\u2581was", "\u2581fil", "med", "\u2581in", "\u2581various", "\u2581locations", "\u2581in", "\u2581New", "\u2581York", "\u2581City", ",", "\u2581including", "\u2581the", "\u2581Bron", "x", ",", "\u2581Brook", "lyn", ",", "\u2581and", "\u2581Queens", ".", "\u2581#", "7", "6", ":", "\u2581R", "eth", "inking", "\u2581How", "\u2581We", "\u2581Lear", "n", "\u2581with", "\u2581Dr", "."]], "entropy": [[0.363525390625, 0.27001953125, 0.69384765625, 0.01141357421875, 0.0018815994262695312, 0.0638427734375, 0.0380859375, 0.0006570816040039062, 4.506111145019531e-05, 0.0032138824462890625, -0.0, 0.00243377685546875, 0.033782958984375, 0.257568359375, 6.794929504394531e-06, 0.325439453125, 0.5947265625, 0.0123291015625, 0.5869140625, 0.1632080078125, 2.2292137145996094e-05, 0.01056671142578125, 0.6337890625, 0.447265625, 1.2919921875, 1.6416015625, 9.113550186157227e-05, 0.70947265625, 1.3046875, 0.0002105236053466797, 0.148193359375, 0.6767578125, 0.6787109375, 0.0845947265625, 1.0791015625, 2.818359375, 3.60546875, 2.322265625, 5.28515625, 3.283203125, 0.8876953125, 4.88671875, 2.416015625, 3.798828125, 0.01068115234375, 3.234375, 2.765625, 0.027099609375]], "avg_entropy": [0.9889893941581249], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "New York City", "score_of_biggest_cluster": 0.2252195179462433, "score_of_first_answer": 0.2252195179462433, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.3113021850585938e-06, "avg_score": 0.2252195179462433, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.3956299726963089, "std_of_first_answer": 0.3956299726963089, "avg_entropy_of_first_answer": 0.9889893941581249, "lex_sim": 1.0}
{"question": "who gave the famous objective co relative theory", "answer": ["Albert Einstein ##### ABOUT THE DIARY ########"], "scores": [[0.0291290283203125, 0.86767578125, 1.0, 0.0, 0.0004944801330566406, 0.0282745361328125, 0.99560546875, 0.271240234375, 9.053945541381836e-05, 0.0009617805480957031, 0.317138671875, 0.4326171875, 0.5888671875]], "normalized_score": [0.0], "tokens": [["\u2581Albert", "\u2581Ein", "stein", "\u2581#####", "\u2581A", "BO", "UT", "\u2581THE", "\u2581DI", "ARY", "\u2581###", "####", "#"]], "entropy": [[1.416015625, 0.46435546875, 0.0002472400665283203, 1.123046875, 1.91015625, 3.12890625, 0.031829833984375, 2.79296875, 1.408203125, 1.5908203125, 3.154296875, 1.0986328125, 1.5]], "avg_entropy": [1.5091907244462233], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "T.S. Eliot", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3796577352842356, "std_of_first_answer": 0.3796577352842356, "avg_entropy_of_first_answer": 1.5091907244462233, "lex_sim": 1.0}
{"question": "what is the baby elephants name in jungle book", "answer": ["Tabaqui #AtoZChallenge: Z is for Zambia and Zanzibar"], "scores": [[0.0210418701171875, 0.8447265625, 0.9931640625, 6.556510925292969e-07, 0.007110595703125, 0.0003287792205810547, 0.9638671875, 0.98974609375, 0.99462890625, 2.09808349609375e-05, 0.0005064010620117188, 0.0270538330078125, 0.96142578125, 0.380126953125, 0.0011157989501953125, 0.369140625, 0.0157470703125, 0.77685546875, 0.015899658203125, 1.0, 0.99658203125]], "normalized_score": [0.034647513180971146], "tokens": [["\u2581T", "aba", "qui", "\u2581#", "A", "to", "Z", "Ch", "allenge", ":", "\u2581Z", "\u2581is", "\u2581for", "\u2581Z", "amb", "ia", "\u2581and", "\u2581Z", "anz", "ib", "ar"]], "entropy": [[2.798828125, 0.6044921875, 0.049957275390625, 0.44677734375, 4.71484375, 0.767578125, 0.25634765625, 0.07745361328125, 0.039093017578125, 0.92724609375, 4.14453125, 2.7109375, 0.295654296875, 2.505859375, 2.021484375, 1.3076171875, 2.458984375, 1.2880859375, 1.5517578125, 0.0016450881958007812, 0.0289154052734375]], "avg_entropy": [1.380861418587821], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Hathi Jr.", "score_of_biggest_cluster": 0.034647513180971146, "score_of_first_answer": 0.034647513180971146, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 6.556510925292969e-07, "avg_score": 0.034647513180971146, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4488236705686798, "std_of_first_answer": 0.4488236705686798, "avg_entropy_of_first_answer": 1.380861418587821, "lex_sim": 1.0}
{"question": "panic at the disco la devotee video cast", "answer": ["The video for \"L.A. Devotee\" features lead vocalist Brendon Urie and two other lead singers, one dressed as Elvis Presley and the other as Kurt Cobain."], "scores": [[0.28759765625, 0.1614990234375, 0.6806640625, 0.93896484375, 0.41748046875, 0.65185546875, 0.9990234375, 0.998046875, 0.998046875, 1.0, 1.0, 0.99951171875, 0.022186279296875, 0.1396484375, 0.476318359375, 1.0, 0.9921875, 0.9267578125, 1.0, 1.0, 0.99951171875, 0.32470703125, 0.0140380859375, 0.025482177734375, 0.0006766319274902344, 0.1639404296875, 1.0, 0.76220703125, 0.09716796875, 0.0128021240234375, 0.8173828125, 0.01727294921875, 0.97412109375, 0.98486328125, 1.0, 0.86669921875, 0.93994140625, 0.99853515625, 0.7978515625, 0.0238494873046875, 0.99951171875, 1.0, 0.7890625, 8.225440979003906e-06, 3.135204315185547e-05, 0.01418304443359375, 0.004878997802734375, 0.0044097900390625]], "normalized_score": [0.17987561225891113], "tokens": [["\u2581The", "\u2581video", "\u2581for", "\u2581\"", "L", ".", "A", ".", "\u2581Dev", "ote", "e", "\"", "\u2581features", "\u2581lead", "\u2581vocal", "ist", "\u2581Br", "end", "on", "\u2581U", "rie", "\u2581and", "\u2581two", "\u2581other", "\u2581lead", "\u2581sing", "ers", ",", "\u2581one", "\u2581dressed", "\u2581as", "\u2581El", "vis", "\u2581Pres", "ley", "\u2581and", "\u2581the", "\u2581other", "\u2581as", "\u2581Kurt", "\u2581Cob", "ain", ".", "\u2581#", "My", "Story", ":", "\u2581How"]], "entropy": [[2.873046875, 0.56494140625, 1.009765625, 0.2783203125, 1.951171875, 1.8046875, 0.01119232177734375, 0.01509857177734375, 0.0157623291015625, 0.0003867149353027344, 3.9458274841308594e-05, 0.002735137939453125, 0.142578125, 2.0390625, 0.69873046875, 0.00041961669921875, 0.048858642578125, 0.29638671875, 0.0011386871337890625, 0.0017642974853515625, 0.004535675048828125, 1.9814453125, 3.34375, 1.966796875, 1.626953125, 1.7666015625, 1.722574234008789e-05, 1.2451171875, 3.6171875, 1.0302734375, 0.509765625, 0.96728515625, 0.13037109375, 0.09521484375, 0.0006732940673828125, 0.420166015625, 0.27685546875, 0.0110321044921875, 0.5419921875, 2.564453125, 0.00507354736328125, 0.00014781951904296875, 0.5732421875, 1.57421875, 3.115234375, 4.1953125, 3.0703125, 4.05859375]], "avg_entropy": [1.0510147797564666], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Noah Schnapp", "score_of_biggest_cluster": 0.17987561225891113, "score_of_first_answer": 0.17987561225891113, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 8.225440979003906e-06, "avg_score": 0.17987561225891113, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42379593596667964, "std_of_first_answer": 0.42379593596667964, "avg_entropy_of_first_answer": 1.0510147797564666, "lex_sim": 1.0}
{"question": "when was the last bear killed in the uk", "answer": ["I'm not sure, can you provide more context or specify the type of bear?"], "scores": [[0.30224609375, 0.40625, 0.99951171875, 0.102294921875, 0.7685546875, 0.332275390625, 0.226806640625, 0.99755859375, 0.50244140625, 0.91845703125, 0.90087890625, 0.6015625, 0.4921875, 0.2373046875, 0.61767578125, 0.9990234375, 0.99365234375, 0.339599609375, 4.76837158203125e-07, 0.00799560546875, 0.06829833984375, 0.0673828125, 8.541345596313477e-05, 0.0012302398681640625, 0.28955078125, 0.0014600753784179688, 0.998046875]], "normalized_score": [0.104673370718956], "tokens": [["\u2581I", "'", "m", "\u2581not", "\u2581sure", ",", "\u2581can", "\u2581you", "\u2581provide", "\u2581more", "\u2581context", "\u2581or", "\u2581specify", "\u2581the", "\u2581type", "\u2581of", "\u2581bear", "?", "\u2581#", "2", "2", "9", "\u2581W", "aters", "hed", "\u2581Prote", "ction"]], "entropy": [[2.498046875, 1.5693359375, 0.00496673583984375, 0.419921875, 0.82421875, 1.6611328125, 2.2578125, 0.019866943359375, 1.169921875, 0.37451171875, 0.35546875, 0.9677734375, 1.3701171875, 1.4599609375, 1.513671875, 0.00716400146484375, 0.04437255859375, 0.68505859375, 0.83837890625, 5.56640625, 2.7734375, 3.357421875, 2.859375, 4.15234375, 3.326171875, 4.12109375, 0.0179443359375]], "avg_entropy": [1.6376258002387152], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "c. 1000 AD", "score_of_biggest_cluster": 0.104673370718956, "score_of_first_answer": 0.104673370718956, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 4.76837158203125e-07, "avg_score": 0.104673370718956, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.36845006411507963, "std_of_first_answer": 0.36845006411507963, "avg_entropy_of_first_answer": 1.6376258002387152, "lex_sim": 1.0}
{"question": "most consecutive games with 20+ points - nba history", "answer": ["Kareem Abdul-Jabbar, 17 consecutive games in the 1971-1972 season."], "scores": [[0.03466796875, 0.6962890625, 0.99951171875, 0.99951171875, 1.0, 0.99462890625, 1.0, 0.9990234375, 0.99951171875, 0.1649169921875, 0.5859375, 0.759765625, 0.515625, 0.0963134765625, 0.99169921875, 0.311767578125, 0.4990234375, 0.99951171875, 1.0, 1.0, 0.78271484375, 0.99072265625, 0.98828125, 0.751953125, 1.0, 1.0, 1.0, 0.994140625, 0.63232421875, 1.615285873413086e-05, 1.1861324310302734e-05, 0.0012292861938476562, 0.017303466796875, 7.62939453125e-06, 0.239990234375, 0.00933837890625, 0.0020084381103515625, 0.1015625, 0.6240234375, 0.2352294921875, 0.016143798828125, 0.97021484375]], "normalized_score": [0.15678296983242035], "tokens": [["\u2581K", "are", "em", "\u2581Abd", "ul", "-", "J", "ab", "bar", ",", "\u2581", "1", "7", "\u2581consecutive", "\u2581games", "\u2581in", "\u2581the", "\u2581", "1", "9", "7", "1", "-", "1", "9", "7", "2", "\u2581season", ".", "\u2581#", "Book", "Re", "view", "\u2581::", "\u2581The", "\u2581W", "ishing", "\u2581Tree", "\u2581by", "\u2581Mary", "\u2581Ho", "oper"]], "entropy": [[1.1748046875, 0.7373046875, 0.002910614013671875, 0.004177093505859375, 6.097555160522461e-05, 0.0340576171875, 0.001773834228515625, 0.007904052734375, 0.005329132080078125, 2.1015625, 1.7509765625, 0.9853515625, 1.6396484375, 1.0126953125, 0.057281494140625, 1.7509765625, 0.7109375, 0.006618499755859375, 0.00030994415283203125, 5.7756900787353516e-05, 0.52392578125, 0.0684814453125, 0.06805419921875, 0.56103515625, 7.30752944946289e-05, 0.00017082691192626953, 0.00031757354736328125, 0.040130615234375, 1.0673828125, 0.176513671875, 2.82421875, 2.0859375, 0.464111328125, 2.298828125, 4.03515625, 5.48046875, 2.986328125, 2.3046875, 1.708984375, 4.484375, 5.51171875, 0.202880859375]], "avg_entropy": [1.1637742689677648], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "126", "score_of_biggest_cluster": 0.15678296983242035, "score_of_first_answer": 0.15678296983242035, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 7.62939453125e-06, "avg_score": 0.15678296983242035, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4115682258313375, "std_of_first_answer": 0.4115682258313375, "avg_entropy_of_first_answer": 1.1637742689677648, "lex_sim": 1.0}
{"question": "who is the minister of local government in zimbabwe", "answer": ["July 24, 2019"], "scores": [[0.2415771484375, 0.0007920265197753906, 0.1341552734375, 0.10504150390625, 0.77099609375, 0.95654296875, 0.98583984375, 1.0, 0.3916015625, 0.88818359375]], "normalized_score": [0.24175050854682922], "tokens": [["\u2581July", "\u2581", "2", "4", ",", "\u2581", "2", "0", "1", "9"]], "entropy": [[2.4140625, 0.057861328125, 1.7705078125, 2.16796875, 1.0673828125, 0.352294921875, 0.0775146484375, 0.0004596710205078125, 0.68359375, 0.42822265625]], "avg_entropy": [0.9019868850708008], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Hon July Moyo", "score_of_biggest_cluster": 0.24175050854682922, "score_of_first_answer": 0.24175050854682922, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0007920265197753906, "avg_score": 0.24175050854682922, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3890547689616218, "std_of_first_answer": 0.3890547689616218, "avg_entropy_of_first_answer": 0.9019868850708008, "lex_sim": 1.0}
{"question": "where is the nfl game in london played", "answer": ["London Stadium ######"], "scores": [[0.001743316650390625, 0.386474609375, 0.0, 0.33984375]], "normalized_score": [0.0], "tokens": [["\u2581London", "\u2581Stadium", "\u2581#####", "#"]], "entropy": [[0.1673583984375, 1.6123046875, 1.5791015625, 2.53125]], "avg_entropy": [1.472503662109375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Twickenham Stadium", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.386474609375, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.18189350334353593, "std_of_first_answer": 0.18189350334353593, "avg_entropy_of_first_answer": 1.472503662109375, "lex_sim": 1.0}
{"question": "when did to kill a mockingbird become popular", "answer": ["The novel \"To Kill a Mockingbird\" was published in 1960 and has since remained a popular and influential work of literature."], "scores": [[0.152099609375, 0.75537109375, 0.47412109375, 1.0, 1.0, 0.9970703125, 1.0, 1.0, 1.0, 0.98486328125, 0.50830078125, 0.84228515625, 0.96533203125, 0.99267578125, 1.0, 1.0, 1.0, 1.0, 0.412353515625, 0.378662109375, 0.60546875, 0.01102447509765625, 0.78466796875, 0.82177734375, 0.8857421875, 0.288818359375, 1.0, 0.94482421875, 0.951171875, 0.7041015625, 0.92529296875, 0.1068115234375, 0.418212890625, 0.472412109375, 0.176513671875, 0.69140625, 1.0, 1.0, 0.46435546875, 0.65576171875, 0.998046875, 0.3974609375, 0.79638671875, 0.5537109375, 0.59619140625, 0.91943359375, 0.71044921875, 0.82861328125, 0.51416015625, 0.8115234375]], "normalized_score": [0.6197463870048523], "tokens": [["\u2581The", "\u2581novel", "\u2581\"", "To", "\u2581Kill", "\u2581a", "\u2581Mock", "ing", "bird", "\"", "\u2581was", "\u2581published", "\u2581in", "\u2581", "1", "9", "6", "0", "\u2581and", "\u2581has", "\u2581since", "\u2581remained", "\u2581a", "\u2581popular", "\u2581and", "\u2581influ", "ential", "\u2581work", "\u2581of", "\u2581literature", ".", "\u2581It", "\u2581has", "\u2581been", "\u2581a", "\u2581st", "ap", "le", "\u2581in", "\u2581high", "\u2581school", "\u2581and", "\u2581college", "\u2581curr", "icul", "ums", "\u2581and", "\u2581has", "\u2581won", "\u2581numerous"]], "entropy": [[2.025390625, 0.7763671875, 1.126953125, 0.0016050338745117188, 0.00014066696166992188, 0.020294189453125, 0.0020732879638671875, 0.00010293722152709961, 0.0017061233520507812, 0.08685302734375, 0.783203125, 0.459716796875, 0.1544189453125, 0.045501708984375, 1.3589859008789062e-05, 5.304813385009766e-06, 2.372264862060547e-05, 0.0009179115295410156, 1.193359375, 1.654296875, 0.97412109375, 0.283935546875, 0.568359375, 0.61328125, 0.49169921875, 1.1982421875, 0.0002892017364501953, 0.291748046875, 0.2379150390625, 0.7470703125, 0.292724609375, 0.81884765625, 1.3759765625, 1.2958984375, 1.7275390625, 1.3125, 0.001148223876953125, 5.841255187988281e-06, 0.70068359375, 1.20703125, 0.017608642578125, 1.43359375, 0.64306640625, 1.318359375, 0.6767578125, 0.283447265625, 0.9130859375, 0.6728515625, 1.09375, 0.599609375]], "avg_entropy": [0.6024818038940429], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1960", "score_of_biggest_cluster": 0.6197463870048523, "score_of_first_answer": 0.6197463870048523, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.01102447509765625, "avg_score": 0.6197463870048523, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.2824588633375032, "std_of_first_answer": 0.2824588633375032, "avg_entropy_of_first_answer": 0.6024818038940429, "lex_sim": 1.0}
{"question": "when did france and belgium invade the ruhr", "answer": ["1923"], "scores": [[0.63623046875, 0.99951171875, 1.0, 1.0, 0.99951171875]], "normalized_score": [0.9133517146110535], "tokens": [["\u2581", "1", "9", "2", "3"]], "entropy": [[0.74365234375, 0.004039764404296875, 0.0025119781494140625, 0.0016689300537109375, 0.005512237548828125]], "avg_entropy": [0.15147705078125], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "11 January 1923", "score_of_biggest_cluster": 0.9133517146110535, "score_of_first_answer": 0.9133517146110535, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.63623046875, "avg_score": 0.9133517146110535, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.14541032021271819, "std_of_first_answer": 0.14541032021271819, "avg_entropy_of_first_answer": 0.15147705078125, "lex_sim": 1.0}
{"question": "when does shadowhunters season 2 episode 17 come out", "answer": ["I'm sorry, I don't have access to current TV schedules."], "scores": [[0.4150390625, 0.60986328125, 1.0, 0.98046875, 0.98876953125, 0.68798828125, 0.39404296875, 0.998046875, 1.0, 0.84912109375, 0.03460693359375, 0.99951171875, 0.234375, 0.2249755859375, 0.587890625, 0.98095703125, 0.82666015625, 0.3369140625, 0.499755859375, 0.82275390625, 0.99951171875, 0.98046875, 0.5791015625, 0.77490234375, 0.7021484375, 0.9287109375, 0.10748291015625, 0.00894927978515625, 0.95654296875, 0.10565185546875, 0.8916015625, 0.68115234375, 0.73193359375, 0.8916015625, 0.91845703125, 0.03521728515625, 0.1002197265625, 0.98876953125, 5.960464477539062e-07, 0.044403076171875, 0.06439208984375, 0.07867431640625, 2.0265579223632812e-06, 0.5888671875, 0.8212890625, 0.00732421875, 0.99609375, 0.0008187294006347656]], "normalized_score": [0.19834206998348236], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581I", "\u2581don", "'", "t", "\u2581have", "\u2581access", "\u2581to", "\u2581current", "\u2581TV", "\u2581sched", "ules", ".", "\u2581You", "\u2581may", "\u2581want", "\u2581to", "\u2581check", "\u2581a", "\u2581TV", "\u2581guide", "\u2581or", "\u2581a", "\u2581source", "\u2581for", "\u2581information", "\u2581on", "\u2581the", "\u2581release", "\u2581date", "\u2581of", "\u2581television", "\u2581episodes", ".", "\u2581#", "1", "4", "4", "\u2581What", "\u2581is", "\u2581the", "\u2581definition", "\u2581of", "\u2581faith"]], "entropy": [[2.37890625, 1.1611328125, 0.002147674560546875, 0.1170654296875, 0.07391357421875, 0.98046875, 1.26171875, 0.0169219970703125, 6.455183029174805e-05, 0.430419921875, 1.08984375, 0.003482818603515625, 2.087890625, 1.9931640625, 0.880859375, 0.0950927734375, 0.7265625, 1.8251953125, 1.1572265625, 0.70166015625, 0.006023406982421875, 0.1187744140625, 1.1455078125, 0.89892578125, 0.87109375, 0.27880859375, 1.8359375, 0.7919921875, 0.2481689453125, 2.123046875, 0.36669921875, 1.3779296875, 1.0546875, 0.43310546875, 0.33984375, 1.5205078125, 0.373046875, 0.07659912109375, 0.68505859375, 5.46484375, 2.818359375, 2.7578125, 2.712890625, 2.056640625, 0.94287109375, 3.560546875, 0.032867431640625, 3.69140625]], "avg_entropy": [1.1576611138880253], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "February\u00a013,\u00a02017", "score_of_biggest_cluster": 0.19834206998348236, "score_of_first_answer": 0.19834206998348236, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539062e-07, "avg_score": 0.19834206998348236, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37910665068903404, "std_of_first_answer": 0.37910665068903404, "avg_entropy_of_first_answer": 1.1576611138880253, "lex_sim": 1.0}
{"question": "when does synapsis of homologous chromosomes occur in mitosis", "answer": ["Metaphase I \\r\\nThroughout her career, Nicole has worked with companies ranging in size from startups to Fortune 500 companies, and across a range of industries including technology, ret"], "scores": [[0.0760498046875, 0.99951171875, 1.0, 0.465576171875, 3.5762786865234375e-07, 2.0503997802734375e-05, 0.18310546875, 0.98583984375, 5.507469177246094e-05, 0.00687408447265625, 0.9990234375, 0.978515625, 1.7881393432617188e-07, 0.0221099853515625, 0.71337890625, 0.00482177734375, 0.1575927734375, 0.09808349609375, 0.0701904296875, 0.31494140625, 0.0137939453125, 0.10430908203125, 0.99951171875, 0.0102996826171875, 0.9873046875, 0.9287109375, 0.4072265625, 0.71630859375, 0.98193359375, 0.498046875, 0.998046875, 0.95751953125, 0.923828125, 0.99951171875, 0.9814453125, 0.33154296875, 0.4462890625, 0.12744140625, 0.1309814453125, 0.415771484375, 0.072265625, 0.99658203125, 0.96826171875, 1.0, 0.732421875, 0.60498046875, 0.99072265625, 0.0867919921875]], "normalized_score": [0.11310331523418427], "tokens": [["\u2581Met", "aph", "ase", "\u2581I", "\u2581\\", "r", "\\", "n", "T", "hr", "ough", "out", "\u2581her", "\u2581career", ",", "\u2581N", "icole", "\u2581has", "\u2581worked", "\u2581with", "\u2581companies", "\u2581r", "anging", "\u2581in", "\u2581size", "\u2581from", "\u2581start", "ups", "\u2581to", "\u2581Fort", "une", "\u2581", "5", "0", "0", "\u2581companies", ",", "\u2581and", "\u2581across", "\u2581a", "\u2581range", "\u2581of", "\u2581indust", "ries", "\u2581including", "\u2581technology", ",", "\u2581ret"]], "entropy": [[1.5126953125, 0.0035114288330078125, 2.2113323211669922e-05, 1.240234375, 1.03125, 0.1898193359375, 0.89013671875, 0.11883544921875, 1.7431640625, 0.8193359375, 0.00890350341796875, 0.1683349609375, 1.443359375, 4.56640625, 1.4677734375, 4.87890625, 4.234375, 2.103515625, 3.51953125, 1.92578125, 3.181640625, 2.384765625, 0.00559234619140625, 0.08074951171875, 0.10394287109375, 0.321533203125, 1.6591796875, 0.619140625, 0.1258544921875, 1.984375, 0.01541900634765625, 0.28125, 0.271728515625, 0.007110595703125, 0.13671875, 1.9375, 1.6181640625, 3.6875, 1.74609375, 1.3251953125, 1.19140625, 0.0258026123046875, 0.2373046875, 0.001300811767578125, 0.92529296875, 1.677734375, 0.06170654296875, 1.791015625]], "avg_entropy": [1.2348106143375237], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "prophase I of meiosis", "score_of_biggest_cluster": 0.11310331523418427, "score_of_first_answer": 0.11310331523418427, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.11310331523418427, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4120114912481238, "std_of_first_answer": 0.4120114912481238, "avg_entropy_of_first_answer": 1.2348106143375237, "lex_sim": 1.0}
{"question": "who is the secretary of state for northern ireland", "answer": ["Julian Smith #HolySmokes: It\u2019s Not a Pipe Dream!"], "scores": [[0.379150390625, 0.99951171875, 1.7881393432617188e-07, 0.0031032562255859375, 0.0135345458984375, 0.00048661231994628906, 0.104248046875, 0.0009851455688476562, 0.004375457763671875, 0.0439453125, 1.0, 0.0003566741943359375, 0.053955078125, 0.001041412353515625, 0.9970703125, 0.80126953125, 0.12353515625]], "normalized_score": [0.01448020152747631], "tokens": [["\u2581Julian", "\u2581Smith", "\u2581#", "H", "oly", "Sm", "okes", ":", "\u2581It", "\u2019", "s", "\u2581Not", "\u2581a", "\u2581Pi", "pe", "\u2581Dream", "!"]], "entropy": [[0.8515625, 0.007030487060546875, 0.88427734375, 4.6796875, 3.84765625, 4.03125, 3.4609375, 2.5, 3.865234375, 1.7353515625, 0.0010862350463867188, 3.4765625, 3.39453125, 4.49609375, 0.025390625, 0.93505859375, 2.345703125]], "avg_entropy": [2.38455374100629], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Karen Bradley", "score_of_biggest_cluster": 0.01448020152747631, "score_of_first_answer": 0.01448020152747631, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.01448020152747631, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39144244771340914, "std_of_first_answer": 0.39144244771340914, "avg_entropy_of_first_answer": 2.38455374100629, "lex_sim": 1.0}
{"question": "when was the last time minnesota vikings was in the super bowl", "answer": ["1970 #3 - 14:00 - 14:45 - B245 Main Hall"], "scores": [[0.71484375, 0.1282958984375, 0.998046875, 0.8505859375, 0.98779296875, 1.7881393432617188e-07, 0.005725860595703125, 0.004962921142578125, 0.07611083984375, 0.61962890625, 0.002597808837890625, 0.0243988037109375, 0.0806884765625, 0.024566650390625, 0.013671875, 0.2427978515625, 0.40185546875, 0.10760498046875, 0.94189453125, 0.048126220703125, 0.5126953125, 0.166748046875, 0.0024890899658203125, 0.011962890625, 0.006916046142578125, 0.0260009765625, 0.0001703500747680664, 0.008331298828125]], "normalized_score": [0.034306976944208145], "tokens": [["\u2581", "1", "9", "7", "0", "\u2581#", "3", "\u2581-", "\u2581", "1", "4", ":", "0", "0", "\u2581-", "\u2581", "1", "4", ":", "4", "5", "\u2581-", "\u2581B", "2", "4", "5", "\u2581Main", "\u2581Hall"]], "entropy": [[1.0087890625, 0.442626953125, 0.0203399658203125, 0.466064453125, 0.08111572265625, 1.484375, 3.56640625, 3.306640625, 3.662109375, 1.0888671875, 0.32958984375, 3.919921875, 2.685546875, 0.8642578125, 2.453125, 4.17578125, 2.025390625, 2.560546875, 0.46337890625, 1.375, 1.6923828125, 2.798828125, 4.86328125, 4.6953125, 3.47265625, 4.12109375, 3.54296875, 5.05859375]], "avg_entropy": [2.36517824445452], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1969", "score_of_biggest_cluster": 0.034306976944208145, "score_of_first_answer": 0.034306976944208145, "max_score_of_first_answer": 0.998046875, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.034306976944208145, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.34220023513975084, "std_of_first_answer": 0.34220023513975084, "avg_entropy_of_first_answer": 2.36517824445452, "lex_sim": 1.0}
{"question": "who wrote most of the declaration of independance", "answer": ["Thomas Jefferson #PopeFrancis says Mass for Cardinals who have died in the past year - FULL TEXT"], "scores": [[0.98974609375, 1.0, 1.7881393432617188e-06, 0.0018186569213867188, 0.00039458274841308594, 0.0086822509765625, 0.99169921875, 2.1338462829589844e-05, 0.0002982616424560547, 0.1634521484375, 0.0006175041198730469, 0.058746337890625, 0.06396484375, 0.09552001953125, 0.7294921875, 0.9404296875, 0.77685546875, 0.75927734375, 0.99658203125, 0.0115203857421875, 0.002727508544921875, 0.92822265625, 0.0679931640625, 0.99853515625]], "normalized_score": [0.03255851939320564], "tokens": [["\u2581Thomas", "\u2581Jefferson", "\u2581#", "P", "ope", "Fran", "cis", "\u2581says", "\u2581Mass", "\u2581for", "\u2581Card", "inals", "\u2581who", "\u2581have", "\u2581died", "\u2581in", "\u2581the", "\u2581past", "\u2581year", "\u2581-", "\u2581F", "ULL", "\u2581T", "EXT"]], "entropy": [[0.09027099609375, 0.00159454345703125, 1.080078125, 5.19921875, 4.48828125, 3.27734375, 0.056976318359375, 2.556640625, 3.814453125, 2.46484375, 3.650390625, 0.276611328125, 1.83984375, 0.826171875, 0.951171875, 0.3447265625, 0.748046875, 0.6220703125, 0.026824951171875, 2.314453125, 4.8125, 0.5390625, 2.091796875, 0.01351165771484375]], "avg_entropy": [1.7536201477050781], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Thomas Jefferson", "score_of_biggest_cluster": 0.03255851939320564, "score_of_first_answer": 0.03255851939320564, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-06, "avg_score": 0.03255851939320564, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4392428614504573, "std_of_first_answer": 0.4392428614504573, "avg_entropy_of_first_answer": 1.7536201477050781, "lex_sim": 1.0}
{"question": "which state is the richest state in nigeria", "answer": ["Lagos #FridayFlash: One Day in the Life of a Ghost"], "scores": [[0.947265625, 1.0, 1.1920928955078125e-07, 0.006954193115234375, 0.0018243789672851562, 1.0, 0.000911712646484375, 0.97314453125, 0.00024962425231933594, 0.0012664794921875, 0.004154205322265625, 0.1409912109375, 0.464599609375, 0.9423828125, 0.9560546875, 0.5224609375, 0.0003104209899902344]], "normalized_score": [0.020234405994415283], "tokens": [["\u2581Lag", "os", "\u2581#", "F", "rid", "ay", "Fl", "ash", ":", "\u2581One", "\u2581Day", "\u2581in", "\u2581the", "\u2581Life", "\u2581of", "\u2581a", "\u2581Ghost"]], "entropy": [[0.38671875, 0.0011777877807617188, 1.24609375, 4.7265625, 2.900390625, 0.0018596649169921875, 2.208984375, 0.1617431640625, 1.6962890625, 4.203125, 3.2265625, 2.884765625, 1.435546875, 0.46728515625, 0.338623046875, 2.498046875, 1.4892578125]], "avg_entropy": [1.7572372099932503], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Lagos State", "score_of_biggest_cluster": 0.020234405994415283, "score_of_first_answer": 0.020234405994415283, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.020234405994415283, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.440828469226633, "std_of_first_answer": 0.440828469226633, "avg_entropy_of_first_answer": 1.7572372099932503, "lex_sim": 1.0}
{"question": "who was charlie writing to in perks of being a wallflower movie", "answer": ["his future self #26: The Easy Way - Interview with the CTO of a Unicorn Company"], "scores": [[0.0251617431640625, 0.44140625, 0.99267578125, 2.384185791015625e-07, 0.03436279296875, 0.01151275634765625, 0.0017366409301757812, 0.0213165283203125, 0.00012934207916259766, 0.00434112548828125, 0.058197021484375, 0.001129150390625, 4.0471553802490234e-05, 0.0989990234375, 0.7080078125, 0.102783203125, 0.00033473968505859375, 0.0008549690246582031, 0.51513671875, 0.1806640625, 0.036346435546875, 1.0, 0.9990234375, 0.310791015625]], "normalized_score": [0.01630409061908722], "tokens": [["\u2581his", "\u2581future", "\u2581self", "\u2581#", "2", "6", ":", "\u2581The", "\u2581E", "asy", "\u2581Way", "\u2581-", "\u2581Inter", "view", "\u2581with", "\u2581the", "\u2581C", "TO", "\u2581of", "\u2581a", "\u2581Un", "ic", "orn", "\u2581Company"]], "entropy": [[2.66015625, 1.3662109375, 0.0693359375, 1.36328125, 2.96875, 1.7822265625, 1.5751953125, 4.17578125, 2.78515625, 3.85546875, 3.15625, 0.78076171875, 5.05859375, 1.947265625, 1.6865234375, 1.07421875, 1.6376953125, 3.95703125, 2.09765625, 5.46875, 4.4453125, 0.0011043548583984375, 0.009246826171875, 2.41796875]], "avg_entropy": [2.347497542699178], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "an unknown recipient", "score_of_biggest_cluster": 0.01630409061908722, "score_of_first_answer": 0.01630409061908722, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.01630409061908722, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3428166695492216, "std_of_first_answer": 0.3428166695492216, "avg_entropy_of_first_answer": 2.347497542699178, "lex_sim": 1.0}
{"question": "who plays the woodsman in over the garden wall", "answer": ["Christopher Lloyd"], "scores": [[0.418212890625, 0.78515625]], "normalized_score": [0.5730292201042175], "tokens": [["\u2581Christopher", "\u2581Lloyd"]], "entropy": [[1.541015625, 1.5068359375]], "avg_entropy": [1.52392578125], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Christopher Lloyd", "score_of_biggest_cluster": 0.5730292201042175, "score_of_first_answer": 0.5730292201042175, "max_score_of_first_answer": 0.78515625, "min_score_of_first_answer": 0.418212890625, "avg_score": 0.5730292201042175, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.1834716796875, "std_of_first_answer": 0.1834716796875, "avg_entropy_of_first_answer": 1.52392578125, "lex_sim": 1.0}
{"question": "what is the big gold dome in jerusalem", "answer": ["the Dome of the Rock #4826: New Celebrity Fit Club 2/8/05: NBC premiered a new series of Celebrity Fit Club, a competitive reality"], "scores": [[0.059112548828125, 0.405029296875, 1.0, 0.99951171875, 0.99951171875, 0.998046875, 1.1920928955078125e-07, 0.005523681640625, 0.051025390625, 0.0908203125, 0.0924072265625, 0.0012111663818359375, 3.6597251892089844e-05, 0.0007824897766113281, 0.07958984375, 0.95849609375, 0.6865234375, 0.0072784423828125, 0.168212890625, 0.01445770263671875, 0.08929443359375, 0.88525390625, 0.0036907196044921875, 0.043243408203125, 0.353515625, 0.07879638671875, 0.08843994140625, 0.0191192626953125, 0.008575439453125, 0.11846923828125, 0.0005779266357421875, 0.64794921875, 0.1693115234375, 0.916015625, 0.0186920166015625, 0.01080322265625, 0.326416015625, 0.966796875, 0.99951171875, 0.99951171875, 0.990234375, 0.9990234375, 0.998046875, 0.5234375, 0.0501708984375, 0.004638671875, 0.95947265625, 0.7568359375]], "normalized_score": [0.07020363956689835], "tokens": [["\u2581the", "\u2581D", "ome", "\u2581of", "\u2581the", "\u2581Rock", "\u2581#", "4", "8", "2", "6", ":", "\u2581New", "\u2581C", "ele", "br", "ity", "\u2581F", "it", "\u2581Club", "\u2581", "2", "/", "8", "/", "0", "5", ":", "\u2581N", "BC", "\u2581premier", "ed", "\u2581a", "\u2581new", "\u2581series", "\u2581of", "\u2581C", "ele", "br", "ity", "\u2581F", "it", "\u2581Club", ",", "\u2581a", "\u2581compet", "itive", "\u2581reality"]], "entropy": [[0.52294921875, 1.02734375, 0.0009074211120605469, 0.005435943603515625, 0.003414154052734375, 0.01483154296875, 1.0078125, 5.37890625, 3.123046875, 3.1015625, 2.748046875, 2.98828125, 4.87890625, 4.484375, 3.33203125, 0.1947021484375, 0.9755859375, 2.435546875, 3.744140625, 1.08203125, 4.64453125, 0.62060546875, 0.556640625, 1.9775390625, 2.81640625, 0.861328125, 2.306640625, 3.947265625, 5.51953125, 1.89453125, 3.919921875, 0.7373046875, 1.591796875, 0.57177734375, 1.8388671875, 1.859375, 2.6640625, 0.16455078125, 0.005588531494140625, 0.00421905517578125, 0.0958251953125, 0.0080108642578125, 0.0195159912109375, 2.25, 2.603515625, 1.4111328125, 0.25048828125, 0.87109375]], "avg_entropy": [1.813790072997411], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Dome of the Rock", "score_of_biggest_cluster": 0.07020363956689835, "score_of_first_answer": 0.07020363956689835, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.07020363956689835, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4179269483718126, "std_of_first_answer": 0.4179269483718126, "avg_entropy_of_first_answer": 1.813790072997411, "lex_sim": 1.0}
{"question": "what is the coldest it has ever been in antarctica", "answer": ["-128.6 \u00b0F (-89.2 \u00b0C), on July 21, 1983 at Vostok Station"], "scores": [[0.9033203125, 0.1922607421875, 0.46728515625, 0.89453125, 0.9873046875, 0.8251953125, 0.2110595703125, 0.9951171875, 0.537109375, 0.998046875, 0.9892578125, 0.9931640625, 0.98681640625, 0.99072265625, 1.0, 0.03436279296875, 0.419921875, 0.8955078125, 0.9990234375, 0.97802734375, 0.99853515625, 0.935546875, 0.9970703125, 0.9990234375, 0.990234375, 0.998046875, 1.0, 0.49072265625, 0.8544921875, 0.99560546875, 1.0, 0.56982421875]], "normalized_score": [0.7103529572486877], "tokens": [["\u2581-", "1", "2", "8", ".", "6", "\u2581\u00b0", "F", "\u2581(-", "8", "9", ".", "2", "\u2581\u00b0", "C", "),", "\u2581on", "\u2581July", "\u2581", "2", "1", ",", "\u2581", "1", "9", "8", "3", "\u2581at", "\u2581V", "ost", "ok", "\u2581Station"]], "entropy": [[0.5556640625, 0.63916015625, 1.2939453125, 0.451416015625, 0.0899658203125, 0.56005859375, 1.650390625, 0.031768798828125, 1.6708984375, 0.0165557861328125, 0.0684814453125, 0.041290283203125, 0.0870361328125, 0.055145263671875, 0.0008816719055175781, 0.1988525390625, 1.85546875, 0.455322265625, 0.0080413818359375, 0.1270751953125, 0.01427459716796875, 0.336181640625, 0.022247314453125, 0.00605010986328125, 0.054656982421875, 0.01480865478515625, 0.0021305084228515625, 1.064453125, 0.427978515625, 0.0311737060546875, 0.0003981590270996094, 1.111328125]], "avg_entropy": [0.40447187423706055], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "\u2212128.6\u00a0\u00b0F", "score_of_biggest_cluster": 0.7103529572486877, "score_of_first_answer": 0.7103529572486877, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.03436279296875, "avg_score": 0.7103529572486877, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.27933802224855436, "std_of_first_answer": 0.27933802224855436, "avg_entropy_of_first_answer": 0.40447187423706055, "lex_sim": 1.0}
{"question": "when did the nfl adopt a salary cap", "answer": ["1993 #MondayMusings: Reflecting on the week that was - NTCE 2018 and Eid al-Fitr"], "scores": [[0.90380859375, 0.9990234375, 1.0, 1.0, 0.671875, 5.960464477539063e-08, 0.0019626617431640625, 0.0999755859375, 1.0, 0.00537872314453125, 0.9873046875, 0.00022995471954345703, 0.0010318756103515625, 0.83154296875, 0.88330078125, 0.98486328125, 0.60205078125, 0.0780029296875, 0.60791015625, 0.94091796875, 0.0034961700439453125, 0.0011138916015625, 0.0014181137084960938, 0.0032863616943359375, 0.0823974609375, 0.447509765625, 0.88818359375, 0.08642578125, 0.232666015625, 0.0418701171875, 0.00450897216796875, 0.441162109375, 0.12225341796875, 0.96240234375, 0.59912109375, 0.9990234375, 0.998046875]], "normalized_score": [0.07837596535682678], "tokens": [["\u2581", "1", "9", "9", "3", "\u2581#", "M", "ond", "ay", "Mus", "ings", ":", "\u2581Ref", "lect", "ing", "\u2581on", "\u2581the", "\u2581week", "\u2581that", "\u2581was", "\u2581-", "\u2581N", "T", "CE", "\u2581", "2", "0", "1", "8", "\u2581and", "\u2581E", "id", "\u2581al", "-", "F", "it", "r"]], "entropy": [[0.4580078125, 0.009002685546875, 0.0004734992980957031, 0.0011997222900390625, 0.63623046875, 0.8740234375, 4.578125, 3.24609375, 0.001895904541015625, 0.218994140625, 0.09783935546875, 0.958984375, 3.81640625, 0.63134765625, 0.53173828125, 0.114990234375, 2.3359375, 3.46875, 1.638671875, 0.299072265625, 2.076171875, 4.453125, 3.392578125, 3.0546875, 4.65234375, 1.615234375, 0.689453125, 0.55078125, 1.5400390625, 3.958984375, 4.42578125, 3.310546875, 1.8291015625, 0.183837890625, 0.68896484375, 0.0116119384765625, 0.01580810546875]], "avg_entropy": [1.631536084252435], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the 1994 season", "score_of_biggest_cluster": 0.07837596535682678, "score_of_first_answer": 0.07837596535682678, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.07837596535682678, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4215182865999248, "std_of_first_answer": 0.4215182865999248, "avg_entropy_of_first_answer": 1.631536084252435, "lex_sim": 1.0}
{"question": "who said some are born great in twelfth night", "answer": ["Sir Toby Belch ### What is the **Flashbake** Difference?"], "scores": [[0.389892578125, 0.9970703125, 1.0, 0.99609375, 1.0, 0.0, 0.0004413127899169922, 0.316650390625, 0.5087890625, 2.7060508728027344e-05, 3.516674041748047e-06, 0.5, 0.004421234130859375, 0.89794921875, 0.7587890625, 0.0015916824340820312, 0.14404296875, 0.8662109375]], "normalized_score": [0.0], "tokens": [["\u2581Sir", "\u2581T", "oby", "\u2581Bel", "ch", "\u2581###", "\u2581What", "\u2581is", "\u2581the", "\u2581**", "Fl", "ash", "b", "ake", "**", "\u2581D", "ifference", "?"]], "entropy": [[2.263671875, 0.0245208740234375, 0.0013093948364257812, 0.0301666259765625, 0.0015077590942382812, 0.765625, 4.3671875, 3.142578125, 1.5458984375, 3.736328125, 4.2265625, 1.4765625, 3.5390625, 0.568359375, 1.9033203125, 4.4140625, 1.35546875, 0.79541015625]], "avg_entropy": [1.8976445727878146], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Malvolio", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40807643045811187, "std_of_first_answer": 0.40807643045811187, "avg_entropy_of_first_answer": 1.8976445727878146, "lex_sim": 1.0}
{"question": "who played in the first fifty shades of grey", "answer": ["Jamie Dornan"], "scores": [[0.68603515625, 1.0, 0.99951171875, 1.0, 1.0]], "normalized_score": [0.9273141026496887], "tokens": [["\u2581Jam", "ie", "\u2581D", "orn", "an"]], "entropy": [[0.84716796875, 0.00015783309936523438, 0.004840850830078125, 0.00027370452880859375, 0.00031304359436035156]], "avg_entropy": [0.17055068016052247], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Marcia Gay Harden", "score_of_biggest_cluster": 0.9273141026496887, "score_of_first_answer": 0.9273141026496887, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.68603515625, "avg_score": 0.9273141026496887, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.12553725181402364, "std_of_first_answer": 0.12553725181402364, "avg_entropy_of_first_answer": 0.17055068016052247, "lex_sim": 1.0}
{"question": "when does dragon ball super episode 130 comes out", "answer": ["Not released yet #FearLessFriday: How to Take a Leap of Faith in Your Career"], "scores": [[0.02813720703125, 0.158447265625, 0.98388671875, 4.172325134277344e-07, 0.05810546875, 2.276897430419922e-05, 0.0234527587890625, 0.0134735107421875, 0.0238494873046875, 0.05438232421875, 0.56591796875, 0.001209259033203125, 0.0116119384765625, 0.178466796875, 0.0007662773132324219, 0.0941162109375, 0.10693359375, 0.990234375, 0.947265625, 0.990234375, 1.0, 0.293701171875, 0.68798828125, 0.81982421875]], "normalized_score": [0.043080419301986694], "tokens": [["\u2581Not", "\u2581released", "\u2581yet", "\u2581#", "F", "ear", "L", "ess", "F", "rid", "ay", ":", "\u2581How", "\u2581to", "\u2581Take", "\u2581a", "\u2581Le", "ap", "\u2581of", "\u2581Fa", "ith", "\u2581in", "\u2581Your", "\u2581Career"]], "entropy": [[1.66015625, 2.138671875, 0.11712646484375, 1.3544921875, 3.791015625, 2.306640625, 1.9111328125, 0.87841796875, 2.833984375, 4.05859375, 0.68896484375, 2.060546875, 5.12109375, 4.2890625, 4.38671875, 2.76953125, 4.0390625, 0.0684814453125, 0.302978515625, 0.07525634765625, 0.001689910888671875, 2.23828125, 1.490234375, 0.736328125]], "avg_entropy": [2.054935932159424], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "March 18, 2018", "score_of_biggest_cluster": 0.043080419301986694, "score_of_first_answer": 0.043080419301986694, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.043080419301986694, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3966624525247331, "std_of_first_answer": 0.3966624525247331, "avg_entropy_of_first_answer": 2.054935932159424, "lex_sim": 1.0}
{"question": "author of the hymn great is thy faithfulness", "answer": ["Thomas Obediah Chisholm #615899 - 03/04/18 09:59 PM 2018 Eligibility Thread"], "scores": [[0.9736328125, 0.38720703125, 0.84423828125, 1.0, 0.9990234375, 0.83544921875, 1.0, 1.0, 2.980232238769531e-07, 0.0027027130126953125, 0.205810546875, 0.017791748046875, 0.045654296875, 0.05810546875, 0.00859832763671875, 0.00038170814514160156, 0.04827880859375, 0.0310211181640625, 0.07513427734375, 0.1749267578125, 0.2646484375, 0.07440185546875, 0.935546875, 0.338623046875, 0.07952880859375, 0.0005941390991210938, 0.258056640625, 0.1348876953125, 0.9814453125, 0.1641845703125, 0.094482421875, 0.08074951171875, 0.01288604736328125, 0.150634765625, 0.304443359375, 0.295166015625, 0.3154296875, 0.00024580955505371094, 0.012176513671875, 0.705078125, 0.0004584789276123047]], "normalized_score": [0.06364740431308746], "tokens": [["\u2581Thomas", "\u2581Ob", "edia", "h", "\u2581Ch", "ish", "ol", "m", "\u2581#", "6", "1", "5", "8", "9", "9", "\u2581-", "\u2581", "0", "3", "/", "0", "4", "/", "1", "8", "\u2581", "0", "9", ":", "5", "9", "\u2581PM", "\u2581", "2", "0", "1", "8", "\u2581El", "ig", "ibility", "\u2581Thread"]], "entropy": [[0.25390625, 1.1875, 0.47607421875, 9.357929229736328e-06, 0.00930023193359375, 0.4501953125, 0.0001653432846069336, 5.644559860229492e-05, 0.82861328125, 3.970703125, 2.560546875, 1.5458984375, 2.435546875, 2.453125, 1.5693359375, 2.62890625, 5.796875, 2.439453125, 2.873046875, 3.23046875, 1.4189453125, 2.1953125, 0.34912109375, 1.19140625, 0.86279296875, 1.8798828125, 1.83203125, 2.33203125, 0.147705078125, 1.798828125, 2.3046875, 2.4296875, 3.44140625, 2.671875, 2.755859375, 2.7578125, 2.146484375, 3.125, 3.671875, 0.76513671875, 5.06640625]], "avg_entropy": [1.9476588731858788], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "William M. Runyan", "score_of_biggest_cluster": 0.06364740431308746, "score_of_first_answer": 0.06364740431308746, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.06364740431308746, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.36592655325457624, "std_of_first_answer": 0.36592655325457624, "avg_entropy_of_first_answer": 1.9476588731858788, "lex_sim": 1.0}
{"question": "where does the term jack mormon come from", "answer": ["The term \"Jack Mormon\" is a nickname for members of The Church of Jesus Christ of Latter-day Saints (LDS Church) who are perceived as not following the strict moral guidelines of the church's"], "scores": [[0.54736328125, 0.9775390625, 0.98095703125, 0.99169921875, 0.99951171875, 1.0, 1.0, 1.0, 0.495849609375, 0.4921875, 0.1151123046875, 1.0, 0.630859375, 0.6630859375, 0.99951171875, 0.876953125, 1.0, 0.9990234375, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 1.0, 1.0, 0.99951171875, 0.99951171875, 1.0, 0.8662109375, 0.99853515625, 0.99951171875, 0.978515625, 0.9912109375, 0.96875, 0.03271484375, 0.76806640625, 1.0, 0.85302734375, 0.9296875, 0.1903076171875, 0.90283203125, 0.8720703125, 0.0660400390625, 0.027130126953125, 1.0, 1.0, 0.84521484375, 0.99951171875, 0.94140625, 0.0190582275390625, 1.0]], "normalized_score": [0.6470249891281128], "tokens": [["\u2581The", "\u2581term", "\u2581\"", "Jack", "\u2581M", "orm", "on", "\"", "\u2581is", "\u2581a", "\u2581nick", "name", "\u2581for", "\u2581members", "\u2581of", "\u2581The", "\u2581Church", "\u2581of", "\u2581Jesus", "\u2581Christ", "\u2581of", "\u2581L", "atter", "-", "day", "\u2581Sain", "ts", "\u2581(", "L", "DS", "\u2581Church", ")", "\u2581who", "\u2581are", "\u2581perce", "ived", "\u2581as", "\u2581not", "\u2581following", "\u2581the", "\u2581strict", "\u2581moral", "\u2581gu", "idel", "ines", "\u2581of", "\u2581the", "\u2581church", "'", "s"]], "entropy": [[1.73828125, 0.1480712890625, 0.1285400390625, 0.047760009765625, 0.004436492919921875, 6.616115570068359e-06, 9.483098983764648e-05, 0.0023345947265625, 1.37109375, 1.7802734375, 1.8701171875, 0.0002741813659667969, 1.0419921875, 0.8984375, 0.004764556884765625, 0.3759765625, 0.00025272369384765625, 0.006683349609375, 0.00351715087890625, 0.0028514862060546875, 0.0028705596923828125, 0.00295257568359375, 6.192922592163086e-05, 0.0013093948364257812, 0.004161834716796875, 0.002460479736328125, 3.123283386230469e-05, 0.457275390625, 0.012908935546875, 0.0048675537109375, 0.12066650390625, 0.053985595703125, 0.14599609375, 0.64501953125, 0.9384765625, 0.00012421607971191406, 0.493896484375, 0.386962890625, 1.521484375, 0.472900390625, 0.65966796875, 1.9130859375, 0.98193359375, 1.4007091522216797e-05, 3.159046173095703e-06, 0.60400390625, 0.006137847900390625, 0.296630859375, 0.83544921875, 0.0007848739624023438]], "avg_entropy": [0.39983766198158266], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Jackson County, Missouri", "score_of_biggest_cluster": 0.6470249891281128, "score_of_first_answer": 0.6470249891281128, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0190582275390625, "avg_score": 0.6470249891281128, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3058413718226081, "std_of_first_answer": 0.3058413718226081, "avg_entropy_of_first_answer": 0.39983766198158266, "lex_sim": 1.0}
{"question": "malcom in the middle season 1 episode 3", "answer": ["\"Bullying\" #Bonas to host screening, discussion of groundbreaking film \u2018A Plastic Ocean\u2019 April 4"], "scores": [[0.50341796875, 0.1304931640625, 0.8212890625, 0.06622314453125, 0.953125, 2.1457672119140625e-06, 0.0025997161865234375, 1.1920928955078125e-07, 0.0003705024719238281, 7.772445678710938e-05, 0.015838623046875, 0.9462890625, 0.251953125, 0.61669921875, 0.9013671875, 0.0030975341796875, 0.99658203125, 1.0, 0.289794921875, 0.038177490234375, 0.002971649169921875, 0.00934600830078125, 0.986328125, 0.9990234375, 0.96923828125, 0.0183563232421875, 0.99365234375, 0.00923919677734375]], "normalized_score": [0.035249002277851105], "tokens": [["\u2581\"", "B", "ul", "lying", "\"", "\u2581#", "B", "onas", "\u2581to", "\u2581host", "\u2581screen", "ing", ",", "\u2581discussion", "\u2581of", "\u2581ground", "bre", "aking", "\u2581film", "\u2581\u2018", "A", "\u2581Pl", "astic", "\u2581Ocean", "\u2019", "\u2581April", "\u2581", "4"]], "entropy": [[2.2265625, 3.271484375, 1.1162109375, 0.845703125, 0.26318359375, 0.5673828125, 2.171875, 1.4697265625, 3.6796875, 4.26171875, 5.4921875, 0.26953125, 0.9814453125, 1.3349609375, 0.4287109375, 3.0, 0.0286102294921875, 0.0014400482177734375, 2.26171875, 1.8740234375, 3.67578125, 3.912109375, 0.0899658203125, 0.01157379150390625, 0.1934814453125, 3.298828125, 0.05218505859375, 1.0693359375]], "avg_entropy": [1.7089080129350935], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Home Alone 4", "score_of_biggest_cluster": 0.035249002277851105, "score_of_first_answer": 0.035249002277851105, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.035249002277851105, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4326976053811142, "std_of_first_answer": 0.4326976053811142, "avg_entropy_of_first_answer": 1.7089080129350935, "lex_sim": 1.0}
{"question": "where is the protien made in the cell", "answer": ["ribosomes #WalangPasok: Class suspensions for tomorrow, June 13, 2019"], "scores": [[0.8828125, 0.99853515625, 0.92724609375, 1.0, 5.960464477539063e-08, 0.0007505416870117188, 0.01103973388671875, 0.00774383544921875, 0.7099609375, 0.927734375, 0.94482421875, 0.00060272216796875, 0.050201416015625, 0.0850830078125, 0.48486328125, 0.2178955078125, 0.0241241455078125, 0.99853515625, 0.95166015625, 0.008087158203125, 0.9951171875, 0.5234375, 0.1337890625, 0.6591796875, 0.97802734375, 1.0, 1.0, 0.131103515625, 0.7958984375]], "normalized_score": [0.11411221325397491], "tokens": [["\u2581rib", "os", "om", "es", "\u2581#", "W", "al", "ang", "P", "as", "ok", ":", "\u2581Class", "\u2581susp", "ensions", "\u2581for", "\u2581tom", "orrow", ",", "\u2581June", "\u2581", "1", "3", ",", "\u2581", "2", "0", "1", "9"]], "entropy": [[0.59912109375, 0.01148223876953125, 0.26220703125, 0.0005559921264648438, 1.0126953125, 5.95703125, 3.853515625, 2.220703125, 2.037109375, 0.480224609375, 0.353759765625, 1.0908203125, 5.03515625, 0.86865234375, 0.88232421875, 1.2060546875, 2.943359375, 0.01476287841796875, 0.31396484375, 2.49609375, 0.03558349609375, 1.57421875, 2.328125, 1.2080078125, 0.159423828125, 0.0008597373962402344, 0.00024366378784179688, 0.39208984375, 0.6826171875]], "avg_entropy": [1.3110608068005791], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "in the cell nucleus", "score_of_biggest_cluster": 0.11411221325397491, "score_of_first_answer": 0.11411221325397491, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.11411221325397491, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4228033371725845, "std_of_first_answer": 0.4228033371725845, "avg_entropy_of_first_answer": 1.3110608068005791, "lex_sim": 1.0}
{"question": "who starred in an officer and a gentleman", "answer": ["Richard Gere"], "scores": [[0.9990234375, 1.0, 1.0]], "normalized_score": [0.999674379825592], "tokens": [["\u2581Richard", "\u2581G", "ere"]], "entropy": [[0.00978851318359375, 0.00041413307189941406, 0.00017321109771728516]], "avg_entropy": [0.0034586191177368164], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Richard Gere", "score_of_biggest_cluster": 0.999674379825592, "score_of_first_answer": 0.999674379825592, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.9990234375, "avg_score": 0.999674379825592, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.0004603559773349919, "std_of_first_answer": 0.0004603559773349919, "avg_entropy_of_first_answer": 0.0034586191177368164, "lex_sim": 1.0}
{"question": "who sang the song if loving you is wrong i don't want to be right", "answer": ["Luther Ingram #Hillary2020?"], "scores": [[0.87548828125, 0.93994140625, 0.99951171875, 1.7881393432617188e-07, 0.0022258758544921875, 0.0003094673156738281, 0.1495361328125, 0.00347900390625, 0.99462890625, 0.92626953125, 0.99755859375, 0.002445220947265625, 2.086162567138672e-06, 0.990234375, 0.00014579296112060547, 1.0, 0.05950927734375, 0.84423828125, 0.994140625, 0.17578125, 0.998046875, 0.99853515625, 0.1171875, 0.28564453125, 1.0, 0.9375]], "normalized_score": [0.05873331055045128], "tokens": [["\u2581Luther", "\u2581In", "gram", "\u2581#", "H", "ill", "ary", "2", "0", "2", "0", "?", "\u2581Form", "er", "\u2581Cl", "inton", "\u2581Ad", "vis", "er", "\u2581Sug", "gest", "s", "\u2581Another", "\u2581President", "ial", "\u2581Run"]], "entropy": [[0.71875, 0.27978515625, 0.006130218505859375, 0.75341796875, 4.62890625, 3.521484375, 3.865234375, 3.51953125, 0.046112060546875, 0.27734375, 0.0214385986328125, 1.6015625, 1.4072265625, 0.09429931640625, 2.400390625, 0.0006456375122070312, 3.404296875, 0.47900390625, 0.044830322265625, 3.43359375, 0.0182952880859375, 0.01763916015625, 3.423828125, 1.298828125, 0.0014247894287109375, 0.243408203125]], "avg_entropy": [1.365669507246751], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The Emotions", "score_of_biggest_cluster": 0.05873331055045128, "score_of_first_answer": 0.05873331055045128, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.05873331055045128, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.45322029606799413, "std_of_first_answer": 0.45322029606799413, "avg_entropy_of_first_answer": 1.365669507246751, "lex_sim": 1.0}
{"question": "guardians of the galaxy blue guy in prison", "answer": ["Peter Quill/Star-Lord #011-95 Punggol Field - Ponggol Jetty Restaurant"], "scores": [[0.1483154296875, 0.99755859375, 1.0, 0.11492919921875, 0.9951171875, 0.99853515625, 0.99951171875, 0.99951171875, 5.960464477539062e-07, 0.016357421875, 0.06488037109375, 0.01483917236328125, 0.001537322998046875, 0.02130126953125, 0.10467529296875, 2.372264862060547e-05, 1.1682510375976562e-05, 0.00015974044799804688, 0.69189453125, 0.0020427703857421875, 0.003284454345703125, 0.011627197265625, 0.01277923583984375, 0.916015625, 0.994140625, 0.00794219970703125, 0.88671875, 0.0190582275390625, 0.00046181678771972656, 0.99658203125]], "normalized_score": [0.02506082132458687], "tokens": [["\u2581Peter", "\u2581Qu", "ill", "/", "Star", "-", "L", "ord", "\u2581#", "0", "1", "1", "-", "9", "5", "\u2581P", "ung", "g", "ol", "\u2581Field", "\u2581-", "\u2581P", "ong", "g", "ol", "\u2581Jet", "ty", "\u2581R", "estaur", "ant"]], "entropy": [[2.1796875, 0.0202178955078125, 0.0011157989501953125, 1.7255859375, 0.031890869140625, 0.01296234130859375, 0.003360748291015625, 0.0029087066650390625, 0.9873046875, 2.521484375, 1.8232421875, 1.0478515625, 1.9462890625, 2.34765625, 2.40625, 2.478515625, 3.388671875, 1.775390625, 1.978515625, 3.583984375, 3.41796875, 4.90234375, 2.81640625, 0.765625, 0.05072021484375, 4.46484375, 0.880859375, 3.84765625, 0.436767578125, 0.0236663818359375]], "avg_entropy": [1.728991444905599], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Michael Rooker", "score_of_biggest_cluster": 0.02506082132458687, "score_of_first_answer": 0.02506082132458687, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539062e-07, "avg_score": 0.02506082132458687, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44982388223698094, "std_of_first_answer": 0.44982388223698094, "avg_entropy_of_first_answer": 1.728991444905599, "lex_sim": 1.0}
{"question": "when was the last wolf pack killed in yellowstone", "answer": ["1926 #826: One of the most powerful things you can do is to be a great leader who is guided by integrity, compassion, and wisdom."], "scores": [[0.306396484375, 0.8935546875, 0.99267578125, 0.1168212890625, 0.994140625, 4.76837158203125e-07, 0.006824493408203125, 0.0836181640625, 0.0117645263671875, 0.0005288124084472656, 0.000308990478515625, 0.42919921875, 0.94775390625, 0.137451171875, 7.468461990356445e-05, 0.007568359375, 0.230224609375, 0.9560546875, 0.95849609375, 0.38037109375, 0.324462890625, 0.07080078125, 0.3876953125, 0.0308074951171875, 0.00023996829986572266, 0.01110076904296875, 0.031829833984375, 0.0044708251953125, 0.9658203125, 0.99462890625, 0.0411376953125, 0.44189453125, 0.0797119140625, 0.9990234375, 0.99951171875, 0.865234375, 0.73876953125, 0.109130859375, 0.9365234375, 9.644031524658203e-05, 0.7177734375, 0.431884765625, 0.403076171875, 0.970703125, 0.9951171875, 0.1318359375, 0.99609375, 0.083251953125]], "normalized_score": [0.081368088722229], "tokens": [["\u2581", "1", "9", "2", "6", "\u2581#", "8", "2", "6", ":", "\u2581One", "\u2581of", "\u2581the", "\u2581most", "\u2581powerful", "\u2581things", "\u2581you", "\u2581can", "\u2581do", "\u2581is", "\u2581to", "\u2581be", "\u2581a", "\u2581great", "\u2581leader", "\u2581who", "\u2581is", "\u2581gu", "ided", "\u2581by", "\u2581integrity", ",", "\u2581comp", "ass", "ion", ",", "\u2581and", "\u2581wisdom", ".", "\u2581Today", ",", "\u2581I", "\u2581challenge", "\u2581you", "\u2581to", "\u2581reflect", "\u2581on", "\u2581what"]], "entropy": [[2.578125, 0.350830078125, 0.0472412109375, 0.49267578125, 0.042083740234375, 1.15234375, 5.68359375, 3.67578125, 1.474609375, 2.2734375, 4.58203125, 2.6015625, 0.358642578125, 1.7685546875, 1.3408203125, 3.302734375, 2.41015625, 0.2734375, 0.300537109375, 1.71484375, 3.642578125, 4.59765625, 2.74609375, 1.6435546875, 1.2001953125, 1.587890625, 3.326171875, 4.0390625, 0.15625, 0.045623779296875, 3.080078125, 1.091796875, 3.412109375, 0.0086669921875, 0.005954742431640625, 0.44580078125, 1.3232421875, 2.94921875, 0.3671875, 3.166015625, 0.951171875, 2.330078125, 1.7451171875, 0.177734375, 0.039337158203125, 1.8935546875, 0.0289154052734375, 1.388671875]], "avg_entropy": [1.7461202144622803], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1926", "score_of_biggest_cluster": 0.081368088722229, "score_of_first_answer": 0.081368088722229, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 4.76837158203125e-07, "avg_score": 0.081368088722229, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4053246913217052, "std_of_first_answer": 0.4053246913217052, "avg_entropy_of_first_answer": 1.7461202144622803, "lex_sim": 1.0}
{"question": "who was suite judy blue eyes written about", "answer": ["Judy Collins"], "scores": [[0.7392578125, 0.99853515625, 0.6259765625]], "normalized_score": [0.7731061577796936], "tokens": [["\u2581Jud", "y", "\u2581Collins"]], "entropy": [[0.9111328125, 0.00969696044921875, 1.2646484375]], "avg_entropy": [0.7284927368164062], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "singer/songwriter Judy Collins", "score_of_biggest_cluster": 0.7731061577796936, "score_of_first_answer": 0.7731061577796936, "max_score_of_first_answer": 0.99853515625, "min_score_of_first_answer": 0.6259765625, "avg_score": 0.7731061577796936, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.15594061845622723, "std_of_first_answer": 0.15594061845622723, "avg_entropy_of_first_answer": 0.7284927368164062, "lex_sim": 1.0}
{"question": "what song is played while raising the american flag", "answer": ["Reveille"], "scores": [[0.04180908203125, 0.998046875, 1.0]], "normalized_score": [0.34684908390045166], "tokens": [["\u2581Re", "ve", "ille"]], "entropy": [[1.3125, 0.020965576171875, 0.000308990478515625]], "avg_entropy": [0.4445915222167969], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Reveille", "score_of_biggest_cluster": 0.34684908390045166, "score_of_first_answer": 0.34684908390045166, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.04180908203125, "avg_score": 0.34684908390045166, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.45123587902520035, "std_of_first_answer": 0.45123587902520035, "avg_entropy_of_first_answer": 0.4445915222167969, "lex_sim": 1.0}
{"question": "where does kevins family go in home alone 2", "answer": ["Miami, Florida #IWD2019: Achieving Gender Parity in Construction"], "scores": [[0.12060546875, 0.263671875, 0.99755859375, 1.1920928955078125e-07, 0.0018186569213867188, 0.00024819374084472656, 0.4990234375, 0.63037109375, 0.025177001953125, 0.68701171875, 0.001049041748046875, 0.0017480850219726562, 0.8408203125, 0.671875, 1.0, 0.035369873046875, 0.9970703125, 0.451171875, 0.00011217594146728516, 0.9990234375]], "normalized_score": [0.03645201399922371], "tokens": [["\u2581Miami", ",", "\u2581Florida", "\u2581#", "I", "WD", "2", "0", "1", "9", ":", "\u2581Ach", "ieving", "\u2581G", "ender", "\u2581Par", "ity", "\u2581in", "\u2581Const", "ruction"]], "entropy": [[2.357421875, 1.3515625, 0.0221099853515625, 1.041015625, 5.63671875, 4.09375, 1.669921875, 1.4677734375, 0.1739501953125, 1.09375, 1.240234375, 4.3046875, 0.5126953125, 1.5048828125, 0.0016355514526367188, 1.064453125, 0.021697998046875, 2.263671875, 3.244140625, 0.00811767578125]], "avg_entropy": [1.6537095546722411], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Florida", "score_of_biggest_cluster": 0.03645201399922371, "score_of_first_answer": 0.03645201399922371, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.03645201399922371, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3982540371119239, "std_of_first_answer": 0.3982540371119239, "avg_entropy_of_first_answer": 1.6537095546722411, "lex_sim": 1.0}
{"question": "who came up with the term baby boomer", "answer": ["writer and social commentator, Edmund \"Eddie\" Leech #PUNK : Punk: Chaos to Couture @MetMuseum : May 9th, 2013"], "scores": [[0.036102294921875, 0.68994140625, 0.6669921875, 0.99609375, 1.0, 0.8662109375, 0.0059967041015625, 0.1444091796875, 0.264404296875, 0.9912109375, 0.9990234375, 1.0, 0.9765625, 0.87744140625, 2.0384788513183594e-05, 0.002742767333984375, 0.022003173828125, 0.70166015625, 3.8564205169677734e-05, 3.7550926208496094e-06, 0.0108642578125, 0.00010216236114501953, 0.8388671875, 0.167724609375, 0.99462890625, 0.99951171875, 1.0, 0.01206207275390625, 0.0447998046875, 0.08941650390625, 0.9990234375, 0.0007762908935546875, 0.002590179443359375, 0.9365234375, 0.99267578125, 0.07415771484375, 0.08544921875, 0.7236328125, 0.98046875, 0.9970703125, 1.0, 0.72705078125]], "normalized_score": [0.09060925990343094], "tokens": [["\u2581writer", "\u2581and", "\u2581social", "\u2581comment", "ator", ",", "\u2581Edmund", "\u2581\"", "E", "dd", "ie", "\"", "\u2581Le", "ech", "\u2581#", "P", "UN", "K", "\u2581:", "\u2581Punk", ":", "\u2581Cha", "os", "\u2581to", "\u2581C", "out", "ure", "\u2581@", "Met", "M", "useum", "\u2581:", "\u2581May", "\u2581", "9", "th", ",", "\u2581", "2", "0", "1", "3"]], "entropy": [[4.4453125, 2.099609375, 1.3203125, 0.03363037109375, 0.0007843971252441406, 0.998046875, 4.2421875, 3.48828125, 1.390625, 0.067626953125, 0.007518768310546875, 0.0003943443298339844, 0.1922607421875, 0.91162109375, 2.521484375, 5.62890625, 5.109375, 1.576171875, 1.7216796875, 4.63671875, 3.99609375, 5.05859375, 0.64599609375, 3.28515625, 0.0587158203125, 0.0034313201904296875, 0.0009293556213378906, 3.0546875, 0.5703125, 1.5546875, 0.01030731201171875, 3.373046875, 5.87890625, 0.50390625, 0.054107666015625, 1.921875, 2.916015625, 2.17578125, 0.131103515625, 0.03094482421875, 0.0014476776123046875, 0.9091796875]], "avg_entropy": [1.8220898423876082], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The Washington Post", "score_of_biggest_cluster": 0.09060925990343094, "score_of_first_answer": 0.09060925990343094, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 3.7550926208496094e-06, "avg_score": 0.09060925990343094, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43984838432948103, "std_of_first_answer": 0.43984838432948103, "avg_entropy_of_first_answer": 1.8220898423876082, "lex_sim": 1.0}
{"question": "when did lord howe island became a world heritage site", "answer": ["1982"], "scores": [[0.93017578125, 0.2061767578125, 0.99853515625, 0.9931640625, 0.998046875]], "normalized_score": [0.7172457575798035], "tokens": [["\u2581", "1", "9", "8", "2"]], "entropy": [[0.43505859375, 0.53515625, 0.0124969482421875, 0.043853759765625, 0.0157623291015625]], "avg_entropy": [0.208465576171875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "in 1982", "score_of_biggest_cluster": 0.7172457575798035, "score_of_first_answer": 0.7172457575798035, "max_score_of_first_answer": 0.99853515625, "min_score_of_first_answer": 0.2061767578125, "avg_score": 0.7172457575798035, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.31059386083844837, "std_of_first_answer": 0.31059386083844837, "avg_entropy_of_first_answer": 0.208465576171875, "lex_sim": 1.0}
{"question": "who played the music producer in pitch perfect 2", "answer": ["Luke Benward"], "scores": [[0.005428314208984375, 0.763671875, 1.0]], "normalized_score": [0.16064132750034332], "tokens": [["\u2581Luke", "\u2581Ben", "ward"]], "entropy": [[3.255859375, 1.482421875, 0.0014142990112304688]], "avg_entropy": [1.579898516337077], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Keegan-Michael Key", "score_of_biggest_cluster": 0.16064132750034332, "score_of_first_answer": 0.16064132750034332, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.005428314208984375, "avg_score": 0.16064132750034332, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42425845350371005, "std_of_first_answer": 0.42425845350371005, "avg_entropy_of_first_answer": 1.579898516337077, "lex_sim": 1.0}
{"question": "who played booster in jingle all the way", "answer": ["Sinbad generously supported by"], "scores": [[0.210205078125, 1.0, 0.0, 0.2435302734375, 0.004161834716796875, 0.331298828125]], "normalized_score": [0.0], "tokens": [["\u2581Sin", "bad", "\u2581gener", "ously", "\u2581supported", "\u2581by"]], "entropy": [[2.67578125, 0.002864837646484375, 0.693359375, 1.78515625, 4.0546875, 2.6171875]], "avg_entropy": [1.971506118774414], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Curtis Armstrong", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3365839024527463, "std_of_first_answer": 0.3365839024527463, "avg_entropy_of_first_answer": 1.971506118774414, "lex_sim": 1.0}
{"question": "where is the oldest civilization known to man", "answer": ["Sumerian civilization in Mesopotamia (modern-day Iraq) is one of the oldest known civilizations."], "scores": [[0.7705078125, 1.0, 0.292236328125, 0.7509765625, 0.99951171875, 0.81640625, 0.947265625, 1.0, 1.0, 1.0, 1.0, 0.359375, 0.890625, 1.0, 0.99560546875, 1.0, 0.99755859375, 1.0, 0.87255859375, 0.265380859375, 0.1417236328125, 1.0, 1.0, 0.98095703125, 0.978515625, 0.98291015625, 0.99560546875, 0.6865234375]], "normalized_score": [0.7777904272079468], "tokens": [["\u2581S", "umer", "ian", "\u2581civil", "ization", "\u2581in", "\u2581Mes", "op", "ot", "am", "ia", "\u2581(", "mod", "ern", "-", "day", "\u2581Ira", "q", ")", "\u2581is", "\u2581one", "\u2581of", "\u2581the", "\u2581oldest", "\u2581known", "\u2581civil", "izations", "."]], "entropy": [[1.1142578125, 3.62396240234375e-05, 1.732421875, 0.75390625, 0.003124237060546875, 0.763671875, 0.281982421875, 0.0017042160034179688, 0.0002124309539794922, 0.0001888275146484375, 2.6941299438476562e-05, 1.61328125, 0.5478515625, 4.9054622650146484e-05, 0.0290985107421875, 0.00021159648895263672, 0.01959228515625, 2.384185791015625e-05, 0.436279296875, 1.033203125, 0.70849609375, 0.0023040771484375, 0.0021686553955078125, 0.09521484375, 0.1165771484375, 0.094482421875, 0.0296173095703125, 1.033203125]], "avg_entropy": [0.3718995473214558], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Mesopotamia", "score_of_biggest_cluster": 0.7777904272079468, "score_of_first_answer": 0.7777904272079468, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.1417236328125, "avg_score": 0.7777904272079468, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.2544953805211506, "std_of_first_answer": 0.2544953805211506, "avg_entropy_of_first_answer": 0.3718995473214558, "lex_sim": 1.0}
{"question": "who won the super heavyweight gold medal at the 2000 olympics", "answer": ["Ruslan Nurudinov #360view: Fans deserve better transparency from governing bodies"], "scores": [[0.1632080078125, 0.99365234375, 0.006591796875, 0.98681640625, 0.99853515625, 0.99951171875, 5.960464477539063e-08, 0.009918212890625, 0.025390625, 0.0501708984375, 2.86102294921875e-06, 0.0067138671875, 0.0022525787353515625, 0.0236053466796875, 0.0004413127899169922, 0.56298828125, 0.2037353515625, 0.00037169456481933594, 0.9482421875, 0.998046875, 0.400390625, 0.005153656005859375, 0.99951171875, 0.99462890625]], "normalized_score": [0.027308134362101555], "tokens": [["\u2581Rus", "lan", "\u2581Nur", "ud", "in", "ov", "\u2581#", "3", "6", "0", "view", ":", "\u2581F", "ans", "\u2581des", "erve", "\u2581better", "\u2581trans", "par", "ency", "\u2581from", "\u2581gover", "ning", "\u2581bodies"]], "entropy": [[4.484375, 0.06170654296875, 1.154296875, 0.10400390625, 0.01485443115234375, 0.0058441162109375, 1.2119140625, 5.05859375, 2.763671875, 2.986328125, 4.28515625, 3.216796875, 5.2578125, 4.40625, 5.734375, 1.3671875, 3.107421875, 3.859375, 0.25439453125, 0.018310546875, 2.69921875, 3.72265625, 0.007205963134765625, 0.046875]], "avg_entropy": [2.3261926968892417], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Audley Harrison", "score_of_biggest_cluster": 0.027308134362101555, "score_of_first_answer": 0.027308134362101555, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.027308134362101555, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44367062291320297, "std_of_first_answer": 0.44367062291320297, "avg_entropy_of_first_answer": 2.3261926968892417, "lex_sim": 1.0}
{"question": "when did the movie varsity blues come out", "answer": ["February 17, 1999 #34 \u2013 An Introduction to OpenStreetMap"], "scores": [[0.123291015625, 0.998046875, 0.91943359375, 0.06439208984375, 0.974609375, 0.9990234375, 0.9990234375, 1.0, 1.0, 1.0, 1.7881393432617188e-07, 0.006256103515625, 0.0517578125, 7.557868957519531e-05, 0.0005054473876953125, 0.00017833709716796875, 0.74560546875, 0.0004634857177734375, 0.0025310516357421875, 0.9609375, 0.99609375]], "normalized_score": [0.03881612792611122], "tokens": [["\u2581February", "\u2581", "1", "7", ",", "\u2581", "1", "9", "9", "9", "\u2581#", "3", "4", "\u2581\u2013", "\u2581An", "\u2581Introduction", "\u2581to", "\u2581Open", "St", "reet", "Map"]], "entropy": [[0.6162109375, 0.0158538818359375, 0.41943359375, 0.89892578125, 0.127197265625, 0.006557464599609375, 0.0061187744140625, 1.1324882507324219e-06, 0.0001285076141357422, 0.00112152099609375, 0.380615234375, 5.62109375, 3.09765625, 3.017578125, 4.6484375, 4.3671875, 1.1298828125, 5.08203125, 4.640625, 0.2110595703125, 0.036895751953125]], "avg_entropy": [1.6345053144863673], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1999", "score_of_biggest_cluster": 0.03881612792611122, "score_of_first_answer": 0.03881612792611122, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.03881612792611122, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.472239664394055, "std_of_first_answer": 0.472239664394055, "avg_entropy_of_first_answer": 1.6345053144863673, "lex_sim": 1.0}
{"question": "what was the name of the horse in steptoe and son", "answer": ["Hercules"], "scores": [[0.49560546875, 0.7705078125]], "normalized_score": [0.6179546117782593], "tokens": [["\u2581Her", "cules"]], "entropy": [[3.37109375, 0.98876953125]], "avg_entropy": [2.179931640625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Hercules", "score_of_biggest_cluster": 0.6179546117782593, "score_of_first_answer": 0.6179546117782593, "max_score_of_first_answer": 0.7705078125, "min_score_of_first_answer": 0.49560546875, "avg_score": 0.6179546117782593, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.137451171875, "std_of_first_answer": 0.137451171875, "avg_entropy_of_first_answer": 2.179931640625, "lex_sim": 1.0}
{"question": "who plays addison shepherd on grey's anatomy", "answer": ["Kate Walsh"], "scores": [[0.97216796875, 0.9931640625, 1.0]], "normalized_score": [0.9883727431297302], "tokens": [["\u2581Kate", "\u2581Wal", "sh"]], "entropy": [[0.2254638671875, 0.04425048828125, 4.506111145019531e-05]], "avg_entropy": [0.0899198055267334], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Kathleen Erin Walsh", "score_of_biggest_cluster": 0.9883727431297302, "score_of_first_answer": 0.9883727431297302, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.97216796875, "avg_score": 0.9883727431297302, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.011842428231498208, "std_of_first_answer": 0.011842428231498208, "avg_entropy_of_first_answer": 0.0899198055267334, "lex_sim": 1.0}
{"question": "the recipient of first jnanpith award was an author which language", "answer": ["Rabindranath Tagore, in Bengali, for his play \"Chitra\" ### Introduction"], "scores": [[0.40869140625, 0.99951171875, 0.98779296875, 1.0, 0.9951171875, 1.0, 0.284423828125, 0.2215576171875, 0.95703125, 1.0, 0.003017425537109375, 0.83056640625, 0.94482421875, 0.002910614013671875, 0.8818359375, 0.421630859375, 0.7626953125, 0.958984375, 0.6806640625, 0.0, 0.0006566047668457031]], "normalized_score": [0.0], "tokens": [["\u2581Rab", "ind", "ran", "ath", "\u2581Tag", "ore", ",", "\u2581in", "\u2581Beng", "ali", ",", "\u2581for", "\u2581his", "\u2581play", "\u2581\"", "Ch", "it", "ra", "\"", "\u2581###", "\u2581Introduction"]], "entropy": [[1.58984375, 0.005458831787109375, 0.0679931640625, 0.001422882080078125, 0.03643798828125, 0.0008726119995117188, 1.87109375, 1.2958984375, 0.2000732421875, 1.531839370727539e-05, 1.283203125, 0.919921875, 0.260986328125, 2.017578125, 0.533203125, 1.6142578125, 0.97119140625, 0.17919921875, 0.763671875, 0.61572265625, 3.4140625]], "avg_entropy": [0.840100382055555], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Malayalam", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39060704084816117, "std_of_first_answer": 0.39060704084816117, "avg_entropy_of_first_answer": 0.840100382055555, "lex_sim": 1.0}
{"question": "when did john hart play the lone ranger", "answer": ["John Hart played the Lone Ranger in the 1956 television series \"The Lone Ranger\"."], "scores": [[0.32177734375, 0.99267578125, 0.525390625, 0.55810546875, 0.771484375, 1.0, 1.0, 1.0, 0.7734375, 0.912109375, 0.59228515625, 0.96240234375, 1.0, 0.89208984375, 0.9765625, 0.59375, 0.9951171875, 0.72412109375, 0.99951171875, 1.0, 1.0, 1.0, 1.0, 0.406982421875]], "normalized_score": [0.7976892590522766], "tokens": [["\u2581John", "\u2581Hart", "\u2581played", "\u2581the", "\u2581L", "one", "\u2581R", "anger", "\u2581in", "\u2581the", "\u2581", "1", "9", "5", "6", "\u2581television", "\u2581series", "\u2581\"", "The", "\u2581L", "one", "\u2581R", "anger", "\"."]], "entropy": [[2.015625, 0.07489013671875, 1.2412109375, 0.75927734375, 0.7138671875, 0.0003299713134765625, 0.0010766983032226562, 0.0002846717834472656, 0.66357421875, 0.38720703125, 1.2041015625, 0.1600341796875, 0.0006418228149414062, 0.448974609375, 0.11773681640625, 1.2880859375, 0.0335693359375, 1.0361328125, 0.006496429443359375, 0.0012264251708984375, 3.993511199951172e-05, 0.00206756591796875, 0.0008244514465332031, 0.82080078125]], "avg_entropy": [0.45741982758045197], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "from 1952 until 1953", "score_of_biggest_cluster": 0.7976892590522766, "score_of_first_answer": 0.7976892590522766, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.32177734375, "avg_score": 0.7976892590522766, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.21380685775969097, "std_of_first_answer": 0.21380685775969097, "avg_entropy_of_first_answer": 0.45741982758045197, "lex_sim": 1.0}
{"question": "who has won the cma entertainer of the year the most", "answer": ["Garth Brooks #BlackLivesMatter: A Year After Ferguson"], "scores": [[0.90234375, 1.0, 0.99951171875, 1.0, 1.7881393432617188e-07, 1.233816146850586e-05, 0.031707763671875, 0.9931640625, 0.99365234375, 0.99951171875, 0.00122833251953125, 0.024139404296875, 0.00020325183868408203, 5.5730342864990234e-05, 0.4541015625, 0.99853515625, 0.9990234375, 1.0]], "normalized_score": [0.03582925722002983], "tokens": [["\u2581Gar", "th", "\u2581Bro", "oks", "\u2581#", "Black", "L", "ives", "M", "atter", ":", "\u2581A", "\u2581Year", "\u2581After", "\u2581Fer", "g", "us", "on"]], "entropy": [[0.41064453125, 0.00020945072174072266, 0.0063018798828125, 4.971027374267578e-05, 1.7724609375, 3.35546875, 3.876953125, 0.059326171875, 0.050140380859375, 0.0029544830322265625, 1.2939453125, 5.90625, 4.44921875, 0.296875, 2.421875, 0.01137542724609375, 0.00844573974609375, 0.0016222000122070312]], "avg_entropy": [1.329117602772183], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Garth Brooks", "score_of_biggest_cluster": 0.03582925722002983, "score_of_first_answer": 0.03582925722002983, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.03582925722002983, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4704174570588857, "std_of_first_answer": 0.4704174570588857, "avg_entropy_of_first_answer": 1.329117602772183, "lex_sim": 1.0}
{"question": "when is the last time congress passed a complete budget", "answer": ["The last time Congress passed a complete budget was on April 15, 1997."], "scores": [[0.2171630859375, 0.615234375, 0.9892578125, 0.9794921875, 0.9990234375, 0.91015625, 0.978515625, 0.9736328125, 0.904296875, 0.038116455078125, 0.9052734375, 0.99853515625, 0.044189453125, 0.611328125, 0.92529296875, 0.99951171875, 0.92724609375, 1.0, 1.0, 0.99560546875, 0.892578125, 4.649162292480469e-06, 0.0006685256958007812, 0.2548828125, 0.95556640625, 0.0088653564453125, 0.025421142578125, 0.2144775390625, 0.0008826255798339844, 7.18832015991211e-05, 0.85791015625, 0.60693359375, 0.998046875, 0.91357421875, 0.0013666152954101562, 5.841255187988281e-06, 1.0, 0.93798828125, 0.65869140625]], "normalized_score": [0.13912028074264526], "tokens": [["\u2581The", "\u2581last", "\u2581time", "\u2581Congress", "\u2581passed", "\u2581a", "\u2581complete", "\u2581budget", "\u2581was", "\u2581on", "\u2581April", "\u2581", "1", "5", ",", "\u2581", "1", "9", "9", "7", ".", "\u2581#", "W", "her", "es", "R", "ey", "?", "\u2581The", "\u2581Fight", "\u2581for", "\u2581Represent", "ation", "\u2581in", "\u2581Disney", "\u2581Mer", "ch", "and", "ise"]], "entropy": [[2.732421875, 1.599609375, 0.0799560546875, 0.12115478515625, 0.00919342041015625, 0.40625, 0.138916015625, 0.1484375, 0.460205078125, 0.4990234375, 0.5283203125, 0.011138916015625, 0.75537109375, 1.4873046875, 0.2724609375, 0.004146575927734375, 0.2607421875, 0.00015401840209960938, 0.0015287399291992188, 0.03363037109375, 0.489501953125, 0.94970703125, 3.541015625, 1.7861328125, 0.28076171875, 0.59130859375, 1.03125, 1.2314453125, 0.56396484375, 4.5234375, 0.6689453125, 1.8583984375, 0.01629638671875, 0.521484375, 1.7666015625, 1.419921875, 0.0018711090087890625, 0.359619140625, 0.67578125]], "avg_entropy": [0.8160874415666629], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "FY2010", "score_of_biggest_cluster": 0.13912028074264526, "score_of_first_answer": 0.13912028074264526, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.649162292480469e-06, "avg_score": 0.13912028074264526, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4142693588843318, "std_of_first_answer": 0.4142693588843318, "avg_entropy_of_first_answer": 0.8160874415666629, "lex_sim": 1.0}
{"question": "where do the florida marlins have spring training", "answer": ["Jupiter, Florida #868: How to Be a Great Networker by Building Real Relationships with Dr. Ivan Misner"], "scores": [[0.399658203125, 1.0, 0.98828125, 0.96923828125, 1.1920928955078125e-07, 0.0004839897155761719, 0.00788116455078125, 0.06097412109375, 0.001220703125, 0.00021648406982421875, 0.01511383056640625, 0.0138702392578125, 0.40087890625, 0.01525115966796875, 0.0007138252258300781, 0.51953125, 0.1954345703125, 0.005115509033203125, 3.594160079956055e-05, 0.72265625, 1.0, 0.99853515625, 0.4296875, 0.147216796875, 0.88330078125, 0.51513671875, 0.97998046875, 1.0]], "normalized_score": [0.040434420108795166], "tokens": [["\u2581Jup", "iter", ",", "\u2581Florida", "\u2581#", "8", "6", "8", ":", "\u2581How", "\u2581to", "\u2581Be", "\u2581a", "\u2581Great", "\u2581Network", "er", "\u2581by", "\u2581Building", "\u2581Real", "\u2581Rel", "ations", "hips", "\u2581with", "\u2581Dr", ".", "\u2581Ivan", "\u2581Mis", "ner"]], "entropy": [[2.451171875, 0.0023174285888671875, 0.0748291015625, 0.14599609375, 0.79833984375, 3.6953125, 1.8427734375, 3.228515625, 3.033203125, 2.4453125, 2.896484375, 5.04296875, 2.546875, 4.015625, 4.66796875, 1.4326171875, 3.1640625, 4.59765625, 0.7548828125, 0.751953125, 0.0007805824279785156, 0.01261138916015625, 2.62109375, 4.69140625, 0.49267578125, 2.900390625, 0.150634765625, 0.0027599334716796875]], "avg_entropy": [2.0879006556102206], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Roger Dean Stadium", "score_of_biggest_cluster": 0.040434420108795166, "score_of_first_answer": 0.040434420108795166, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.040434420108795166, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4116244511403091, "std_of_first_answer": 0.4116244511403091, "avg_entropy_of_first_answer": 2.0879006556102206, "lex_sim": 1.0}
{"question": "when was kudzu introduced to the united states", "answer": ["Kudzu was introduced to the United States in 1876."], "scores": [[0.1324462890625, 1.0, 1.0, 0.9658203125, 0.611328125, 0.98486328125, 1.0, 0.9951171875, 1.0, 0.99658203125, 0.93115234375, 1.0, 1.0, 0.94775390625, 0.99951171875, 0.1282958984375, 7.748603820800781e-07, 0.00969696044921875, 0.0006651878356933594, 0.022247314453125, 0.046844482421875, 0.24462890625, 0.99365234375, 4.988908767700195e-05, 0.0006265640258789062, 0.00806427001953125, 0.0020465850830078125, 0.450439453125, 0.22705078125, 0.9931640625, 0.004024505615234375, 0.99951171875, 0.0020656585693359375, 0.69970703125, 0.50830078125, 0.3701171875, 0.99072265625, 0.74072265625, 0.212890625, 0.95068359375, 0.0010194778442382812, 0.90771484375]], "normalized_score": [0.11119500547647476], "tokens": [["\u2581K", "ud", "zu", "\u2581was", "\u2581introduced", "\u2581to", "\u2581the", "\u2581United", "\u2581States", "\u2581in", "\u2581", "1", "8", "7", "6", ".", "\u2581#", "T", "each", "ing", "T", "ues", "day", "\u2581\u2013", "\u2581L", "iz", "\u2581St", "in", "cel", "li", "\u2019", "s", "\u2581Top", "\u2581", "5", "\u2581T", "ips", "\u2581for", "\u2581Te", "aching", "\u2581Creative", "\u2581Writing"]], "entropy": [[1.15625, 0.0021514892578125, 5.1081180572509766e-05, 0.2020263671875, 0.7919921875, 0.09136962890625, 0.0021915435791015625, 0.034088134765625, 0.0008153915405273438, 0.030670166015625, 0.254150390625, 3.796815872192383e-05, 0.0004467964172363281, 0.2061767578125, 0.003376007080078125, 0.998046875, 0.6552734375, 3.48828125, 0.3232421875, 0.52978515625, 3.8203125, 1.6435546875, 0.039154052734375, 1.1435546875, 4.48046875, 3.017578125, 4.22265625, 1.1552734375, 1.7451171875, 0.06170654296875, 3.533203125, 0.003509521484375, 3.205078125, 1.666015625, 1.2001953125, 3.89453125, 0.078369140625, 1.1455078125, 4.31640625, 0.2178955078125, 4.44921875, 0.6015625]], "avg_entropy": [1.2955069513547988], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1876", "score_of_biggest_cluster": 0.11119500547647476, "score_of_first_answer": 0.11119500547647476, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 7.748603820800781e-07, "avg_score": 0.11119500547647476, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.432431145262375, "std_of_first_answer": 0.432431145262375, "avg_entropy_of_first_answer": 1.2955069513547988, "lex_sim": 1.0}
{"question": "the first element on the periodic table is", "answer": ["Hydrogen #OscarsSoWhite: For Many Black People, the Academy Awards Are a Source of Pain and Frustration"], "scores": [[0.48095703125, 1.0, 1.0, 1.430511474609375e-06, 6.616115570068359e-06, 8.672475814819336e-05, 0.026519775390625, 0.0235595703125, 0.8994140625, 0.005725860595703125, 0.0013628005981445312, 0.0003285408020019531, 0.04150390625, 0.0025081634521484375, 0.8984375, 0.109130859375, 0.445556640625, 0.99169921875, 0.5537109375, 0.308837890625, 0.041351318359375, 0.994140625, 0.59033203125, 0.990234375, 0.338623046875, 0.6767578125, 0.99658203125]], "normalized_score": [0.04795088246464729], "tokens": [["\u2581H", "ydro", "gen", "\u2581#", "O", "sc", "ars", "So", "White", ":", "\u2581For", "\u2581Many", "\u2581Black", "\u2581People", ",", "\u2581the", "\u2581Academy", "\u2581Awards", "\u2581Are", "\u2581a", "\u2581Source", "\u2581of", "\u2581P", "ain", "\u2581and", "\u2581Fr", "ustration"]], "entropy": [[0.75048828125, 0.00106048583984375, 0.00015616416931152344, 0.94140625, 0.68798828125, 2.7109375, 0.24072265625, 1.064453125, 0.72216796875, 1.3525390625, 5.25, 2.857421875, 2.9921875, 2.115234375, 0.6640625, 2.03515625, 1.708984375, 0.06610107421875, 2.1171875, 2.3125, 3.7734375, 0.0416259765625, 1.419921875, 0.057952880859375, 2.74609375, 1.3486328125, 0.028472900390625]], "avg_entropy": [1.4817367747977928], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Hydro\u00adgen", "score_of_biggest_cluster": 0.04795088246464729, "score_of_first_answer": 0.04795088246464729, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.430511474609375e-06, "avg_score": 0.04795088246464729, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4083963220705125, "std_of_first_answer": 0.4083963220705125, "avg_entropy_of_first_answer": 1.4817367747977928, "lex_sim": 1.0}
{"question": "prior to 1948 north and south vietnam were a part of", "answer": ["French Indochina"], "scores": [[0.93310546875, 0.99853515625, 0.99951171875, 1.0]], "normalized_score": [0.9823595881462097], "tokens": [["\u2581French", "\u2581Ind", "och", "ina"]], "entropy": [[0.368408203125, 0.014068603515625, 0.00461578369140625, 0.000751495361328125]], "avg_entropy": [0.09696102142333984], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "France", "score_of_biggest_cluster": 0.9823595881462097, "score_of_first_answer": 0.9823595881462097, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.93310546875, "avg_score": 0.9823595881462097, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.028689120560626728, "std_of_first_answer": 0.028689120560626728, "avg_entropy_of_first_answer": 0.09696102142333984, "lex_sim": 1.0}
{"question": "georgia out of angus thongs and perfect snogging", "answer": ["Georgia Nicholson #BookReview: Dark Matter by Blake Crouch @blakecrouchbooks"], "scores": [[0.7275390625, 0.04388427734375, 0.9423828125, 1.0, 1.6689300537109375e-06, 2.2351741790771484e-05, 0.061065673828125, 0.91455078125, 0.0830078125, 2.8967857360839844e-05, 0.0006561279296875, 0.94921875, 0.292236328125, 0.52001953125, 0.99853515625, 0.99853515625, 0.99951171875, 0.07684326171875, 0.697265625, 1.0, 0.9921875, 0.99267578125, 0.046630859375]], "normalized_score": [0.07820101827383041], "tokens": [["\u2581Georgia", "\u2581Nich", "ol", "son", "\u2581#", "Book", "Re", "view", ":", "\u2581Dark", "\u2581M", "atter", "\u2581by", "\u2581Bla", "ke", "\u2581Cr", "ouch", "\u2581@", "bla", "ke", "cr", "ouch", "books"]], "entropy": [[1.3486328125, 3.2109375, 0.25537109375, 0.0005736351013183594, 0.94384765625, 0.8828125, 4.4765625, 0.438720703125, 2.248046875, 3.220703125, 1.1533203125, 0.37109375, 2.96484375, 1.2734375, 0.01422882080078125, 0.01418304443359375, 0.00482940673828125, 2.193359375, 1.9677734375, 0.00027179718017578125, 0.07537841796875, 0.0477294921875, 2.4375]], "avg_entropy": [1.2845285871754522], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Georgia Groome as Georgia Nicolson", "score_of_biggest_cluster": 0.07820101827383041, "score_of_first_answer": 0.07820101827383041, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.6689300537109375e-06, "avg_score": 0.07820101827383041, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43555113390496436, "std_of_first_answer": 0.43555113390496436, "avg_entropy_of_first_answer": 1.2845285871754522, "lex_sim": 1.0}
{"question": "jawaharlal nehru centre for advanced scientific research jakkur campus", "answer": ["The Jawaharlal Nehru Centre for Advanced Scientific Research (JNCASR) is located in Jakkur, Bangalore, India."], "scores": [[0.2171630859375, 0.9931640625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9931640625, 0.9970703125, 0.99853515625, 1.0, 0.99951171875, 0.998046875, 0.8974609375, 0.99951171875, 0.9970703125, 0.99365234375, 0.99951171875, 0.9931640625, 0.78125, 0.76318359375, 0.7841796875, 0.96337890625, 1.0, 0.984375, 0.94775390625, 0.99951171875, 1.0, 0.904296875, 0.70703125, 0.98876953125, 0.6318359375, 0.6689453125, 0.95703125, 0.70751953125, 0.178955078125, 0.454833984375, 0.935546875, 1.0, 0.9990234375, 0.1766357421875, 0.400146484375, 0.63427734375, 0.99951171875, 0.6484375, 0.99951171875, 0.982421875]], "normalized_score": [0.8124849200248718], "tokens": [["\u2581The", "\u2581J", "aw", "ah", "ar", "l", "al", "\u2581Ne", "h", "ru", "\u2581Centre", "\u2581for", "\u2581Advanced", "\u2581Scient", "ific", "\u2581Research", "\u2581(", "J", "NC", "AS", "R", ")", "\u2581is", "\u2581located", "\u2581in", "\u2581Jak", "kur", ",", "\u2581Bang", "al", "ore", ",", "\u2581India", ".", "\u2581It", "\u2581is", "\u2581a", "\u2581research", "\u2581institution", "\u2581that", "\u2581focus", "es", "\u2581on", "\u2581basic", "\u2581sciences", "\u2581such", "\u2581as", "\u2581physics", ",", "\u2581chem"]], "entropy": [[1.810546875, 0.06396484375, 0.0008373260498046875, 4.6133995056152344e-05, 0.0012340545654296875, 0.0017223358154296875, 3.212690353393555e-05, 0.0004317760467529297, 3.4749507904052734e-05, 2.9146671295166016e-05, 0.044342041015625, 0.0198516845703125, 0.0132598876953125, 0.0014934539794921875, 0.003322601318359375, 0.01548004150390625, 0.47412109375, 0.00334930419921875, 0.02191162109375, 0.04180908203125, 0.003284454345703125, 0.047698974609375, 0.84716796875, 0.66796875, 0.62255859375, 0.1761474609375, 0.0010538101196289062, 0.119384765625, 0.280029296875, 0.0032253265380859375, 0.0006456375122070312, 0.3671875, 0.625, 0.0784912109375, 1.0849609375, 0.8466796875, 0.2235107421875, 1.3056640625, 1.13671875, 1.5712890625, 0.374267578125, 0.0003705024719238281, 0.006969451904296875, 2.0234375, 1.05859375, 0.9833984375, 0.002841949462890625, 1.1728515625, 0.005870819091796875, 0.11309814453125]], "avg_entropy": [0.3653637373447418], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Jakkur, Bangalore, India", "score_of_biggest_cluster": 0.8124849200248718, "score_of_first_answer": 0.8124849200248718, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.1766357421875, "avg_score": 0.8124849200248718, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.2268262992165784, "std_of_first_answer": 0.2268262992165784, "avg_entropy_of_first_answer": 0.3653637373447418, "lex_sim": 1.0}
{"question": "who is the most played artist on spotify", "answer": ["Ed Sheeran"], "scores": [[0.42919921875, 0.9990234375, 0.99951171875, 1.0]], "normalized_score": [0.8091063499450684], "tokens": [["\u2581Ed", "\u2581She", "er", "an"]], "entropy": [[2.00390625, 0.0094451904296875, 0.004238128662109375, 0.0005202293395996094]], "avg_entropy": [0.5045274496078491], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Justin Bieber", "score_of_biggest_cluster": 0.8091063499450684, "score_of_first_answer": 0.8091063499450684, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.42919921875, "avg_score": 0.8091063499450684, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.24695279790849997, "std_of_first_answer": 0.24695279790849997, "avg_entropy_of_first_answer": 0.5045274496078491, "lex_sim": 1.0}
{"question": "who played anne in anne with an e", "answer": ["Amybeth McNulty"], "scores": [[0.99462890625, 0.98828125, 1.0, 0.998046875, 0.99951171875, 0.998046875]], "normalized_score": [0.996411144733429], "tokens": [["\u2581Amy", "b", "eth", "\u2581Mc", "N", "ulty"]], "entropy": [[0.05889892578125, 0.07281494140625, 5.2928924560546875e-05, 0.01953125, 0.00661468505859375, 0.0191497802734375]], "avg_entropy": [0.0295104185740153], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Amybeth McNulty", "score_of_biggest_cluster": 0.996411144733429, "score_of_first_answer": 0.996411144733429, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.98828125, "avg_score": 0.996411144733429, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.004023179392678476, "std_of_first_answer": 0.004023179392678476, "avg_entropy_of_first_answer": 0.0295104185740153, "lex_sim": 1.0}
{"question": "who does claire from mcleods daughters end up with", "answer": ["Dr. Alec Patrick"], "scores": [[0.163818359375, 0.9970703125, 0.08563232421875, 1.0, 0.06768798828125]], "normalized_score": [0.24845489859580994], "tokens": [["\u2581Dr", ".", "\u2581Ale", "c", "\u2581Patrick"]], "entropy": [[3.9609375, 0.0296630859375, 3.47265625, 0.0011587142944335938, 4.95703125]], "avg_entropy": [2.484289360046387], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Alex Ryan", "score_of_biggest_cluster": 0.24845489859580994, "score_of_first_answer": 0.24845489859580994, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.06768798828125, "avg_score": 0.24845489859580994, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4385858130339918, "std_of_first_answer": 0.4385858130339918, "avg_entropy_of_first_answer": 2.484289360046387, "lex_sim": 1.0}
{"question": "who played sandy's jock boyfriend in grease", "answer": ["Barry Pearl #SavetheDay at D23 Expo Japan with Marvel"], "scores": [[0.470947265625, 0.998046875, 1.0, 5.960464477539063e-08, 0.0190887451171875, 0.0005669593811035156, 0.12103271484375, 7.331371307373047e-06, 1.9729137420654297e-05, 0.00566864013671875, 0.00027751922607421875, 0.9990234375, 0.5498046875, 1.0, 0.0234832763671875, 0.16162109375, 3.6716461181640625e-05]], "normalized_score": [0.007428782060742378], "tokens": [["\u2581Barry", "\u2581Pear", "l", "\u2581#", "S", "av", "ethe", "Day", "\u2581at", "\u2581D", "2", "3", "\u2581Ex", "po", "\u2581Japan", "\u2581with", "\u2581Marvel"]], "entropy": [[2.09765625, 0.0169677734375, 0.0019216537475585938, 0.74658203125, 4.93359375, 1.3359375, 4.04296875, 2.892578125, 2.23046875, 3.48828125, 2.5234375, 0.00931549072265625, 2.09375, 0.0002982616424560547, 3.412109375, 3.14453125, 4.57421875]], "avg_entropy": [2.2085068506353043], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "John Travolta", "score_of_biggest_cluster": 0.007428782060742378, "score_of_first_answer": 0.007428782060742378, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.007428782060742378, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41134643388631403, "std_of_first_answer": 0.41134643388631403, "avg_entropy_of_first_answer": 2.2085068506353043, "lex_sim": 1.0}
{"question": "who wrote the declaration of man and citizen", "answer": ["Jean-Jacques Rousseau #PlaidAgenda: Our top political stories this week"], "scores": [[0.4306640625, 0.99169921875, 0.994140625, 1.0, 0.99853515625, 1.0, 1.0, 1.4901161193847656e-06, 0.00342559814453125, 0.0003135204315185547, 0.035675048828125, 0.002300262451171875, 0.04718017578125, 0.00438690185546875, 7.039308547973633e-05, 0.00677490234375, 0.0005135536193847656, 0.009857177734375, 0.0810546875, 0.71240234375]], "normalized_score": [0.022924207150936127], "tokens": [["\u2581Jean", "-", "Jac", "ques", "\u2581R", "ous", "seau", "\u2581#", "P", "la", "id", "Ag", "enda", ":", "\u2581Our", "\u2581top", "\u2581political", "\u2581stories", "\u2581this", "\u2581week"]], "entropy": [[3.005859375, 0.057037353515625, 0.046630859375, 0.00029158592224121094, 0.01568603515625, 0.00024044513702392578, 0.00017774105072021484, 0.86767578125, 5.68359375, 4.90234375, 3.865234375, 4.9453125, 1.0712890625, 2.306640625, 4.9375, 5.83984375, 3.82421875, 4.30859375, 2.271484375, 0.88134765625]], "avg_entropy": [2.441550076007843], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "General Lafayette", "score_of_biggest_cluster": 0.022924207150936127, "score_of_first_answer": 0.022924207150936127, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.4901161193847656e-06, "avg_score": 0.022924207150936127, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44686171125396434, "std_of_first_answer": 0.44686171125396434, "avg_entropy_of_first_answer": 2.441550076007843, "lex_sim": 1.0}
{"question": "when was the first driver's license required", "answer": ["In 1901, New York State passed the first mandatory automobile license plates law making the first driver's license required."], "scores": [[0.06695556640625, 0.191650390625, 1.0, 0.9931640625, 0.97802734375, 0.95458984375, 0.7958984375, 0.54736328125, 0.99755859375, 0.6845703125, 0.157958984375, 0.82373046875, 0.99951171875, 0.034149169921875, 1.0, 0.468994140625, 0.99853515625, 0.75537109375, 8.738040924072266e-05, 0.94970703125, 0.69921875, 0.00148773193359375, 0.2056884765625, 0.75537109375, 0.9306640625, 0.96435546875, 1.0, 0.98876953125, 0.91455078125, 0.6416015625, 5.960464477539063e-08, 0.89013671875, 8.893013000488281e-05, 0.00373077392578125, 5.7637691497802734e-05, 0.442138671875, 0.007221221923828125, 0.98876953125, 0.23291015625, 0.003749847412109375, 0.004985809326171875, 0.072265625, 0.763671875, 0.0848388671875, 0.98583984375, 0.763671875, 0.153076171875, 0.87646484375]], "normalized_score": [0.12962190806865692], "tokens": [["\u2581In", "\u2581", "1", "9", "0", "1", ",", "\u2581New", "\u2581York", "\u2581State", "\u2581passed", "\u2581the", "\u2581first", "\u2581mand", "atory", "\u2581autom", "obile", "\u2581license", "\u2581pl", "ates", "\u2581law", "\u2581making", "\u2581the", "\u2581first", "\u2581driver", "'", "s", "\u2581license", "\u2581required", ".", "\u2581Tags", ":", "\u2581F", "ake", "\u2581Blood", ",", "\u2581Hor", "ror", ",", "\u2581M", "idget", "s", ",", "\u2581Mur", "der", ",", "\u2581N", "ud"]], "entropy": [[1.7021484375, 0.6083984375, 0.0004100799560546875, 0.0443115234375, 0.11090087890625, 0.261962890625, 0.68603515625, 1.046875, 0.0234222412109375, 0.861328125, 1.7822265625, 0.49755859375, 0.00376129150390625, 1.83984375, 0.0006952285766601562, 1.2080078125, 0.0099639892578125, 0.85546875, 0.157958984375, 0.326416015625, 1.095703125, 1.248046875, 0.81787109375, 1.427734375, 0.35791015625, 0.1845703125, 0.00039839744567871094, 0.06451416015625, 0.5546875, 1.134765625, 0.8232421875, 0.72412109375, 4.66015625, 3.291015625, 4.0625, 3.669921875, 6.72265625, 0.08447265625, 2.14453125, 5.2109375, 2.98046875, 1.7548828125, 1.162109375, 5.625, 0.08123779296875, 1.2587890625, 4.9609375, 0.5458984375]], "avg_entropy": [1.4307661205530167], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1888", "score_of_biggest_cluster": 0.12962190806865692, "score_of_first_answer": 0.12962190806865692, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.12962190806865692, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.404089840190664, "std_of_first_answer": 0.404089840190664, "avg_entropy_of_first_answer": 1.4307661205530167, "lex_sim": 1.0}
{"question": "tujhe dekha toh yeh jana sanam movie name", "answer": ["Kabhi Khusi Kabhie Gham #ThrowbackThursday: Celebrating the Mitsubishi Lancer"], "scores": [[0.208251953125, 0.96826171875, 0.54638671875, 0.00130462646484375, 0.986328125, 0.9990234375, 0.94921875, 1.0, 0.99755859375, 1.0, 0.0, 0.00020968914031982422, 0.99853515625, 0.01355743408203125, 0.9951171875, 0.9970703125, 0.002529144287109375, 0.0009393692016601562, 0.7451171875, 0.9130859375, 0.939453125, 0.1387939453125, 0.0010700225830078125, 5.602836608886719e-06, 0.9853515625, 0.986328125, 0.0615234375, 1.0]], "normalized_score": [0.0], "tokens": [["\u2581Kab", "hi", "\u2581Kh", "us", "i", "\u2581Kab", "h", "ie", "\u2581G", "ham", "\u2581#", "Throw", "back", "Th", "urs", "day", ":", "\u2581C", "ele", "br", "ating", "\u2581the", "\u2581M", "its", "ub", "ishi", "\u2581Lan", "cer"]], "entropy": [[2.0625, 0.1531982421875, 0.81396484375, 0.01007843017578125, 0.07830810546875, 0.00896453857421875, 0.201904296875, 0.00014030933380126953, 0.019866943359375, 0.00021135807037353516, 0.481201171875, 5.16796875, 0.0121307373046875, 3.498046875, 0.048187255859375, 0.0209503173828125, 2.7109375, 4.83984375, 1.1689453125, 0.388671875, 0.282958984375, 1.9287109375, 4.76171875, 3.341796875, 0.11676025390625, 0.0855712890625, 3.404296875, 0.00044608116149902344]], "avg_entropy": [1.2717243092400687], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Dilwale Dulhania Le Jayenge", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.45196661263609206, "std_of_first_answer": 0.45196661263609206, "avg_entropy_of_first_answer": 1.2717243092400687, "lex_sim": 1.0}
{"question": "who is the first indian climber of mount everest", "answer": ["Nariesh Gajurel"], "scores": [[0.154541015625, 0.007793426513671875, 0.66162109375, 0.0294189453125, 0.1629638671875, 0.69140625, 1.0]], "normalized_score": [0.1596316546201706], "tokens": [["\u2581N", "aries", "h", "\u2581G", "aj", "ure", "l"]], "entropy": [[2.494140625, 1.580078125, 2.021484375, 3.361328125, 3.900390625, 1.0859375, 5.608797073364258e-05]], "avg_entropy": [2.0633450661386763], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Bachendri Pal", "score_of_biggest_cluster": 0.1596316546201706, "score_of_first_answer": 0.1596316546201706, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.007793426513671875, "avg_score": 0.1596316546201706, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.36247953425830254, "std_of_first_answer": 0.36247953425830254, "avg_entropy_of_first_answer": 2.0633450661386763, "lex_sim": 1.0}
{"question": "who started the tradition of coloring easter eggs", "answer": ["It is believed to have originated with ancient cultures who exchanged colored eggs as a symbol of rebirth and renewal."], "scores": [[0.1656494140625, 0.94921875, 0.30712890625, 0.19775390625, 0.9873046875, 0.669921875, 1.0, 0.5185546875, 0.115966796875, 0.82666015625, 1.0, 0.93603515625, 0.8623046875, 0.9990234375, 0.3505859375, 0.99853515625, 0.99853515625, 0.9326171875, 0.99755859375, 1.0, 0.01641845703125, 1.0, 0.52392578125, 0.50927734375, 0.99560546875, 0.8427734375]], "normalized_score": [0.5613948702812195], "tokens": [["\u2581It", "\u2581is", "\u2581believed", "\u2581to", "\u2581have", "\u2581origin", "ated", "\u2581with", "\u2581ancient", "\u2581cult", "ures", "\u2581who", "\u2581ex", "changed", "\u2581colored", "\u2581eggs", "\u2581as", "\u2581a", "\u2581symbol", "\u2581of", "\u2581reb", "irth", "\u2581and", "\u2581renew", "al", "."]], "entropy": [[2.751953125, 0.22607421875, 1.583984375, 0.55029296875, 0.08074951171875, 0.85302734375, 0.0002275705337524414, 1.099609375, 0.6962890625, 0.89404296875, 0.00023031234741210938, 0.342529296875, 0.60498046875, 0.0089569091796875, 1.07421875, 0.01259613037109375, 0.01271820068359375, 0.30126953125, 0.020904541015625, 0.0006685256958007812, 0.419677734375, 2.6404857635498047e-05, 1.0810546875, 1.099609375, 0.0295257568359375, 0.66064453125]], "avg_entropy": [0.5540716029130496], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "early Christians of Mesopotamia", "score_of_biggest_cluster": 0.5613948702812195, "score_of_first_answer": 0.5613948702812195, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.01641845703125, "avg_score": 0.5613948702812195, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.33020781639964114, "std_of_first_answer": 0.33020781639964114, "avg_entropy_of_first_answer": 0.5540716029130496, "lex_sim": 1.0}
{"question": "when did the government change the retirement age", "answer": ["I believe you are referring to the increase in the full retirement age for Social Security benefits from 65 to 67, which was signed into law in 1983 and phased in gradually."], "scores": [[0.252685546875, 0.00699615478515625, 0.9189453125, 0.87109375, 0.9072265625, 0.99951171875, 0.86572265625, 0.0227203369140625, 0.94287109375, 0.8818359375, 0.93505859375, 0.99755859375, 1.0, 1.0, 0.9794921875, 0.99267578125, 1.0, 0.1900634765625, 0.197265625, 0.95068359375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8974609375, 0.64892578125, 0.9990234375, 0.9765625, 0.31005859375, 1.0, 1.0, 0.8828125, 0.9912109375, 0.99951171875, 1.0, 0.99951171875, 1.0, 0.12744140625, 0.9140625, 1.0, 0.998046875, 0.0780029296875, 0.09100341796875, 2.384185791015625e-07, 0.0083465576171875, 0.0005865097045898438, 0.7255859375]], "normalized_score": [0.34579765796661377], "tokens": [["\u2581I", "\u2581believe", "\u2581you", "\u2581are", "\u2581referring", "\u2581to", "\u2581the", "\u2581increase", "\u2581in", "\u2581the", "\u2581full", "\u2581ret", "irement", "\u2581age", "\u2581for", "\u2581Social", "\u2581Security", "\u2581benefits", "\u2581from", "\u2581", "6", "5", "\u2581to", "\u2581", "6", "7", ",", "\u2581which", "\u2581was", "\u2581signed", "\u2581into", "\u2581law", "\u2581in", "\u2581", "1", "9", "8", "3", "\u2581and", "\u2581ph", "ased", "\u2581in", "\u2581gradually", ".", "\u2581#", "M", "ot", "iv"]], "entropy": [[2.267578125, 1.484375, 0.389892578125, 0.5546875, 0.38818359375, 0.006145477294921875, 0.638671875, 2.220703125, 0.2255859375, 0.403076171875, 0.347412109375, 0.019256591796875, 2.0265579223632812e-06, 0.0006165504455566406, 0.1329345703125, 0.045867919921875, 0.0017414093017578125, 1.6279296875, 1.4111328125, 0.2158203125, 0.0007085800170898438, 0.0015125274658203125, 0.001682281494140625, 0.0016231536865234375, 6.121397018432617e-05, 0.330810546875, 0.78076171875, 0.009765625, 0.1357421875, 1.197265625, 0.001220703125, 0.0008225440979003906, 0.42724609375, 0.05426025390625, 0.0024585723876953125, -0.0, 0.0024013519287109375, 0.0015478134155273438, 1.2236328125, 0.46337890625, 7.68899917602539e-06, 0.015350341796875, 1.1845703125, 1.701171875, 1.529296875, 4.61328125, 3.3671875, 0.8173828125]], "avg_entropy": [0.630140927930673], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2015", "score_of_biggest_cluster": 0.34579765796661377, "score_of_first_answer": 0.34579765796661377, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.34579765796661377, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3757543409078231, "std_of_first_answer": 0.3757543409078231, "avg_entropy_of_first_answer": 0.630140927930673, "lex_sim": 1.0}
{"question": "star cast of ab tumhare hawale watan sathiyon", "answer": ["Mohanlal, Priyamani, Nadhiya, and Jagathy Sreekumar."], "scores": [[0.05731201171875, 0.79248046875, 0.98876953125, 1.0, 0.98193359375, 0.0159759521484375, 0.9912109375, 0.99462890625, 1.0, 0.96875, 0.00150299072265625, 0.85595703125, 1.0, 0.8037109375, 0.2091064453125, 0.227783203125, 0.59375, 0.9931640625, 0.99755859375, 0.9951171875, 0.99951171875, 0.40576171875, 8.940696716308594e-07, 0.0030803680419921875, 3.6954879760742188e-06, 0.00566864013671875, 0.0015420913696289062, 0.023895263671875, 0.031951904296875, 0.00511932373046875, 0.0102996826171875, 0.9248046875, 0.0281982421875, 0.1097412109375, 0.483642578125, 0.712890625, 0.208251953125, 0.359619140625, 0.85693359375, 0.035003662109375, 0.0006203651428222656, 0.8564453125, 0.99951171875, 0.6064453125, 0.0085296630859375, 0.323974609375, 0.9970703125, 0.99072265625]], "normalized_score": [0.10870309174060822], "tokens": [["\u2581Moh", "an", "l", "al", ",", "\u2581Pri", "y", "am", "ani", ",", "\u2581Nad", "hi", "ya", ",", "\u2581and", "\u2581Jag", "ath", "y", "\u2581S", "reek", "umar", ".", "\u2581#", "B", "log", "T", "our", ":", "\u2581The", "\u2581Last", "\u2581Days", "\u2581of", "\u2581L", "eda", "\u2581Grey", "\u2581by", "\u2581Ess", "ie", "\u2581Fox", "\u2581@", "writer", "ess", "ie", "\u2581@", "F", "ab", "er", "Book"]], "entropy": [[4.21484375, 0.85595703125, 0.0784912109375, 0.001232147216796875, 0.11334228515625, 3.919921875, 0.05712890625, 0.04132080078125, 0.00031280517578125, 0.176513671875, 2.77734375, 0.75634765625, 0.0004150867462158203, 0.755859375, 3.201171875, 2.646484375, 0.96240234375, 0.041900634765625, 0.020782470703125, 0.0380859375, 0.0032749176025390625, 1.14453125, 0.30908203125, 2.599609375, 0.30078125, 3.76953125, 1.44921875, 3.765625, 5.16015625, 6.19140625, 4.14453125, 0.453857421875, 2.986328125, 3.70703125, 1.763671875, 1.3056640625, 4.35546875, 1.966796875, 0.7177734375, 2.6328125, 1.2197265625, 0.5458984375, 0.005859375, 1.5546875, 3.77734375, 1.595703125, 0.0233612060546875, 0.0909423828125]], "avg_entropy": [1.6291777541240056], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Bobby Deol", "score_of_biggest_cluster": 0.10870309174060822, "score_of_first_answer": 0.10870309174060822, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 8.940696716308594e-07, "avg_score": 0.10870309174060822, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4253628983733062, "std_of_first_answer": 0.4253628983733062, "avg_entropy_of_first_answer": 1.6291777541240056, "lex_sim": 1.0}
{"question": "who is president of india in present time", "answer": ["Ram Nath Kovind (as of 2021) #CBR5 Maneater by Jonathan Maberry"], "scores": [[0.98583984375, 0.99658203125, 1.0, 1.0, 1.0, 0.99951171875, 0.04815673828125, 0.5966796875, 0.99853515625, 0.483154296875, 0.998046875, 0.998046875, 0.7744140625, 0.9892578125, 0.9521484375, 5.960464477539063e-08, 0.0023937225341796875, 0.00032901763916015625, 0.0009441375732421875, 8.404254913330078e-06, 0.00027179718017578125, 0.1837158203125, 0.353271484375, 5.3942203521728516e-05, 0.092529296875, 0.9990234375, 1.0, 1.0]], "normalized_score": [0.06367239356040955], "tokens": [["\u2581Ram", "\u2581N", "ath", "\u2581K", "ov", "ind", "\u2581(", "as", "\u2581of", "\u2581", "2", "0", "2", "1", ")", "\u2581#", "C", "BR", "5", "\u2581M", "ane", "ater", "\u2581by", "\u2581Jonathan", "\u2581M", "ab", "er", "ry"]], "entropy": [[0.113525390625, 0.0259552001953125, 0.001819610595703125, 0.001064300537109375, 0.0001914501190185547, 0.002742767333984375, 1.0888671875, 1.353515625, 0.01226806640625, 1.150390625, 0.0154876708984375, 0.018402099609375, 0.5341796875, 0.06768798828125, 0.2235107421875, 0.1375732421875, 2.197265625, 3.7734375, 1.38671875, 2.6640625, 2.619140625, 3.09765625, 3.13671875, 1.94140625, 2.80859375, 0.00995635986328125, 0.00013899803161621094, 0.00083160400390625]], "avg_entropy": [1.013682450566973], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ram Nath Kovind", "score_of_biggest_cluster": 0.06367239356040955, "score_of_first_answer": 0.06367239356040955, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.06367239356040955, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4443066161103781, "std_of_first_answer": 0.4443066161103781, "avg_entropy_of_first_answer": 1.013682450566973, "lex_sim": 1.0}
{"question": "who has played raoul in phantom of the opera", "answer": ["It is a role that has been played by several actors in various productions of The Phantom of the Opera, including John Cudia, Peter J. Lucas, and Norm Lewis."], "scores": [[0.01708984375, 0.362548828125, 0.859375, 0.422607421875, 0.79443359375, 0.861328125, 0.998046875, 0.70849609375, 0.9990234375, 0.4072265625, 0.98291015625, 0.56787109375, 0.487060546875, 0.97314453125, 1.0, 0.70654296875, 0.42138671875, 1.0, 0.99951171875, 1.0, 0.99853515625, 1.0, 0.3896484375, 0.83935546875, 0.06024169921875, 0.96728515625, 0.97705078125, 0.9912109375, 0.68212890625, 0.06927490234375, 0.9794921875, 0.7373046875, 0.004657745361328125, 0.9833984375, 0.7197265625, 0.09454345703125, 0.9912109375, 0.98828125, 7.152557373046875e-07, 0.0007052421569824219, 0.0003120899200439453, 0.00511932373046875, 0.0007786750793457031, 0.7998046875, 0.9892578125, 0.0005440711975097656, 0.0089111328125, 0.0787353515625]], "normalized_score": [0.1787133812904358], "tokens": [["\u2581It", "\u2581is", "\u2581a", "\u2581role", "\u2581that", "\u2581has", "\u2581been", "\u2581played", "\u2581by", "\u2581several", "\u2581actors", "\u2581in", "\u2581various", "\u2581produ", "ctions", "\u2581of", "\u2581The", "\u2581Ph", "antom", "\u2581of", "\u2581the", "\u2581Opera", ",", "\u2581including", "\u2581John", "\u2581C", "ud", "ia", ",", "\u2581Peter", "\u2581J", ".", "\u2581Lucas", ",", "\u2581and", "\u2581Norm", "\u2581Lewis", ".", "\u2581#", "D", "ream", "Big", "Pr", "in", "cess", ":", "\u2581", "2"]], "entropy": [[4.59375, 1.298828125, 0.69287109375, 2.23046875, 0.828125, 0.5478515625, 0.0211181640625, 0.69189453125, 0.0093841552734375, 1.3583984375, 0.11126708984375, 1.36328125, 0.90625, 0.1700439453125, 2.0325183868408203e-05, 0.8681640625, 1.287109375, 0.0012149810791015625, 0.004302978515625, 0.0008535385131835938, 0.010223388671875, 0.0014677047729492188, 0.82177734375, 0.7724609375, 3.322265625, 0.29052734375, 0.1951904296875, 0.0767822265625, 0.65673828125, 2.796875, 0.1783447265625, 0.76611328125, 2.83984375, 0.08746337890625, 1.3681640625, 3.1171875, 0.0751953125, 0.07879638671875, 0.53369140625, 5.58984375, 3.892578125, 4.44140625, 2.0546875, 0.87646484375, 0.0782470703125, 1.3154296875, 4.09375, 2.986328125]], "avg_entropy": [1.2563133500516415], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Tim Martin Gleason", "score_of_biggest_cluster": 0.1787133812904358, "score_of_first_answer": 0.1787133812904358, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 7.152557373046875e-07, "avg_score": 0.1787133812904358, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39742812376400105, "std_of_first_answer": 0.39742812376400105, "avg_entropy_of_first_answer": 1.2563133500516415, "lex_sim": 1.0}
{"question": "where did they film the book of eli", "answer": ["New Zealand and Australia"], "scores": [[0.252197265625, 0.005828857421875, 0.492431640625, 0.0885009765625]], "normalized_score": [0.08946526050567627], "tokens": [["\u2581New", "\u2581Zealand", "\u2581and", "\u2581Australia"]], "entropy": [[3.12109375, 0.2369384765625, 1.29296875, 2.87890625]], "avg_entropy": [1.882476806640625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "New Mexico", "score_of_biggest_cluster": 0.08946526050567627, "score_of_first_answer": 0.08946526050567627, "max_score_of_first_answer": 0.492431640625, "min_score_of_first_answer": 0.005828857421875, "avg_score": 0.08946526050567627, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.18573895522668657, "std_of_first_answer": 0.18573895522668657, "avg_entropy_of_first_answer": 1.882476806640625, "lex_sim": 1.0}
{"question": "when does the new season on the 100 come out", "answer": ["February 6, 2021"], "scores": [[0.0165252685546875, 0.99267578125, 0.0360107421875, 0.56005859375, 0.99755859375, 1.0, 1.0, 0.99365234375, 0.1475830078125]], "normalized_score": [0.33154061436653137], "tokens": [["\u2581February", "\u2581", "6", ",", "\u2581", "2", "0", "2", "1"]], "entropy": [[2.017578125, 0.048309326171875, 1.07421875, 0.74658203125, 0.0175933837890625, 0.001373291015625, 0.00018227100372314453, 0.0391845703125, 1.271484375]], "avg_entropy": [0.579611791504754], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "April 24, 2018", "score_of_biggest_cluster": 0.33154061436653137, "score_of_first_answer": 0.33154061436653137, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0165252685546875, "avg_score": 0.33154061436653137, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4267264288413099, "std_of_first_answer": 0.4267264288413099, "avg_entropy_of_first_answer": 0.579611791504754, "lex_sim": 1.0}
{"question": "where did the battle of corinth take place", "answer": ["The Battle of Corinth took place near the town of Corinth, Mississippi, in the United States."], "scores": [[0.006313323974609375, 0.8251953125, 0.99951171875, 0.9921875, 1.0, 0.990234375, 0.99951171875, 0.07147216796875, 0.79296875, 0.6708984375, 0.99951171875, 1.0, 1.0, 0.9931640625, 0.9951171875, 0.363525390625, 0.88916015625, 0.9755859375, 0.7373046875, 1.0, 0.95751953125, 1.8477439880371094e-06, 0.0012731552124023438, 0.0006694793701171875, 0.020477294921875, 0.0010900497436523438]], "normalized_score": [0.15816694498062134], "tokens": [["\u2581The", "\u2581Battle", "\u2581of", "\u2581Cor", "inth", "\u2581took", "\u2581place", "\u2581near", "\u2581the", "\u2581town", "\u2581of", "\u2581Cor", "inth", ",", "\u2581Mississippi", ",", "\u2581in", "\u2581the", "\u2581United", "\u2581States", ".", "\u2581#", "E", "v", "ap", "co"]], "entropy": [[0.58740234375, 0.55810546875, 0.0038909912109375, 0.0528564453125, 0.0006198883056640625, 0.06494140625, 0.0038509368896484375, 0.271240234375, 0.51220703125, 0.78173828125, 0.00516510009765625, 0.0014057159423828125, 0.00011038780212402344, 0.046478271484375, 0.03497314453125, 1.126953125, 0.4892578125, 0.1475830078125, 1.0341796875, 0.0007677078247070312, 0.2381591796875, 0.405029296875, 3.8671875, 1.798828125, 2.166015625, 3.91015625]], "avg_entropy": [0.6965039601692786], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "in Corinth, Mississippi", "score_of_biggest_cluster": 0.15816694498062134, "score_of_first_answer": 0.15816694498062134, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.8477439880371094e-06, "avg_score": 0.15816694498062134, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.41837496393812634, "std_of_first_answer": 0.41837496393812634, "avg_entropy_of_first_answer": 0.6965039601692786, "lex_sim": 1.0}
{"question": "where does the sweetness of fruit come from", "answer": ["natural sugars in the fruit."], "scores": [[0.54443359375, 0.93359375, 1.0, 0.1116943359375, 0.98583984375, 0.966796875, 0.275146484375, 3.039836883544922e-06, 1.8477439880371094e-06, 0.005611419677734375, 0.084716796875, 0.003917694091796875, 0.11572265625, 0.0020580291748046875, 0.0001513957977294922, 0.09405517578125, 0.99853515625, 0.99462890625, 0.99951171875, 0.8759765625, 0.998046875, 1.0, 0.99853515625, 0.99951171875]], "normalized_score": [0.07258535921573639], "tokens": [["\u2581natural", "\u2581sug", "ars", "\u2581in", "\u2581the", "\u2581fruit", ".", "\u2581#", "Book", "B", "last", ":", "\u2581The", "\u2581Un", "h", "one", "ym", "oon", "ers", "\u2581by", "\u2581Christ", "ina", "\u2581La", "uren"]], "entropy": [[2.08984375, 0.263916015625, 7.992982864379883e-05, 2.255859375, 0.09002685546875, 0.166748046875, 1.4423828125, 0.0673828125, 4.30859375, 3.974609375, 2.6875, 1.6171875, 3.525390625, 3.912109375, 3.736328125, 1.62890625, 0.01113128662109375, 0.03973388671875, 0.006481170654296875, 0.69580078125, 0.0166473388671875, 0.0009493827819824219, 0.0157470703125, 0.0037059783935546875]], "avg_entropy": [1.3565442288915317], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Fructose, or fruit sugar", "score_of_biggest_cluster": 0.07258535921573639, "score_of_first_answer": 0.07258535921573639, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.8477439880371094e-06, "avg_score": 0.07258535921573639, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4522139259408607, "std_of_first_answer": 0.4522139259408607, "avg_entropy_of_first_answer": 1.3565442288915317, "lex_sim": 1.0}
{"question": "who is the president of the republic of zambia", "answer": ["Edgar Lungu."], "scores": [[0.64404296875, 1.0, 0.56494140625, 1.0, 1.0, 0.063720703125, 2.980232238769531e-07, 0.046112060546875, 7.349252700805664e-05, 0.1737060546875, 7.778406143188477e-05, 0.005191802978515625, 0.97900390625, 0.8701171875, 0.16845703125, 0.12091064453125]], "normalized_score": [0.038987722247838974], "tokens": [["\u2581Ed", "gar", "\u2581L", "ung", "u", ".", "\u2581#", "1", "\u2581Re", "ason", "\u2581Women", "\u2581Le", "ave", "\u2581Men", "\u2581They", "\u2581Love"]], "entropy": [[1.3203125, 0.0006084442138671875, 0.70263671875, 0.0012578964233398438, 0.0013904571533203125, 0.94287109375, 0.4384765625, 5.43359375, 3.140625, 2.423828125, 3.578125, 3.314453125, 0.1446533203125, 0.8515625, 3.306640625, 0.60693359375]], "avg_entropy": [1.6379980444908142], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Edgar Lungu", "score_of_biggest_cluster": 0.038987722247838974, "score_of_first_answer": 0.038987722247838974, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.038987722247838974, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4165566819837681, "std_of_first_answer": 0.4165566819837681, "avg_entropy_of_first_answer": 1.6379980444908142, "lex_sim": 1.0}
{"question": "who plays timon in lion king on broadway", "answer": ["Alton Fitzgerald White #26 Post by TroyBlade \u00bb Fri Jun 19, 2009 10:43 pm"], "scores": [[0.087158203125, 0.9970703125, 0.9873046875, 0.99853515625, 1.0, 0.9990234375, 2.5033950805664062e-06, 0.074462890625, 0.0100555419921875, 2.384185791015625e-07, 0.023284912109375, 0.00782012939453125, 0.005767822265625, 0.01160430908203125, 0.07080078125, 0.771484375, 0.1474609375, 0.04486083984375, 0.9970703125, 0.301025390625, 0.044586181640625, 0.9990234375, 0.98291015625, 0.99951171875, 1.0, 0.0002655982971191406, 0.9990234375, 0.994140625, 0.40234375, 0.288818359375, 0.9990234375, 0.1612548828125, 0.093994140625, 0.55322265625]], "normalized_score": [0.08589227497577667], "tokens": [["\u2581Al", "ton", "\u2581Fitz", "ger", "ald", "\u2581White", "\u2581#", "2", "6", "\u2581Post", "\u2581by", "\u2581T", "roy", "B", "lade", "\u2581\u00bb", "\u2581Fri", "\u2581Jun", "\u2581", "1", "9", ",", "\u2581", "2", "0", "0", "9", "\u2581", "1", "0", ":", "4", "3", "\u2581pm"]], "entropy": [[3.6328125, 0.0306549072265625, 0.0906982421875, 0.01416015625, 0.0006160736083984375, 0.0071258544921875, 0.66845703125, 3.49609375, 2.208984375, 2.962890625, 3.185546875, 5.0546875, 5.38671875, 5.30078125, 4.54296875, 1.5234375, 2.25, 2.470703125, 0.0213165283203125, 1.2041015625, 1.4775390625, 0.0099639892578125, 0.12054443359375, 0.004848480224609375, 4.9054622650146484e-05, 0.11016845703125, 0.007106781005859375, 0.05255126953125, 1.9140625, 1.3974609375, 0.009979248046875, 1.7919921875, 2.302734375, 0.70849609375]], "avg_entropy": [1.5870662419235004], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Max Casella", "score_of_biggest_cluster": 0.08589227497577667, "score_of_first_answer": 0.08589227497577667, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.08589227497577667, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4420293262487875, "std_of_first_answer": 0.4420293262487875, "avg_entropy_of_first_answer": 1.5870662419235004, "lex_sim": 1.0}
{"question": "what color is the golden gate bridge in san francisco", "answer": ["International Orange"], "scores": [[0.8564453125, 0.77978515625]], "normalized_score": [0.8172168135643005], "tokens": [["\u2581International", "\u2581Orange"]], "entropy": [[0.70947265625, 0.52685546875]], "avg_entropy": [0.6181640625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "orange vermilion called international orange", "score_of_biggest_cluster": 0.8172168135643005, "score_of_first_answer": 0.8172168135643005, "max_score_of_first_answer": 0.8564453125, "min_score_of_first_answer": 0.77978515625, "avg_score": 0.8172168135643005, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.038330078125, "std_of_first_answer": 0.038330078125, "avg_entropy_of_first_answer": 0.6181640625, "lex_sim": 1.0}
{"question": "when did season 4 of glee come out", "answer": ["September 20, 2012"], "scores": [[0.069580078125, 0.9921875, 0.978515625, 0.9990234375, 0.55322265625, 0.99658203125, 1.0, 1.0, 0.99951171875, 0.98828125]], "normalized_score": [0.7186713814735413], "tokens": [["\u2581September", "\u2581", "2", "0", ",", "\u2581", "2", "0", "1", "2"]], "entropy": [[1.02734375, 0.05352783203125, 0.11627197265625, 0.009124755859375, 0.70751953125, 0.025634765625, 7.808208465576172e-05, 1.1324882507324219e-06, 0.005512237548828125, 0.073486328125]], "avg_entropy": [0.20185003876686097], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "September 13, 2012", "score_of_biggest_cluster": 0.7186713814735413, "score_of_first_answer": 0.7186713814735413, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.069580078125, "avg_score": 0.7186713814735413, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2938441602474222, "std_of_first_answer": 0.2938441602474222, "avg_entropy_of_first_answer": 0.20185003876686097, "lex_sim": 1.0}
{"question": "where did huntington's disease get its name", "answer": ["After George Huntington, the American physician who first described the condition in 1872."], "scores": [[0.6162109375, 0.9248046875, 0.99853515625, 1.0, 1.0, 0.71142578125, 0.54833984375, 0.8544921875, 0.99462890625, 1.0, 0.99951171875, 0.99072265625, 0.9990234375, 0.96435546875, 0.01535797119140625, 0.93994140625, 0.99462890625, 1.0, 1.0, 1.0, 1.0, 0.9296875, 0.0, 0.2169189453125]], "normalized_score": [0.0], "tokens": [["\u2581After", "\u2581George", "\u2581Hun", "ting", "ton", ",", "\u2581the", "\u2581American", "\u2581phys", "ician", "\u2581who", "\u2581first", "\u2581described", "\u2581the", "\u2581condition", "\u2581in", "\u2581", "1", "8", "7", "2", ".", "\u2581#####", "#"]], "entropy": [[1.173828125, 0.440673828125, 0.0131378173828125, 0.0004525184631347656, 0.0003075599670410156, 0.85400390625, 1.16796875, 0.546875, 0.03778076171875, 0.00011545419692993164, 0.00550079345703125, 0.07275390625, 0.01194000244140625, 0.1552734375, 0.31640625, 0.2496337890625, 0.04205322265625, 3.7789344787597656e-05, 2.181529998779297e-05, 0.00030803680419921875, 0.0009584426879882812, 0.279296875, 0.09466552734375, 1.23828125]], "avg_entropy": [0.27926145245631534], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the physician George Huntington", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.30843513992311894, "std_of_first_answer": 0.30843513992311894, "avg_entropy_of_first_answer": 0.27926145245631534, "lex_sim": 1.0}
{"question": "what is the process to become a santero", "answer": ["Santero is a term used to describe someone who practices Santer\u00eda, a religion originating in West Africa and practiced primarily in the Caribbean and Latin America."], "scores": [[0.137939453125, 0.0814208984375, 0.95263671875, 0.98876953125, 0.487548828125, 0.77001953125, 0.8125, 0.736328125, 0.1048583984375, 0.99951171875, 0.8369140625, 0.1856689453125, 1.0, 0.320068359375, 0.99609375, 0.95166015625, 0.88720703125, 0.1827392578125, 0.974609375, 0.44873046875, 0.587890625, 0.99755859375, 0.47021484375, 0.035980224609375, 1.0, 0.230224609375, 0.99951171875, 0.609375, 0.89892578125, 1.0, 1.0, 0.57763671875, 0.72216796875, 0.99755859375, 0.98486328125, 0.370361328125, 0.99951171875, 0.9990234375, 0.403076171875, 0.908203125, 0.982421875, 0.96044921875, 0.55859375, 0.2978515625, 0.998046875, 1.0, 0.84423828125, 0.97998046875, 0.99462890625, 0.7158203125]], "normalized_score": [0.5950273871421814], "tokens": [["\u2581San", "tero", "\u2581is", "\u2581a", "\u2581term", "\u2581used", "\u2581to", "\u2581describe", "\u2581someone", "\u2581who", "\u2581practices", "\u2581San", "ter", "\u00eda", ",", "\u2581a", "\u2581religion", "\u2581origin", "ating", "\u2581in", "\u2581West", "\u2581Africa", "\u2581and", "\u2581pract", "iced", "\u2581primarily", "\u2581in", "\u2581the", "\u2581Car", "ib", "bean", "\u2581and", "\u2581Latin", "\u2581America", ".", "\u2581To", "\u2581become", "\u2581a", "\u2581san", "tero", ",", "\u2581one", "\u2581must", "\u2581be", "\u2581initi", "ated", "\u2581into", "\u2581the", "\u2581religion", "\u2581by"]], "entropy": [[2.462890625, 0.291259765625, 0.307373046875, 0.077392578125, 1.8095703125, 0.96435546875, 0.5166015625, 0.58935546875, 0.59423828125, 0.0072021484375, 0.67822265625, 1.2392578125, 0.0017852783203125, 0.64306640625, 0.0302581787109375, 0.2364501953125, 0.58544921875, 0.82568359375, 0.11962890625, 0.69775390625, 1.2255859375, 0.019134521484375, 1.1103515625, 1.5107421875, 0.0016536712646484375, 0.80322265625, 0.0057373046875, 0.8505859375, 0.44580078125, 0.0013952255249023438, 0.0009374618530273438, 0.72607421875, 0.78564453125, 0.018341064453125, 0.0809326171875, 1.544921875, 0.0046539306640625, 0.010040283203125, 0.92431640625, 0.3701171875, 0.114990234375, 0.2196044921875, 1.140625, 1.751953125, 0.0163116455078125, 0.0003273487091064453, 0.5439453125, 0.10321044921875, 0.041961669921875, 0.771484375]], "avg_entropy": [0.5564479684829712], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "a cleansing ritual", "score_of_biggest_cluster": 0.5950273871421814, "score_of_first_answer": 0.5950273871421814, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.035980224609375, "avg_score": 0.5950273871421814, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3151553200272791, "std_of_first_answer": 0.3151553200272791, "avg_entropy_of_first_answer": 0.5564479684829712, "lex_sim": 1.0}
{"question": "who were the first non native settlers in the us", "answer": ["The first non-native settlers in the present-day United States were European explorers and settlers, who arrived in the 16th and 17th centuries."], "scores": [[0.1568603515625, 0.86474609375, 0.76513671875, 0.998046875, 0.61279296875, 0.9912109375, 0.9990234375, 0.958984375, 0.9169921875, 0.0136871337890625, 0.99755859375, 1.0, 0.99658203125, 1.0, 0.998046875, 0.5361328125, 0.2288818359375, 1.0, 1.0, 0.91064453125, 0.65185546875, 1.0, 0.7900390625, 0.470458984375, 0.2176513671875, 0.46875, 0.9609375, 0.87060546875, 1.0, 0.880859375, 1.0, 0.509765625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.93701171875, 0.2398681640625, 0.2340087890625, 0.272216796875, 0.9970703125, 0.99951171875, 0.2015380859375, 0.05810546875, 0.369384765625, 0.95458984375, 0.99658203125, 0.99365234375, 0.1146240234375]], "normalized_score": [0.5947510600090027], "tokens": [["\u2581The", "\u2581first", "\u2581non", "-", "native", "\u2581sett", "lers", "\u2581in", "\u2581the", "\u2581present", "-", "day", "\u2581United", "\u2581States", "\u2581were", "\u2581European", "\u2581expl", "or", "ers", "\u2581and", "\u2581sett", "lers", ",", "\u2581who", "\u2581arrived", "\u2581in", "\u2581the", "\u2581", "1", "6", "th", "\u2581and", "\u2581", "1", "7", "th", "\u2581centuries", ".", "\u2581The", "\u2581Spanish", "\u2581were", "\u2581the", "\u2581first", "\u2581to", "\u2581arrive", ",", "\u2581followed", "\u2581by", "\u2581the", "\u2581French"]], "entropy": [[2.337890625, 0.5234375, 0.83544921875, 0.01522064208984375, 0.72216796875, 0.06317138671875, 0.006580352783203125, 0.20703125, 0.306884765625, 0.98291015625, 0.0177001953125, 0.001552581787109375, 0.0270233154296875, 0.0011243820190429688, 0.017669677734375, 1.5478515625, 0.9658203125, 0.00014019012451171875, 1.0132789611816406e-06, 0.319580078125, 0.71484375, 0.0001361370086669922, 0.705078125, 0.97216796875, 0.71630859375, 1.4189453125, 0.244140625, 0.50048828125, 2.1338462829589844e-05, 0.37548828125, 0.0025177001953125, 0.9990234375, 0.002254486083984375, 2.086162567138672e-06, 3.039836883544922e-05, 0.0018243789672851562, 0.0011501312255859375, 0.26904296875, 1.650390625, 0.8681640625, 1.1640625, 0.0226898193359375, 0.005016326904296875, 0.63623046875, 0.73095703125, 0.796875, 0.2347412109375, 0.0264892578125, 0.044769287109375, 0.6484375]], "avg_entropy": [0.45302988529205324], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "European colonization", "score_of_biggest_cluster": 0.5947510600090027, "score_of_first_answer": 0.5947510600090027, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0136871337890625, "avg_score": 0.5947510600090027, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.32992233910927116, "std_of_first_answer": 0.32992233910927116, "avg_entropy_of_first_answer": 0.45302988529205324, "lex_sim": 1.0}
{"question": "who is the father of genetics and what did he study", "answer": ["Gregor Mendel, he studied pea plants and formulated the basic laws of heredity."], "scores": [[0.990234375, 1.0, 0.88525390625, 1.0, 1.0, 0.413330078125, 0.82763671875, 0.9951171875, 0.7392578125, 0.99365234375, 0.9951171875, 0.0291748046875, 0.104248046875, 1.0, 0.974609375, 0.115234375, 0.77197265625, 0.9990234375, 0.472412109375, 1.0, 1.0, 0.78759765625, 0.0, 0.0005898475646972656, 0.228759765625, 0.06549072265625, 0.003704071044921875, 0.0021877288818359375, 0.923828125, 0.15576171875, 0.966796875, 0.00583648681640625, 0.465087890625, 0.953125, 0.99951171875, 0.2099609375]], "normalized_score": [0.0], "tokens": [["\u2581Greg", "or", "\u2581M", "end", "el", ",", "\u2581he", "\u2581studied", "\u2581pe", "a", "\u2581plants", "\u2581and", "\u2581form", "ulated", "\u2581the", "\u2581basic", "\u2581laws", "\u2581of", "\u2581her", "ed", "ity", ".", "\u2581CHAPTER", "\u2581VI", ".", "\u2581THE", "\u2581B", "IO", "LOG", "Y", "\u2581OF", "\u2581VI", "R", "USE", "S", "."]], "entropy": [[0.0838623046875, 2.7835369110107422e-05, 0.35986328125, 0.00016117095947265625, 0.0005445480346679688, 1.2294921875, 0.72998046875, 0.039581298828125, 1.0078125, 0.039276123046875, 0.03192138671875, 0.7998046875, 2.373046875, 0.0011844635009765625, 0.1368408203125, 1.0546875, 0.5771484375, 0.0089874267578125, 1.0595703125, 0.0005207061767578125, 1.9431114196777344e-05, 0.80224609375, 0.40478515625, 2.00390625, 3.294921875, 3.05078125, 2.939453125, 1.0390625, 0.42431640625, 0.447509765625, 0.2237548828125, 2.533203125, 1.4853515625, 0.240478515625, 0.00582122802734375, 3.2890625]], "avg_entropy": [0.8810830000374053], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the common edible pea", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4098794209803659, "std_of_first_answer": 0.4098794209803659, "avg_entropy_of_first_answer": 0.8810830000374053, "lex_sim": 1.0}
{"question": "who is the actress who plays baker on blue bloods", "answer": ["Tanya Clarke"], "scores": [[0.1864013671875, 0.0037517547607421875, 0.364501953125, 1.0]], "normalized_score": [0.12635600566864014], "tokens": [["\u2581T", "anya", "\u2581Clar", "ke"]], "entropy": [[3.255859375, 3.81640625, 2.248046875, 0.0006399154663085938]], "avg_entropy": [2.330238103866577], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Abigail Hawk", "score_of_biggest_cluster": 0.12635600566864014, "score_of_first_answer": 0.12635600566864014, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0037517547607421875, "avg_score": 0.12635600566864014, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.375294257407553, "std_of_first_answer": 0.375294257407553, "avg_entropy_of_first_answer": 2.330238103866577, "lex_sim": 1.0}
{"question": "who sings you can't get what you want", "answer": ["Arctic Monkeys CHAPTER 4: STAKES"], "scores": [[0.254150390625, 0.533203125, 0.998046875, 1.0, 0.0, 0.214111328125, 0.08062744140625, 0.58837890625, 0.007678985595703125, 0.006450653076171875, 0.0228424072265625, 0.99462890625]], "normalized_score": [0.0], "tokens": [["\u2581Ar", "ctic", "\u2581Mon", "keys", "\u2581CHAPTER", "\u2581", "4", ":", "\u2581S", "TA", "K", "ES"]], "entropy": [[2.59765625, 0.958984375, 0.0162200927734375, 0.0007214546203613281, 0.8310546875, 2.3046875, 1.802734375, 1.8154296875, 2.4453125, 3.6640625, 1.1943359375, 0.05096435546875]], "avg_entropy": [1.4735136429468791], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the Rolling Stones", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39712636417422753, "std_of_first_answer": 0.39712636417422753, "avg_entropy_of_first_answer": 1.4735136429468791, "lex_sim": 1.0}
{"question": "who won the oscar for best picture in 1976", "answer": ["Rocky"], "scores": [[0.873046875, 1.0]], "normalized_score": [0.9343697428703308], "tokens": [["\u2581Rock", "y"]], "entropy": [[0.5751953125, 0.0005412101745605469]], "avg_entropy": [0.2878682613372803], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Rocky", "score_of_biggest_cluster": 0.9343697428703308, "score_of_first_answer": 0.9343697428703308, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.873046875, "avg_score": 0.9343697428703308, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.0634765625, "std_of_first_answer": 0.0634765625, "avg_entropy_of_first_answer": 0.2878682613372803, "lex_sim": 1.0}
{"question": "who wrote the song oh lord won't you buy me a mercedes benz", "answer": ["Janis Ian"], "scores": [[0.9482421875, 0.83203125, 0.034454345703125]], "normalized_score": [0.3006775379180908], "tokens": [["\u2581Jan", "is", "\u2581Ian"]], "entropy": [[0.396728515625, 1.1044921875, 0.348876953125]], "avg_entropy": [0.61669921875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Janis Joplin", "score_of_biggest_cluster": 0.3006775379180908, "score_of_first_answer": 0.3006775379180908, "max_score_of_first_answer": 0.9482421875, "min_score_of_first_answer": 0.034454345703125, "avg_score": 0.3006775379180908, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4061529706455994, "std_of_first_answer": 0.4061529706455994, "avg_entropy_of_first_answer": 0.61669921875, "lex_sim": 1.0}
{"question": "when do new episodes of mindy project air", "answer": ["The Mindy Project has been canceled and therefore does not have new episodes."], "scores": [[0.298583984375, 0.90478515625, 1.0, 0.99853515625, 0.1920166015625, 0.01751708984375, 0.666015625, 1.0, 1.0, 0.53662109375, 0.09857177734375, 0.0445556640625, 1.0, 0.6279296875, 0.66845703125, 0.9990234375, 0.413330078125]], "normalized_score": [0.4086203873157501], "tokens": [["\u2581The", "\u2581Mind", "y", "\u2581Project", "\u2581has", "\u2581been", "\u2581can", "ce", "led", "\u2581and", "\u2581therefore", "\u2581does", "\u2581not", "\u2581have", "\u2581new", "\u2581episodes", "."]], "entropy": [[3.015625, 0.453857421875, 0.00013196468353271484, 0.01247406005859375, 2.666015625, 1.509765625, 0.8095703125, 0.0012083053588867188, 0.00011205673217773438, 1.064453125, 2.224609375, 1.2470703125, 0.0007090568542480469, 0.830078125, 0.67333984375, 0.0079803466796875, 0.8515625]], "avg_entropy": [0.9040331209407133], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "November\u00a07,\u00a02017", "score_of_biggest_cluster": 0.4086203873157501, "score_of_first_answer": 0.4086203873157501, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.01751708984375, "avg_score": 0.4086203873157501, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3639657202067574, "std_of_first_answer": 0.3639657202067574, "avg_entropy_of_first_answer": 0.9040331209407133, "lex_sim": 1.0}
{"question": "what is the salary of the ceo of microsoft", "answer": ["I'm sorry, I don't have that information."], "scores": [[0.01108551025390625, 0.11346435546875, 0.9921875, 0.96337890625, 0.9873046875, 0.69970703125, 0.57177734375, 0.99755859375, 1.0, 0.83447265625, 0.27099609375, 0.9912109375, 0.91650390625, 0.285400390625, 0.144287109375, 0.99951171875, 0.3994140625, 0.99755859375, 0.75830078125, 0.9990234375, 1.0, 0.9970703125, 0.9990234375, 0.501953125, 0.53466796875, 0.396484375, 0.94775390625, 1.0, 0.81201171875, 0.7841796875, 0.9541015625, 0.93017578125, 0.62744140625, 0.97509765625, 2.980232238769531e-07, 0.01160430908203125, 0.00027179718017578125, 0.01983642578125, 0.0012311935424804688, 0.107666015625, 8.845329284667969e-05, 0.98974609375, 0.0013875961303710938, 0.38818359375, 0.070556640625, 0.328857421875, 0.25927734375, 0.9970703125]], "normalized_score": [0.19079992175102234], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581I", "\u2581don", "'", "t", "\u2581have", "\u2581that", "\u2581information", ".", "\u2581The", "\u2581CE", "O", "\u2581of", "\u2581Microsoft", "\u2581is", "\u2581Sat", "ya", "\u2581Nad", "ella", "\u2581and", "\u2581his", "\u2581current", "\u2581sal", "ary", "\u2581is", "\u2581not", "\u2581public", "ly", "\u2581available", ".", "\u2581#", "I", "WS", "G", "\u2581-", "\u2581The", "\u2581Power", "\u2581of", "\u2581Re", "views", "\u2581and", "\u2581Re", "comm", "end"]], "entropy": [[0.51611328125, 1.5, 0.048248291015625, 0.19189453125, 0.08203125, 0.9931640625, 0.9794921875, 0.01824951171875, 0.0008440017700195312, 0.45556640625, 1.5517578125, 0.059326171875, 0.423583984375, 1.9697265625, 0.6611328125, 0.0037784576416015625, 1.04296875, 0.0190887451171875, 0.9658203125, 0.00992584228515625, 0.00012314319610595703, 0.024444580078125, 0.0086517333984375, 1.0478515625, 1.189453125, 0.96142578125, 0.254150390625, 0.00018608570098876953, 0.73876953125, 0.8466796875, 0.2357177734375, 0.320068359375, 0.90771484375, 0.1561279296875, 0.61376953125, 4.49609375, 1.220703125, 2.34375, 1.064453125, 4.63671875, 2.21875, 0.068115234375, 3.607421875, 2.205078125, 2.796875, 2.73828125, 1.5908203125, 0.024200439453125]], "avg_entropy": [0.996023083726565], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "$84.3 million", "score_of_biggest_cluster": 0.19079992175102234, "score_of_first_answer": 0.19079992175102234, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.19079992175102234, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3933339846373561, "std_of_first_answer": 0.3933339846373561, "avg_entropy_of_first_answer": 0.996023083726565, "lex_sim": 1.0}
{"question": "what channel is celebrity big brother on in the usa", "answer": ["CBS All Access #1733: The Last War"], "scores": [[0.53125, 0.26416015625, 0.9970703125, 2.086162567138672e-06, 0.00740814208984375, 0.0029888153076171875, 0.0745849609375, 0.021942138671875, 0.0013484954833984375, 0.0133514404296875, 0.001346588134765625, 0.0014133453369140625]], "normalized_score": [0.009189038537442684], "tokens": [["\u2581CBS", "\u2581All", "\u2581Access", "\u2581#", "1", "7", "3", "3", ":", "\u2581The", "\u2581Last", "\u2581War"]], "entropy": [[1.9921875, 1.146484375, 0.0234832763671875, 1.32421875, 2.234375, 1.6845703125, 2.6171875, 1.9365234375, 2.89453125, 4.9609375, 5.8671875, 5.3203125]], "avg_entropy": [2.666833241780599], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "CBS", "score_of_biggest_cluster": 0.009189038537442684, "score_of_first_answer": 0.009189038537442684, "max_score_of_first_answer": 0.9970703125, "min_score_of_first_answer": 2.086162567138672e-06, "avg_score": 0.009189038537442684, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.29527534383759385, "std_of_first_answer": 0.29527534383759385, "avg_entropy_of_first_answer": 2.666833241780599, "lex_sim": 1.0}
{"question": "who wrote he ain't heavy he's my brother lyrics", "answer": ["Bobby Russell #RivetingReviews: Anna-Joyce Dijkmans reviews NOCTURA by Kazuo Ishiguro"], "scores": [[0.60400390625, 0.3466796875, 2.384185791015625e-07, 0.0089263916015625, 0.0028533935546875, 0.67431640625, 0.005290985107421875, 0.0210723876953125, 0.0009551048278808594, 3.331899642944336e-05, 0.006488800048828125, 0.0002989768981933594, 0.263671875, 0.0018758773803710938, 0.032958984375, 0.004665374755859375, 0.03656005859375, 0.99462890625, 0.005794525146484375, 2.7000904083251953e-05, 0.00958251953125, 0.296875, 0.0662841796875, 0.0120697021484375, 0.006809234619140625, 0.132568359375, 0.9951171875, 0.666015625, 0.9609375, 0.998046875, 0.998046875]], "normalized_score": [0.01883264072239399], "tokens": [["\u2581Bobby", "\u2581Russell", "\u2581#", "R", "iv", "eting", "Re", "views", ":", "\u2581Anna", "-", "Jo", "y", "ce", "\u2581D", "ij", "km", "ans", "\u2581reviews", "\u2581NO", "CT", "UR", "A", "\u2581by", "\u2581K", "azu", "o", "\u2581I", "sh", "ig", "uro"]], "entropy": [[1.703125, 0.693359375, 0.64453125, 5.4609375, 4.0078125, 2.24609375, 3.4140625, 0.755859375, 0.9912109375, 4.75, 3.11328125, 2.3828125, 3.19140625, 5.0234375, 4.93359375, 4.45703125, 2.666015625, 0.040496826171875, 4.140625, 3.29296875, 4.82421875, 1.3193359375, 1.0263671875, 1.685546875, 4.375, 3.197265625, 0.044586181640625, 0.84521484375, 0.232421875, 0.0182037353515625, 0.016357421875]], "avg_entropy": [2.4352638490738405], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Bobby Scott", "score_of_biggest_cluster": 0.01883264072239399, "score_of_first_answer": 0.01883264072239399, "max_score_of_first_answer": 0.998046875, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.01883264072239399, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3731705302896034, "std_of_first_answer": 0.3731705302896034, "avg_entropy_of_first_answer": 2.4352638490738405, "lex_sim": 1.0}
{"question": "what is the largest city in the united states per square mile", "answer": ["Manhattan, New York City #IWSG Post: The Importance of Honesty & Vulnerability in Writing"], "scores": [[0.55126953125, 1.0, 0.62548828125, 0.98291015625, 1.0, 0.96435546875, 2.384185791015625e-07, 0.0022449493408203125, 0.00040435791015625, 0.052947998046875, 9.834766387939453e-06, 0.10235595703125, 0.10546875, 0.330810546875, 0.9990234375, 0.9765625, 0.00806427001953125, 0.9111328125, 0.006305694580078125, 0.44189453125, 0.99609375, 0.990234375, 0.99853515625, 0.74462890625, 0.85595703125]], "normalized_score": [0.08485819399356842], "tokens": [["\u2581Manh", "attan", ",", "\u2581New", "\u2581York", "\u2581City", "\u2581#", "I", "WS", "G", "\u2581Post", ":", "\u2581The", "\u2581Import", "ance", "\u2581of", "\u2581Hon", "esty", "\u2581&", "\u2581V", "ul", "ner", "ability", "\u2581in", "\u2581Writing"]], "entropy": [[2.921875, 0.0002944469451904297, 1.1484375, 0.11077880859375, 0.00011235475540161133, 0.19775390625, 1.3310546875, 5.234375, 4.51171875, 2.888671875, 1.296875, 2.34375, 4.359375, 3.65625, 0.0099945068359375, 0.12432861328125, 3.724609375, 0.3408203125, 1.1142578125, 1.5859375, 0.0304412841796875, 0.06341552734375, 0.012908935546875, 1.21875, 0.77490234375]], "avg_entropy": [1.5600675415992737], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Sitka", "score_of_biggest_cluster": 0.08485819399356842, "score_of_first_answer": 0.08485819399356842, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.08485819399356842, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42473576287885867, "std_of_first_answer": 0.42473576287885867, "avg_entropy_of_first_answer": 1.5600675415992737, "lex_sim": 1.0}
{"question": "what is the main objective of criminal law", "answer": ["To protect society and punish those who break the law."], "scores": [[0.34619140625, 0.360107421875, 0.9912109375, 0.587890625, 0.66259765625, 0.998046875, 0.701171875, 1.0, 0.50390625, 0.99169921875, 0.9990234375, 0.97314453125, 0.003200531005859375, 0.01143646240234375, 1.0, 0.10162353515625, 0.0, 0.98046875, 0.9091796875, 0.0174560546875, 0.9697265625, 0.99951171875, 0.99951171875, 0.9951171875, 0.875, 0.01293182373046875, 0.11468505859375, 0.90185546875, 0.146240234375, 0.9501953125, 0.9990234375, 1.0, 0.95703125, 0.97119140625, 0.002685546875, 1.0, 1.0, 0.0011920928955078125, 1.0, 1.0, 0.9638671875, 0.170166015625, 0.86767578125, 0.998046875, 0.892578125, 0.93212890625, 0.99951171875, 0.962890625]], "normalized_score": [0.0], "tokens": [["\u2581To", "\u2581protect", "\u2581society", "\u2581and", "\u2581pun", "ish", "\u2581those", "\u2581who", "\u2581break", "\u2581the", "\u2581law", ".", "\u2581It", "'", "s", "\u2581a", "\u2581Wonder", "ful", "\u2581Life", "\u2581(", "1", "9", "4", "6", ")", "\u2581-", "\u2581James", "\u2581Stewart", "\u2581plays", "\u2581George", "\u2581Ba", "iley", ",", "\u2581a", "\u2581fr", "ustr", "ated", "\u2581entrepr", "ene", "ur", "\u2581who", "\u2581has", "\u2581given", "\u2581up", "\u2581his", "\u2581dream", "s", "\u2581to"]], "entropy": [[1.1630859375, 1.6630859375, 0.0638427734375, 0.96044921875, 1.3408203125, 0.0163116455078125, 1.1015625, 0.00243377685546875, 1.1435546875, 0.05743408203125, 0.00687408447265625, 0.1546630859375, 0.2061767578125, 1.02734375, 1.3113021850585938e-05, 1.8046875, 1.59765625, 0.10760498046875, 0.56689453125, 2.26171875, 0.1927490234375, 0.004547119140625, 0.00502777099609375, 0.034515380859375, 0.5537109375, 2.16015625, 4.0, 0.434814453125, 2.01171875, 0.2332763671875, 0.006824493408203125, 0.0013332366943359375, 0.242919921875, 0.1800537109375, 0.0977783203125, 0.00019168853759765625, 1.0728836059570312e-06, 0.912109375, 0.0016880035400390625, 0.00011843442916870117, 0.200927734375, 2.96484375, 0.49365234375, 0.01439666748046875, 0.35498046875, 0.287841796875, 0.00487518310546875, 0.2164306640625]], "avg_entropy": [0.6428686790168285], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Incapacitation", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38880352399985313, "std_of_first_answer": 0.38880352399985313, "avg_entropy_of_first_answer": 0.6428686790168285, "lex_sim": 1.0}
{"question": "when will the next episode of flash be aired", "answer": ["The Flash is currently in its seventh season, which premiered on October 8, 2020."], "scores": [[0.130126953125, 0.408203125, 0.6123046875, 0.41259765625, 0.3359375, 0.97265625, 0.491455078125, 1.0, 0.99755859375, 0.58349609375, 0.487060546875, 0.80615234375, 1.0, 0.98974609375, 0.95947265625, 0.99853515625, 0.82861328125, 0.9375, 0.99853515625, 1.0, 1.0, 0.25390625, 0.9453125, 0.8857421875, 0.0163726806640625, 0.99853515625, 0.202880859375, 0.69482421875, 0.9990234375, 1.0, 0.57958984375, 1.0, 0.9931640625, 0.9677734375, 0.58056640625, 0.9990234375, 0.99658203125, 0.82373046875, 0.9990234375, 0.3466796875, 0.446044921875, 0.341552734375, 0.53759765625, 0.00453948974609375, 0.320556640625, 0.118896484375, 0.403076171875, 0.99951171875, 0.099365234375, 0.9111328125]], "normalized_score": [0.5230043530464172], "tokens": [["\u2581The", "\u2581Flash", "\u2581is", "\u2581currently", "\u2581in", "\u2581its", "\u2581sevent", "h", "\u2581season", ",", "\u2581which", "\u2581premier", "ed", "\u2581on", "\u2581October", "\u2581", "8", ",", "\u2581", "2", "0", "2", "0", ".", "\u2581Unfortunately", ",", "\u2581as", "\u2581an", "\u2581A", "I", "\u2581language", "\u2581model", ",", "\u2581I", "\u2581do", "\u2581not", "\u2581have", "\u2581access", "\u2581to", "\u2581future", "\u2581sched", "ules", "\u2581or", "\u2581news", ".", "\u2581Please", "\u2581refer", "\u2581to", "\u2581a", "\u2581reliable"]], "entropy": [[1.8671875, 2.091796875, 1.6748046875, 1.2978515625, 1.009765625, 0.1724853515625, 1.1982421875, 3.707408905029297e-05, 0.019866943359375, 1.0244140625, 1.3076171875, 0.79052734375, 0.0003871917724609375, 0.0643310546875, 0.207763671875, 0.0103912353515625, 0.572265625, 0.2391357421875, 0.01293182373046875, 1.5437602996826172e-05, 4.827976226806641e-06, 0.56640625, 0.2216796875, 0.422119140625, 2.0546875, 0.012481689453125, 1.3017578125, 0.8271484375, 0.0083770751953125, 0.00012731552124023438, 1.078125, 0.0014791488647460938, 0.047637939453125, 0.1453857421875, 1.013671875, 0.00897979736328125, 0.0259246826171875, 0.70361328125, 0.006511688232421875, 2.001953125, 1.501953125, 0.642578125, 1.412109375, 2.330078125, 1.646484375, 1.939453125, 0.92431640625, 0.0027027130126953125, 1.4853515625, 0.50537109375]], "avg_entropy": [0.7280057644844056], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "May\u00a015,\u00a02018", "score_of_biggest_cluster": 0.5230043530464172, "score_of_first_answer": 0.5230043530464172, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.00453948974609375, "avg_score": 0.5230043530464172, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.32841643232125284, "std_of_first_answer": 0.32841643232125284, "avg_entropy_of_first_answer": 0.7280057644844056, "lex_sim": 1.0}
{"question": "who sang once upon a dream at the end of maleficent", "answer": ["Lana Del Rey #1 New York Times bestselling author Sandra Brown introduces a fiercely suspenseful new series set in the heart of Texas."], "scores": [[0.99658203125, 0.99462890625, 0.978515625, 0.9921875, 5.364418029785156e-07, 0.04876708984375, 0.00012540817260742188, 0.86669921875, 0.99267578125, 0.2149658203125, 0.399658203125, 0.953125, 0.94580078125, 2.586841583251953e-05, 0.9990234375, 0.97265625, 0.001644134521484375, 1.0, 0.66650390625, 0.09136962890625, 0.70361328125, 0.99853515625, 0.01216888427734375, 1.0, 1.0, 0.99951171875, 0.302001953125, 0.20654296875, 0.9619140625, 0.8837890625, 0.013946533203125, 0.9638671875, 0.87255859375, 0.388671875]], "normalized_score": [0.16107484698295593], "tokens": [["\u2581L", "ana", "\u2581Del", "\u2581Rey", "\u2581#", "1", "\u2581New", "\u2581York", "\u2581Times", "\u2581best", "s", "elling", "\u2581author", "\u2581Sand", "ra", "\u2581Brown", "\u2581introdu", "ces", "\u2581a", "\u2581fier", "c", "ely", "\u2581susp", "ense", "ful", "\u2581new", "\u2581series", "\u2581set", "\u2581in", "\u2581the", "\u2581heart", "\u2581of", "\u2581Texas", "."]], "entropy": [[0.03582763671875, 0.04095458984375, 0.10906982421875, 0.049652099609375, 0.79248046875, 4.8984375, 3.076171875, 0.7109375, 0.057037353515625, 0.7470703125, 0.7890625, 0.1947021484375, 0.39892578125, 2.109375, 0.01035308837890625, 0.209228515625, 3.462890625, 0.0005106925964355469, 1.3583984375, 4.0234375, 0.80712890625, 0.01015472412109375, 2.14453125, 0.0015554428100585938, 1.1324882507324219e-06, 0.004024505615234375, 1.7958984375, 2.05859375, 0.199462890625, 0.73779296875, 3.59375, 0.175048828125, 0.443359375, 1.337890625]], "avg_entropy": [1.0701093025067274], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Lana Del Rey", "score_of_biggest_cluster": 0.16107484698295593, "score_of_first_answer": 0.16107484698295593, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.364418029785156e-07, "avg_score": 0.16107484698295593, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41105808261252, "std_of_first_answer": 0.41105808261252, "avg_entropy_of_first_answer": 1.0701093025067274, "lex_sim": 1.0}
{"question": "where does the sciatic nerve run in the foot", "answer": ["It runs from the lower back, through the buttocks, and down the back of the leg to the ankle and foot."], "scores": [[0.0780029296875, 0.86572265625, 0.26611328125, 0.99755859375, 0.33251953125, 1.0, 0.355224609375, 0.482666015625, 0.99951171875, 0.93994140625, 1.0, 0.98974609375, 0.35546875, 0.587890625, 0.99853515625, 0.99365234375, 0.58935546875, 0.99951171875, 0.99853515625, 0.98779296875, 0.4033203125, 0.99853515625, 0.01441192626953125, 1.0, 0.9990234375, 0.94287109375, 0.98046875, 0.966796875, 8.344650268554688e-07, 0.006439208984375, 0.064697265625, 0.0191802978515625, 5.364418029785156e-07, 0.005718231201171875, 0.002834320068359375, 0.0003387928009033203, 0.01192474365234375, 0.71142578125, 0.061248779296875, 0.32421875, 0.07916259765625, 0.07904052734375, 0.998046875, 0.365478515625, 0.1573486328125, 0.99560546875, 0.99365234375, 0.99951171875]], "normalized_score": [0.1528395712375641], "tokens": [["\u2581It", "\u2581runs", "\u2581from", "\u2581the", "\u2581lower", "\u2581back", ",", "\u2581through", "\u2581the", "\u2581but", "to", "cks", ",", "\u2581and", "\u2581down", "\u2581the", "\u2581back", "\u2581of", "\u2581the", "\u2581leg", "\u2581to", "\u2581the", "\u2581an", "k", "le", "\u2581and", "\u2581foot", ".", "\u2581#", "2", "5", "1", "\u2581Post", "\u2581by", "\u2581John", "AS", "4", "2", "4", "\u2581\u00bb", "\u2581Wed", "\u2581May", "\u2581", "0", "1", ",", "\u2581", "2"]], "entropy": [[3.546875, 0.56396484375, 1.6083984375, 0.0206756591796875, 1.888671875, 0.0026645660400390625, 1.3203125, 0.720703125, 0.00569915771484375, 0.281005859375, 8.147954940795898e-05, 0.058258056640625, 0.65625, 0.6904296875, 0.01416015625, 0.044708251953125, 0.96435546875, 0.003192901611328125, 0.01221466064453125, 0.07275390625, 1.3583984375, 0.0139617919921875, 0.351318359375, 0.0001900196075439453, 0.0091400146484375, 0.26953125, 0.14501953125, 0.19091796875, 0.426513671875, 4.09765625, 3.162109375, 2.41015625, 2.51171875, 2.720703125, 6.4296875, 4.48046875, 4.28125, 1.3271484375, 2.12109375, 2.357421875, 1.9267578125, 2.474609375, 0.01358795166015625, 1.236328125, 1.9453125, 0.03045654296875, 0.05023193359375, 0.004932403564453125]], "avg_entropy": [1.225458278010289], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "on the posterior aspect", "score_of_biggest_cluster": 0.1528395712375641, "score_of_first_answer": 0.1528395712375641, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.364418029785156e-07, "avg_score": 0.1528395712375641, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4195680911057696, "std_of_first_answer": 0.4195680911057696, "avg_entropy_of_first_answer": 1.225458278010289, "lex_sim": 1.0}
{"question": "puella magi madoka magica when does madoka become a magical girl", "answer": ["Episode 1 Tags: Eurasia, Eurozone, Federal Reserve, France, German, Germany, international trade, Iran, Middle East, Mohammad Sarafraz, Persian Gulf, Russia, Syria, Te"], "scores": [[0.376708984375, 1.0, 0.9990234375, 0.7626953125, 0.0, 0.80517578125, 0.0009765625, 1.1920928955078125e-07, 0.998046875, 0.1593017578125, 6.556510925292969e-06, 0.0022735595703125, 0.64501953125, 0.0013284683227539062, 0.7880859375, 0.4130859375, 0.015655517578125, 0.97802734375, 0.037078857421875, 0.81494140625, 0.21435546875, 0.9794921875, 0.000797271728515625, 0.057281494140625, 0.947265625, 0.0230865478515625, 0.970703125, 0.020416259765625, 0.984375, 0.9853515625, 0.003814697265625, 0.87646484375, 0.9990234375, 0.00014698505401611328, 0.41357421875, 0.9873046875, 0.9501953125, 0.0117950439453125, 0.91650390625, 0.724609375, 0.9990234375, 0.982421875, 0.0711669921875, 0.99267578125, 0.042449951171875, 0.89794921875, 0.98974609375, 0.1611328125]], "normalized_score": [0.0], "tokens": [["\u2581E", "pisode", "\u2581", "1", "\u2581Tags", ":", "\u2581E", "uras", "ia", ",", "\u2581Euro", "zone", ",", "\u2581Federal", "\u2581Reserve", ",", "\u2581France", ",", "\u2581German", ",", "\u2581Germany", ",", "\u2581international", "\u2581trade", ",", "\u2581Iran", ",", "\u2581Middle", "\u2581East", ",", "\u2581Moh", "amm", "ad", "\u2581Sar", "af", "raz", ",", "\u2581Pers", "ian", "\u2581G", "ulf", ",", "\u2581Russia", ",", "\u2581Sy", "ria", ",", "\u2581Te"]], "entropy": [[2.32421875, 0.00032806396484375, 0.00917816162109375, 0.76123046875, 0.86669921875, 1.330078125, 3.8359375, 0.6962890625, 0.0169830322265625, 2.728515625, 5.00390625, 3.171875, 1.775390625, 5.26171875, 1.2890625, 1.2060546875, 5.28515625, 0.1695556640625, 2.794921875, 1.1298828125, 3.759765625, 0.1331787109375, 3.900390625, 1.7578125, 0.417236328125, 3.564453125, 0.2139892578125, 3.244140625, 0.11248779296875, 0.1146240234375, 3.818359375, 0.46484375, 0.01049041748046875, 1.66796875, 3.138671875, 0.100830078125, 0.438232421875, 4.23046875, 0.29638671875, 0.89013671875, 0.00830078125, 0.1387939453125, 4.8046875, 0.067138671875, 2.23046875, 0.3662109375, 0.08612060546875, 3.470703125]], "avg_entropy": [1.7313307126363118], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "My Very Best Friend", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43148562468721496, "std_of_first_answer": 0.43148562468721496, "avg_entropy_of_first_answer": 1.7313307126363118, "lex_sim": 1.0}
{"question": "what type of energy do satellites generally use to communicate with earth", "answer": ["Radio Wave \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ is a software development method used to create software through incremental and iterative development."], "scores": [[0.62158203125, 0.0802001953125, 0.366455078125, 3.5762786865234375e-07, 0.005397796630859375, 0.9873046875, 0.99755859375, 0.98046875, 0.85498046875, 0.88671875, 0.9052734375, 0.91064453125, 0.919921875, 0.1414794921875, 0.0004496574401855469, 0.039215087890625, 1.3113021850585938e-06, 0.0098419189453125, 0.0213775634765625, 0.0038242340087890625, 0.284423828125, 0.1864013671875, 0.43115234375, 0.0020503997802734375, 0.07470703125, 0.99169921875, 0.71533203125, 0.27734375, 0.99853515625, 0.87255859375, 0.720703125]], "normalized_score": [0.07624281942844391], "tokens": [["\u2581Radio", "\u2581W", "ave", "\u2581\\", "_\\", "_\\", "_\\", "_\\", "_\\", "_\\", "_\\", "_\\", "_\\", "_", "\u2581is", "\u2581a", "\u2581software", "\u2581development", "\u2581method", "\u2581used", "\u2581to", "\u2581create", "\u2581software", "\u2581through", "\u2581increment", "al", "\u2581and", "\u2581iter", "ative", "\u2581development", "."]], "entropy": [[1.1474609375, 1.0771484375, 0.66259765625, 0.970703125, 0.49267578125, 0.0706787109375, 0.01739501953125, 0.1112060546875, 0.435546875, 0.369384765625, 0.326171875, 0.314697265625, 0.299560546875, 0.449462890625, 1.6865234375, 1.53515625, 1.494140625, 3.9765625, 2.59765625, 0.336669921875, 1.77734375, 2.203125, 3.0859375, 1.6201171875, 2.759765625, 0.058807373046875, 1.1533203125, 1.615234375, 0.01074981689453125, 0.73388671875, 1.0771484375]], "avg_entropy": [1.1118333878055695], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "radio and microwave frequencies", "score_of_biggest_cluster": 0.07624281942844391, "score_of_first_answer": 0.07624281942844391, "max_score_of_first_answer": 0.99853515625, "min_score_of_first_answer": 3.5762786865234375e-07, "avg_score": 0.07624281942844391, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4042034637560011, "std_of_first_answer": 0.4042034637560011, "avg_entropy_of_first_answer": 1.1118333878055695, "lex_sim": 1.0}
{"question": "when did the botswana currency first come into circulation", "answer": ["1976"], "scores": [[0.8759765625, 0.9990234375, 0.9892578125, 0.9912109375, 0.98388671875]], "normalized_score": [0.9667134881019592], "tokens": [["\u2581", "1", "9", "7", "6"]], "entropy": [[0.73291015625, 0.00916290283203125, 0.06976318359375, 0.058807373046875, 0.09869384765625]], "avg_entropy": [0.19386749267578124], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1976", "score_of_biggest_cluster": 0.9667134881019592, "score_of_first_answer": 0.9667134881019592, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 0.8759765625, "avg_score": 0.9667134881019592, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.046203276256304666, "std_of_first_answer": 0.046203276256304666, "avg_entropy_of_first_answer": 0.19386749267578124, "lex_sim": 1.0}
{"question": "who wrote the first declaration of human rights", "answer": ["The first declaration of human rights was written in 1789 during the French Revolution by the National Constituent Assembly."], "scores": [[0.84228515625, 0.2032470703125, 0.1695556640625, 0.99951171875, 0.99609375, 1.0, 0.89697265625, 0.461669921875, 0.0140380859375, 0.94580078125, 1.0, 0.9775390625, 0.8388671875, 1.0, 0.0122528076171875, 0.99560546875, 0.99072265625, 0.99951171875, 0.75, 0.97998046875, 0.44775390625, 0.92431640625, 1.0, 1.0, 0.99951171875, 0.40771484375, 0.493896484375, 0.95263671875, 0.1329345703125, 0.99609375, 0.30859375, 0.74072265625, 0.9990234375, 0.057464599609375, 0.07855224609375, 1.0, 0.8203125, 0.09271240234375, 0.99658203125, 0.92578125, 0.771484375, 0.0252685546875, 0.88818359375, 1.0, 0.9990234375, 0.7861328125, 0.52392578125, 0.7705078125, 0.99951171875, 0.943359375]], "normalized_score": [0.5166087746620178], "tokens": [["\u2581The", "\u2581first", "\u2581declaration", "\u2581of", "\u2581human", "\u2581rights", "\u2581was", "\u2581written", "\u2581in", "\u2581", "1", "7", "8", "9", "\u2581during", "\u2581the", "\u2581French", "\u2581Revolution", "\u2581by", "\u2581the", "\u2581National", "\u2581Const", "itu", "ent", "\u2581Assembly", ".", "\u2581It", "\u2581was", "\u2581written", "\u2581by", "\u2581a", "\u2581group", "\u2581of", "\u2581French", "\u2581think", "ers", "\u2581and", "\u2581states", "men", ",", "\u2581including", "\u2581La", "f", "ay", "ette", ",", "\u2581B", "ail", "ly", ","]], "entropy": [[1.0908203125, 3.611328125, 2.591796875, 0.00516510009765625, 0.031158447265625, 0.001628875732421875, 0.435791015625, 1.5478515625, 0.0897216796875, 0.253173828125, 0.0016880035400390625, 0.11962890625, 0.51171875, 0.0004982948303222656, 0.227294921875, 0.032196044921875, 0.078369140625, 0.005954742431640625, 0.79736328125, 0.1304931640625, 2.12109375, 0.276123046875, 0.0002739429473876953, 0.0012216567993164062, 0.004695892333984375, 1.37890625, 1.408203125, 0.2073974609375, 1.6298828125, 0.0316162109375, 2.294921875, 0.7587890625, 0.00783538818359375, 2.03125, 2.814453125, 0.00039005279541015625, 0.576171875, 1.8759765625, 0.0246429443359375, 0.39892578125, 0.95068359375, 3.20703125, 0.4404296875, 0.00016832351684570312, 0.007350921630859375, 0.53173828125, 2.158203125, 1.2080078125, 0.00687408447265625, 0.2205810546875]], "avg_entropy": [0.7627496004104615], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Cyrus", "score_of_biggest_cluster": 0.5166087746620178, "score_of_first_answer": 0.5166087746620178, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0122528076171875, "avg_score": 0.5166087746620178, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3468456418646373, "std_of_first_answer": 0.3468456418646373, "avg_entropy_of_first_answer": 0.7627496004104615, "lex_sim": 1.0}
{"question": "who played ice queen in chronicles of narnia", "answer": ["Tilda Swinton"], "scores": [[0.9853515625, 1.0, 1.0, 0.99658203125]], "normalized_score": [0.9954651594161987], "tokens": [["\u2581T", "ilda", "\u2581Sw", "inton"]], "entropy": [[0.13720703125, 0.00014781951904296875, 0.001708984375, 0.0287017822265625]], "avg_entropy": [0.04194140434265137], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Tilda Swinton", "score_of_biggest_cluster": 0.9954651594161987, "score_of_first_answer": 0.9954651594161987, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.9853515625, "avg_score": 0.9954651594161987, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.00601374410974297, "std_of_first_answer": 0.00601374410974297, "avg_entropy_of_first_answer": 0.04194140434265137, "lex_sim": 1.0}
{"question": "how many episodes of season 5 of curse of oak island", "answer": ["17 #KKK #Racism #Nazis #WhiteSupremacy"], "scores": [[0.92724609375, 0.658203125, 0.206298828125, 1.7881393432617188e-07, 5.2988529205322266e-05, 0.004734039306640625, 0.01641845703125, 0.056060791015625, 0.0164642333984375, 0.2237548828125, 0.36474609375, 0.35888671875, 0.0226287841796875, 0.60986328125, 0.1600341796875, 0.6044921875, 0.38134765625, 0.7568359375, 1.0, 1.0, 0.8818359375]], "normalized_score": [0.07142087072134018], "tokens": [["\u2581", "1", "7", "\u2581#", "K", "K", "K", "\u2581#", "R", "ac", "ism", "\u2581#", "N", "az", "is", "\u2581#", "White", "S", "up", "rem", "acy"]], "entropy": [[0.416748046875, 1.103515625, 2.173828125, 0.8203125, 3.138671875, 4.06640625, 1.453125, 1.666015625, 5.10546875, 3.521484375, 0.736328125, 1.275390625, 2.509765625, 0.833984375, 0.456298828125, 1.01953125, 2.73046875, 0.87353515625, 0.0013742446899414062, 0.0008449554443359375, 0.404541015625]], "avg_entropy": [1.6336971010480608], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "18", "score_of_biggest_cluster": 0.07142087072134018, "score_of_first_answer": 0.07142087072134018, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.07142087072134018, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.35653887705001636, "std_of_first_answer": 0.35653887705001636, "avg_entropy_of_first_answer": 1.6336971010480608, "lex_sim": 1.0}
{"question": "whens the last time the patriots played the eagles", "answer": ["Super Bowl LII on February 4, 2018."], "scores": [[0.04193115234375, 0.99755859375, 0.966796875, 0.998046875, 0.52392578125, 0.98193359375, 0.99951171875, 0.9990234375, 0.95458984375, 0.99951171875, 1.0, 1.0, 1.0, 1.0, 0.56640625, 0.60205078125, 0.88427734375, 1.0, 0.6025390625, 0.9580078125, 1.0, 1.0, 0.970703125, 1.0, 1.0, 0.9970703125, 2.384185791015625e-07, 0.06640625, 0.0013074874877929688, 0.8701171875, 9.298324584960938e-06, 0.037567138671875, 0.003326416015625, 0.99267578125, 0.35693359375, 0.99853515625, 0.99951171875, 0.9580078125, 0.99951171875, 0.0012884140014648438, 0.033233642578125, 6.264448165893555e-05, 0.2415771484375, 0.2763671875, 0.035430908203125, 0.9951171875, 0.99609375, 0.1041259765625]], "normalized_score": [0.18826940655708313], "tokens": [["\u2581Super", "\u2581Bowl", "\u2581L", "II", "\u2581on", "\u2581February", "\u2581", "4", ",", "\u2581", "2", "0", "1", "8", ".", "\u2581The", "\u2581Patri", "ots", "\u2581won", "\u2581", "4", "1", "-", "3", "3", ".", "\u2581#", "N", "FT", "\u2581#", "CR", "Y", "P", "TO", "CUR", "R", "EN", "C", "Y", "\u2581FOR", "\u2581#", "PO", "ET", "RY", "\u2581LO", "VER", "S", "!"]], "entropy": [[2.666015625, 0.0200042724609375, 0.1768798828125, 0.0157012939453125, 1.203125, 0.10101318359375, 0.005077362060546875, 0.0090789794921875, 0.186279296875, 0.0034656524658203125, 2.2530555725097656e-05, 2.0265579223632812e-06, 1.8835067749023438e-05, 0.00012177228927612305, 1.0537109375, 0.75244140625, 0.4345703125, 3.0100345611572266e-05, 0.72412109375, 0.1881103515625, 0.0007295608520507812, 0.00017273426055908203, 0.134521484375, 0.0019779205322265625, 0.0017976760864257812, 0.022125244140625, 0.10784912109375, 2.533203125, 0.287353515625, 0.5791015625, 2.2578125, 3.115234375, 1.25390625, 0.058929443359375, 1.5576171875, 0.013824462890625, 0.0052490234375, 0.1851806640625, 0.005939483642578125, 1.3515625, 3.09765625, 2.67578125, 2.375, 0.89404296875, 3.86328125, 0.035400390625, 0.041168212890625, 3.216796875]], "avg_entropy": [0.7752709363897642], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Super Bowl LII", "score_of_biggest_cluster": 0.18826940655708313, "score_of_first_answer": 0.18826940655708313, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.18826940655708313, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4165108070393075, "std_of_first_answer": 0.4165108070393075, "avg_entropy_of_first_answer": 0.7752709363897642, "lex_sim": 1.0}
{"question": "whos jack the ripper in gotham by gaslight", "answer": ["Jack the Ripper is a fictional character in the movie \"Gotham by Gaslight\"."], "scores": [[0.4052734375, 0.98291015625, 0.99951171875, 1.0, 0.83154296875, 0.822265625, 0.4970703125, 0.99853515625, 0.9970703125, 0.97900390625, 0.6318359375, 0.82373046875, 0.52685546875, 0.99951171875, 1.0, 1.0, 0.9970703125, 0.99951171875, 0.99951171875, 0.43798828125, 1.1920928955078125e-07, 0.012359619140625, 5.125999450683594e-06, 0.2415771484375]], "normalized_score": [0.204546719789505], "tokens": [["\u2581Jack", "\u2581the", "\u2581Ri", "pper", "\u2581is", "\u2581a", "\u2581fict", "ional", "\u2581character", "\u2581in", "\u2581the", "\u2581movie", "\u2581\"", "G", "oth", "am", "\u2581by", "\u2581Gas", "light", "\".", "\u2581#", "S", "kin", "Game"]], "entropy": [[1.806640625, 0.11480712890625, 0.00629425048828125, 5.9485435485839844e-05, 0.78369140625, 0.64599609375, 1.400390625, 0.011932373046875, 0.0229034423828125, 0.1539306640625, 0.80419921875, 0.78271484375, 0.75390625, 0.00635528564453125, 0.0015840530395507812, 0.00047326087951660156, 0.022064208984375, 0.003173828125, 0.003040313720703125, 1.361328125, 1.634765625, 4.60546875, 0.1541748046875, 3.00390625]], "avg_entropy": [0.7534917046626409], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Jacob Packer", "score_of_biggest_cluster": 0.204546719789505, "score_of_first_answer": 0.204546719789505, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.204546719789505, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.35285109492383226, "std_of_first_answer": 0.35285109492383226, "avg_entropy_of_first_answer": 0.7534917046626409, "lex_sim": 1.0}
{"question": "what is the highest scoring letter in scrabble", "answer": ["Q #543: How I Became a Millionaire Trading Stocks: Chris Reining"], "scores": [[0.9462890625, 1.6987323760986328e-05, 0.00835418701171875, 0.0386962890625, 0.0038852691650390625, 6.395578384399414e-05, 0.001617431640625, 0.0018224716186523438, 0.007312774658203125, 0.99951171875, 0.99951171875, 0.5693359375, 0.0002913475036621094, 0.998046875, 0.99169921875, 0.003665924072265625, 0.98828125, 0.167236328125, 1.0, 0.14599609375, 4.2438507080078125e-05, 0.91259765625, 0.8564453125]], "normalized_score": [0.030463553965091705], "tokens": [["\u2581Q", "\u2581#", "5", "4", "3", ":", "\u2581How", "\u2581I", "\u2581B", "ec", "ame", "\u2581a", "\u2581Mill", "ion", "aire", "\u2581Tr", "ading", "\u2581Sto", "cks", ":", "\u2581Chris", "\u2581Re", "ining"]], "entropy": [[0.34423828125, 1.1298828125, 1.5869140625, 2.537109375, 2.005859375, 2.34375, 3.830078125, 2.05859375, 3.0703125, 0.0053863525390625, 0.006256103515625, 1.82421875, 2.421875, 0.0186920166015625, 0.0672607421875, 2.666015625, 0.0701904296875, 3.00390625, 0.002307891845703125, 3.041015625, 3.806640625, 0.70166015625, 0.75634765625]], "avg_entropy": [1.6216744132663892], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Q", "score_of_biggest_cluster": 0.030463553965091705, "score_of_first_answer": 0.030463553965091705, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.6987323760986328e-05, "avg_score": 0.030463553965091705, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.45445468779629, "std_of_first_answer": 0.45445468779629, "avg_entropy_of_first_answer": 1.6216744132663892, "lex_sim": 1.0}
{"question": "days of our lives cast doug and julie", "answer": ["Doug Williamson and Julie Pinson #143288 - 04/08/03 08:26 PM Re: Am I the only one here who is against censorship?"], "scores": [[0.87841796875, 0.1727294921875, 0.9765625, 0.9599609375, 0.998046875, 1.0, 0.287109375, 0.99951171875, 1.7881393432617188e-07, 0.00021028518676757812, 0.028656005859375, 0.06036376953125, 0.09417724609375, 0.060943603515625, 0.08294677734375, 0.0020694732666015625, 0.5244140625, 0.4267578125, 0.1959228515625, 0.98681640625, 0.21484375, 0.159912109375, 0.9208984375, 0.04656982421875, 0.10540771484375, 0.0181427001953125, 0.45458984375, 0.06768798828125, 0.794921875, 0.20556640625, 0.11138916015625, 0.378662109375, 0.00022411346435546875, 0.775390625, 7.420778274536133e-05, 0.39404296875, 0.1083984375, 0.80029296875, 0.95458984375, 0.03662109375, 0.1934814453125, 0.0672607421875, 0.0017843246459960938, 0.00205230712890625, 0.8447265625, 0.90087890625, 0.77587890625]], "normalized_score": [0.08832710981369019], "tokens": [["\u2581Doug", "\u2581William", "son", "\u2581and", "\u2581Jul", "ie", "\u2581Pin", "son", "\u2581#", "1", "4", "3", "2", "8", "8", "\u2581-", "\u2581", "0", "4", "/", "0", "8", "/", "0", "3", "\u2581", "0", "8", ":", "2", "6", "\u2581PM", "\u2581Re", ":", "\u2581Am", "\u2581I", "\u2581the", "\u2581only", "\u2581one", "\u2581here", "\u2581who", "\u2581is", "\u2581against", "\u2581c", "ensor", "ship", "?"]], "entropy": [[0.8046875, 0.904296875, 0.1806640625, 0.2183837890625, 0.016387939453125, 0.00014638900756835938, 2.80078125, 0.0029144287109375, 1.03515625, 1.5546875, 3.462890625, 3.3984375, 2.916015625, 3.353515625, 3.005859375, 3.021484375, 3.2421875, 1.7900390625, 2.228515625, 0.10125732421875, 1.2412109375, 2.13671875, 0.400634765625, 0.96875, 2.13671875, 2.458984375, 1.9130859375, 2.197265625, 0.84033203125, 1.794921875, 2.302734375, 1.3466796875, 2.369140625, 1.302734375, 2.6953125, 2.505859375, 4.59765625, 1.1240234375, 0.372802734375, 2.169921875, 2.4765625, 3.7578125, 4.5859375, 4.6796875, 1.029296875, 0.35986328125, 1.291015625]], "avg_entropy": [1.8956164400628273], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Susan Seaforth Hayes", "score_of_biggest_cluster": 0.08832710981369019, "score_of_first_answer": 0.08832710981369019, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.08832710981369019, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37939415963354006, "std_of_first_answer": 0.37939415963354006, "avg_entropy_of_first_answer": 1.8956164400628273, "lex_sim": 1.0}
{"question": "how many books are in the diary of a whimpy kid series", "answer": ["15 #362 \u2013 The Hunt for Red October by Tom Clancy"], "scores": [[0.9365234375, 0.9892578125, 0.039581298828125, 4.76837158203125e-07, 0.0025787353515625, 0.0775146484375, 0.0240478515625, 2.092123031616211e-05, 0.2303466796875, 0.0004482269287109375, 0.00804901123046875, 0.9775390625, 0.004512786865234375, 0.8095703125, 0.049713134765625, 0.99462890625, 0.9990234375, 0.99951171875]], "normalized_score": [0.029328031465411186], "tokens": [["\u2581", "1", "5", "\u2581#", "3", "6", "2", "\u2581\u2013", "\u2581The", "\u2581H", "unt", "\u2581for", "\u2581Red", "\u2581October", "\u2581by", "\u2581Tom", "\u2581Cl", "ancy"]], "entropy": [[0.400634765625, 0.07904052734375, 1.103515625, 0.98974609375, 4.62890625, 3.48046875, 3.087890625, 2.658203125, 4.05859375, 3.83984375, 2.1640625, 0.1484375, 2.40234375, 1.1474609375, 2.3203125, 0.047576904296875, 0.0110626220703125, 0.003337860107421875]], "avg_entropy": [1.8095243242051866], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "12", "score_of_biggest_cluster": 0.029328031465411186, "score_of_first_answer": 0.029328031465411186, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 4.76837158203125e-07, "avg_score": 0.029328031465411186, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.452299828852864, "std_of_first_answer": 0.452299828852864, "avg_entropy_of_first_answer": 1.8095243242051866, "lex_sim": 1.0}
{"question": "where is the highest level of fluoride stored in the teeth", "answer": ["Teeth enamel"], "scores": [[0.0013704299926757812, 0.998046875, 0.61279296875, 1.0, 1.0]], "normalized_score": [0.2424735277891159], "tokens": [["\u2581Te", "eth", "\u2581en", "am", "el"]], "entropy": [[1.884765625, 0.0172271728515625, 1.4462890625, 5.40614128112793e-05, 0.0021991729736328125]], "avg_entropy": [0.6701070189476013], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "surface of the enamel", "score_of_biggest_cluster": 0.2424735277891159, "score_of_first_answer": 0.2424735277891159, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0013704299926757812, "avg_score": 0.2424735277891159, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.3903849518049182, "std_of_first_answer": 0.3903849518049182, "avg_entropy_of_first_answer": 0.6701070189476013, "lex_sim": 1.0}
{"question": "who played buffy the vampire slayer in the movie", "answer": ["Sarah Michelle Gellar"], "scores": [[0.1837158203125, 0.99951171875, 1.0, 0.99951171875, 0.9921875, 1.0]], "normalized_score": [0.7528688907623291], "tokens": [["\u2581Sarah", "\u2581Mich", "elle", "\u2581G", "ell", "ar"]], "entropy": [[0.59033203125, 0.007080078125, 6.961822509765625e-05, 0.006397247314453125, 0.045257568359375, 0.00010323524475097656]], "avg_entropy": [0.10820662975311279], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Kristy Swanson", "score_of_biggest_cluster": 0.7528688907623291, "score_of_first_answer": 0.7528688907623291, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.1837158203125, "avg_score": 0.7528688907623291, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.303568699392705, "std_of_first_answer": 0.303568699392705, "avg_entropy_of_first_answer": 0.10820662975311279, "lex_sim": 1.0}
{"question": "when does zay come to girl meets world", "answer": ["Season 3, episode 23 \"Wild Style\" #BREAKING: Hundreds Of Flights Canceled As Storms Sweep Throughout Florida"], "scores": [[0.08349609375, 0.9990234375, 0.6611328125, 0.47607421875, 0.1075439453125, 0.99365234375, 0.07940673828125, 0.06597900390625, 0.1435546875, 0.002605438232421875, 0.22900390625, 0.2271728515625, 0.98681640625, 1.6033649444580078e-05, 0.005489349365234375, 1.2278556823730469e-05, 0.994140625, 0.8505859375, 0.09161376953125, 0.0013227462768554688, 0.0005273818969726562, 0.99951171875, 0.007045745849609375, 0.010009765625, 0.92578125, 0.58447265625, 0.98876953125, 0.99951171875, 0.51904296875, 0.12054443359375, 0.00983428955078125, 0.4873046875, 0.74560546875, 0.998046875, 0.1556396484375, 0.13037109375, 0.0019588470458984375]], "normalized_score": [0.07671802490949631], "tokens": [["\u2581Season", "\u2581", "3", ",", "\u2581episode", "\u2581", "2", "3", "\u2581\"", "W", "ild", "\u2581Style", "\"", "\u2581#", "B", "RE", "AK", "ING", ":", "\u2581H", "undred", "s", "\u2581Of", "\u2581Fl", "ights", "\u2581C", "ance", "led", "\u2581As", "\u2581Storm", "s", "\u2581S", "we", "ep", "\u2581Through", "out", "\u2581Florida"]], "entropy": [[3.4921875, 0.00952911376953125, 0.76806640625, 1.4384765625, 0.385986328125, 0.04156494140625, 1.4306640625, 2.44140625, 1.5791015625, 2.271484375, 2.72265625, 1.826171875, 0.1044921875, 1.3203125, 2.08203125, 2.5390625, 0.05126953125, 0.578125, 2.814453125, 4.13671875, 4.3203125, 0.006816864013671875, 0.935546875, 3.525390625, 0.446533203125, 1.08984375, 0.0621337890625, 0.003192901611328125, 1.892578125, 3.79296875, 2.884765625, 2.24609375, 0.5732421875, 0.01605224609375, 1.271484375, 3.0234375, 2.30859375]], "avg_entropy": [1.633317483438028], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "May\u00a013,\u00a02015", "score_of_biggest_cluster": 0.07671802490949631, "score_of_first_answer": 0.07671802490949631, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 1.2278556823730469e-05, "avg_score": 0.07671802490949631, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4013444283612805, "std_of_first_answer": 0.4013444283612805, "avg_entropy_of_first_answer": 1.633317483438028, "lex_sim": 1.0}
{"question": "when did the united states start using the death penalty", "answer": ["The United States has used the death penalty for centuries, but the first recorded execution in the colonies was in 1608."], "scores": [[0.26171875, 0.2939453125, 0.99951171875, 0.80322265625, 0.96142578125, 0.74853515625, 0.99951171875, 1.0, 0.0219879150390625, 0.72216796875, 0.8720703125, 0.6845703125, 0.5205078125, 0.7353515625, 0.88037109375, 0.9873046875, 0.5126953125, 0.91650390625, 0.75927734375, 1.0, 0.338134765625, 0.9716796875, 0.94140625, 1.0, 1.0, 0.994140625, 0.99609375, 0.6708984375, 0.06396484375, 0.21875, 0.34716796875, 0.99951171875, 1.0, 0.72998046875, 0.56787109375, 0.80908203125, 0.94189453125, 0.99951171875, 1.0, 1.0, 1.0, 0.99609375, 0.99951171875, 0.03814697265625, 0.437255859375, 1.0, 0.99853515625, 0.8603515625, 0.77392578125, 0.9326171875]], "normalized_score": [0.637087345123291], "tokens": [["\u2581The", "\u2581United", "\u2581States", "\u2581has", "\u2581used", "\u2581the", "\u2581death", "\u2581penalty", "\u2581for", "\u2581centuries", ",", "\u2581but", "\u2581the", "\u2581first", "\u2581recorded", "\u2581execution", "\u2581in", "\u2581the", "\u2581colon", "ies", "\u2581was", "\u2581in", "\u2581", "1", "6", "0", "8", ".", "\u2581In", "\u2581the", "\u2581late", "\u2581", "1", "8", "th", "\u2581and", "\u2581early", "\u2581", "1", "9", "th", "\u2581centuries", ",", "\u2581the", "\u2581death", "\u2581penalty", "\u2581was", "\u2581used", "\u2581for", "\u2581a"]], "entropy": [[1.9970703125, 1.4443359375, 0.00328826904296875, 0.88720703125, 0.2193603515625, 0.5712890625, 0.0032634735107421875, 0.00032782554626464844, 1.1767578125, 1.1376953125, 0.466064453125, 1.197265625, 0.92431640625, 1.171875, 0.68603515625, 0.08380126953125, 1.458984375, 0.354736328125, 1.1142578125, 0.00011748075485229492, 0.74853515625, 0.1685791015625, 0.23779296875, 1.0728836059570312e-06, 3.159046173095703e-06, 0.035308837890625, 0.02545166015625, 0.7763671875, 1.564453125, 1.083984375, 1.6044921875, 0.006275177001953125, 0.0021724700927734375, 0.79541015625, 0.73583984375, 0.5009765625, 0.2247314453125, 0.00452423095703125, 5.340576171875e-05, 8.219480514526367e-05, 0.00034689903259277344, 0.02789306640625, 0.005786895751953125, 0.72802734375, 1.484375, 0.0005941390991210938, 0.01493072509765625, 0.64501953125, 0.91357421875, 0.308349609375]], "avg_entropy": [0.5508396208286286], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the beginning", "score_of_biggest_cluster": 0.637087345123291, "score_of_first_answer": 0.637087345123291, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0219879150390625, "avg_score": 0.637087345123291, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2918493369651538, "std_of_first_answer": 0.2918493369651538, "avg_entropy_of_first_answer": 0.5508396208286286, "lex_sim": 1.0}
{"question": "when were 2 dollar bills stopped being made", "answer": ["U.S. two-dollar bills have been issued by the government since 1862, but they are no longer in circulation."], "scores": [[0.0007691383361816406, 0.97314453125, 0.99951171875, 0.9013671875, 0.467529296875, 0.99267578125, 1.0, 1.0, 0.998046875, 1.0, 0.1798095703125, 0.6787109375, 0.267578125, 0.76416015625, 1.0, 0.0200653076171875, 0.31396484375, 0.97705078125, 1.0, 0.99951171875, 0.77001953125, 0.9990234375, 0.72607421875, 0.78515625, 0.76318359375, 0.434326171875, 0.1812744140625, 1.0, 0.89306640625, 0.423583984375, 1.0, 0.2464599609375, 0.345947265625, 0.8193359375, 0.7978515625, 0.7451171875, 0.9931640625, 0.98046875, 0.97900390625, 0.85009765625, 0.8564453125, 0.96728515625, 0.477783203125, 0.52783203125, 0.64794921875, 0.12445068359375, 0.7666015625, 0.818359375, 0.9912109375, 1.0]], "normalized_score": [0.5553080439567566], "tokens": [["\u2581U", ".", "S", ".", "\u2581two", "-", "d", "ollar", "\u2581b", "ills", "\u2581have", "\u2581been", "\u2581issued", "\u2581by", "\u2581the", "\u2581government", "\u2581since", "\u2581", "1", "8", "6", "2", ",", "\u2581but", "\u2581they", "\u2581are", "\u2581no", "\u2581longer", "\u2581in", "\u2581circul", "ation", ".", "\u2581They", "\u2581were", "\u2581last", "\u2581printed", "\u2581in", "\u2581", "1", "9", "6", "6", "\u2581and", "\u2581are", "\u2581now", "\u2581rare", "\u2581collect", "or", "'", "s"]], "entropy": [[1.5166015625, 0.177978515625, 0.0033092498779296875, 0.5947265625, 1.998046875, 0.044158935546875, 0.0018625259399414062, 8.869171142578125e-05, 0.0174713134765625, 8.243322372436523e-05, 0.609375, 0.83447265625, 2.40234375, 1.1044921875, 0.0012960433959960938, 1.3115234375, 2.53125, 0.11224365234375, 0.0002218484878540039, 0.00293731689453125, 0.7021484375, 0.00811767578125, 0.8525390625, 0.75732421875, 1.02734375, 1.2236328125, 1.4697265625, 0.0009183883666992188, 0.5859375, 0.84423828125, 0.00022602081298828125, 1.03515625, 1.4013671875, 0.64013671875, 0.71923828125, 0.771484375, 0.054046630859375, 0.10418701171875, 0.10186767578125, 0.422607421875, 0.48974609375, 0.18212890625, 1.166015625, 1.4267578125, 1.3203125, 2.0625, 0.74951171875, 0.63525390625, 0.055755615234375, 1.0132789611816406e-06]], "avg_entropy": [0.6814942002296448], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "current denomination of U.S. currency", "score_of_biggest_cluster": 0.5553080439567566, "score_of_first_answer": 0.5553080439567566, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0007691383361816406, "avg_score": 0.5553080439567566, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3044383658462322, "std_of_first_answer": 0.3044383658462322, "avg_entropy_of_first_answer": 0.6814942002296448, "lex_sim": 1.0}
{"question": "when will the flash season 4 be released", "answer": ["I'm sorry, but I do not have information on future releases of The Flash."], "scores": [[0.474609375, 0.52685546875, 1.0, 0.9677734375, 0.98779296875, 0.25048828125, 0.75244140625, 0.3876953125, 0.9990234375, 0.97509765625, 0.8046875, 0.53857421875, 0.1402587890625, 0.457763671875, 0.5322265625, 0.28466796875, 1.0, 0.264404296875, 0.1273193359375, 0.994140625, 0.85986328125, 0.280517578125, 0.6416015625, 0.9990234375, 0.99951171875, 1.7881393432617188e-07, 0.0021724700927734375, 1.9431114196777344e-05, 0.994140625, 0.30615234375, 0.947265625, 0.0004544258117675781, 0.0144195556640625, 0.1573486328125, 0.875, 0.058197021484375, 0.0014925003051757812, 0.2078857421875, 0.99658203125]], "normalized_score": [0.15222987532615662], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581but", "\u2581I", "\u2581do", "\u2581not", "\u2581have", "\u2581information", "\u2581on", "\u2581future", "\u2581releases", "\u2581of", "\u2581The", "\u2581Flash", ".", "\u2581Can", "\u2581I", "\u2581help", "\u2581with", "\u2581anything", "\u2581else", "?", "\u2581#", "A", "to", "Z", "Ch", "allenge", ":", "\u2581X", "\u2581is", "\u2581for", "\u2581X", "i", "\u2581Jin", "ping"]], "entropy": [[2.03515625, 1.2197265625, 0.0016698837280273438, 0.1732177734375, 0.0748291015625, 0.982421875, 0.98486328125, 1.4013671875, 0.0071868896484375, 0.121337890625, 0.88232421875, 0.87158203125, 0.95703125, 1.009765625, 0.9404296875, 1.7392578125, 0.002498626708984375, 1.6640625, 2.11328125, 0.0389404296875, 0.427490234375, 0.61767578125, 0.7041015625, 0.00627899169921875, 0.00548553466796875, 0.375, 5.34375, 1.5908203125, 0.057037353515625, 2.91796875, 0.2171630859375, 0.8984375, 3.05078125, 2.392578125, 0.66748046875, 2.453125, 0.73193359375, 2.318359375, 0.023834228515625]], "avg_entropy": [1.0774423403617663], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "October 10, 2017", "score_of_biggest_cluster": 0.15222987532615662, "score_of_first_answer": 0.15222987532615662, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.15222987532615662, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3817633800822599, "std_of_first_answer": 0.3817633800822599, "avg_entropy_of_first_answer": 1.0774423403617663, "lex_sim": 1.0}
{"question": "where is fight or flight in the brain", "answer": ["The hypothalamus and limbic system"], "scores": [[0.13720703125, 0.3134765625, 0.99951171875, 0.99951171875, 0.99755859375, 0.3779296875, 0.049591064453125, 1.0, 1.0, 0.98974609375]], "normalized_score": [0.4898277521133423], "tokens": [["\u2581The", "\u2581hypoth", "al", "am", "us", "\u2581and", "\u2581lim", "b", "ic", "\u2581system"]], "entropy": [[2.3046875, 1.3642578125, 0.00566864013671875, 0.005832672119140625, 0.017303466796875, 1.5, 1.6611328125, 0.0004277229309082031, 0.00038623809814453125, 0.062408447265625]], "avg_entropy": [0.6922105312347412], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the adrenal medulla", "score_of_biggest_cluster": 0.4898277521133423, "score_of_first_answer": 0.4898277521133423, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.049591064453125, "avg_score": 0.4898277521133423, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39025256857450163, "std_of_first_answer": 0.39025256857450163, "avg_entropy_of_first_answer": 0.6922105312347412, "lex_sim": 1.0}
{"question": "where is the suez canal located on a map", "answer": ["I am a text-based AI model and do not have the capability to provide a visual map #GivingTuesday: The Ultimate Guide to Maximizing Your Impact"], "scores": [[0.0014600753784179688, 0.591796875, 0.0531005859375, 0.9736328125, 0.9521484375, 1.0, 0.986328125, 1.0, 0.04522705078125, 0.77392578125, 0.61279296875, 0.9990234375, 0.998046875, 0.83251953125, 0.60888671875, 1.0, 0.99169921875, 0.2030029296875, 0.22265625, 0.271728515625, 0.74658203125, 0.0, 0.0036945343017578125, 0.00024116039276123047, 0.031158447265625, 0.98681640625, 0.99658203125, 0.006626129150390625, 0.01039886474609375, 0.026947021484375, 0.9990234375, 0.81201171875, 0.74560546875, 0.0119171142578125, 0.62744140625, 0.91552734375, 0.833984375, 0.998046875]], "normalized_score": [0.0], "tokens": [["\u2581I", "\u2581am", "\u2581a", "\u2581text", "-", "based", "\u2581A", "I", "\u2581model", "\u2581and", "\u2581do", "\u2581not", "\u2581have", "\u2581the", "\u2581cap", "ability", "\u2581to", "\u2581provide", "\u2581a", "\u2581visual", "\u2581map", "\u2581#", "G", "iving", "T", "ues", "day", ":", "\u2581The", "\u2581Ult", "imate", "\u2581Guide", "\u2581to", "\u2581Maxim", "izing", "\u2581Your", "\u2581Imp", "act"]], "entropy": [[0.79443359375, 1.3857421875, 0.94970703125, 0.1343994140625, 0.2420654296875, 0.002216339111328125, 0.09991455078125, 0.0006499290466308594, 1.103515625, 0.56298828125, 1.2470703125, 0.00811767578125, 0.0183258056640625, 0.62255859375, 0.7001953125, 0.0003027915954589844, 0.053558349609375, 1.173828125, 1.7734375, 0.6796875, 0.791015625, 0.638671875, 5.46484375, 3.4375, 3.59765625, 0.111328125, 0.0296173095703125, 2.0078125, 4.50390625, 4.92578125, 0.00798797607421875, 1.0458984375, 1.146484375, 2.615234375, 0.71484375, 0.422119140625, 0.9091796875, 0.017547607421875]], "avg_entropy": [1.1563195429350202], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Egypt", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.411633675375634, "std_of_first_answer": 0.411633675375634, "avg_entropy_of_first_answer": 1.1563195429350202, "lex_sim": 1.0}
{"question": "suffix applied to the end of the name of enzymes", "answer": ["-ase #WPLongform, Food for Thought, Post A Day 2013, T.V."], "scores": [[0.9951171875, 0.99755859375, 5.960464477539063e-08, 0.000255584716796875, 0.00028014183044433594, 0.031280517578125, 0.91796875, 0.0015630722045898438, 2.3066997528076172e-05, 0.060516357421875, 0.42431640625, 1.0, 0.85205078125, 0.0440673828125, 0.395751953125, 0.9873046875, 0.2103271484375, 1.0, 1.0, 0.433837890625, 0.043426513671875, 0.92529296875, 0.011199951171875, 0.00201416015625, 0.380859375, 0.95947265625, 0.25, 1.0, 0.92529296875, 0.99658203125, 0.6083984375, 0.99609375, 0.97509765625]], "normalized_score": [0.08596570044755936], "tokens": [["\u2581-", "ase", "\u2581#", "W", "PL", "ong", "form", ",", "\u2581Food", "\u2581for", "\u2581Th", "ought", ",", "\u2581Post", "\u2581A", "\u2581Day", "\u2581", "2", "0", "1", "3", ",", "\u2581T", ".", "V", ".", "\u2581Anton", "y", "\u2581Raj", ",", "\u2581This", "\u2581is", "\u2581Life"]], "entropy": [[0.042694091796875, 0.022247314453125, 0.138427734375, 5.09375, 0.71044921875, 4.03125, 0.372802734375, 1.1796875, 2.828125, 2.978515625, 1.72265625, 0.0017118453979492188, 0.7763671875, 5.33203125, 1.6728515625, 0.0731201171875, 0.7431640625, 0.0012187957763671875, 0.0007419586181640625, 0.685546875, 1.7392578125, 0.37158203125, 2.134765625, 2.716796875, 1.234375, 0.287353515625, 2.826171875, 0.0002949237823486328, 0.47216796875, 0.02935791015625, 0.98828125, 0.028564453125, 0.1448974609375]], "avg_entropy": [1.2539765401320024], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "-ase", "score_of_biggest_cluster": 0.08596570044755936, "score_of_first_answer": 0.08596570044755936, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.08596570044755936, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.42822443588814585, "std_of_first_answer": 0.42822443588814585, "avg_entropy_of_first_answer": 1.2539765401320024, "lex_sim": 1.0}
{"question": "how many champions league trophies does arsenal have", "answer": ["3"], "scores": [[0.79833984375, 0.99267578125]], "normalized_score": [0.8902205228805542], "tokens": [["\u2581", "3"]], "entropy": [[0.828125, 0.051849365234375]], "avg_entropy": [0.4399871826171875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "13", "score_of_biggest_cluster": 0.8902205228805542, "score_of_first_answer": 0.8902205228805542, "max_score_of_first_answer": 0.99267578125, "min_score_of_first_answer": 0.79833984375, "avg_score": 0.8902205228805542, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.09716796875, "std_of_first_answer": 0.09716796875, "avg_entropy_of_first_answer": 0.4399871826171875, "lex_sim": 1.0}
{"question": "where was uncle tom's cabin first published", "answer": ["New York City, in 1852"], "scores": [[0.348876953125, 1.0, 0.94677734375, 0.46630859375, 0.0084991455078125, 0.282958984375, 1.0, 0.9970703125, 1.0, 0.943359375]], "normalized_score": [0.4510342478752136], "tokens": [["\u2581New", "\u2581York", "\u2581City", ",", "\u2581in", "\u2581", "1", "8", "5", "2"]], "entropy": [[2.19921875, 0.0011434555053710938, 0.270263671875, 1.13671875, 1.1337890625, 1.13671875, 0.0003638267517089844, 0.020721435546875, 0.0003769397735595703, 0.2242431640625]], "avg_entropy": [0.6123557806015014], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The National Era", "score_of_biggest_cluster": 0.4510342478752136, "score_of_first_answer": 0.4510342478752136, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0084991455078125, "avg_score": 0.4510342478752136, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.36171335887096934, "std_of_first_answer": 0.36171335887096934, "avg_entropy_of_first_answer": 0.6123557806015014, "lex_sim": 1.0}
{"question": "who is the original singer of you re going to love me", "answer": ["Erasure ##The Different Types of Artillery in Battle of Kursk"], "scores": [[0.09869384765625, 0.76513671875, 0.0, 0.005313873291015625, 0.00012433528900146484, 0.0144805908203125, 4.7206878662109375e-05, 0.9931640625, 0.00495147705078125, 0.006671905517578125, 0.0921630859375, 0.0005865097045898438, 0.034332275390625, 0.465087890625, 0.99951171875]], "normalized_score": [0.0], "tokens": [["\u2581Er", "asure", "\u2581##", "The", "\u2581D", "ifferent", "\u2581Types", "\u2581of", "\u2581Art", "illery", "\u2581in", "\u2581Battle", "\u2581of", "\u2581Kur", "sk"]], "entropy": [[3.994140625, 0.83056640625, 1.34375, 5.7734375, 3.51953125, 4.87109375, 2.130859375, 0.04449462890625, 3.068359375, 0.80419921875, 2.19921875, 2.361328125, 2.01953125, 2.708984375, 0.003063201904296875]], "avg_entropy": [2.3781705220540363], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Jennifer Holliday", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3650914782623808, "std_of_first_answer": 0.3650914782623808, "avg_entropy_of_first_answer": 2.3781705220540363, "lex_sim": 1.0}
{"question": "who died in the plane crash greys anatomy", "answer": ["Denny Duquette"], "scores": [[0.154541015625, 0.9853515625, 0.99072265625, 0.99560546875, 1.0]], "normalized_score": [0.6844391822814941], "tokens": [["\u2581Den", "ny", "\u2581Du", "qu", "ette"]], "entropy": [[2.740234375, 0.09210205078125, 0.07122802734375, 0.03863525390625, 0.0014333724975585938]], "avg_entropy": [0.5887266159057617], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Dr. Lexie Grey", "score_of_biggest_cluster": 0.6844391822814941, "score_of_first_answer": 0.6844391822814941, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.154541015625, "avg_score": 0.6844391822814941, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.33538717926124934, "std_of_first_answer": 0.33538717926124934, "avg_entropy_of_first_answer": 0.5887266159057617, "lex_sim": 1.0}
{"question": "when do the walking dead comics come out", "answer": ["Regularly released monthly, on average."], "scores": [[0.04620361328125, 1.0, 0.990234375, 0.185791015625, 0.26416015625, 1.0, 0.066650390625, 0.0908203125, 0.11737060546875, 0.701171875, 3.8504600524902344e-05, 0.0030498504638671875, 9.834766387939453e-06, 0.0009918212890625, 3.635883331298828e-06]], "normalized_score": [0.017561092972755432], "tokens": [["\u2581Reg", "ular", "ly", "\u2581released", "\u2581month", "ly", ",", "\u2581on", "\u2581average", ".", "\u2581#", "A", "ir", "line", "\u2581News"]], "entropy": [[2.703125, 7.146596908569336e-05, 0.07171630859375, 1.92578125, 1.720703125, 0.0015554428100585938, 1.537109375, 2.8125, 1.0556640625, 1.2099609375, 1.3525390625, 3.232421875, 0.2939453125, 3.05078125, 2.572265625]], "avg_entropy": [1.5693426728248596], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "October\u00a02003\u00a0\u2013 present", "score_of_biggest_cluster": 0.017561092972755432, "score_of_first_answer": 0.017561092972755432, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 3.635883331298828e-06, "avg_score": 0.017561092972755432, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38945638179932407, "std_of_first_answer": 0.38945638179932407, "avg_entropy_of_first_answer": 1.5693426728248596, "lex_sim": 1.0}
{"question": "who are you in assassin's creed 4", "answer": ["Edward Kenway"], "scores": [[0.67626953125, 0.99951171875, 1.0]], "normalized_score": [0.8776120543479919], "tokens": [["\u2581Edward", "\u2581Ken", "way"]], "entropy": [[1.162109375, 0.005340576171875, 0.0010080337524414062]], "avg_entropy": [0.38948599497477215], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "third-person perspective", "score_of_biggest_cluster": 0.8776120543479919, "score_of_first_answer": 0.8776120543479919, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.67626953125, "avg_score": 0.8776120543479919, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.15249304778158795, "std_of_first_answer": 0.15249304778158795, "avg_entropy_of_first_answer": 0.38948599497477215, "lex_sim": 1.0}
{"question": "who played anna in once upon a time", "answer": ["Elizabeth Lail"], "scores": [[0.92919921875, 0.70703125, 0.99951171875]], "normalized_score": [0.869184136390686], "tokens": [["\u2581Elizabeth", "\u2581L", "ail"]], "entropy": [[0.5078125, 0.6328125, 0.0034847259521484375]], "avg_entropy": [0.3813699086507161], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Elizabeth Dean Lail", "score_of_biggest_cluster": 0.869184136390686, "score_of_first_answer": 0.869184136390686, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.70703125, "avg_score": 0.869184136390686, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.12465386680946684, "std_of_first_answer": 0.12465386680946684, "avg_entropy_of_first_answer": 0.3813699086507161, "lex_sim": 1.0}
{"question": "what is the purpose of the bromophenol blue dye in the samples", "answer": ["To act"], "scores": [[0.2498779296875, 0.246826171875]], "normalized_score": [0.24834734201431274], "tokens": [["\u2581To", "\u2581act"]], "entropy": [[2.140625, 2.890625]], "avg_entropy": [2.515625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "as a pH indicator", "score_of_biggest_cluster": 0.24834734201431274, "score_of_first_answer": 0.24834734201431274, "max_score_of_first_answer": 0.2498779296875, "min_score_of_first_answer": 0.246826171875, "avg_score": 0.24834734201431274, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.00152587890625, "std_of_first_answer": 0.00152587890625, "avg_entropy_of_first_answer": 2.515625, "lex_sim": 1.0}
{"question": "when was the last time mount ruapehu erupted", "answer": ["September 26, 2016 (updated on 3/2/2023) #KateStewart"], "scores": [[0.396728515625, 0.9853515625, 0.99658203125, 0.215087890625, 0.8759765625, 0.998046875, 0.9990234375, 1.0, 0.6513671875, 0.0230865478515625, 0.0132904052734375, 0.00591278076171875, 0.043182373046875, 0.1168212890625, 0.03204345703125, 0.35009765625, 0.322265625, 0.119384765625, 0.99951171875, 0.98779296875, 0.99951171875, 0.95458984375, 0.9130859375, 9.47713851928711e-06, 0.0009794235229492188, 0.00013256072998046875, 0.00036215782165527344, 0.4384765625]], "normalized_score": [0.09597436338663101], "tokens": [["\u2581September", "\u2581", "2", "6", ",", "\u2581", "2", "0", "1", "6", "\u2581(", "updated", "\u2581on", "\u2581", "3", "/", "2", "/", "2", "0", "2", "3", ")", "\u2581#", "K", "ate", "Ste", "wart"]], "entropy": [[1.2021484375, 0.08599853515625, 0.025360107421875, 0.5947265625, 0.40771484375, 0.0143890380859375, 0.00763702392578125, 4.798173904418945e-05, 0.88623046875, 0.41015625, 1.4990234375, 3.541015625, 2.560546875, 2.640625, 1.3623046875, 1.68359375, 1.421875, 2.37890625, 0.0044708251953125, 0.0810546875, 0.00611114501953125, 0.2216796875, 0.43896484375, 0.57861328125, 5.64453125, 1.6123046875, 3.154296875, 1.9443359375]], "avg_entropy": [1.2288808247872762], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "25 September 2007", "score_of_biggest_cluster": 0.09597436338663101, "score_of_first_answer": 0.09597436338663101, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 9.47713851928711e-06, "avg_score": 0.09597436338663101, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.425630972586866, "std_of_first_answer": 0.425630972586866, "avg_entropy_of_first_answer": 1.2288808247872762, "lex_sim": 1.0}
{"question": "what was going on in the world in 1900", "answer": ["Some notable events of 1900 include the Boxer Rebellion in China, the Second Boer War in South Africa, the founding of the American Society of Civil Engineers, and the completion of the first Nobel Prizes"], "scores": [[0.0105743408203125, 0.495849609375, 0.99853515625, 0.3583984375, 0.93212890625, 1.0, 1.0, 1.0, 1.0, 0.984375, 0.89111328125, 0.8076171875, 1.0, 0.99951171875, 1.0, 1.0, 0.9951171875, 1.0, 0.9951171875, 0.99658203125, 0.39013671875, 0.99951171875, 1.0, 1.0, 0.9609375, 0.99267578125, 1.0, 0.9990234375, 0.460693359375, 0.02362060546875, 1.0, 1.0, 0.9169921875, 0.0187835693359375, 0.46142578125, 1.0, 0.814453125, 0.9990234375, 1.0, 0.9697265625, 0.89013671875, 0.99853515625, 0.11981201171875, 1.0, 0.99658203125, 0.50927734375, 0.1683349609375, 0.87646484375, 0.99951171875, 1.0]], "normalized_score": [0.642473578453064], "tokens": [["\u2581Some", "\u2581notable", "\u2581events", "\u2581of", "\u2581", "1", "9", "0", "0", "\u2581include", "\u2581the", "\u2581Box", "er", "\u2581Reb", "ell", "ion", "\u2581in", "\u2581China", ",", "\u2581the", "\u2581Second", "\u2581Bo", "er", "\u2581War", "\u2581in", "\u2581South", "\u2581Africa", ",", "\u2581the", "\u2581found", "ing", "\u2581of", "\u2581the", "\u2581American", "\u2581Society", "\u2581of", "\u2581Civil", "\u2581Engine", "ers", ",", "\u2581and", "\u2581the", "\u2581completion", "\u2581of", "\u2581the", "\u2581first", "\u2581Nobel", "\u2581P", "riz", "es"]], "entropy": [[2.169921875, 1.4814453125, 0.01364898681640625, 1.3369140625, 0.266357421875, 1.5497207641601562e-05, 6.008148193359375e-05, 0.00014972686767578125, 0.00010919570922851562, 0.09100341796875, 0.38818359375, 0.953125, 7.37309455871582e-05, 0.003307342529296875, 0.00016117095947265625, 0.0002865791320800781, 0.03204345703125, 0.0003914833068847656, 0.0321044921875, 0.034912109375, 3.01171875, 0.006053924560546875, 0.0005178451538085938, 0.0005025863647460938, 0.2088623046875, 0.05029296875, 0.000743865966796875, 0.010498046875, 0.701171875, 3.966796875, 7.104873657226562e-05, 0.0003750324249267578, 0.7099609375, 3.32421875, 2.775390625, 0.0005917549133300781, 0.66650390625, 0.00867462158203125, 3.159046173095703e-06, 0.1380615234375, 0.35009765625, 0.01557159423828125, 2.435546875, 0.0006833076477050781, 0.031494140625, 2.544921875, 4.6640625, 0.41796875, 0.002834320068359375, 0.00010597705841064453]], "avg_entropy": [0.6569702386856079], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Galveston hurricane", "score_of_biggest_cluster": 0.642473578453064, "score_of_first_answer": 0.642473578453064, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0105743408203125, "avg_score": 0.642473578453064, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.30779439939794206, "std_of_first_answer": 0.30779439939794206, "avg_entropy_of_first_answer": 0.6569702386856079, "lex_sim": 1.0}
{"question": "yo la tengo theres a riot going on release date", "answer": ["2006"], "scores": [[0.26611328125, 0.1412353515625, 0.990234375, 0.0042572021484375, 0.966796875]], "normalized_score": [0.17260029911994934], "tokens": [["\u2581", "2", "0", "0", "6"]], "entropy": [[2.150390625, 0.54345703125, 0.078369140625, 0.04473876953125, 0.2166748046875]], "avg_entropy": [0.60672607421875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "March 16, 2018", "score_of_biggest_cluster": 0.17260029911994934, "score_of_first_answer": 0.17260029911994934, "max_score_of_first_answer": 0.990234375, "min_score_of_first_answer": 0.0042572021484375, "avg_score": 0.17260029911994934, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42046493638583327, "std_of_first_answer": 0.42046493638583327, "avg_entropy_of_first_answer": 0.60672607421875, "lex_sim": 1.0}
{"question": "how many seasons of prison break are on netflix", "answer": ["4"], "scores": [[0.72265625, 0.990234375]], "normalized_score": [0.8459308743476868], "tokens": [["\u2581", "4"]], "entropy": [[1.1318359375, 0.06903076171875]], "avg_entropy": [0.600433349609375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "five", "score_of_biggest_cluster": 0.8459308743476868, "score_of_first_answer": 0.8459308743476868, "max_score_of_first_answer": 0.990234375, "min_score_of_first_answer": 0.72265625, "avg_score": 0.8459308743476868, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.1337890625, "std_of_first_answer": 0.1337890625, "avg_entropy_of_first_answer": 0.600433349609375, "lex_sim": 1.0}
{"question": "who sang the song suddenly with olivia newton john", "answer": ["Cliff Richard and Olivia Newton-John #Sustainability: Why It Matters"], "scores": [[0.0195465087890625, 0.99951171875, 0.9658203125, 0.00557708740234375, 0.93505859375, 1.0, 1.0, 0.99462890625, 1.0, 8.344650268554688e-07, 0.0809326171875, 0.0, 0.85791015625, 0.0205230712890625, 0.0052642822265625, 0.0026798248291015625, 0.0670166015625, 0.68017578125, 0.99951171875]], "normalized_score": [0.0], "tokens": [["\u2581Cl", "iff", "\u2581Richard", "\u2581and", "\u2581Oliv", "ia", "\u2581Newton", "-", "John", "\u2581#", "S", "ust", "ain", "ability", ":", "\u2581Why", "\u2581It", "\u2581Mat", "ters"]], "entropy": [[0.9697265625, 0.0027141571044921875, 0.1519775390625, 0.9716796875, 0.3515625, 0.00021135807037353516, 0.0013628005981445312, 0.03765869140625, 0.0010995864868164062, 1.1484375, 3.66015625, 0.0063018798828125, 1.01953125, 3.384765625, 3.525390625, 4.82421875, 3.28515625, 1.0849609375, 0.005084991455078125]], "avg_entropy": [1.2858945758719194], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Cliff Richard", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4656592196595434, "std_of_first_answer": 0.4656592196595434, "avg_entropy_of_first_answer": 1.2858945758719194, "lex_sim": 1.0}
{"question": "how many times has lake placid hosted the winter olympics", "answer": ["Two times."], "scores": [[0.022918701171875, 0.79052734375, 0.209716796875, 0.1859130859375, 0.35400390625, 1.0, 1.0, 0.9970703125, 1.0, 0.85107421875, 0.98291015625, 1.0, 1.0, 1.0, 1.0, 0.970703125, 0.99560546875, 0.783203125, 0.1715087890625, 0.98681640625, 0.9873046875, 0.99853515625, 0.99951171875, 1.0, 1.0, 0.88330078125, 0.94140625, 1.0, 0.6904296875, 0.97900390625, 0.9794921875, 6.556510925292969e-07, 0.0048828125, 0.70556640625, 0.0011415481567382812, 0.024749755859375, 2.682209014892578e-06, 0.231201171875, 0.006046295166015625, 0.0186614990234375, 0.11212158203125, 1.0, 0.607421875, 0.2427978515625, 0.11126708984375, 0.00023484230041503906, 0.196044921875, 0.65283203125]], "normalized_score": [0.18261556327342987], "tokens": [["\u2581Two", "\u2581times", ".", "\u2581The", "\u2581", "1", "9", "3", "2", "\u2581and", "\u2581", "1", "9", "8", "0", "\u2581Winter", "\u2581Olympics", "\u2581were", "\u2581both", "\u2581held", "\u2581in", "\u2581Lake", "\u2581P", "lac", "id", ",", "\u2581New", "\u2581York", ",", "\u2581USA", ".", "\u2581#", "A", "sk", "Al", "an", "\u2581mail", "bag", ":", "\u2581What", "'", "s", "\u2581the", "\u2581most", "\u2581popular", "\u2581car", "\u2581color", "?"]], "entropy": [[2.5234375, 0.802734375, 1.7802734375, 2.01171875, 1.39453125, 0.00011837482452392578, 0.0008745193481445312, 0.020172119140625, 0.000667572021484375, 0.456298828125, 0.0882568359375, 6.508827209472656e-05, 0.00038361549377441406, 0.00043582916259765625, 0.0015726089477539062, 0.15869140625, 0.0279388427734375, 0.67822265625, 0.513671875, 0.07080078125, 0.070068359375, 0.0113372802734375, 0.003429412841796875, 2.9206275939941406e-06, 0.0009665489196777344, 0.385498046875, 0.23583984375, 0.0003848075866699219, 0.66455078125, 0.115234375, 0.1053466796875, 0.202880859375, 3.158203125, 1.7744140625, 4.12109375, 1.42578125, 2.376953125, 2.595703125, 3.8984375, 4.6015625, 2.58203125, 0.0011157989501953125, 1.3720703125, 3.171875, 3.205078125, 4.37109375, 1.9755859375, 1.125]], "avg_entropy": [1.1267167665064335], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "twice", "score_of_biggest_cluster": 0.18261556327342987, "score_of_first_answer": 0.18261556327342987, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 6.556510925292969e-07, "avg_score": 0.18261556327342987, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4137884674300807, "std_of_first_answer": 0.4137884674300807, "avg_entropy_of_first_answer": 1.1267167665064335, "lex_sim": 1.0}
{"question": "when did the celebrities enter the big brother house", "answer": ["I'm sorry, I do not have information on specific dates for the entry of celebrities into the Big Brother house."], "scores": [[0.732421875, 0.60302734375, 0.99951171875, 0.9765625, 0.97998046875, 0.744140625, 0.228759765625, 0.9990234375, 0.95654296875, 0.52001953125, 0.490966796875, 0.04046630859375, 0.2366943359375, 0.6025390625, 0.309326171875, 0.6142578125, 0.99853515625, 0.97265625, 1.0, 1.0, 0.9677734375, 0.7705078125, 0.91943359375, 0.99658203125, 1.0, 0.96728515625, 0.66015625, 0.59716796875, 0.8212890625, 0.845703125, 0.552734375, 0.9951171875, 0.52734375, 0.99853515625, 0.99853515625]], "normalized_score": [0.6734352111816406], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581I", "\u2581do", "\u2581not", "\u2581have", "\u2581information", "\u2581on", "\u2581specific", "\u2581dates", "\u2581for", "\u2581the", "\u2581entry", "\u2581of", "\u2581cele", "brit", "ies", "\u2581into", "\u2581the", "\u2581Big", "\u2581Bro", "ther", "\u2581house", ".", "\u2581Can", "\u2581I", "\u2581help", "\u2581you", "\u2581with", "\u2581anything", "\u2581else", "?"]], "entropy": [[1.4287109375, 1.2373046875, 0.0027408599853515625, 0.1304931640625, 0.10797119140625, 0.7705078125, 1.6884765625, 0.00910186767578125, 0.2037353515625, 1.4580078125, 0.8388671875, 2.125, 1.9814453125, 1.400390625, 1.6552734375, 1.5693359375, 0.0106048583984375, 0.16796875, 0.0005679130554199219, 0.0007266998291015625, 0.1585693359375, 0.60400390625, 0.3388671875, 0.0265655517578125, 0.00021791458129882812, 0.1541748046875, 0.90478515625, 1.4150390625, 0.47607421875, 0.46044921875, 0.71240234375, 0.033477783203125, 0.736328125, 0.01195526123046875, 0.0121917724609375]], "avg_entropy": [0.6523523603166853], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "February\u00a07,\u00a02018", "score_of_biggest_cluster": 0.6734352111816406, "score_of_first_answer": 0.6734352111816406, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.04046630859375, "avg_score": 0.6734352111816406, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.26636543487504993, "std_of_first_answer": 0.26636543487504993, "avg_entropy_of_first_answer": 0.6523523603166853, "lex_sim": 1.0}
{"question": "what languages are spoken in india the most", "answer": ["Hindi, Bengali, Punjabi, and Telugu Tags: US | Earthquake"], "scores": [[0.7373046875, 1.0, 0.537109375, 0.251708984375, 1.0, 0.9931640625, 0.0188751220703125, 1.0, 1.0, 1.0, 0.9375, 0.137939453125, 0.6328125, 1.0, 1.0, 0.0, 0.9443359375, 6.568431854248047e-05, 0.0001722574234008789, 8.875131607055664e-05, 0.0012502670288085938, 0.8984375]], "normalized_score": [0.0], "tokens": [["\u2581H", "indi", ",", "\u2581Beng", "ali", ",", "\u2581P", "un", "j", "abi", ",", "\u2581and", "\u2581Tel", "ug", "u", "\u2581Tags", ":", "\u2581US", "\u2581|", "\u2581Earth", "qu", "ake"]], "entropy": [[0.97021484375, 0.002277374267578125, 0.75390625, 0.68505859375, 0.0012979507446289062, 0.047576904296875, 0.5048828125, 0.000743865966796875, 3.2782554626464844e-05, 0.0008153915405273438, 0.31640625, 1.265625, 1.333984375, 0.0010328292846679688, 0.0005660057067871094, 1.419921875, 0.3583984375, 4.28125, 3.556640625, 4.0703125, 1.1181640625, 0.332763671875]], "avg_entropy": [0.955539654601704], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Bengali", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43117600571257286, "std_of_first_answer": 0.43117600571257286, "avg_entropy_of_first_answer": 0.955539654601704, "lex_sim": 1.0}
{"question": "how do you spell padawan from star wars", "answer": ["P-A-D-A-W-A-N #195: R.J. STEWART - AUTHOR, SPEAKER & COACH"], "scores": [[0.9462890625, 0.998046875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.1920928955078125e-07, 0.003082275390625, 0.04803466796875, 0.06072998046875, 0.0008511543273925781, 0.0005178451538085938, 0.01293182373046875, 0.0066375732421875, 0.955078125, 0.004383087158203125, 0.043182373046875, 0.7705078125, 0.9921875, 0.041351318359375, 0.00217437744140625, 0.78173828125, 0.97509765625, 0.1429443359375, 0.1683349609375, 0.86767578125, 0.9951171875, 0.99951171875, 0.07757568359375, 0.2440185546875, 0.92578125, 1.0]], "normalized_score": [0.1353001892566681], "tokens": [["\u2581P", "-", "A", "-", "D", "-", "A", "-", "W", "-", "A", "-", "N", "\u2581#", "1", "9", "5", ":", "\u2581R", ".", "J", ".", "\u2581S", "TE", "W", "ART", "\u2581-", "\u2581AUT", "H", "OR", ",", "\u2581S", "PE", "AK", "ER", "\u2581&", "\u2581CO", "AC", "H"]], "entropy": [[0.2445068359375, 0.0201416015625, 0.0005350112915039062, 9.495019912719727e-05, 0.0003647804260253906, 0.00013518333435058594, 0.0013017654418945312, 9.530782699584961e-05, 0.001964569091796875, 0.0003142356872558594, 0.0018072128295898438, 0.0004405975341796875, 0.0014276504516601562, 0.2305908203125, 3.23046875, 4.05859375, 2.8671875, 2.509765625, 5.2265625, 4.36328125, 4.58984375, 0.4306640625, 3.267578125, 4.61328125, 1.015625, 0.061187744140625, 3.71484375, 5.06640625, 0.86865234375, 0.173583984375, 3.12890625, 3.787109375, 0.6533203125, 0.03863525390625, 0.0033016204833984375, 0.841796875, 3.271484375, 0.4326171875, 0.001209259033203125]], "avg_entropy": [1.5056314529516759], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Padawan", "score_of_biggest_cluster": 0.1353001892566681, "score_of_first_answer": 0.1353001892566681, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.1353001892566681, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.45369451431796237, "std_of_first_answer": 0.45369451431796237, "avg_entropy_of_first_answer": 1.5056314529516759, "lex_sim": 1.0}
{"question": "what percent of the us population controls the wealth", "answer": ["Income inequality is a complex issue with various statistical measures, but as of 2021, the top 1% of the US population holds 42.7% of the wealth, while the bottom 90% holds"], "scores": [[0.006977081298828125, 0.128173828125, 0.8056640625, 0.5498046875, 0.94189453125, 0.9951171875, 0.8818359375, 0.165283203125, 0.177490234375, 0.0173187255859375, 0.5849609375, 0.3583984375, 0.92041015625, 0.14501953125, 0.94384765625, 0.86083984375, 1.0, 1.0, 0.92529296875, 0.98779296875, 0.99560546875, 0.79931640625, 0.98828125, 0.998046875, 0.99755859375, 0.330810546875, 0.99755859375, 0.3828125, 0.63623046875, 1.0, 0.541015625, 0.154052734375, 0.1461181640625, 0.58935546875, 0.751953125, 0.4833984375, 0.99951171875, 1.0, 0.98974609375, 0.751953125, 0.83447265625, 0.69775390625, 1.0, 0.93994140625, 1.0, 0.99365234375, 1.0, 1.0, 0.93994140625]], "normalized_score": [0.5514575242996216], "tokens": [["\u2581In", "come", "\u2581inequality", "\u2581is", "\u2581a", "\u2581complex", "\u2581issue", "\u2581with", "\u2581various", "\u2581statistical", "\u2581measures", ",", "\u2581but", "\u2581as", "\u2581of", "\u2581", "2", "0", "2", "1", ",", "\u2581the", "\u2581top", "\u2581", "1", "%", "\u2581of", "\u2581the", "\u2581US", "\u2581population", "\u2581holds", "\u2581", "4", "2", ".", "7", "%", "\u2581of", "\u2581the", "\u2581wealth", ",", "\u2581while", "\u2581the", "\u2581bottom", "\u2581", "9", "0", "%", "\u2581holds"]], "entropy": [[2.802734375, 1.2421875, 0.64208984375, 1.6923828125, 0.330810546875, 0.04473876953125, 0.434814453125, 1.228515625, 1.869140625, 2.09375, 1.30859375, 1.21875, 0.4501953125, 1.7802734375, 0.26123046875, 0.451171875, 0.0006256103515625, 0.0012340545654296875, 0.265869140625, 0.0770263671875, 0.036468505859375, 0.91064453125, 0.08294677734375, 0.019012451171875, 0.0166015625, 0.64404296875, 0.022552490234375, 1.1689453125, 0.86669921875, 0.0013885498046875, 1.3525390625, 1.6767578125, 0.417236328125, 0.88330078125, 0.5615234375, 1.41015625, 0.0034694671630859375, 0.0005807876586914062, 0.07220458984375, 0.7646484375, 0.63671875, 0.9091796875, 0.0017375946044921875, 0.2398681640625, 0.001495361328125, 0.039764404296875, 0.0005083084106445312, 0.0004630088806152344, 0.254638671875]], "avg_entropy": [0.6365760783759915], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1%", "score_of_biggest_cluster": 0.5514575242996216, "score_of_first_answer": 0.5514575242996216, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.006977081298828125, "avg_score": 0.5514575242996216, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3264917598849523, "std_of_first_answer": 0.3264917598849523, "avg_entropy_of_first_answer": 0.6365760783759915, "lex_sim": 1.0}
{"question": "who is jojo in horton hears a who", "answer": ["Jojo is the son of the mayor of Whoville in the story \"Horton Hears a Who!\""], "scores": [[0.85595703125, 0.751953125, 0.94140625, 0.224365234375, 0.81201171875, 0.99951171875, 0.83447265625, 0.35791015625, 0.884765625, 0.986328125, 1.0, 1.0, 0.837890625, 0.93115234375, 0.09136962890625, 0.71337890625, 0.9990234375, 1.0, 1.0, 0.99853515625, 0.99462890625, 1.0, 0.90234375, 0.0, 2.3066997528076172e-05]], "normalized_score": [0.0], "tokens": [["\u2581Jo", "jo", "\u2581is", "\u2581the", "\u2581son", "\u2581of", "\u2581the", "\u2581mayor", "\u2581of", "\u2581Wh", "ov", "ille", "\u2581in", "\u2581the", "\u2581story", "\u2581\"", "H", "orton", "\u2581H", "ears", "\u2581a", "\u2581Who", "!\"", "\u2581##", "Description"]], "entropy": [[0.73583984375, 0.63330078125, 0.341796875, 0.8515625, 0.9814453125, 0.006328582763671875, 0.73583984375, 0.7919921875, 0.422607421875, 0.07421875, 0.0003609657287597656, 0.000274658203125, 0.61376953125, 0.294921875, 1.1904296875, 0.974609375, 0.0103607177734375, 0.001049041748046875, 0.0005030632019042969, 0.009521484375, 0.033111572265625, 0.0022563934326171875, 0.402587890625, 1.7568359375, 5.98828125]], "avg_entropy": [0.6741522216796875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Jesse McCartney", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3310426379186244, "std_of_first_answer": 0.3310426379186244, "avg_entropy_of_first_answer": 0.6741522216796875, "lex_sim": 1.0}
{"question": "where are they building the new raiders stadium", "answer": ["In Las Vegas, Nevada, USA ### Overview"], "scores": [[0.1739501953125, 0.97705078125, 1.0, 1.0, 0.873046875, 0.998046875, 1.0, 0.1319580078125, 0.685546875, 0.0, 0.0015058517456054688, 0.00833892822265625]], "normalized_score": [0.0], "tokens": [["\u2581In", "\u2581Las", "\u2581Veg", "as", ",", "\u2581Nev", "ada", ",", "\u2581USA", "\u2581###", "\u2581Over", "view"]], "entropy": [[1.142578125, 0.1484375, 0.0010557174682617188, 5.066394805908203e-06, 0.5107421875, 0.019195556640625, 0.0005321502685546875, 1.146484375, 0.96533203125, 0.755859375, 3.310546875, 1.720703125]], "avg_entropy": [0.8101226737101873], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Paradise, Nevada", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4397992451396014, "std_of_first_answer": 0.4397992451396014, "avg_entropy_of_first_answer": 0.8101226737101873, "lex_sim": 1.0}
{"question": "university of michigan school of public health ranking", "answer": ["University of Michigan School of Public Health is consistently ranked as one of the top public health schools in the United States."], "scores": [[0.1361083984375, 1.0, 0.99951171875, 0.9892578125, 0.99951171875, 0.99951171875, 0.99951171875, 0.9619140625, 0.345703125, 1.0, 0.99951171875, 0.181640625, 0.9970703125, 0.998046875, 1.0, 0.99853515625, 0.94580078125, 0.99951171875, 0.98486328125, 0.998046875, 1.0, 0.88134765625, 1.0, 0.80126953125, 0.166015625, 0.5009765625, 1.0, 1.0, 0.99951171875, 0.8017578125, 0.99951171875, 0.95947265625, 0.9306640625, 0.99951171875, 0.55126953125, 0.1810302734375, 1.0, 0.2471923828125, 0.72314453125, 1.0, 1.0, 0.99267578125, 0.99853515625, 0.984375, 1.0, 0.99609375, 0.7177734375, 0.004642486572265625, 0.87548828125, 0.88037109375]], "normalized_score": [0.6965087056159973], "tokens": [["\u2581University", "\u2581of", "\u2581Michigan", "\u2581School", "\u2581of", "\u2581Public", "\u2581Health", "\u2581is", "\u2581consist", "ently", "\u2581ranked", "\u2581as", "\u2581one", "\u2581of", "\u2581the", "\u2581top", "\u2581public", "\u2581health", "\u2581schools", "\u2581in", "\u2581the", "\u2581United", "\u2581States", ".", "\u2581In", "\u2581", "2", "0", "2", "1", ",", "\u2581it", "\u2581was", "\u2581ranked", "\u2581", "7", "th", "\u2581by", "\u2581U", ".", "S", ".", "\u2581News", "\u2581&", "\u2581World", "\u2581Report", ".", "\u2581The", "\u2581school", "\u2581is"]], "entropy": [[2.201171875, 0.001674652099609375, 0.005748748779296875, 0.08441162109375, 0.0023956298828125, 0.00335693359375, 0.005184173583984375, 0.2061767578125, 1.556640625, 3.6776065826416016e-05, 0.0034084320068359375, 0.576171875, 0.0213623046875, 0.01348876953125, 0.0017652511596679688, 0.01360321044921875, 0.275146484375, 0.003025054931640625, 0.08819580078125, 0.015899658203125, 0.0017614364624023438, 0.489013671875, 0.0014820098876953125, 0.68798828125, 1.3310546875, 0.9892578125, 4.094839096069336e-05, 5.7220458984375e-06, 0.0045166015625, 0.5673828125, 0.005199432373046875, 0.2227783203125, 0.2900390625, 0.005435943603515625, 0.85791015625, 1.53515625, 0.0013284683227539062, 1.0546875, 0.76611328125, 0.0008306503295898438, 0.0003695487976074219, 0.043792724609375, 0.0123443603515625, 0.0802001953125, 0.0023345947265625, 0.0269775390625, 1.0556640625, 0.5458984375, 0.55908203125, 0.5390625]], "avg_entropy": [0.3351314735412598], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "#4", "score_of_biggest_cluster": 0.6965087056159973, "score_of_first_answer": 0.6965087056159973, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.004642486572265625, "avg_score": 0.6965087056159973, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2877414651301729, "std_of_first_answer": 0.2877414651301729, "avg_entropy_of_first_answer": 0.3351314735412598, "lex_sim": 1.0}
{"question": "when was looking for a sunset bird in winter written", "answer": ["I'm sorry, I cannot determine the information you are asking for."], "scores": [[0.380615234375, 0.57763671875, 0.99951171875, 0.97998046875, 0.98779296875, 0.8466796875, 0.1800537109375, 0.239990234375, 0.8857421875, 0.002010345458984375, 0.83447265625, 0.76123046875, 0.650390625, 0.419677734375, 0.5380859375, 0.24755859375, 0.99853515625, 0.9345703125, 0.701171875, 0.01654052734375, 0.904296875, 0.93359375, 0.118408203125, 0.433349609375, 0.12078857421875, 0.9755859375, 0.8681640625, 0.69580078125, 0.99951171875, 0.9833984375, 5.364418029785156e-07, 6.556510925292969e-07, 0.0576171875, 0.05718994140625, 3.1054019927978516e-05, 0.6982421875, 0.3427734375, 0.035064697265625, 0.55029296875, 0.01070404052734375, 0.89794921875, 0.0016422271728515625, 9.894371032714844e-05, 0.300048828125, 0.09454345703125, 0.60302734375]], "normalized_score": [0.11429139971733093], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581I", "\u2581cannot", "\u2581determine", "\u2581the", "\u2581information", "\u2581you", "\u2581are", "\u2581asking", "\u2581for", ".", "\u2581Could", "\u2581you", "\u2581please", "\u2581provide", "\u2581additional", "\u2581context", "\u2581or", "\u2581specify", "\u2581the", "\u2581information", "\u2581you", "\u2581are", "\u2581looking", "\u2581for", "?", "\u2581\\", "\u2581Fish", "ing", "\u2581\\", "\u2581United", "\u2581States", "\u2581\\", "\u2581California", "\u2581\\", "\u2581Fish", "ing", "\u2581Near", "\u2581Com", "pton", ",", "\u2581California"]], "entropy": [[2.302734375, 1.4033203125, 0.004589080810546875, 0.12457275390625, 0.08026123046875, 0.67822265625, 1.70703125, 1.6318359375, 0.50537109375, 1.685546875, 0.79443359375, 0.783203125, 0.921875, 1.4794921875, 1.2880859375, 1.865234375, 0.0124053955078125, 0.27880859375, 0.890625, 0.390625, 0.3857421875, 0.276611328125, 1.033203125, 1.2470703125, 3.146484375, 0.1658935546875, 0.5810546875, 0.81005859375, 0.00586700439453125, 0.11444091796875, 0.406005859375, 1.3369140625, 3.470703125, 2.470703125, 5.2578125, 1.5625, 2.548828125, 5.7578125, 1.4736328125, 5.33203125, 0.69482421875, 3.4140625, 3.900390625, 1.537109375, 3.099609375, 1.798828125]], "avg_entropy": [1.53601016169009], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1923", "score_of_biggest_cluster": 0.11429139971733093, "score_of_first_answer": 0.11429139971733093, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 5.364418029785156e-07, "avg_score": 0.11429139971733093, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3751716239778916, "std_of_first_answer": 0.3751716239778916, "avg_entropy_of_first_answer": 1.53601016169009, "lex_sim": 1.0}
{"question": "who has the most ncaa basketball tournament appearances", "answer": ["Kentucky Wildcats with 57 appearances #358673 - 11/09/08 05:32 AM Re: Males who are hesitant to disclose sexual abuse"], "scores": [[0.51220703125, 0.671875, 1.0, 1.0, 0.1690673828125, 0.9990234375, 0.998046875, 0.2939453125, 0.98388671875, 5.960464477539063e-08, 0.0021114349365234375, 0.0059814453125, 0.0131072998046875, 0.0787353515625, 0.054412841796875, 0.0679931640625, 0.0004067420959472656, 0.1839599609375, 0.1160888671875, 0.1287841796875, 0.0158233642578125, 0.1568603515625, 0.043792724609375, 0.9921875, 0.003147125244140625, 0.076904296875, 0.2890625, 0.354736328125, 0.08984375, 0.99609375, 0.1800537109375, 0.094482421875, 0.0216522216796875, 0.0022792816162109375, 0.19775390625, 0.0015401840209960938, 0.0007195472717285156, 0.0269622802734375, 0.056488037109375, 8.088350296020508e-05, 0.85546875, 0.98193359375, 0.72509765625, 0.003711700439453125, 0.99560546875, 0.06536865234375, 0.04974365234375, 0.990234375]], "normalized_score": [0.05712282657623291], "tokens": [["\u2581Kentucky", "\u2581Wild", "c", "ats", "\u2581with", "\u2581", "5", "7", "\u2581appearances", "\u2581#", "3", "5", "8", "6", "7", "3", "\u2581-", "\u2581", "1", "1", "/", "0", "9", "/", "0", "8", "\u2581", "0", "5", ":", "3", "2", "\u2581AM", "\u2581Re", ":", "\u2581M", "ales", "\u2581who", "\u2581are", "\u2581hes", "it", "ant", "\u2581to", "\u2581disc", "lose", "\u2581sexual", "\u2581ab", "use"]], "entropy": [[1.529296875, 1.052734375, 0.0003724098205566406, 3.045797348022461e-05, 1.701171875, 0.0097503662109375, 0.0165252685546875, 1.1162109375, 0.10992431640625, 1.12890625, 3.19921875, 2.69140625, 3.876953125, 3.158203125, 3.001953125, 2.888671875, 2.783203125, 5.7265625, 1.326171875, 2.77734375, 3.390625, 1.873046875, 1.845703125, 0.065673828125, 0.145263671875, 2.14453125, 1.9755859375, 1.361328125, 2.29296875, 0.03857421875, 1.80078125, 2.3203125, 0.80908203125, 3.0546875, 2.171875, 4.9375, 3.3984375, 4.84765625, 3.666015625, 5.3671875, 0.8408203125, 0.10223388671875, 1.552734375, 3.822265625, 0.039794921875, 3.73828125, 3.291015625, 0.08856201171875]], "avg_entropy": [2.0641073870162168], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Kentucky", "score_of_biggest_cluster": 0.05712282657623291, "score_of_first_answer": 0.05712282657623291, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.05712282657623291, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39118017199498306, "std_of_first_answer": 0.39118017199498306, "avg_entropy_of_first_answer": 2.0641073870162168, "lex_sim": 1.0}
{"question": "what culture region is germany a part of", "answer": ["Central Europe"], "scores": [[0.51171875, 0.94091796875]], "normalized_score": [0.6938914656639099], "tokens": [["\u2581Central", "\u2581Europe"]], "entropy": [[1.32421875, 0.31982421875]], "avg_entropy": [0.822021484375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Central Germany", "score_of_biggest_cluster": 0.6938914656639099, "score_of_first_answer": 0.6938914656639099, "max_score_of_first_answer": 0.94091796875, "min_score_of_first_answer": 0.51171875, "avg_score": 0.6938914656639099, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.214599609375, "std_of_first_answer": 0.214599609375, "avg_entropy_of_first_answer": 0.822021484375, "lex_sim": 1.0}
{"question": "what is the full form of ib board", "answer": ["International Baccalaureate (IB) Board."], "scores": [[0.99658203125, 0.99951171875, 1.0, 1.0, 1.0, 0.140869140625, 0.9990234375, 0.9833984375, 0.0894775390625, 0.26416015625, 2.980232238769531e-07, 0.005161285400390625, 0.00395965576171875, 0.99951171875, 0.0038471221923828125, 0.96923828125, 0.00012242794036865234, 0.0758056640625, 0.0010776519775390625, 0.9990234375, 0.88232421875, 0.0023899078369140625, 0.9921875, 0.99462890625]], "normalized_score": [0.07634639739990234], "tokens": [["\u2581International", "\u2581Bac", "cala", "ure", "ate", "\u2581(", "IB", ")", "\u2581Board", ".", "\u2581#", "M", "ond", "ay", "Mus", "ings", "\u2581-", "\u2581The", "\u2581Beaut", "y", "\u2581of", "\u2581Sim", "p", "licity"]], "entropy": [[0.0309600830078125, 0.00601959228515625, 0.0004470348358154297, 3.147125244140625e-05, 0.00046706199645996094, 1.5498046875, 0.00896453857421875, 0.08868408203125, 0.705078125, 0.79150390625, 0.1390380859375, 5.41796875, 3.541015625, 0.002902984619140625, 0.5400390625, 0.23193359375, 0.457275390625, 4.61328125, 4.80078125, 0.0073699951171875, 0.50830078125, 3.494140625, 0.05291748046875, 0.037139892578125]], "avg_entropy": [1.1260860562324524], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "International Baccalaureate", "score_of_biggest_cluster": 0.07634639739990234, "score_of_first_answer": 0.07634639739990234, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.07634639739990234, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.46838545505433304, "std_of_first_answer": 0.46838545505433304, "avg_entropy_of_first_answer": 1.1260860562324524, "lex_sim": 1.0}
{"question": "how much square feet is a basketball court", "answer": ["A regulation NBA basketball court is 94 by 50 feet, which has a total area of approximately 4,714 square feet."], "scores": [[0.12432861328125, 0.69775390625, 1.0, 0.60546875, 0.94775390625, 0.9990234375, 0.994140625, 0.96044921875, 0.63916015625, 0.99755859375, 0.27294921875, 1.0, 1.0, 1.0, 0.998046875, 0.59765625, 0.261962890625, 0.0115966796875, 0.78857421875, 0.99853515625, 0.92724609375, 1.0, 0.1492919921875, 0.99951171875, 0.99853515625, 0.92431640625, 0.99658203125, 0.65185546875, 0.70556640625, 0.806640625, 1.0, 0.93603515625, 2.980232238769531e-07, 0.0005660057067871094, 0.0352783203125, 0.07598876953125, 0.06817626953125, 0.06597900390625, 0.094970703125, 0.0010328292846679688, 0.35791015625, 0.22265625, 0.2587890625, 0.09820556640625, 0.083740234375, 0.10113525390625, 0.97607421875, 0.01171112060546875]], "normalized_score": [0.21866431832313538], "tokens": [["\u2581A", "\u2581reg", "ulation", "\u2581NBA", "\u2581basketball", "\u2581court", "\u2581is", "\u2581", "9", "4", "\u2581by", "\u2581", "5", "0", "\u2581feet", ",", "\u2581which", "\u2581has", "\u2581a", "\u2581total", "\u2581area", "\u2581of", "\u2581approximately", "\u2581", "4", ",", "7", "1", "4", "\u2581square", "\u2581feet", ".", "\u2581#", "3", "4", "9", "6", "2", "2", "\u2581-", "\u2581", "1", "0", "/", "0", "9", "/", "0"]], "entropy": [[2.052734375, 0.98095703125, 0.000240325927734375, 0.89306640625, 0.232666015625, 0.00997161865234375, 0.04315185546875, 0.182373046875, 0.95166015625, 0.0207977294921875, 0.7607421875, 0.0020465850830078125, 0.0021991729736328125, 0.0009021759033203125, 0.01537322998046875, 1.203125, 1.7080078125, 0.298095703125, 0.52880859375, 0.01123809814453125, 0.3212890625, 0.002155303955078125, 0.62060546875, 0.0049591064453125, 0.01502227783203125, 0.328125, 0.02825927734375, 0.958984375, 1.138671875, 0.50390625, 0.0013027191162109375, 0.30078125, 0.72119140625, 2.125, 3.82421875, 3.326171875, 2.783203125, 2.734375, 2.7421875, 2.5703125, 4.80859375, 2.0078125, 2.650390625, 3.681640625, 1.728515625, 2.1796875, 0.1485595703125, 0.429931640625]], "avg_entropy": [1.0955002307891846], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "94 by 50 feet", "score_of_biggest_cluster": 0.21866431832313538, "score_of_first_answer": 0.21866431832313538, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.21866431832313538, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4064613971452345, "std_of_first_answer": 0.4064613971452345, "avg_entropy_of_first_answer": 1.0955002307891846, "lex_sim": 1.0}
{"question": "the oligodynamic effect is a phenomenon that describes", "answer": ["The ability of certain metal ions to kill microorganisms in small concentrations."], "scores": [[0.17236328125, 0.422119140625, 0.99853515625, 0.60498046875, 0.0160369873046875, 0.9990234375, 1.0, 0.97265625, 0.8583984375, 0.9111328125, 0.66845703125, 0.99951171875, 0.689453125, 0.0307464599609375, 0.98388671875, 1.0, 0.88427734375, 1.5676021575927734e-05, 0.061431884765625, 0.9609375, 0.0010662078857421875, 0.8818359375, 0.1048583984375, 0.00034332275390625, 0.2103271484375, 0.80419921875, 0.011260986328125, 0.70947265625, 0.58447265625, 0.33154296875, 0.20849609375, 0.01038360595703125, 0.2451171875, 0.9990234375, 0.3408203125, 0.0091094970703125, 0.9873046875, 0.06219482421875, 0.07421875, 0.99853515625, 0.09124755859375, 0.0056610107421875, 0.68896484375, 0.83154296875, 0.169921875, 0.00749969482421875, 0.521484375, 0.9716796875]], "normalized_score": [0.16860105097293854], "tokens": [["\u2581The", "\u2581ability", "\u2581of", "\u2581certain", "\u2581metal", "\u2581", "ions", "\u2581to", "\u2581kill", "\u2581micro", "organ", "isms", "\u2581in", "\u2581small", "\u2581concentr", "ations", ".", "\u2581I", "'", "m", "\u2581interested", "\u2581in", "\u2581the", "\u2581inter", "play", "\u2581between", "\u2581art", "\u2581and", "\u2581science", ",", "\u2581and", "\u2581enjoy", "\u2581expl", "oring", "\u2581the", "\u2581natural", "\u2581world", "\u2581through", "\u2581phot", "ography", ",", "\u2581video", ",", "\u2581and", "\u2581other", "\u2581visual", "\u2581media", "."]], "entropy": [[0.76025390625, 2.087890625, 0.0128173828125, 1.3330078125, 0.137939453125, 0.0077056884765625, 3.993511199951172e-06, 0.132568359375, 0.59814453125, 0.365234375, 0.6728515625, 0.004383087158203125, 0.9599609375, 1.8857421875, 0.0955810546875, 1.728534698486328e-05, 0.5078125, 0.357666015625, 1.375, 0.1982421875, 2.384765625, 0.5576171875, 3.20703125, 4.2578125, 2.048828125, 0.54296875, 3.98046875, 0.9306640625, 1.7001953125, 1.29296875, 3.884765625, 3.0546875, 3.302734375, 0.007373809814453125, 2.578125, 3.48046875, 0.0948486328125, 1.4169921875, 3.123046875, 0.0110931396484375, 1.029296875, 3.587890625, 1.142578125, 1.0087890625, 3.22265625, 1.849609375, 1.2109375, 0.186279296875]], "avg_entropy": [1.3872565887868404], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "a biocidal effect of metals", "score_of_biggest_cluster": 0.16860105097293854, "score_of_first_answer": 0.16860105097293854, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.5676021575927734e-05, "avg_score": 0.16860105097293854, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.3989104478158567, "std_of_first_answer": 0.3989104478158567, "avg_entropy_of_first_answer": 1.3872565887868404, "lex_sim": 1.0}
{"question": "what is the name of the dragon in eragon", "answer": ["Saphira #MondayMusings \u2013 A Quiet Week"], "scores": [[0.02392578125, 0.998046875, 0.95849609375, 0.99658203125, 5.960464477539062e-07, 0.01537322998046875, 0.002223968505859375, 0.986328125, 0.01427459716796875, 0.99560546875, 2.866983413696289e-05, 0.035614013671875, 0.0007886886596679688, 0.018463134765625, 0.30517578125]], "normalized_score": [0.019863314926624298], "tokens": [["\u2581S", "ap", "hi", "ra", "\u2581#", "M", "ond", "ay", "Mus", "ings", "\u2581\u2013", "\u2581A", "\u2581Qu", "iet", "\u2581Week"]], "entropy": [[3.943359375, 0.0173797607421875, 0.1951904296875, 0.026763916015625, 0.75390625, 4.875, 4.33203125, 0.10296630859375, 0.52685546875, 0.03802490234375, 1.1787109375, 5.1484375, 2.84375, 1.884765625, 3.3671875]], "avg_entropy": [1.948955281575521], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Saphira", "score_of_biggest_cluster": 0.019863314926624298, "score_of_first_answer": 0.019863314926624298, "max_score_of_first_answer": 0.998046875, "min_score_of_first_answer": 5.960464477539062e-07, "avg_score": 0.019863314926624298, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4515892737801216, "std_of_first_answer": 0.4515892737801216, "avg_entropy_of_first_answer": 1.948955281575521, "lex_sim": 1.0}
{"question": "when does the stock market open in hong kong", "answer": ["9:30 am #KUWTK Season 17: Kardashians, Kanye Get Real!"], "scores": [[0.70068359375, 0.9970703125, 0.97021484375, 0.98876953125, 1.0, 0.1756591796875, 1.0728836059570312e-06, 0.0004944801330566406, 0.0003211498260498047, 0.1064453125, 0.9990234375, 0.0002777576446533203, 0.888671875, 0.89306640625, 0.53076171875, 0.0016660690307617188, 0.0675048828125, 0.1693115234375, 0.9951171875, 0.390380859375, 0.0084075927734375, 0.0887451171875, 0.050262451171875, 0.99755859375, 0.0004191398620605469, 0.26904296875, 0.01305389404296875]], "normalized_score": [0.055081624537706375], "tokens": [["\u2581", "9", ":", "3", "0", "\u2581am", "\u2581#", "K", "U", "WT", "K", "\u2581Season", "\u2581", "1", "7", ":", "\u2581K", "ard", "ash", "ians", ",", "\u2581K", "any", "e", "\u2581Get", "\u2581Real", "!"]], "entropy": [[1.560546875, 0.02239990234375, 0.1689453125, 0.06365966796875, 0.00022983551025390625, 1.115234375, 1.3515625, 2.189453125, 1.484375, 3.12109375, 0.009613037109375, 0.716796875, 0.662109375, 0.369873046875, 1.01953125, 0.85498046875, 2.982421875, 1.546875, 0.04571533203125, 0.7158203125, 4.75390625, 5.1875, 2.404296875, 0.0177154541015625, 2.119140625, 3.294921875, 1.87890625]], "avg_entropy": [1.4688008979514793], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "09:15", "score_of_biggest_cluster": 0.055081624537706375, "score_of_first_answer": 0.055081624537706375, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.0728836059570312e-06, "avg_score": 0.055081624537706375, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42320016330057214, "std_of_first_answer": 0.42320016330057214, "avg_entropy_of_first_answer": 1.4688008979514793, "lex_sim": 1.0}
{"question": "what proposition made the insurance commissioner an elected position", "answer": ["Proposition 103 #Vision2020: Enugu Govt."], "scores": [[0.97216796875, 0.99951171875, 0.97412109375, 0.99755859375, 1.0, 5.960464477539063e-08, 0.0022258758544921875, 0.00028705596923828125, 0.08544921875, 0.98583984375, 0.85205078125, 0.939453125, 0.0010118484497070312, 0.0018415451049804688, 5.78761100769043e-05, 0.99853515625, 0.0028285980224609375, 0.0014972686767578125, 0.96728515625, 0.219482421875, 0.00168609619140625, 0.01099395751953125, 0.0035381317138671875, 0.99609375, 0.9140625, 0.9951171875, 0.1549072265625, 0.587890625, 0.27783203125, 0.451416015625, 0.98388671875, 0.00655364990234375, 0.9951171875, 1.0, 0.3193359375, 1.0, 0.56201171875]], "normalized_score": [0.06997834146022797], "tokens": [["\u2581Proposition", "\u2581", "1", "0", "3", "\u2581#", "V", "ision", "2", "0", "2", "0", ":", "\u2581En", "ug", "u", "\u2581G", "ov", "t", ".", "\u2581to", "\u2581Begin", "\u2581Dem", "ol", "ition", "\u2581of", "\u2581Mark", "ets", ",", "\u2581Sh", "ops", "\u2581Ob", "struct", "ing", "\u2581D", "rain", "ages"]], "entropy": [[0.16357421875, 0.004474639892578125, 0.166748046875, 0.0214996337890625, 0.002655029296875, 1.45703125, 2.921875, 0.67529296875, 2.486328125, 0.1395263671875, 0.65673828125, 0.331298828125, 2.115234375, 4.4453125, 0.78759765625, 0.012298583984375, 2.48046875, 0.7548828125, 0.271728515625, 4.12109375, 4.16015625, 4.95703125, 3.642578125, 0.0294036865234375, 0.30029296875, 0.04107666015625, 2.640625, 0.75732421875, 3.10546875, 2.70703125, 0.0892333984375, 2.310546875, 0.033538818359375, 0.0010271072387695312, 2.33203125, 0.0010633468627929688, 0.6865234375]], "avg_entropy": [1.4002868033744194], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Proposition 103", "score_of_biggest_cluster": 0.06997834146022797, "score_of_first_answer": 0.06997834146022797, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.06997834146022797, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4434004202624262, "std_of_first_answer": 0.4434004202624262, "avg_entropy_of_first_answer": 1.4002868033744194, "lex_sim": 1.0}
{"question": "where would the group bacteroids likely be found", "answer": ["In the human gut microbiome."], "scores": [[0.07147216796875, 0.970703125, 0.60498046875, 0.83544921875, 0.48486328125, 1.0, 0.9921875, 0.61767578125, 3.5762786865234375e-07, 0.0020904541015625, 0.048614501953125, 0.0188446044921875, 0.01325225830078125, 0.05859375, 0.00044655799865722656, 0.9404296875, 0.0007171630859375, 4.941225051879883e-05, 0.607421875, 0.99462890625]], "normalized_score": [0.03844781592488289], "tokens": [["\u2581In", "\u2581the", "\u2581human", "\u2581gut", "\u2581micro", "bi", "ome", ".", "\u2581#", "2", "8", "5", ":", "\u2581The", "\u2581Power", "\u2581of", "\u2581Personal", "\u2581Mission", "\u2581Stat", "ements"]], "entropy": [[2.26953125, 0.216552734375, 1.12890625, 0.6904296875, 1.30078125, 0.0012331008911132812, 0.0465087890625, 1.0107421875, 0.13818359375, 2.68359375, 3.095703125, 2.880859375, 2.623046875, 4.97265625, 3.26171875, 0.41162109375, 2.072265625, 1.6982421875, 1.966796875, 0.03411865234375]], "avg_entropy": [1.6251745700836182], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the human colon", "score_of_biggest_cluster": 0.03844781592488289, "score_of_first_answer": 0.03844781592488289, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 3.5762786865234375e-07, "avg_score": 0.03844781592488289, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.41521137503032524, "std_of_first_answer": 0.41521137503032524, "avg_entropy_of_first_answer": 1.6251745700836182, "lex_sim": 1.0}
{"question": "when's the last time michigan won a national championship in basketball", "answer": ["2003 (Men's NCAA)"], "scores": [[0.90234375, 0.99609375, 1.0, 0.375732421875, 0.0277099609375, 0.104736328125, 0.419921875, 0.990234375, 1.0, 0.08831787109375, 0.05029296875]], "normalized_score": [0.30059167742729187], "tokens": [["\u2581", "2", "0", "0", "3", "\u2581(", "Men", "'", "s", "\u2581NCAA", ")"]], "entropy": [[0.56396484375, 0.0260467529296875, 0.0012607574462890625, 0.68896484375, 1.37890625, 2.31640625, 1.1904296875, 0.0635986328125, 6.765127182006836e-05, 1.6748046875, 1.3857421875]], "avg_entropy": [0.8445629585872997], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1989", "score_of_biggest_cluster": 0.30059167742729187, "score_of_first_answer": 0.30059167742729187, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0277099609375, "avg_score": 0.30059167742729187, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4158596621511912, "std_of_first_answer": 0.4158596621511912, "avg_entropy_of_first_answer": 0.8445629585872997, "lex_sim": 1.0}
{"question": "when did athens emerges as wealthiest greek city state", "answer": ["5th century BCE"], "scores": [[0.44384765625, 0.98828125, 0.99169921875, 0.97900390625, 0.81689453125, 0.990234375]], "normalized_score": [0.8372666835784912], "tokens": [["\u2581", "5", "th", "\u2581century", "\u2581B", "CE"]], "entropy": [[2.271484375, 0.07421875, 0.056060791015625, 0.1307373046875, 0.50927734375, 0.05450439453125]], "avg_entropy": [0.5160471598307291], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the late 6th century BCE", "score_of_biggest_cluster": 0.8372666835784912, "score_of_first_answer": 0.8372666835784912, "max_score_of_first_answer": 0.99169921875, "min_score_of_first_answer": 0.44384765625, "avg_score": 0.8372666835784912, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.19981179654063827, "std_of_first_answer": 0.19981179654063827, "avg_entropy_of_first_answer": 0.5160471598307291, "lex_sim": 1.0}
{"question": "the roman name for a liberal arts education is known as", "answer": ["Humanitas"], "scores": [[0.289306640625, 0.334716796875]], "normalized_score": [0.31118446588516235], "tokens": [["\u2581Human", "itas"]], "entropy": [[1.6689453125, 1.4638671875]], "avg_entropy": [1.56640625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "liberalia studia", "score_of_biggest_cluster": 0.31118446588516235, "score_of_first_answer": 0.31118446588516235, "max_score_of_first_answer": 0.334716796875, "min_score_of_first_answer": 0.289306640625, "avg_score": 0.31118446588516235, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.022705078125, "std_of_first_answer": 0.022705078125, "avg_entropy_of_first_answer": 1.56640625, "lex_sim": 1.0}
{"question": "when was the last time a hurricane hit the uk", "answer": ["Hurricane Gordon in 2006"], "scores": [[0.394775390625, 1.0, 0.98193359375, 0.12939453125, 0.9462890625, 0.96533203125, 1.0, 1.0, 0.994140625, 1.0]], "normalized_score": [0.7342596650123596], "tokens": [["\u2581H", "urr", "icane", "\u2581Gordon", "\u2581in", "\u2581", "2", "0", "0", "6"]], "entropy": [[2.060546875, 4.1961669921875e-05, 0.09014892578125, 3.400390625, 0.310791015625, 0.15625, 0.0018548965454101562, 1.8596649169921875e-05, 0.03594970703125, 0.00034332275390625]], "avg_entropy": [0.6056335926055908], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the autumn of 2017", "score_of_biggest_cluster": 0.7342596650123596, "score_of_first_answer": 0.7342596650123596, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.12939453125, "avg_score": 0.7342596650123596, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.29605421240144714, "std_of_first_answer": 0.29605421240144714, "avg_entropy_of_first_answer": 0.6056335926055908, "lex_sim": 1.0}
{"question": "when did the usa join world war one", "answer": ["April 6, 1917 # 153 \u2013 29 February 2020 \u2013 Racist hate speech, Cyclone Pam and COVID-19 \u2013 A week in review"], "scores": [[0.783203125, 0.9990234375, 0.99951171875, 0.94482421875, 0.99853515625, 1.0, 1.0, 1.0, 1.0, 5.960464477539063e-08, 0.0126190185546875, 0.41015625, 0.016387939453125, 0.09161376953125, 0.00012123584747314453, 0.329833984375, 0.146240234375, 0.041290283203125, 3.93986701965332e-05, 0.703125, 0.0160675048828125, 0.95947265625, 0.8671875, 0.311279296875, 0.01407623291015625, 0.001186370849609375, 3.260374069213867e-05, 0.1884765625, 0.0009098052978515625, 0.744140625, 0.1036376953125, 4.51207160949707e-05, 0.00028777122497558594, 0.057373046875, 0.035614013671875, 0.0074615478515625, 0.955078125, 0.99560546875, 0.99951171875, 0.08074951171875, 0.03009033203125, 0.08587646484375, 0.37841796875, 0.059722900390625]], "normalized_score": [0.04752282053232193], "tokens": [["\u2581April", "\u2581", "6", ",", "\u2581", "1", "9", "1", "7", "\u2581#", "\u2581", "1", "5", "3", "\u2581\u2013", "\u2581", "2", "9", "\u2581February", "\u2581", "2", "0", "2", "0", "\u2581\u2013", "\u2581R", "ac", "ist", "\u2581hate", "\u2581speech", ",", "\u2581Cy", "clone", "\u2581Pam", "\u2581and", "\u2581COVID", "-", "1", "9", "\u2581\u2013", "\u2581A", "\u2581week", "\u2581in", "\u2581review"]], "entropy": [[0.70751953125, 0.006687164306640625, 0.0030536651611328125, 0.2178955078125, 0.0131988525390625, 0.00013327598571777344, -0.0, 0.001407623291015625, 0.001434326171875, 0.9599609375, 4.90234375, 1.748046875, 1.765625, 2.99609375, 3.068359375, 3.95703125, 1.9765625, 2.60546875, 3.259765625, 1.4140625, 0.126953125, 0.289794921875, 0.54150390625, 1.3017578125, 2.15625, 3.88671875, 2.51953125, 2.2734375, 5.97265625, 1.6455078125, 3.275390625, 3.630859375, 0.265625, 2.994140625, 3.533203125, 6.32421875, 0.377197265625, 0.034881591796875, 0.00473785400390625, 4.44140625, 6.17578125, 4.53125, 1.484375, 2.392578125]], "avg_entropy": [2.040554691444744], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "April 1917", "score_of_biggest_cluster": 0.04752282053232193, "score_of_first_answer": 0.04752282053232193, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.04752282053232193, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4233486765319408, "std_of_first_answer": 0.4233486765319408, "avg_entropy_of_first_answer": 2.040554691444744, "lex_sim": 1.0}
{"question": "where was the u.s.s maine when it exploded in 1898", "answer": ["Havana, Cuba #RomanticTuesday: Romantic Short Story"], "scores": [[0.89599609375, 0.99951171875, 0.86767578125, 0.998046875, 4.172325134277344e-07, 0.0030364990234375, 8.004903793334961e-05, 0.121337890625, 0.0537109375, 0.0018453598022460938, 0.90087890625, 0.000179290771484375, 0.0022735595703125, 0.81201171875, 0.0035419464111328125, 0.299560546875]], "normalized_score": [0.019043829292058945], "tokens": [["\u2581Hav", "ana", ",", "\u2581Cuba", "\u2581#", "R", "om", "antic", "T", "ues", "day", ":", "\u2581Rom", "antic", "\u2581Short", "\u2581Story"]], "entropy": [[0.54833984375, 0.002674102783203125, 0.4638671875, 0.01561737060546875, 0.85595703125, 3.71875, 4.44140625, 1.888671875, 4.19140625, 1.40234375, 0.352294921875, 1.662109375, 4.609375, 0.58251953125, 5.3125, 2.236328125]], "avg_entropy": [2.0177600383758545], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Havana Harbor", "score_of_biggest_cluster": 0.019043829292058945, "score_of_first_answer": 0.019043829292058945, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.019043829292058945, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.42641270534384246, "std_of_first_answer": 0.42641270534384246, "avg_entropy_of_first_answer": 2.0177600383758545, "lex_sim": 1.0}
{"question": "who played the mom on what's eating gilbert grape", "answer": ["Leonardo DiCaprio Chapter 31: Reunited"], "scores": [[0.1888427734375, 0.98876953125, 0.994140625, 0.99951171875, 1.0, 0.0, 0.442138671875, 0.05169677734375, 0.0195770263671875, 0.237060546875, 0.003398895263671875, 0.0153350830078125, 0.79443359375]], "normalized_score": [0.0], "tokens": [["\u2581Leon", "ardo", "\u2581Di", "Cap", "rio", "\u2581Chapter", "\u2581", "3", "1", ":", "\u2581Re", "un", "ited"]], "entropy": [[2.08203125, 0.07720947265625, 0.03802490234375, 0.0040130615234375, 0.00021982192993164062, 0.951171875, 3.28125, 1.42578125, 3.19140625, 3.912109375, 5.0703125, 3.42578125, 0.779296875]], "avg_entropy": [1.8645082987271822], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Darlene Cates", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4257883105902714, "std_of_first_answer": 0.4257883105902714, "avg_entropy_of_first_answer": 1.8645082987271822, "lex_sim": 1.0}
{"question": "who plays lady talisa in game of thrones", "answer": ["Nikolaj Coster-Waldau #25."], "scores": [[0.060699462890625, 0.9990234375, 0.99853515625, 1.0, 0.998046875, 0.99951171875, 1.0, 1.0, 1.7285346984863281e-06, 0.03253173828125, 0.121337890625, 0.00592041015625, 4.4405460357666016e-05, 0.0008521080017089844, 0.9990234375, 0.5439453125, 0.0013055801391601562]], "normalized_score": [0.04955347999930382], "tokens": [["\u2581Nikol", "aj", "\u2581Cost", "er", "-", "W", "ald", "au", "\u2581#", "2", "5", ".", "\u2581Be", "\u2581thank", "ful", "\u2581for", "\u2581life"]], "entropy": [[2.408203125, 0.007965087890625, 0.01483917236328125, 2.872943878173828e-05, 0.01490020751953125, 0.0029087066650390625, 0.00030612945556640625, 0.0003075599670410156, 0.9306640625, 3.34765625, 2.921875, 2.72265625, 2.658203125, 4.28515625, 0.0080413818359375, 1.9560546875, 0.64501953125]], "avg_entropy": [1.2896932503756355], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Oona Castilla Chaplin", "score_of_biggest_cluster": 0.04955347999930382, "score_of_first_answer": 0.04955347999930382, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7285346984863281e-06, "avg_score": 0.04955347999930382, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4720972831848456, "std_of_first_answer": 0.4720972831848456, "avg_entropy_of_first_answer": 1.2896932503756355, "lex_sim": 1.0}
{"question": "what is the population of keystone heights florida", "answer": ["I'm sorry, I don't have information on the current population of Keystone Heights, Florida."], "scores": [[0.59814453125, 0.703125, 0.99951171875, 0.9912109375, 0.9892578125, 0.8134765625, 0.54833984375, 0.998046875, 1.0, 0.96142578125, 0.2003173828125, 0.69189453125, 0.9453125, 0.3466796875, 0.9990234375, 0.99755859375, 0.9677734375, 1.0, 1.0, 0.998046875, 1.0, 0.994140625, 0.982421875, 0.9404296875, 0.1292724609375, 0.9658203125, 0.09503173828125, 0.97119140625, 0.99365234375, 0.6572265625, 0.9990234375, 0.99951171875, 0.0, 0.23193359375, 3.3855438232421875e-05, 0.026641845703125, 0.1866455078125, 0.05657958984375, 0.036773681640625, 0.9755859375, 0.99951171875, 0.19921875, 0.1070556640625]], "normalized_score": [0.0], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581I", "\u2581don", "'", "t", "\u2581have", "\u2581information", "\u2581on", "\u2581the", "\u2581current", "\u2581population", "\u2581of", "\u2581Ke", "yst", "one", "\u2581He", "ights", ",", "\u2581Florida", ".", "\u2581Can", "\u2581I", "\u2581assist", "\u2581you", "\u2581with", "\u2581anything", "\u2581else", "?", "\u2581#####", "#", "\u2581P", "\u2581R", "\u2581E", "\u2581F", "\u2581A", "\u2581C", "\u2581E", "\u2581###", "####"]], "entropy": [[1.69921875, 1.12109375, 0.004589080810546875, 0.061920166015625, 0.06890869140625, 0.6083984375, 1.1181640625, 0.01690673828125, 0.0005130767822265625, 0.168212890625, 1.384765625, 0.68115234375, 0.288330078125, 0.84033203125, 0.007793426513671875, 0.0196990966796875, 0.1923828125, 0.0004138946533203125, 0.000396728515625, 0.0147552490234375, 0.00048732757568359375, 0.042694091796875, 0.093017578125, 0.298095703125, 2.12109375, 0.1507568359375, 0.34033203125, 0.1368408203125, 0.042938232421875, 0.68310546875, 0.00689697265625, 0.005771636962890625, 0.25634765625, 1.3818359375, 0.59619140625, 2.501953125, 1.0888671875, 0.7294921875, 0.408203125, 0.1484375, 0.003414154052734375, 2.05859375, 2.248046875]], "avg_entropy": [0.549799076346464], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1,350", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38714590577478253, "std_of_first_answer": 0.38714590577478253, "avg_entropy_of_first_answer": 0.549799076346464, "lex_sim": 1.0}
{"question": "where can carbon be found in the biosphere", "answer": ["Carbon can be found in various forms in the biosphere, including in the carbon dioxide in the Earth's atmosphere, in the organic matter in living organisms, and in the sedimentary rocks."], "scores": [[0.2100830078125, 1.0, 0.79052734375, 0.99951171875, 1.0, 0.98046875, 0.04693603515625, 0.27294921875, 0.91455078125, 0.998046875, 0.99609375, 1.0, 1.0, 0.87255859375, 0.85205078125, 0.9501953125, 0.93359375, 0.006591796875, 0.76806640625, 1.0, 1.0, 0.96875, 0.99853515625, 0.01082611083984375, 0.99658203125, 1.0, 0.99951171875, 0.9384765625, 0.8388671875, 0.896484375, 0.6708984375, 1.0, 0.21630859375, 0.87890625, 0.170654296875, 0.99609375, 1.0, 0.96923828125, 0.91748046875, 0.9990234375, 0.346435546875, 0.2413330078125, 0.30078125, 0.60400390625, 0.94677734375, 0.048858642578125, 0.0]], "normalized_score": [0.0], "tokens": [["\u2581Car", "bon", "\u2581can", "\u2581be", "\u2581found", "\u2581in", "\u2581various", "\u2581forms", "\u2581in", "\u2581the", "\u2581b", "ios", "phere", ",", "\u2581including", "\u2581in", "\u2581the", "\u2581carbon", "\u2581dio", "x", "ide", "\u2581in", "\u2581the", "\u2581Earth", "'", "s", "\u2581atmosphere", ",", "\u2581in", "\u2581the", "\u2581organ", "ic", "\u2581matter", "\u2581in", "\u2581living", "\u2581organ", "isms", ",", "\u2581and", "\u2581in", "\u2581the", "\u2581sed", "iment", "ary", "\u2581rocks", ".", "\u2581CHAPTER"]], "entropy": [[2.044921875, 2.7060508728027344e-05, 0.568359375, 0.004596710205078125, 0.00171661376953125, 0.1199951171875, 0.732421875, 1.396484375, 0.428466796875, 0.0164947509765625, 0.0305938720703125, 0.00041866302490234375, 0.0018587112426757812, 0.470947265625, 0.4345703125, 0.295166015625, 0.36083984375, 0.9931640625, 0.57470703125, 0.00028896331787109375, 2.110004425048828e-05, 0.1851806640625, 0.0113983154296875, 0.56396484375, 0.02508544921875, 0.0001138448715209961, 0.0027313232421875, 0.2403564453125, 0.6142578125, 0.495361328125, 1.41015625, 9.28044319152832e-05, 0.60791015625, 0.5419921875, 0.9150390625, 0.029815673828125, 0.00042700767517089844, 0.16552734375, 0.292236328125, 0.0095367431640625, 1.265625, 2.033203125, 0.611328125, 0.87548828125, 0.2147216796875, 1.3232421875, 0.81787109375]], "avg_entropy": [0.4623132652424751], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "other living organisms", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.354522858341959, "std_of_first_answer": 0.354522858341959, "avg_entropy_of_first_answer": 0.4623132652424751, "lex_sim": 1.0}
{"question": "where do they film young and the restless", "answer": ["Los Angeles, California #FRA (11) / #France (14)"], "scores": [[0.346435546875, 0.99951171875, 0.92626953125, 0.88623046875, 5.960464477539063e-08, 0.00443267822265625, 0.0001894235610961914, 0.0009050369262695312, 0.00821685791015625, 0.0240478515625, 0.051513671875, 0.0008563995361328125, 0.086669921875, 0.0002340078353881836, 0.87939453125, 0.68408203125, 0.03765869140625, 0.93896484375]], "normalized_score": [0.018208712339401245], "tokens": [["\u2581Los", "\u2581Angeles", ",", "\u2581California", "\u2581#", "F", "RA", "\u2581(", "1", "1", ")", "\u2581/", "\u2581#", "France", "\u2581(", "1", "4", ")"]], "entropy": [[2.13671875, 0.00516510009765625, 0.330810546875, 0.37109375, 1.3408203125, 4.7734375, 2.939453125, 1.1923828125, 5.234375, 2.09765625, 3.10546875, 1.62109375, 3.939453125, 2.986328125, 0.67724609375, 1.4345703125, 1.2998046875, 0.41162109375]], "avg_entropy": [1.9943055046929254], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "CBS Television City", "score_of_biggest_cluster": 0.018208712339401245, "score_of_first_answer": 0.018208712339401245, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.018208712339401245, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4068643264249438, "std_of_first_answer": 0.4068643264249438, "avg_entropy_of_first_answer": 1.9943055046929254, "lex_sim": 1.0}
{"question": "which songs did liam write as you were", "answer": ["Several songs, including:"], "scores": [[0.0032939910888671875, 0.62744140625, 0.272705078125, 0.98583984375, 0.1259765625]], "normalized_score": [0.1475764364004135], "tokens": [["\u2581Several", "\u2581songs", ",", "\u2581including", ":"]], "entropy": [[3.23828125, 1.2275390625, 1.798828125, 0.09765625, 1.4599609375]], "avg_entropy": [1.564453125], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "I've All I Need", "score_of_biggest_cluster": 0.1475764364004135, "score_of_first_answer": 0.1475764364004135, "max_score_of_first_answer": 0.98583984375, "min_score_of_first_answer": 0.0032939910888671875, "avg_score": 0.1475764364004135, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.35876450779160257, "std_of_first_answer": 0.35876450779160257, "avg_entropy_of_first_answer": 1.564453125, "lex_sim": 1.0}
{"question": "what was the city of beijing previously known as", "answer": ["Peking ### What is the book about?"], "scores": [[0.34716796875, 0.998046875, 0.99951171875, 0.0, 0.0004665851593017578, 0.5625, 0.71875, 0.00012129545211791992, 0.042144775390625, 0.1451416015625]], "normalized_score": [0.0], "tokens": [["\u2581P", "ek", "ing", "\u2581###", "\u2581What", "\u2581is", "\u2581the", "\u2581book", "\u2581about", "?"]], "entropy": [[1.361328125, 0.016387939453125, 0.006023406982421875, 0.6123046875, 3.990234375, 2.359375, 1.234375, 4.203125, 2.826171875, 4.42578125]], "avg_entropy": [2.1035106658935545], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Peking", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.3894805955220744, "std_of_first_answer": 0.3894805955220744, "avg_entropy_of_first_answer": 2.1035106658935545, "lex_sim": 1.0}
{"question": "who holds the most home runs in mlb history", "answer": ["Hank Aaron #EthicsDailyOnline"], "scores": [[0.61376953125, 1.0, 0.99951171875, 1.0, 4.112720489501953e-06, 0.0001360177993774414, 0.0006885528564453125, 0.02789306640625, 0.0110321044921875, 0.1917724609375, 0.0265960693359375, 0.79833984375]], "normalized_score": [0.028572624549269676], "tokens": [["\u2581H", "ank", "\u2581A", "aron", "\u2581#", "E", "th", "ics", "D", "aily", "On", "line"]], "entropy": [[0.7607421875, 0.0019388198852539062, 0.00514984130859375, 0.000240325927734375, 1.29296875, 2.162109375, 3.771484375, 2.486328125, 2.939453125, 2.193359375, 3.251953125, 1.240234375]], "avg_entropy": [1.6754968166351318], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Barry Bonds", "score_of_biggest_cluster": 0.028572624549269676, "score_of_first_answer": 0.028572624549269676, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.112720489501953e-06, "avg_score": 0.028572624549269676, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43149534478818574, "std_of_first_answer": 0.43149534478818574, "avg_entropy_of_first_answer": 1.6754968166351318, "lex_sim": 1.0}
{"question": "ajay devgan preity zinta and madhuri dixit movie", "answer": ["\"Raid\" (Ajay Devgn, Ileana D'Cruz) ### What is it?"], "scores": [[0.27001953125, 0.0020923614501953125, 0.72021484375, 0.1790771484375, 0.98486328125, 0.191650390625, 0.0484619140625, 1.0, 1.0, 1.0, 0.921875, 0.953125, 0.99951171875, 0.99951171875, 1.0, 0.99951171875, 0.9990234375, 0.9990234375, 1.0, 1.0, 0.43310546875, 0.0, 3.820657730102539e-05, 0.53271484375, 0.0023632049560546875, 0.399658203125]], "normalized_score": [0.0], "tokens": [["\u2581\"", "R", "a", "id", "\"", "\u2581(", "A", "j", "ay", "\u2581Dev", "gn", ",", "\u2581I", "le", "ana", "\u2581D", "'", "C", "ru", "z", ")", "\u2581###", "\u2581What", "\u2581is", "\u2581it", "?"]], "entropy": [[1.8330078125, 2.30859375, 0.98486328125, 0.791015625, 0.1015625, 1.08203125, 0.55078125, 0.0011091232299804688, 0.0007495880126953125, 0.0018949508666992188, 0.275146484375, 0.2431640625, 0.00383758544921875, 0.004611968994140625, 0.0003056526184082031, 0.0039825439453125, 0.00942230224609375, 0.008056640625, 6.985664367675781e-05, 0.00018739700317382812, 0.9833984375, 1.3173828125, 1.0, 2.59765625, 1.68359375, 2.060546875]], "avg_entropy": [0.6864219903945923], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Yeh Raaste Hain Pyaar Ke", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4100194447878258, "std_of_first_answer": 0.4100194447878258, "avg_entropy_of_first_answer": 0.6864219903945923, "lex_sim": 1.0}
{"question": "when did the united states became a nation", "answer": ["July 4, 1776 #TBT to the first #TBT post (originally shared on June 9, 2011 as part of the then-new trend)."], "scores": [[0.85498046875, 0.99951171875, 1.0, 0.89794921875, 0.9990234375, 1.0, 1.0, 1.0, 1.0, 5.960464477539063e-08, 5.412101745605469e-05, 0.99658203125, 0.00247955322265625, 0.436767578125, 0.005954742431640625, 0.3896484375, 3.516674041748047e-05, 0.99951171875, 0.22802734375, 0.01116180419921875, 0.0018215179443359375, 0.9833984375, 0.031768798828125, 0.599609375, 0.01983642578125, 0.9970703125, 0.0020885467529296875, 0.7734375, 0.99658203125, 0.77734375, 0.99951171875, 0.93212890625, 0.86572265625, 0.00017082691192626953, 0.375, 0.99853515625, 0.285888671875, 0.00241851806640625, 0.90283203125, 0.94482421875, 0.021484375, 0.97900390625, 0.033843994140625]], "normalized_score": [0.09481566399335861], "tokens": [["\u2581July", "\u2581", "4", ",", "\u2581", "1", "7", "7", "6", "\u2581#", "TB", "T", "\u2581to", "\u2581the", "\u2581first", "\u2581#", "TB", "T", "\u2581post", "\u2581(", "origin", "ally", "\u2581shared", "\u2581on", "\u2581June", "\u2581", "9", ",", "\u2581", "2", "0", "1", "1", "\u2581as", "\u2581part", "\u2581of", "\u2581the", "\u2581then", "-", "new", "\u2581tr", "end", ")."]], "entropy": [[0.67919921875, 0.004947662353515625, 0.0013332366943359375, 0.337158203125, 0.00958251953125, 1.2278556823730469e-05, 2.09808349609375e-05, 0.00023984909057617188, 0.0005102157592773438, 1.16796875, 4.28515625, 0.035675048828125, 1.5439453125, 2.2109375, 2.4453125, 2.37109375, 1.14453125, 0.00750732421875, 2.712890625, 2.498046875, 2.97265625, 0.09991455078125, 2.595703125, 1.1875, 1.3310546875, 0.0211334228515625, 0.92333984375, 0.54638671875, 0.02703857421875, 0.53076171875, 0.00650787353515625, 0.2493896484375, 0.548828125, 1.0537109375, 1.6640625, 0.01271820068359375, 1.87109375, 2.564453125, 0.4755859375, 0.38427734375, 2.525390625, 0.10272216796875, 1.451171875]], "avg_entropy": [1.0372434965399808], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1776", "score_of_biggest_cluster": 0.09481566399335861, "score_of_first_answer": 0.09481566399335861, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.09481566399335861, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.43560745262829376, "std_of_first_answer": 0.43560745262829376, "avg_entropy_of_first_answer": 1.0372434965399808, "lex_sim": 1.0}
{"question": "what type of speed does a speedometer measure", "answer": ["miles per hour (MPH) or kilometers per hour (KPH) #AskAnArchivist: Question and Answers from our Live Twitter Chat"], "scores": [[0.01470947265625, 0.99853515625, 0.9990234375, 0.363037109375, 0.537109375, 1.0, 0.970703125, 0.6884765625, 0.99658203125, 1.0, 1.0, 1.0, 0.99853515625, 0.95458984375, 0.9462890625, 0.8896484375, 4.172325134277344e-07, 0.005130767822265625, 0.791015625, 0.0216064453125, 0.0008168220520019531, 0.488037109375, 0.99853515625, 0.0011138916015625, 0.00026679039001464844, 0.002696990966796875, 0.00640106201171875, 0.98095703125, 0.041168212890625, 0.0013265609741210938, 0.00011157989501953125, 0.08367919921875, 0.6826171875, 0.9853515625]], "normalized_score": [0.07935105264186859], "tokens": [["\u2581miles", "\u2581per", "\u2581hour", "\u2581(", "MP", "H", ")", "\u2581or", "\u2581kilom", "eters", "\u2581per", "\u2581hour", "\u2581(", "K", "PH", ")", "\u2581#", "A", "sk", "An", "Arch", "iv", "ist", ":", "\u2581Question", "\u2581and", "\u2581An", "swers", "\u2581from", "\u2581our", "\u2581Live", "\u2581Twitter", "\u2581Ch", "at"]], "entropy": [[2.4765625, 0.0127716064453125, 0.006732940673828125, 1.4609375, 0.93310546875, 0.0009059906005859375, 0.1583251953125, 0.7744140625, 0.0266571044921875, 7.706880569458008e-05, 0.0003437995910644531, 0.0004868507385253906, 0.0120849609375, 0.198486328125, 0.272216796875, 0.369140625, 0.62841796875, 5.99609375, 1.33984375, 4.8125, 2.74609375, 0.93310546875, 0.01546478271484375, 1.1904296875, 3.84765625, 2.974609375, 0.79833984375, 0.1502685546875, 4.0, 2.8671875, 3.90234375, 3.296875, 1.396484375, 0.07794189453125]], "avg_entropy": [1.4022618970450234], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "instantaneous speed", "score_of_biggest_cluster": 0.07935105264186859, "score_of_first_answer": 0.07935105264186859, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.07935105264186859, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4432476111090052, "std_of_first_answer": 0.4432476111090052, "avg_entropy_of_first_answer": 1.4022618970450234, "lex_sim": 1.0}
{"question": "when was the last time the boston red sox pitched a no-hitter", "answer": ["July 23, 2015 (by Rick Porcello)."], "scores": [[0.01142120361328125, 0.99853515625, 0.98876953125, 0.9990234375, 0.95458984375, 0.998046875, 0.99755859375, 1.0, 0.884765625, 0.97119140625, 0.179443359375, 0.72607421875, 0.453857421875, 1.0, 1.0, 0.99951171875, 0.1170654296875, 2.205371856689453e-06, 0.0006546974182128906, 0.0004112720489501953, 0.6533203125, 0.0008244514465332031, 0.79345703125, 0.0003886222839355469, 0.003143310546875, 0.2210693359375, 0.0172271728515625, 0.00701141357421875, 0.994140625, 0.94580078125, 0.0014657974243164062, 0.60595703125, 0.98974609375, 0.99853515625, 0.6708984375, 0.99951171875, 0.00031113624572753906]], "normalized_score": [0.09973779320716858], "tokens": [["\u2581July", "\u2581", "2", "3", ",", "\u2581", "2", "0", "1", "5", "\u2581(", "by", "\u2581Rick", "\u2581Por", "cel", "lo", ").", "\u2581#", "I", "r", "ish", "Fil", "m", ":", "\u2581Watch", "\u2581the", "\u2581Irish", "\u2581tra", "iler", "\u2581for", "\u2581L", "ance", "\u2581Dal", "y", "'", "s", "\u2581Kin"]], "entropy": [[2.6328125, 0.011993408203125, 0.06341552734375, 0.01122283935546875, 0.1937255859375, 0.0142974853515625, 0.0173492431640625, 4.369020462036133e-05, 0.404541015625, 0.159423828125, 1.75, 1.427734375, 1.4560546875, 0.0010547637939453125, 0.0009374618530273438, 0.00310516357421875, 0.53515625, 0.185546875, 3.40625, 1.8583984375, 1.26953125, 4.375, 0.90771484375, 2.857421875, 5.3046875, 4.53515625, 4.22265625, 3.533203125, 0.045928955078125, 0.371826171875, 3.533203125, 2.05859375, 0.105712890625, 0.0147552490234375, 0.75048828125, 0.003513336181640625, 2.923828125]], "avg_entropy": [1.3769265977112022], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "May 19, 2008", "score_of_biggest_cluster": 0.09973779320716858, "score_of_first_answer": 0.09973779320716858, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.205371856689453e-06, "avg_score": 0.09973779320716858, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43596983860409605, "std_of_first_answer": 0.43596983860409605, "avg_entropy_of_first_answer": 1.3769265977112022, "lex_sim": 1.0}
{"question": "who died doing the luge in the olympics", "answer": ["Nodar Kumaritashvili #BookReview: The Glass Hotel by Emily St. John Mandel"], "scores": [[0.60595703125, 0.9990234375, 0.99951171875, 0.9990234375, 0.99951171875, 0.99951171875, 1.0, 0.99951171875, 1.0, 2.980232238769531e-07, 1.6093254089355469e-06, 0.01213836669921875, 0.234375, 0.08587646484375, 0.20654296875, 0.004909515380859375, 0.62548828125, 0.423095703125, 0.837890625, 0.96875, 0.9990234375, 0.998046875, 0.9619140625, 0.93505859375, 0.9912109375, 0.99951171875]], "normalized_score": [0.17219209671020508], "tokens": [["\u2581N", "od", "ar", "\u2581K", "umar", "it", "ash", "v", "ili", "\u2581#", "Book", "Re", "view", ":", "\u2581The", "\u2581G", "lass", "\u2581Hotel", "\u2581by", "\u2581Em", "ily", "\u2581St", ".", "\u2581John", "\u2581Mand", "el"]], "entropy": [[2.41796875, 0.00994110107421875, 0.00392913818359375, 0.00878143310546875, 0.004070281982421875, 0.0034427642822265625, 0.00203704833984375, 0.00506591796875, 0.0009965896606445312, 1.0107421875, 3.71875, 3.240234375, 0.6162109375, 2.4296875, 3.556640625, 5.7734375, 1.64453125, 1.2431640625, 0.859375, 0.1871337890625, 0.01216888427734375, 0.01708984375, 0.2054443359375, 0.29443359375, 0.06793212890625, 0.00429534912109375]], "avg_entropy": [1.0514424764193022], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Nodar Kumaritashvili", "score_of_biggest_cluster": 0.17219209671020508, "score_of_first_answer": 0.17219209671020508, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.17219209671020508, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39935246282450054, "std_of_first_answer": 0.39935246282450054, "avg_entropy_of_first_answer": 1.0514424764193022, "lex_sim": 1.0}
{"question": "who played cruella de vil in 101 dalmatians", "answer": ["Glenn Close Preface > H > Hindon"], "scores": [[0.984375, 0.99609375, 0.9990234375, 0.0, 0.0120391845703125, 3.641843795776367e-05, 0.0003364086151123047, 0.00205230712890625, 0.0712890625, 4.464387893676758e-05, 0.0023174285888671875]], "normalized_score": [0.0], "tokens": [["\u2581Gl", "enn", "\u2581Close", "\u2581Pref", "ace", "\u2581>", "\u2581H", "\u2581>", "\u2581H", "ind", "on"]], "entropy": [[0.1053466796875, 0.026519775390625, 0.00699615478515625, 0.78515625, 0.892578125, 1.189453125, 4.11328125, 4.84375, 4.90625, 4.83203125, 4.078125]], "avg_entropy": [2.3435897827148438], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Glenn Close", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43786748300169914, "std_of_first_answer": 0.43786748300169914, "avg_entropy_of_first_answer": 2.3435897827148438, "lex_sim": 1.0}
{"question": "when was the movie the king and i made", "answer": ["1956 #BookReview: The Incomplete Book of Running by Murakami @Haruki_Murakami"], "scores": [[0.97314453125, 0.99951171875, 1.0, 1.0, 0.99951171875, 1.1920928955078125e-07, 7.987022399902344e-06, 0.004436492919921875, 0.29296875, 0.060577392578125, 0.4970703125, 0.001373291015625, 0.0014667510986328125, 0.9365234375, 0.99755859375, 0.98583984375, 0.67041015625, 0.042999267578125, 1.0, 0.99853515625, 0.01290130615234375, 0.01476287841796875, 0.94287109375, 0.994140625, 0.591796875, 0.99755859375, 1.0, 0.9697265625, 0.90234375]], "normalized_score": [0.11044661700725555], "tokens": [["\u2581", "1", "9", "5", "6", "\u2581#", "Book", "Re", "view", ":", "\u2581The", "\u2581In", "complete", "\u2581Book", "\u2581of", "\u2581Running", "\u2581by", "\u2581Mur", "ak", "ami", "\u2581@", "H", "aru", "ki", "_", "M", "ur", "ak", "ami"]], "entropy": [[0.1768798828125, 0.004291534423828125, 0.000331878662109375, 0.0011959075927734375, 0.004364013671875, 0.880859375, 5.3984375, 3.34375, 0.78173828125, 2.390625, 2.1328125, 2.126953125, 1.9326171875, 0.4697265625, 0.0210418701171875, 0.12481689453125, 0.84375, 1.5126953125, 0.0005288124084472656, 0.01403045654296875, 2.1015625, 4.2109375, 0.41259765625, 0.043182373046875, 0.77978515625, 0.025390625, 0.0025463104248046875, 0.1573486328125, 0.487060546875]], "avg_entropy": [1.0476502550059352], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1956", "score_of_biggest_cluster": 0.11044661700725555, "score_of_first_answer": 0.11044661700725555, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.11044661700725555, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4362022572909606, "std_of_first_answer": 0.4362022572909606, "avg_entropy_of_first_answer": 1.0476502550059352, "lex_sim": 1.0}
{"question": "what category was hurricane charley when it hit florida", "answer": ["It was a Category 4 hurricane when it made landfall in Florida."], "scores": [[0.06341552734375, 0.98681640625, 0.81591796875, 0.438720703125, 1.0, 0.98974609375, 0.912109375, 1.0, 1.0, 0.73974609375, 0.99951171875, 0.382080078125, 0.99951171875, 1.0, 0.99267578125, 0.99658203125, 0.73095703125, 8.344650268554688e-07, 0.00839996337890625, 7.736682891845703e-05, 0.01580810546875, 0.00018799304962158203, 0.0006647109985351562, 0.0123138427734375, 0.00048065185546875, 0.1536865234375, 0.1270751953125, 0.9970703125, 0.99853515625, 0.65625, 0.2440185546875, 0.7373046875, 0.9990234375, 0.1893310546875, 0.0011959075927734375, 0.1455078125, 0.73486328125, 0.0003807544708251953, 0.01047515869140625, 0.31982421875, 0.4267578125, 0.0015516281127929688, 0.81591796875, 0.59423828125, 0.1298828125]], "normalized_score": [0.09447051584720612], "tokens": [["\u2581It", "\u2581was", "\u2581a", "\u2581Category", "\u2581", "4", "\u2581h", "urr", "icane", "\u2581when", "\u2581it", "\u2581made", "\u2581land", "fall", "\u2581in", "\u2581Florida", ".", "\u2581#", "S", "y", "ria", "\u2581:", "\u2581T", "ik", "rit", "\u2581was", "\u2581re", "capt", "ured", "\u2581by", "\u2581the", "\u2581Ira", "qi", "\u2581army", "\u2581a", "\u2581week", "\u2581ago", "\u2581&", "\u2581this", "\u2581is", "\u2581the", "\u2581photo", "\u2581of", "\u2581the", "\u2581day"]], "entropy": [[1.865234375, 0.09393310546875, 0.59814453125, 1.310546875, 0.002094268798828125, 0.059539794921875, 0.415771484375, 0.00036597251892089844, 5.7756900787353516e-05, 0.73193359375, 0.003665924072265625, 0.74755859375, 0.005840301513671875, 0.0015163421630859375, 0.05316162109375, 0.0276641845703125, 0.7880859375, 0.268310546875, 2.453125, 0.45458984375, 4.21484375, 2.169921875, 5.62890625, 4.76953125, 0.30908203125, 3.27734375, 1.81640625, 0.027740478515625, 0.0115509033203125, 0.77197265625, 1.1982421875, 0.9423828125, 0.0078125, 1.2822265625, 1.7548828125, 1.861328125, 0.8603515625, 1.712890625, 3.197265625, 3.3125, 2.376953125, 3.3203125, 1.05078125, 2.2734375, 4.46484375]], "avg_entropy": [1.3887700041135151], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "4", "score_of_biggest_cluster": 0.09447051584720612, "score_of_first_answer": 0.09447051584720612, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 8.344650268554688e-07, "avg_score": 0.09447051584720612, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4140133959579592, "std_of_first_answer": 0.4140133959579592, "avg_entropy_of_first_answer": 1.3887700041135151, "lex_sim": 1.0}
{"question": "is aluminium a ferrous or non ferrous metal", "answer": ["non ferrous #WeChat: The Changing Face of Social Media in South Africa"], "scores": [[0.94775390625, 0.1856689453125, 1.0, 1.0, 5.960464477539063e-08, 6.35981559753418e-05, 0.0066986083984375, 0.98779296875, 0.0027866363525390625, 0.00815582275390625, 0.0006289482116699219, 0.003093719482421875, 0.353271484375, 0.98046875, 0.279296875, 0.9462890625, 0.63720703125, 0.003124237060546875, 0.58837890625]], "normalized_score": [0.03094329871237278], "tokens": [["\u2581non", "\u2581f", "err", "ous", "\u2581#", "We", "Ch", "at", ":", "\u2581The", "\u2581Ch", "anging", "\u2581Face", "\u2581of", "\u2581Social", "\u2581Media", "\u2581in", "\u2581South", "\u2581Africa"]], "entropy": [[0.2178955078125, 0.53076171875, 7.033348083496094e-05, 0.00024962425231933594, 0.84619140625, 4.1484375, 3.62109375, 0.0853271484375, 3.96484375, 4.6796875, 4.546875, 0.578125, 1.677734375, 0.11737060546875, 3.005859375, 0.375, 1.5927734375, 0.79248046875, 1.416015625]], "avg_entropy": [1.6945680066158897], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "non-ferrous", "score_of_biggest_cluster": 0.03094329871237278, "score_of_first_answer": 0.03094329871237278, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.03094329871237278, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.42364939487028785, "std_of_first_answer": 0.42364939487028785, "avg_entropy_of_first_answer": 1.6945680066158897, "lex_sim": 1.0}
{"question": "when was the miraculous journey of edward tulane published", "answer": ["2001"], "scores": [[0.90185546875, 0.9580078125, 1.0, 0.99951171875, 0.97314453125]], "normalized_score": [0.9658156633377075], "tokens": [["\u2581", "2", "0", "0", "1"]], "entropy": [[0.60986328125, 0.1756591796875, 0.0015869140625, 0.003871917724609375, 0.167236328125]], "avg_entropy": [0.19164352416992186], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2006", "score_of_biggest_cluster": 0.9658156633377075, "score_of_first_answer": 0.9658156633377075, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.90185546875, "avg_score": 0.9658156633377075, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.03607549296443436, "std_of_first_answer": 0.03607549296443436, "avg_entropy_of_first_answer": 0.19164352416992186, "lex_sim": 1.0}
{"question": "when is the new jurassic world game coming out", "answer": ["I'm sorry, I don't have information on a Jurassic World game scheduled for release."], "scores": [[0.4482421875, 0.62255859375, 1.0, 0.96337890625, 0.98779296875, 0.7255859375, 0.3857421875, 0.99755859375, 1.0, 0.9287109375, 0.72900390625, 0.5576171875, 0.1427001953125, 0.07012939453125, 0.998046875, 1.0, 0.9931640625, 0.99755859375, 0.010101318359375, 0.8896484375, 0.98876953125, 0.8203125, 0.0537109375, 0.149658203125, 0.990234375, 0.4921875, 0.998046875, 1.0, 0.75048828125, 0.96435546875, 0.2099609375, 0.81689453125, 1.0, 1.0, 0.9990234375, 0.99755859375, 0.99951171875, 0.998046875, 0.998046875, 0.9990234375, 0.97216796875, 0.9599609375, 1.0, 1.0, 1.0, 0.99951171875, 0.9833984375, 0.01020050048828125, 0.70458984375, 0.7509765625]], "normalized_score": [0.5938019156455994], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581I", "\u2581don", "'", "t", "\u2581have", "\u2581information", "\u2581on", "\u2581a", "\u2581Jur", "ass", "ic", "\u2581World", "\u2581game", "\u2581scheduled", "\u2581for", "\u2581release", ".", "\u2581The", "\u2581most", "\u2581recent", "\u2581Jur", "ass", "ic", "\u2581World", "\u2581game", ",", "\u2581Jur", "ass", "ic", "\u2581World", "\u2581E", "volution", ",", "\u2581was", "\u2581released", "\u2581in", "\u2581", "2", "0", "1", "8", ".", "\u2581Check", "\u2581with", "\u2581the"]], "entropy": [[1.966796875, 1.142578125, 0.0018787384033203125, 0.1781005859375, 0.07568359375, 0.8876953125, 0.95458984375, 0.0185394287109375, 0.0008974075317382812, 0.26318359375, 0.9931640625, 0.76171875, 1.515625, 1.033203125, 0.0131988525390625, 0.0005793571472167969, 0.048797607421875, 0.0205078125, 1.3876953125, 0.3515625, 0.06622314453125, 0.712890625, 2.0390625, 1.00390625, 0.06231689453125, 0.896484375, 0.01446533203125, 0.0004258155822753906, 0.57666015625, 0.1942138671875, 1.365234375, 0.5966796875, 0.0006079673767089844, 0.0003681182861328125, 0.0098724365234375, 0.0201873779296875, 0.0030670166015625, 0.016021728515625, 0.0160675048828125, 0.00811004638671875, 0.134033203125, 0.1712646484375, 4.571676254272461e-05, 0.0009794235229492188, 0.0008134841918945312, 0.0028285980224609375, 0.107421875, 1.283203125, 1.083984375, 0.7099609375]], "avg_entropy": [0.45426792979240416], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "June 12, 2018", "score_of_biggest_cluster": 0.5938019156455994, "score_of_first_answer": 0.5938019156455994, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.010101318359375, "avg_score": 0.5938019156455994, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.320392490965316, "std_of_first_answer": 0.320392490965316, "avg_entropy_of_first_answer": 0.45426792979240416, "lex_sim": 1.0}
{"question": "the fertile crescent is located between what two bodies of water", "answer": ["Between the Mediterranean Sea and the Persian Gulf."], "scores": [[0.007488250732421875, 0.99755859375, 0.77783203125, 1.0, 1.0, 0.95458984375, 0.97705078125, 0.9951171875, 0.98388671875, 1.0, 0.99951171875, 0.99951171875, 0.470458984375, 2.384185791015625e-07, 0.024017333984375, 1.1146068572998047e-05, 0.004077911376953125, 4.982948303222656e-05, 0.91845703125, 0.057220458984375, 0.00033926963806152344, 7.468461990356445e-05, 0.99755859375, 0.451904296875, 0.103759765625, 0.74755859375, 0.99072265625, 0.8818359375, 0.9990234375, 0.97705078125, 0.93359375, 0.953125, 0.0823974609375, 0.9990234375, 0.1474609375, 0.1002197265625, 0.5400390625]], "normalized_score": [0.10559956729412079], "tokens": [["\u2581Between", "\u2581the", "\u2581Mediter", "rane", "an", "\u2581Sea", "\u2581and", "\u2581the", "\u2581Pers", "ian", "\u2581G", "ulf", ".", "\u2581#", "1", "\u2581by", "\u2581B", "lim", "unda", ",", "\u2581Mon", "\u2581Jun", "\u2581", "1", "1", ",", "\u2581", "2", "0", "1", "8", "\u2581", "9", ":", "5", "3", "\u2581am"]], "entropy": [[1.2646484375, 0.0212249755859375, 0.9482421875, 0.0011568069458007812, 7.581710815429688e-05, 0.2164306640625, 0.1329345703125, 0.0340576171875, 0.099609375, 0.0001156926155090332, 0.00385284423828125, 0.0031070709228515625, 1.154296875, 0.175537109375, 4.03125, 3.333984375, 5.84765625, 4.46484375, 0.42431640625, 4.41796875, 4.64453125, 2.40625, 0.022979736328125, 1.5673828125, 2.228515625, 0.6865234375, 0.10302734375, 0.52294921875, 0.011138916015625, 0.11956787109375, 0.2734375, 0.29052734375, 1.904296875, 0.010284423828125, 1.787109375, 2.3046875, 1.0859375]], "avg_entropy": [1.2579582784626935], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Tigris and Euphrates rivers", "score_of_biggest_cluster": 0.10559956729412079, "score_of_first_answer": 0.10559956729412079, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.10559956729412079, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43224138579456717, "std_of_first_answer": 0.43224138579456717, "avg_entropy_of_first_answer": 1.2579582784626935, "lex_sim": 1.0}
{"question": "what is the membrane on the surface of the stomach called", "answer": ["gastric mucosa THE MATADOR OF OCCIDENTE"], "scores": [[0.5224609375, 0.83984375, 1.0, 0.90380859375, 1.0, 0.9990234375, 0.0, 0.0153961181640625, 0.01270294189453125, 1.6748905181884766e-05, 0.93017578125, 0.01027679443359375, 0.005245208740234375, 0.00112152099609375, 0.1429443359375, 0.99951171875, 0.0196685791015625]], "normalized_score": [0.0], "tokens": [["\u2581g", "astr", "ic", "\u2581m", "uc", "osa", "\u2581THE", "\u2581M", "AT", "AD", "OR", "\u2581OF", "\u2581O", "CC", "ID", "ENT", "E"]], "entropy": [[1.546875, 0.487060546875, 0.0002841949462890625, 0.465576171875, 0.0020580291748046875, 0.00688934326171875, 0.71533203125, 2.470703125, 2.583984375, 0.81689453125, 0.329345703125, 2.697265625, 3.048828125, 1.1962890625, 2.216796875, 0.004791259765625, 2.232421875]], "avg_entropy": [1.224787992589614], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the visceral membrane", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.45086421393444837, "std_of_first_answer": 0.45086421393444837, "avg_entropy_of_first_answer": 1.224787992589614, "lex_sim": 1.0}
{"question": "when does the shape of water book come out", "answer": ["September 4, 2018 #Iran: Is a Second Revolution on the Horizon?"], "scores": [[0.0163726806640625, 0.984375, 0.84619140625, 0.58642578125, 0.99853515625, 0.99853515625, 1.0, 0.99755859375, 0.90283203125, 2.384185791015625e-07, 0.0019102096557617188, 2.9981136322021484e-05, 0.0076141357421875, 0.00038313865661621094, 0.0021305084228515625, 6.306171417236328e-05, 0.394775390625, 0.09429931640625, 0.935546875, 0.9619140625, 0.99951171875, 0.9599609375]], "normalized_score": [0.04370564967393875], "tokens": [["\u2581September", "\u2581", "4", ",", "\u2581", "2", "0", "1", "8", "\u2581#", "I", "ran", ":", "\u2581Is", "\u2581a", "\u2581Second", "\u2581Revolution", "\u2581on", "\u2581the", "\u2581Hor", "izon", "?"]], "entropy": [[2.498046875, 0.10064697265625, 0.6611328125, 0.7685546875, 0.0131378173828125, 0.0104522705078125, 0.0005888938903808594, 0.02166748046875, 0.365966796875, 0.92236328125, 5.07421875, 1.1689453125, 3.65625, 5.609375, 0.7744140625, 6.25, 3.318359375, 2.76171875, 0.32568359375, 0.208251953125, 0.003063201904296875, 0.288330078125]], "avg_entropy": [1.5818712711334229], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "March 6, 2018", "score_of_biggest_cluster": 0.04370564967393875, "score_of_first_answer": 0.04370564967393875, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.04370564967393875, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.45271459911464945, "std_of_first_answer": 0.45271459911464945, "avg_entropy_of_first_answer": 1.5818712711334229, "lex_sim": 1.0}
{"question": "who plays the voice of chucky in seed of chucky", "answer": ["Brad Dourif"], "scores": [[0.80615234375, 0.998046875, 1.0, 0.99951171875]], "normalized_score": [0.9469760060310364], "tokens": [["\u2581Brad", "\u2581D", "our", "if"]], "entropy": [[0.74462890625, 0.016265869140625, 0.00045490264892578125, 0.0030231475830078125]], "avg_entropy": [0.19109320640563965], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Brad Dourif", "score_of_biggest_cluster": 0.9469760060310364, "score_of_first_answer": 0.9469760060310364, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.80615234375, "avg_score": 0.9469760060310364, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.08358920076059566, "std_of_first_answer": 0.08358920076059566, "avg_entropy_of_first_answer": 0.19109320640563965, "lex_sim": 1.0}
{"question": "who wrote the guitar solo in beat it", "answer": ["Steve Lukather"], "scores": [[0.1414794921875, 0.95703125, 1.0, 1.0]], "normalized_score": [0.6066035032272339], "tokens": [["\u2581Steve", "\u2581L", "uk", "ather"]], "entropy": [[0.6865234375, 0.1995849609375, 0.0003714561462402344, 0.0007829666137695312]], "avg_entropy": [0.22181570529937744], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Eddie Van Halen", "score_of_biggest_cluster": 0.6066035032272339, "score_of_first_answer": 0.6066035032272339, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.1414794921875, "avg_score": 0.6066035032272339, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.36596893834154914, "std_of_first_answer": 0.36596893834154914, "avg_entropy_of_first_answer": 0.22181570529937744, "lex_sim": 1.0}
{"question": "which condition would most likely require nutrition delivered through tpn", "answer": ["Severe malnutrition"], "scores": [[0.223876953125, 0.99267578125, 0.912109375, 0.9873046875, 0.99951171875, 1.0]], "normalized_score": [0.7647458910942078], "tokens": [["\u2581Se", "vere", "\u2581mal", "nut", "r", "ition"]], "entropy": [[2.900390625, 0.048004150390625, 0.4990234375, 0.07501220703125, 0.00334930419921875, 0.00011336803436279297]], "avg_entropy": [0.587648848692576], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "bowel obstruction", "score_of_biggest_cluster": 0.7647458910942078, "score_of_first_answer": 0.7647458910942078, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.223876953125, "avg_score": 0.7647458910942078, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2828163194720446, "std_of_first_answer": 0.2828163194720446, "avg_entropy_of_first_answer": 0.587648848692576, "lex_sim": 1.0}
{"question": "when was harry potter and the philosophers stone published", "answer": ["1997 #494 in Best Public Middle Schools in California"], "scores": [[0.974609375, 0.99365234375, 1.0, 1.0, 0.99951171875, 2.384185791015625e-07, 0.0025539398193359375, 0.049407958984375, 0.056488037109375, 0.002166748046875, 0.07196044921875, 8.58306884765625e-06, 0.0003006458282470703, 0.99658203125, 0.97998046875, 0.998046875, 0.0406494140625]], "normalized_score": [0.03127643093466759], "tokens": [["\u2581", "1", "9", "9", "7", "\u2581#", "4", "9", "4", "\u2581in", "\u2581Best", "\u2581Public", "\u2581Middle", "\u2581School", "s", "\u2581in", "\u2581California"]], "entropy": [[0.1795654296875, 0.04296875, 0.00255584716796875, 0.0027618408203125, 0.0028285980224609375, 0.78955078125, 5.56640625, 3.314453125, 3.525390625, 2.93359375, 2.265625, 0.63037109375, 2.9453125, 0.03399658203125, 0.1318359375, 0.0192108154296875, 0.67529296875]], "avg_entropy": [1.3565717584946577], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "in 1997", "score_of_biggest_cluster": 0.03127643093466759, "score_of_first_answer": 0.03127643093466759, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.03127643093466759, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4836051511582161, "std_of_first_answer": 0.4836051511582161, "avg_entropy_of_first_answer": 1.3565717584946577, "lex_sim": 1.0}
{"question": "how many pennsylvania house of representatives are there", "answer": ["203"], "scores": [[0.97265625, 1.0, 0.99951171875, 0.99951171875]], "normalized_score": [0.9928503632545471], "tokens": [["\u2581", "2", "0", "3"]], "entropy": [[0.1673583984375, 0.001461029052734375, 0.0031280517578125, 0.003856658935546875]], "avg_entropy": [0.04395103454589844], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "203", "score_of_biggest_cluster": 0.9928503632545471, "score_of_first_answer": 0.9928503632545471, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.97265625, "avg_score": 0.9928503632545471, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.011700934537423593, "std_of_first_answer": 0.011700934537423593, "avg_entropy_of_first_answer": 0.04395103454589844, "lex_sim": 1.0}
{"question": "how long do nhl players stay on waivers", "answer": ["24 hours"], "scores": [[0.87548828125, 0.352783203125, 0.955078125, 0.9853515625]], "normalized_score": [0.734255313873291], "tokens": [["\u2581", "2", "4", "\u2581hours"]], "entropy": [[0.7978515625, 1.076171875, 0.254638671875, 0.0966796875]], "avg_entropy": [0.55633544921875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "24 hours", "score_of_biggest_cluster": 0.734255313873291, "score_of_first_answer": 0.734255313873291, "max_score_of_first_answer": 0.9853515625, "min_score_of_first_answer": 0.352783203125, "avg_score": 0.734255313873291, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.2568369455644094, "std_of_first_answer": 0.2568369455644094, "avg_entropy_of_first_answer": 0.55633544921875, "lex_sim": 1.0}
{"question": "who is the voice of the other mother in coraline", "answer": ["Dakota Fanning (alternate: Teri Hatcher)"], "scores": [[0.19580078125, 1.0, 0.9990234375, 1.0, 0.0274505615234375, 0.0047454833984375, 0.55078125, 0.174072265625, 0.9130859375, 0.99755859375, 1.0, 1.0, 0.9990234375, 0.990234375]], "normalized_score": [0.3943725824356079], "tokens": [["\u2581Dak", "ota", "\u2581F", "anning", "\u2581(", "altern", "ate", ":", "\u2581Ter", "i", "\u2581H", "atch", "er", ")"]], "entropy": [[1.14453125, 0.0004367828369140625, 0.00905609130859375, 0.0007033348083496094, 1.033203125, 2.734375, 1.1025390625, 2.330078125, 0.358642578125, 0.017059326171875, 0.0015964508056640625, 0.00016689300537109375, 0.006969451904296875, 0.07562255859375]], "avg_entropy": [0.6296414307185582], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Teri Hatcher", "score_of_biggest_cluster": 0.3943725824356079, "score_of_first_answer": 0.3943725824356079, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0047454833984375, "avg_score": 0.3943725824356079, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40050021707486905, "std_of_first_answer": 0.40050021707486905, "avg_entropy_of_first_answer": 0.6296414307185582, "lex_sim": 1.0}
{"question": "where do some of the natural air pollutants come from", "answer": ["Some natural air pollutants come from volcanic eruptions and wildfires."], "scores": [[0.019866943359375, 0.92333984375, 0.93798828125, 0.9970703125, 0.99951171875, 1.0, 0.857421875, 0.99951171875, 0.92138671875, 0.900390625, 1.0, 0.9208984375, 1.0, 1.0, 0.6416015625, 0.98046875, 0.99609375, 1.0, 0.97802734375, 8.940696716308594e-07, 0.0005006790161132812, 0.00037026405334472656]], "normalized_score": [0.20930306613445282], "tokens": [["\u2581Some", "\u2581natural", "\u2581air", "\u2581poll", "ut", "ants", "\u2581come", "\u2581from", "\u2581vol", "can", "ic", "\u2581er", "u", "ptions", "\u2581and", "\u2581wild", "f", "ires", ".", "\u2581###", "\u2581P", "ipeline"]], "entropy": [[1.8369140625, 0.3125, 0.240478515625, 0.021484375, 0.002628326416015625, 0.0012798309326171875, 0.6103515625, 0.00641632080078125, 0.441162109375, 0.325439453125, 0.0002460479736328125, 0.341796875, 2.3305416107177734e-05, 0.0019626617431640625, 0.7890625, 0.1427001953125, 0.025115966796875, 0.00018799304962158203, 0.1259765625, 0.708984375, 6.0859375, 3.384765625]], "avg_entropy": [0.7002460983666506], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "wildfires", "score_of_biggest_cluster": 0.20930306613445282, "score_of_first_answer": 0.20930306613445282, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 8.940696716308594e-07, "avg_score": 0.20930306613445282, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3715991631059543, "std_of_first_answer": 0.3715991631059543, "avg_entropy_of_first_answer": 0.7002460983666506, "lex_sim": 1.0}
{"question": "who drove the number 18 car in nascar", "answer": ["Ryan Newman, Denny Hamlin, and Matt Kenseth (former drivers) #Bonas professor publishes article on 'Brigadoon'"], "scores": [[0.297607421875, 0.93701171875, 1.0, 0.016845703125, 0.0026264190673828125, 1.0, 1.0, 1.0, 0.84619140625, 0.472900390625, 0.01294708251953125, 0.95751953125, 0.99951171875, 1.0, 0.01116180419921875, 0.0005216598510742188, 0.307373046875, 0.861328125, 4.76837158203125e-06, 0.00011771917343139648, 1.0848045349121094e-05, 6.556510925292969e-07, 0.00030922889709472656, 0.9990234375, 0.2291259765625, 0.74462890625, 0.0177001953125, 0.01033782958984375, 0.0008130073547363281, 0.6494140625, 0.99853515625, 0.73876953125]], "normalized_score": [0.03966931253671646], "tokens": [["\u2581Ryan", "\u2581New", "man", ",", "\u2581Den", "ny", "\u2581Ham", "lin", ",", "\u2581and", "\u2581Matt", "\u2581K", "ens", "eth", "\u2581(", "former", "\u2581drivers", ")", "\u2581#", "B", "onas", "\u2581professor", "\u2581publish", "es", "\u2581article", "\u2581on", "\u2581'", "B", "rig", "ado", "on", "'"]], "entropy": [[2.57421875, 0.275390625, 0.0006108283996582031, 1.162109375, 2.96484375, 0.0004024505615234375, 0.0007557868957519531, 0.00012105703353881836, 0.59228515625, 2.07421875, 2.3359375, 0.1912841796875, 0.0068206787109375, 1.0073184967041016e-05, 1.814453125, 2.46875, 1.0869140625, 0.60791015625, 0.93408203125, 0.5244140625, 3.884765625, 4.265625, 5.2890625, 0.01104736328125, 2.5390625, 1.0205078125, 6.609375, 6.13671875, 3.890625, 1.232421875, 0.014984130859375, 1.130859375]], "avg_entropy": [1.7387683540582657], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Kyle Busch", "score_of_biggest_cluster": 0.03966931253671646, "score_of_first_answer": 0.03966931253671646, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 6.556510925292969e-07, "avg_score": 0.03966931253671646, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43632417679267027, "std_of_first_answer": 0.43632417679267027, "avg_entropy_of_first_answer": 1.7387683540582657, "lex_sim": 1.0}
{"question": "where does water come from in new york city", "answer": ["The water supply for New York City comes from the Catskill Mountains and from the Croton River in upstate New York."], "scores": [[0.19921875, 0.5732421875, 0.6591796875, 0.8779296875, 0.990234375, 1.0, 0.99951171875, 0.95849609375, 0.9501953125, 0.7939453125, 0.96826171875, 1.0, 0.9990234375, 0.99609375, 0.75390625, 0.04656982421875, 0.362060546875, 0.06927490234375, 1.0, 0.841796875, 0.2440185546875, 0.11529541015625, 0.99951171875, 0.99072265625, 1.0, 0.87646484375, 0.40185546875, 0.98681640625, 0.884765625, 0.55078125, 0.07861328125, 1.0, 0.6171875, 0.3134765625, 0.98828125, 0.93017578125, 0.86474609375, 1.0, 1.0, 0.99755859375, 0.76611328125, 0.87744140625, 0.240966796875, 1.0, 0.9931640625, 0.99609375, 1.0, 1.0, 0.399658203125, 0.99609375]], "normalized_score": [0.6335399746894836], "tokens": [["\u2581The", "\u2581water", "\u2581supply", "\u2581for", "\u2581New", "\u2581York", "\u2581City", "\u2581comes", "\u2581from", "\u2581the", "\u2581Cat", "sk", "ill", "\u2581Mountains", "\u2581and", "\u2581from", "\u2581the", "\u2581Cro", "ton", "\u2581River", "\u2581in", "\u2581up", "state", "\u2581New", "\u2581York", ".", "\u2581It", "\u2581is", "\u2581treated", "\u2581at", "\u2581one", "\u2581of", "\u2581the", "\u2581largest", "\u2581water", "\u2581treatment", "\u2581plants", "\u2581in", "\u2581the", "\u2581world", ",", "\u2581the", "\u2581Jer", "ome", "\u2581Park", "\u2581Res", "er", "voir", "\u2581in", "\u2581the"]], "entropy": [[2.47265625, 1.5771484375, 1.2021484375, 0.51708984375, 0.061553955078125, 0.00040435791015625, 0.0039520263671875, 0.2059326171875, 0.22119140625, 0.84326171875, 0.2100830078125, 1.2040138244628906e-05, 0.009246826171875, 0.03228759765625, 0.79296875, 0.88720703125, 1.5576171875, 1.1396484375, 5.269050598144531e-05, 0.71728515625, 1.921875, 0.56396484375, 0.00383758544921875, 0.05706787109375, 0.0011758804321289062, 0.48193359375, 1.3466796875, 0.09637451171875, 0.578125, 0.72900390625, 1.0537109375, 0.0004930496215820312, 1.361328125, 1.671875, 0.08917236328125, 0.3173828125, 0.412841796875, 0.0014753341674804688, 0.0007658004760742188, 0.02020263671875, 0.84228515625, 0.541015625, 3.12109375, 0.00263214111328125, 0.05224609375, 0.030487060546875, 0.0007224082946777344, 0.0009908676147460938, 1.1748046875, 0.0285186767578125]], "avg_entropy": [0.5791165995597839], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The Catskill Aqueduct", "score_of_biggest_cluster": 0.6335399746894836, "score_of_first_answer": 0.6335399746894836, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.04656982421875, "avg_score": 0.6335399746894836, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3130512856352911, "std_of_first_answer": 0.3130512856352911, "avg_entropy_of_first_answer": 0.5791165995597839, "lex_sim": 1.0}
{"question": "name the four major layers of the earth in order", "answer": ["From the center outwards: inner core, outer core, mantle, outer solid layer (the crust)."], "scores": [[0.05010986328125, 0.418701171875, 0.95361328125, 0.677734375, 0.444580078125, 0.9287109375, 0.45654296875, 0.9990234375, 1.0, 0.9970703125, 1.0, 1.0, 0.99755859375, 1.0, 0.998046875, 0.0009284019470214844, 0.115478515625, 0.77587890625, 0.94482421875, 0.09307861328125, 0.9951171875, 1.0, 0.857421875, 2.384185791015625e-07, 0.0008378028869628906, 0.0184326171875, 0.0308837890625, 0.0877685546875, 0.00018286705017089844, 0.00011014938354492188, 0.027618408203125, 0.0, 0.006610870361328125]], "normalized_score": [0.0], "tokens": [["\u2581From", "\u2581the", "\u2581center", "\u2581out", "wards", ":", "\u2581inner", "\u2581core", ",", "\u2581outer", "\u2581core", ",", "\u2581mant", "le", ",", "\u2581outer", "\u2581solid", "\u2581layer", "\u2581(", "the", "\u2581cr", "ust", ").", "\u2581#", "4", "1", "9", "5", ":", "\u2581THE", "\u2581T", "oby", "\u2581Show"]], "entropy": [[2.349609375, 1.9423828125, 0.2666015625, 0.8994140625, 0.87255859375, 0.311767578125, 1.5283203125, 0.01041412353515625, 0.001354217529296875, 0.020843505859375, 0.0022296905517578125, 0.00012177228927612305, 0.023162841796875, 4.7087669372558594e-05, 0.0144195556640625, 0.2442626953125, 1.9853515625, 1.0146484375, 0.305419921875, 0.7880859375, 0.03558349609375, 0.0003571510314941406, 0.42626953125, 0.154296875, 2.5625, 3.185546875, 2.853515625, 2.552734375, 2.43359375, 5.33203125, 3.2109375, 1.3291015625, 5.7578125]], "avg_entropy": [1.2853120041616035], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "a liquid outer core", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4410481670563236, "std_of_first_answer": 0.4410481670563236, "avg_entropy_of_first_answer": 1.2853120041616035, "lex_sim": 1.0}
{"question": "who helped them recapture mycenae once they were old enough to fight", "answer": ["Pelopidas and Diocles #90 - The Rules of Conversation"], "scores": [[0.006072998046875, 0.40380859375, 0.494873046875, 0.8369140625, 7.134675979614258e-05, 0.998046875, 1.7881393432617188e-07, 0.01029205322265625, 0.06591796875, 0.000217437744140625, 0.170654296875, 0.0179443359375, 1.3709068298339844e-06, 0.9912109375, 0.0003726482391357422, 0.03704833984375, 0.98974609375]], "normalized_score": [0.010047974064946175], "tokens": [["\u2581Pel", "op", "idas", "\u2581and", "\u2581Dioc", "les", "\u2581#", "9", "0", "\u2581-", "\u2581The", "\u2581R", "ules", "\u2581of", "\u2581Con", "vers", "ation"]], "entropy": [[2.54296875, 0.7841796875, 1.7822265625, 0.65087890625, 0.2327880859375, 0.0174713134765625, 0.96240234375, 5.50390625, 3.078125, 2.677734375, 4.60546875, 4.30078125, 0.053558349609375, 0.06658935546875, 1.607421875, 0.297607421875, 0.07635498046875]], "avg_entropy": [1.720027250402114], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Aegisthus", "score_of_biggest_cluster": 0.010047974064946175, "score_of_first_answer": 0.010047974064946175, "max_score_of_first_answer": 0.998046875, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.010047974064946175, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39240007724330866, "std_of_first_answer": 0.39240007724330866, "avg_entropy_of_first_answer": 1.720027250402114, "lex_sim": 1.0}
{"question": "what type of car is a jeep considered", "answer": ["SUV To dream of a person holding a snake in their hand, denotes that you will control dangerous rivalry and succeed in business."], "scores": [[0.7392578125, 1.0, 0.0, 2.6702880859375e-05, 0.79052734375, 0.8134765625, 0.00011438131332397461, 0.003452301025390625, 0.74267578125, 0.0174407958984375, 0.96875, 0.1964111328125, 0.78076171875, 0.46435546875, 0.478271484375, 0.2005615234375, 0.420166015625, 0.95703125, 0.75390625, 0.0001283884048461914, 0.01148223876953125, 0.0019512176513671875, 0.222412109375, 0.91064453125, 0.061492919921875, 0.994140625, 0.191650390625, 0.578125]], "normalized_score": [0.0], "tokens": [["\u2581SU", "V", "\u2581To", "\u2581dream", "\u2581of", "\u2581a", "\u2581person", "\u2581holding", "\u2581a", "\u2581s", "nake", "\u2581in", "\u2581their", "\u2581hand", ",", "\u2581denotes", "\u2581that", "\u2581you", "\u2581will", "\u2581control", "\u2581dangerous", "\u2581rival", "ry", "\u2581and", "\u2581succeed", "\u2581in", "\u2581business", "."]], "entropy": [[1.1015625, 0.00011920928955078125, 1.2197265625, 4.40625, 1.166015625, 0.89892578125, 1.3544921875, 3.880859375, 1.359375, 3.708984375, 0.1856689453125, 1.7041015625, 0.87890625, 1.259765625, 2.103515625, 2.931640625, 2.953125, 0.339599609375, 0.74658203125, 0.59716796875, 2.978515625, 2.146484375, 0.54638671875, 0.4599609375, 5.09375, 0.047943115234375, 2.271484375, 1.185546875]], "avg_entropy": [1.697373424257551], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "off-road vehicles", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37590515930559837, "std_of_first_answer": 0.37590515930559837, "avg_entropy_of_first_answer": 1.697373424257551, "lex_sim": 1.0}
{"question": "who is darrell brother in the walking dead", "answer": ["Darryl Dixon #538: A Hundred Feet Below Daylight by The Microphones"], "scores": [[0.01207733154296875, 0.435791015625, 0.99951171875, 0.96337890625, 1.0, 1.0728836059570312e-06, 0.004199981689453125, 0.032745361328125, 0.0223388671875, 0.0030612945556640625, 0.031463623046875, 0.00019681453704833984, 0.00036716461181640625, 0.0273284912109375, 0.99755859375, 0.0010442733764648438, 0.0029296875, 0.990234375, 0.00818634033203125, 0.011932373046875, 0.0016031265258789062, 0.9462890625, 0.99951171875]], "normalized_score": [0.020464446395635605], "tokens": [["\u2581Dar", "ry", "l", "\u2581D", "ixon", "\u2581#", "5", "3", "8", ":", "\u2581A", "\u2581H", "undred", "\u2581Fe", "et", "\u2581Below", "\u2581Day", "light", "\u2581by", "\u2581The", "\u2581Micro", "ph", "ones"]], "entropy": [[0.982421875, 0.71435546875, 0.003265380859375, 0.219482421875, 0.0007801055908203125, 1.11328125, 1.0205078125, 3.029296875, 2.81640625, 2.85546875, 5.234375, 4.4609375, 1.80859375, 2.853515625, 0.0199737548828125, 0.95166015625, 1.7119140625, 0.076171875, 3.080078125, 4.2890625, 4.7578125, 0.348876953125, 0.0031452178955078125]], "avg_entropy": [1.8413644873577615], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Merle Dixon", "score_of_biggest_cluster": 0.020464446395635605, "score_of_first_answer": 0.020464446395635605, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.0728836059570312e-06, "avg_score": 0.020464446395635605, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44480761033922656, "std_of_first_answer": 0.44480761033922656, "avg_entropy_of_first_answer": 1.8413644873577615, "lex_sim": 1.0}
{"question": "who played guitar on my guitar gently weeps", "answer": ["Jesse Carmichael #007: How the EEOC Works and Who it Protects with Attorney Lisa Banks"], "scores": [[0.004047393798828125, 0.250244140625, 0.1400146484375, 0.99951171875, 0.998046875, 1.0, 1.430511474609375e-06, 0.00521087646484375, 0.442626953125, 0.0120849609375, 0.0009732246398925781, 0.0002155303955078125, 0.007694244384765625, 0.0015211105346679688, 0.0036945343017578125, 0.0025310516357421875, 0.0474853515625, 0.140625, 0.0234375, 0.01071929931640625, 0.671875, 1.0, 0.9990234375, 0.00341796875, 0.00048065185546875, 0.912109375, 0.01258087158203125, 0.382080078125, 0.9306640625]], "normalized_score": [0.028050139546394348], "tokens": [["\u2581J", "esse", "\u2581Car", "m", "ich", "ael", "\u2581#", "0", "0", "7", ":", "\u2581How", "\u2581the", "\u2581E", "E", "OC", "\u2581Works", "\u2581and", "\u2581Who", "\u2581it", "\u2581Prote", "ct", "s", "\u2581with", "\u2581Att", "orney", "\u2581Lisa", "\u2581B", "anks"]], "entropy": [[1.046875, 2.390625, 3.38671875, 0.002872467041015625, 0.0149993896484375, 0.0003185272216796875, 1.2578125, 5.953125, 2.8515625, 1.3369140625, 3.080078125, 5.10546875, 3.48828125, 4.30078125, 1.4296875, 5.15234375, 4.01953125, 2.966796875, 2.09765625, 2.1171875, 1.2646484375, 0.0003781318664550781, 0.0094146728515625, 2.94921875, 6.00390625, 0.385009765625, 4.65625, 3.46875, 0.3837890625]], "avg_entropy": [2.452448302301867], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Eric Clapton", "score_of_biggest_cluster": 0.028050139546394348, "score_of_first_answer": 0.028050139546394348, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.430511474609375e-06, "avg_score": 0.028050139546394348, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40662685447521923, "std_of_first_answer": 0.40662685447521923, "avg_entropy_of_first_answer": 2.452448302301867, "lex_sim": 1.0}
{"question": "who came up with popcorn at the movies", "answer": ["It is uncertain who first served popcorn at the movies, but it was a common snack at carnivals and fairs in the early 20th century."], "scores": [[0.283203125, 0.89892578125, 0.208251953125, 0.97412109375, 0.405029296875, 0.77880859375, 0.99853515625, 1.0, 1.0, 0.99853515625, 0.92431640625, 0.998046875, 1.0, 0.69287109375, 0.90966796875, 0.8544921875, 0.12371826171875, 0.388427734375, 0.339599609375, 0.51904296875, 1.0, 0.63916015625, 0.2354736328125, 1.0, 0.99853515625, 1.0, 0.98486328125, 0.9873046875, 1.0, 0.58251953125, 0.99951171875, 0.5009765625, 0.99951171875, 0.7880859375, 1.0, 1.0, 1.0, 0.62744140625, 0.09259033203125, 0.2705078125, 0.458984375, 0.79345703125, 0.9326171875, 0.8583984375, 1.0, 0.99755859375, 0.1497802734375, 0.9990234375, 0.953125, 1.0]], "normalized_score": [0.6660385131835938], "tokens": [["\u2581It", "\u2581is", "\u2581uncertain", "\u2581who", "\u2581first", "\u2581served", "\u2581pop", "c", "orn", "\u2581at", "\u2581the", "\u2581mov", "ies", ",", "\u2581but", "\u2581it", "\u2581was", "\u2581a", "\u2581common", "\u2581sn", "ack", "\u2581at", "\u2581car", "n", "iv", "als", "\u2581and", "\u2581fair", "s", "\u2581in", "\u2581the", "\u2581early", "\u2581", "2", "0", "th", "\u2581century", ".", "\u2581It", "\u2581was", "\u2581likely", "\u2581introduced", "\u2581to", "\u2581movie", "\u2581the", "aters", "\u2581in", "\u2581the", "\u2581", "1"]], "entropy": [[3.7578125, 0.384033203125, 1.42578125, 0.1673583984375, 1.6728515625, 0.83251953125, 0.011871337890625, 0.0003066062927246094, 0.0003399848937988281, 0.0109710693359375, 0.3212890625, 0.0172271728515625, 6.121397018432617e-05, 0.69580078125, 0.390625, 0.5068359375, 1.140625, 1.298828125, 0.69091796875, 0.90966796875, 1.6748905181884766e-05, 1.1083984375, 2.26953125, 6.651878356933594e-05, 0.00984954833984375, 3.319978713989258e-05, 0.088623046875, 0.0941162109375, 0.0016880035400390625, 1.1064453125, 0.0034694671630859375, 0.849609375, 0.00466156005859375, 0.5166015625, 0.00014162063598632812, 0.0006117820739746094, 0.0013885498046875, 1.0888671875, 1.2431640625, 1.94140625, 1.8017578125, 0.95703125, 0.2919921875, 0.578125, 0.0006427764892578125, 0.0184478759765625, 1.314453125, 0.011077880859375, 0.2301025390625, 0.00014328956604003906]], "avg_entropy": [0.5953637421131134], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Glen W. Dickson", "score_of_biggest_cluster": 0.6660385131835938, "score_of_first_answer": 0.6660385131835938, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.09259033203125, "avg_score": 0.6660385131835938, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2981639573996494, "std_of_first_answer": 0.2981639573996494, "avg_entropy_of_first_answer": 0.5953637421131134, "lex_sim": 1.0}
{"question": "who was originally cast to play indiana jones", "answer": ["Harrison Ford was originally cast to play Indiana Jones."], "scores": [[0.88232421875, 0.99951171875, 0.232666015625, 0.9599609375, 0.994140625, 0.87548828125, 1.0, 0.95751953125, 1.0, 0.875, 4.76837158203125e-07, 0.64599609375, 0.98779296875, 0.00661468505859375, 1.5974044799804688e-05, 0.0003306865692138672, 0.0307464599609375, 0.97802734375, 0.7021484375, 0.0010213851928710938, 1.0, 0.99365234375, 1.0, 0.998046875, 0.379150390625, 0.0650634765625, 0.002475738525390625, 0.0158843994140625, 0.359375, 0.32421875, 0.779296875]], "normalized_score": [0.1114453673362732], "tokens": [["\u2581Harrison", "\u2581Ford", "\u2581was", "\u2581originally", "\u2581cast", "\u2581to", "\u2581play", "\u2581Indiana", "\u2581Jones", ".", "\u2581\\", "*\\", "*", "NOT", "ABLE", "\u2581L", "IV", "ING", "\u2581P", "UB", "LIC", "\u2581F", "IG", "URE", "S", ",", "\u2581CON", "T", "IN", "U", "ED"]], "entropy": [[0.81640625, 0.0029315948486328125, 1.255859375, 0.2337646484375, 0.043975830078125, 0.47802734375, 0.0016117095947265625, 0.1826171875, 0.0018329620361328125, 0.5458984375, 0.6650390625, 1.3466796875, 0.07489013671875, 4.05078125, 0.09759521484375, 1.7587890625, 2.314453125, 0.1280517578125, 1.5302734375, 0.228515625, 0.001682281494140625, 0.047943115234375, 7.18235969543457e-05, 0.0177154541015625, 2.568359375, 3.806640625, 3.41796875, 0.393310546875, 1.0107421875, 0.763671875, 0.755859375]], "avg_entropy": [0.9207083582878113], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Tom Selleck", "score_of_biggest_cluster": 0.1114453673362732, "score_of_first_answer": 0.1114453673362732, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.76837158203125e-07, "avg_score": 0.1114453673362732, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4212746373142393, "std_of_first_answer": 0.4212746373142393, "avg_entropy_of_first_answer": 0.9207083582878113, "lex_sim": 1.0}
{"question": "who ruled the ottoman empire in the 1500s", "answer": ["Suleiman the Magnificent #MK48Hours: A Social Media Adventure"], "scores": [[0.9287109375, 0.99951171875, 0.994140625, 0.99853515625, 0.99755859375, 1.0, 1.0, 1.7881393432617188e-07, 0.0053253173828125, 0.0013866424560546875, 0.00766754150390625, 0.068359375, 0.001491546630859375, 0.0005431175231933594, 0.00592803955078125, 0.01062774658203125, 0.0020599365234375, 0.491943359375, 0.00592041015625, 0.99658203125]], "normalized_score": [0.02913433499634266], "tokens": [["\u2581S", "ule", "iman", "\u2581the", "\u2581Magn", "ific", "ent", "\u2581#", "M", "K", "4", "8", "H", "ours", ":", "\u2581A", "\u2581Social", "\u2581Media", "\u2581Advent", "ure"]], "entropy": [[0.34130859375, 0.0030364990234375, 0.03515625, 0.01113128662109375, 0.02020263671875, 0.00013494491577148438, 0.0013523101806640625, 1.0615234375, 4.6953125, 4.37109375, 4.859375, 4.14453125, 2.837890625, 3.9453125, 2.431640625, 5.40234375, 4.4609375, 1.853515625, 3.36328125, 0.0295562744140625]], "avg_entropy": [2.193431830406189], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Selim I", "score_of_biggest_cluster": 0.02913433499634266, "score_of_first_answer": 0.02913433499634266, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.02913433499634266, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.47200705296383483, "std_of_first_answer": 0.47200705296383483, "avg_entropy_of_first_answer": 2.193431830406189, "lex_sim": 1.0}
{"question": "where does the last name waller come from", "answer": ["It is of English origin and means \"one who lives at the wall.\""], "scores": [[0.1290283203125, 0.8623046875, 0.66015625, 0.98974609375, 0.9970703125, 0.76806640625, 0.5703125, 0.8955078125, 0.497802734375, 1.0, 0.74365234375, 0.0015926361083984375, 0.8466796875, 0.91748046875, 0.6650390625, 5.960464477539063e-08, 0.00608062744140625, 0.065673828125, 0.063232421875, 0.06634521484375, 0.030487060546875, 0.0743408203125, 0.0007104873657226562, 0.10626220703125, 0.0565185546875, 0.02410888671875, 0.63134765625, 0.274169921875, 0.0888671875, 0.98095703125, 0.0139312744140625, 0.64794921875, 0.10394287109375, 0.416015625, 0.0916748046875, 0.98876953125, 0.205078125, 0.10186767578125, 0.2177734375, 0.0022220611572265625, 0.4580078125, 0.046722412109375, 0.00016748905181884766, 0.006496429443359375, 0.9814453125, 0.759765625, 0.272216796875, 0.00036525726318359375]], "normalized_score": [0.08774151653051376], "tokens": [["\u2581It", "\u2581is", "\u2581of", "\u2581English", "\u2581origin", "\u2581and", "\u2581means", "\u2581\"", "one", "\u2581who", "\u2581lives", "\u2581at", "\u2581the", "\u2581wall", ".\"", "\u2581#", "2", "1", "4", "7", "8", "7", "\u2581-", "\u2581", "0", "9", "/", "2", "2", "/", "1", "9", "\u2581", "0", "3", ":", "2", "1", "\u2581PM", "\u2581Re", ":", "\u2581What", "\u2581In", "fl", "uen", "ced", "\u2581Your", "\u2581Musical"]], "entropy": [[3.53125, 0.662109375, 0.92138671875, 0.07965087890625, 0.0230712890625, 0.68212890625, 1.1611328125, 0.495849609375, 1.466796875, 0.0004940032958984375, 0.74169921875, 0.880859375, 0.515625, 0.544921875, 0.9970703125, 0.81103515625, 5.36328125, 2.80078125, 3.08984375, 2.53515625, 1.5712890625, 2.466796875, 2.09765625, 6.19140625, 1.689453125, 2.662109375, 1.693359375, 1.265625, 2.314453125, 0.1353759765625, 0.140380859375, 1.310546875, 1.3154296875, 1.326171875, 2.31640625, 0.07220458984375, 1.8056640625, 2.306640625, 2.275390625, 2.736328125, 1.419921875, 5.1953125, 2.439453125, 1.482421875, 0.11083984375, 0.7451171875, 3.33203125, 4.28515625]], "avg_entropy": [1.7501476208368938], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Anglo-Saxon origin", "score_of_biggest_cluster": 0.08774151653051376, "score_of_first_answer": 0.08774151653051376, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.08774151653051376, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3731916842791491, "std_of_first_answer": 0.3731916842791491, "avg_entropy_of_first_answer": 1.7501476208368938, "lex_sim": 1.0}
{"question": "what is on a mcchicken sandwich from mcdonalds", "answer": ["Chicken breast filet, lettuce, tomato, cheese, and sauce on a sesame seed bun."], "scores": [[0.348388671875, 1.0, 0.253662109375, 0.401611328125, 1.0, 0.94580078125, 0.87353515625, 1.0, 0.99951171875, 0.6611328125, 0.96875, 0.9990234375, 0.39404296875, 1.0, 0.96728515625, 0.3642578125, 0.141845703125, 0.99951171875, 0.76025390625, 0.99951171875, 0.9091796875, 1.0, 0.998046875, 0.99951171875, 1.0, 0.8701171875]], "normalized_score": [0.723480224609375], "tokens": [["\u2581Ch", "icken", "\u2581breast", "\u2581file", "t", ",", "\u2581lett", "uce", ",", "\u2581tom", "ato", ",", "\u2581che", "ese", ",", "\u2581and", "\u2581sau", "ce", "\u2581on", "\u2581a", "\u2581ses", "ame", "\u2581seed", "\u2581b", "un", "."]], "entropy": [[1.484375, 0.0006341934204101562, 2.115234375, 0.90185546875, 0.0011310577392578125, 0.30419921875, 0.669921875, 0.0013532638549804688, 0.005428314208984375, 0.994140625, 0.138916015625, 0.01032257080078125, 1.140625, 0.00019478797912597656, 0.15869140625, 0.98193359375, 2.26171875, 0.002349853515625, 0.9326171875, 0.0033779144287109375, 0.480224609375, 0.002529144287109375, 0.0160980224609375, 0.002704620361328125, 0.0010213851928710938, 0.54443359375]], "avg_entropy": [0.5060012248846201], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "a breaded chicken patty", "score_of_biggest_cluster": 0.723480224609375, "score_of_first_answer": 0.723480224609375, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.141845703125, "avg_score": 0.723480224609375, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2806416986391945, "std_of_first_answer": 0.2806416986391945, "avg_entropy_of_first_answer": 0.5060012248846201, "lex_sim": 1.0}
{"question": "who has won the eurovision song contest the most times", "answer": ["ABBA from Sweden, who won the contest in 1974 and 1979."], "scores": [[0.0155181884765625, 1.0, 0.07086181640625, 1.0, 0.08837890625, 0.1820068359375, 0.990234375, 0.360107421875, 0.974609375, 0.59130859375, 0.990234375, 1.0, 1.0, 1.0, 1.0, 0.00676727294921875, 0.86279296875, 1.0, 1.0, 0.9873046875, 0.919921875, 0.85400390625, 3.039836883544922e-06, 0.0007724761962890625, 0.0645751953125, 0.027740478515625, 0.0025234222412109375, 0.0433349609375, 3.5762786865234375e-05, 0.381591796875, 0.0164031982421875, 0.1494140625, 0.007137298583984375, 0.08758544921875, 0.88916015625, 0.176513671875, 0.11767578125, 0.9990234375]], "normalized_score": [0.11608369648456573], "tokens": [["\u2581AB", "BA", "\u2581from", "\u2581Sweden", ",", "\u2581who", "\u2581won", "\u2581the", "\u2581contest", "\u2581in", "\u2581", "1", "9", "7", "4", "\u2581and", "\u2581", "1", "9", "7", "9", ".", "\u2581#", "1", "2", "0", ":", "\u2581The", "\u2581One", "\u2581Where", "\u2581N", "ate", "\u2581Re", "comm", "ends", "\u2581a", "\u2581Pod", "cast"]], "entropy": [[1.7529296875, 0.0002465248107910156, 1.490234375, 0.0019483566284179688, 1.7998046875, 1.537109375, 0.07208251953125, 0.9765625, 0.134521484375, 1.306640625, 0.0653076171875, 0.0002340078353881836, 0.00018072128295898438, 0.0008673667907714844, 0.0014066696166992188, 0.161865234375, 0.7373046875, 0.0018739700317382812, 0.0009603500366210938, 0.07696533203125, 0.323486328125, 0.66259765625, 1.001953125, 1.3046875, 3.501953125, 3.841796875, 3.927734375, 6.1171875, 4.52734375, 2.158203125, 3.501953125, 3.3828125, 2.994140625, 1.8603515625, 0.3974609375, 3.4609375, 3.9375, 0.01082611083984375]], "avg_entropy": [1.5008413634802167], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ireland's Johnny Logan", "score_of_biggest_cluster": 0.11608369648456573, "score_of_first_answer": 0.11608369648456573, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 3.039836883544922e-06, "avg_score": 0.11608369648456573, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4409814789028695, "std_of_first_answer": 0.4409814789028695, "avg_entropy_of_first_answer": 1.5008413634802167, "lex_sim": 1.0}
{"question": "what are some elements that are similar to silver", "answer": ["silver is similar to other metals in group 11 of the periodic table, which includes copper, gold, and platinum."], "scores": [[0.267333984375, 0.09320068359375, 0.3154296875, 0.990234375, 0.37548828125, 0.7900390625, 1.0, 0.29150390625, 0.3046875, 1.0, 1.0, 1.0, 0.94482421875, 1.0, 0.99951171875, 1.0, 0.84228515625, 0.23583984375, 0.73876953125, 0.79052734375, 1.0, 0.9208984375, 0.9951171875, 0.9990234375, 0.99755859375, 0.3291015625, 1.0, 1.0, 0.91552734375, 5.960464477539063e-08, 0.0013637542724609375, 0.0080718994140625, 0.0007328987121582031, 0.2939453125, 0.11260986328125, 0.93994140625, 0.96728515625, 0.1663818359375, 0.079345703125, 0.0201873779296875, 0.09271240234375, 0.99755859375, 0.3828125, 0.14990234375, 0.60791015625, 0.029449462890625, 0.990234375, 1.0]], "normalized_score": [0.24116253852844238], "tokens": [["\u2581silver", "\u2581is", "\u2581similar", "\u2581to", "\u2581other", "\u2581met", "als", "\u2581in", "\u2581group", "\u2581", "1", "1", "\u2581of", "\u2581the", "\u2581periodic", "\u2581table", ",", "\u2581which", "\u2581includes", "\u2581co", "pper", ",", "\u2581gold", ",", "\u2581and", "\u2581plat", "in", "um", ".", "\u2581#", "R", "PG", "a", "DAY", "\u2581", "2", "0", "1", "7", ",", "\u2581Day", "\u2581", "1", "6", ":", "\u2581F", "avor", "ite"]], "entropy": [[2.708984375, 1.296875, 1.0546875, 0.05584716796875, 1.5693359375, 0.86376953125, 0.0009217262268066406, 0.77392578125, 0.671875, 0.0026092529296875, 0.0004138946533203125, 0.0006442070007324219, 0.2578125, 0.0002472400665283203, 0.004428863525390625, 0.00022935867309570312, 0.501953125, 1.1669921875, 0.58642578125, 0.97607421875, 0.0001131296157836914, 0.281494140625, 0.04718017578125, 0.0098724365234375, 0.02099609375, 1.001953125, 5.525350570678711e-05, 1.8477439880371094e-05, 0.363037109375, 1.46875, 3.1015625, 4.1015625, 3.51953125, 0.77587890625, 1.455078125, 0.326171875, 0.22509765625, 0.46337890625, 0.93603515625, 1.2373046875, 3.419921875, 0.022003173828125, 1.625, 2.27734375, 1.3134765625, 0.78662109375, 0.061004638671875, 0.0005002021789550781]], "avg_entropy": [0.8611457385122776], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Roentgenium (Rg)", "score_of_biggest_cluster": 0.24116253852844238, "score_of_first_answer": 0.24116253852844238, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.24116253852844238, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4003012089374417, "std_of_first_answer": 0.4003012089374417, "avg_entropy_of_first_answer": 0.8611457385122776, "lex_sim": 1.0}
{"question": "a request to the supreme court that it review a case that was already decided is made via a(n)", "answer": ["writ of certiorari"], "scores": [[0.6298828125, 1.0, 0.998046875, 0.99951171875, 1.0]], "normalized_score": [0.9112545847892761], "tokens": [["\u2581writ", "\u2581of", "\u2581cert", "ior", "ari"]], "entropy": [[1.4990234375, 0.00121307373046875, 0.0165863037109375, 0.0029010772705078125, 0.0001919269561767578]], "avg_entropy": [0.3039831638336182], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "a writ of certiorari", "score_of_biggest_cluster": 0.9112545847892761, "score_of_first_answer": 0.9112545847892761, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.6298828125, "avg_score": 0.9112545847892761, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.14780446843269615, "std_of_first_answer": 0.14780446843269615, "avg_entropy_of_first_answer": 0.3039831638336182, "lex_sim": 1.0}
{"question": "how many wing stops are there in the united states", "answer": ["There are over 800 Wing Stop restaurants located in the United States."], "scores": [[0.0287628173828125, 0.7763671875, 0.57177734375, 0.99853515625, 0.2724609375, 0.861328125, 0.99853515625, 0.98046875, 0.06866455078125, 0.35546875, 1.0, 0.1087646484375, 0.7119140625, 0.67138671875, 0.99169921875, 0.99951171875, 0.9033203125, 1.1920928955078125e-07, 2.384185791015625e-06]], "normalized_score": [0.11255376785993576], "tokens": [["\u2581There", "\u2581are", "\u2581over", "\u2581", "8", "0", "0", "\u2581Wing", "\u2581Stop", "\u2581restaur", "ants", "\u2581located", "\u2581in", "\u2581the", "\u2581United", "\u2581States", ".", "\u2581###", "\u2581Description"]], "entropy": [[2.31640625, 0.56201171875, 1.5625, 0.01155853271484375, 1.408203125, 0.468994140625, 0.0123748779296875, 0.11572265625, 0.32666015625, 0.72265625, 3.993511199951172e-06, 0.625, 0.7138671875, 0.83056640625, 0.060760498046875, 0.0032749176025390625, 0.450439453125, 0.85107421875, 5.70703125]], "avg_entropy": [0.8815318753844813], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1,000", "score_of_biggest_cluster": 0.11255376785993576, "score_of_first_answer": 0.11255376785993576, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.11255376785993576, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38944980129770085, "std_of_first_answer": 0.38944980129770085, "avg_entropy_of_first_answer": 0.8815318753844813, "lex_sim": 1.0}
{"question": "what album is sacrifice by elton john on", "answer": ["The Lion King"], "scores": [[0.268798828125, 0.52490234375, 1.0]], "normalized_score": [0.5205973982810974], "tokens": [["\u2581The", "\u2581Lion", "\u2581King"]], "entropy": [[1.759765625, 2.181640625, 5.7578086853027344e-05]], "avg_entropy": [1.313821276028951], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Sleeping with the Past.", "score_of_biggest_cluster": 0.5205973982810974, "score_of_first_answer": 0.5205973982810974, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.268798828125, "avg_score": 0.5205973982810974, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3029414955328469, "std_of_first_answer": 0.3029414955328469, "avg_entropy_of_first_answer": 1.313821276028951, "lex_sim": 1.0}
{"question": "what are the 3 layers of the meninges", "answer": ["Dura mater, Arachnoid mater, and Pia mater."], "scores": [[0.755859375, 0.99951171875, 0.99267578125, 0.9990234375, 0.79052734375, 1.0, 1.0, 0.9990234375, 0.99755859375, 0.99267578125, 0.498779296875, 0.9140625, 0.99365234375, 0.379638671875, 2.980232238769531e-07, 0.00222015380859375, 0.0814208984375, 0.00011813640594482422, 0.0001266002655029297, 0.01378631591796875, 0.02734375, 0.0001569986343383789, 0.08563232421875, 0.033050537109375, 0.28955078125, 0.00948333740234375, 0.0088348388671875, 0.07269287109375, 0.271240234375, 0.0141143798828125, 0.91015625, 0.99951171875, 0.50146484375, 0.0050048828125, 0.90234375, 0.85400390625]], "normalized_score": [0.07846487313508987], "tokens": [["\u2581D", "ura", "\u2581mater", ",", "\u2581A", "rach", "no", "id", "\u2581mater", ",", "\u2581and", "\u2581Pia", "\u2581mater", ".", "\u2581#", "2", "5", "\u2581in", "\u2581K", "ids", ",", "\u2581People", "\u2581and", "\u2581Places", ",", "\u2581People", "\u2581and", "\u2581Places", ",", "\u2581Bi", "ograph", "ies", ",", "\u2581Arts", "\u2581and", "\u2581Entertainment"]], "entropy": [[1.1005859375, 0.004421234130859375, 0.05023193359375, 0.00899505615234375, 0.5166015625, 0.0012035369873046875, 4.1425228118896484e-05, 0.00667572021484375, 0.022369384765625, 0.042877197265625, 0.8037109375, 0.41357421875, 0.038818359375, 0.7685546875, 0.07080078125, 3.998046875, 2.888671875, 2.5859375, 3.71875, 4.82421875, 4.83203125, 1.0380859375, 1.9365234375, 2.048828125, 2.70703125, 3.98046875, 2.2890625, 0.64208984375, 3.322265625, 4.9609375, 0.41552734375, 0.005229949951171875, 1.7353515625, 4.93359375, 0.42529296875, 0.6279296875]], "avg_entropy": [1.6045926792754068], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the arachnoid mater", "score_of_biggest_cluster": 0.07846487313508987, "score_of_first_answer": 0.07846487313508987, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.07846487313508987, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43362723562643823, "std_of_first_answer": 0.43362723562643823, "avg_entropy_of_first_answer": 1.6045926792754068, "lex_sim": 1.0}
{"question": "who played chaka on land of the lost tv show", "answer": ["Wesley Eure ### What is Chakra?"], "scores": [[0.6806640625, 0.99951171875, 0.99853515625, 0.9990234375, 0.0, 0.0006022453308105469, 0.43212890625, 0.00023257732391357422, 0.0029296875, 0.0787353515625, 0.54345703125]], "normalized_score": [0.0], "tokens": [["\u2581Wes", "ley", "\u2581E", "ure", "\u2581###", "\u2581What", "\u2581is", "\u2581Ch", "ak", "ra", "?"]], "entropy": [[2.16796875, 0.00433349609375, 0.01678466796875, 0.0092315673828125, 0.6611328125, 4.2890625, 1.791015625, 0.919921875, 0.040740966796875, 2.57421875, 1.94140625]], "avg_entropy": [1.3105288418856533], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Phillip Paley", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41635084543042267, "std_of_first_answer": 0.41635084543042267, "avg_entropy_of_first_answer": 1.3105288418856533, "lex_sim": 1.0}
{"question": "what language is the olympic anthem sang in", "answer": ["The Olympic Anthem is a musical composition and not sung."], "scores": [[0.07000732421875, 0.99853515625, 0.90576171875, 1.0, 0.91796875, 0.284423828125, 0.5458984375, 0.9951171875, 0.279541015625, 0.252685546875, 0.109130859375, 1.0, 0.053680419921875, 0.69287109375, 0.92529296875, 0.6708984375, 0.29150390625, 0.958984375, 0.97314453125, 0.8779296875, 0.9970703125, 0.99609375, 0.016387939453125, 0.52880859375, 0.66015625, 0.00466156005859375, 0.9853515625, 1.0, 0.0005483627319335938, 0.03814697265625, 0.85302734375, 0.2286376953125, 0.90087890625, 0.7109375, 0.0166015625, 1.0, 0.030548095703125, 0.0784912109375, 0.36962890625, 0.7275390625, 0.7890625, 0.5458984375, 0.9853515625, 0.99951171875, 0.9892578125, 0.427490234375, 1.0, 0.9716796875, 0.99462890625]], "normalized_score": [0.3504079580307007], "tokens": [["\u2581The", "\u2581Olympic", "\u2581Anth", "em", "\u2581is", "\u2581a", "\u2581musical", "\u2581composition", "\u2581and", "\u2581not", "\u2581s", "ung", ".", "\u2581It", "\u2581is", "\u2581played", "\u2581at", "\u2581the", "\u2581opening", "\u2581ceremony", "\u2581of", "\u2581the", "\u2581Olympics", "\u2581and", "\u2581is", "\u2581an", "\u2581instrument", "al", "\u2581musical", "\u2581arrangement", ".", "\u2581It", "\u2581is", "\u2581not", "\u2581set", "\u2581to", "\u2581words", ",", "\u2581and", "\u2581therefore", ",", "\u2581there", "\u2581is", "\u2581no", "\u2581language", "\u2581associated", "\u2581with", "\u2581it", "."]], "entropy": [[1.6474609375, 0.0140228271484375, 0.34326171875, 0.00019812583923339844, 0.372314453125, 2.22265625, 1.6044921875, 0.037506103515625, 1.328125, 1.8369140625, 0.89013671875, 0.0013170242309570312, 0.54248046875, 1.22265625, 0.390380859375, 1.4892578125, 1.53125, 0.2041015625, 0.1639404296875, 0.4619140625, 0.0233306884765625, 0.029541015625, 0.0888671875, 0.9697265625, 1.3203125, 2.55078125, 0.093505859375, 5.072355270385742e-05, 0.5693359375, 0.407470703125, 0.75927734375, 1.59375, 0.45703125, 1.173828125, 0.6708984375, 0.0013837814331054688, 0.740234375, 1.2119140625, 1.732421875, 1.099609375, 0.89794921875, 1.3212890625, 0.0780029296875, 0.00399017333984375, 0.0771484375, 1.5849609375, 0.0016107559204101562, 0.1334228515625, 0.043304443359375]], "avg_entropy": [0.7334558513699746], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Greek", "score_of_biggest_cluster": 0.3504079580307007, "score_of_first_answer": 0.3504079580307007, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0005483627319335938, "avg_score": 0.3504079580307007, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37683517594316857, "std_of_first_answer": 0.37683517594316857, "avg_entropy_of_first_answer": 0.7334558513699746, "lex_sim": 1.0}
{"question": "who directed the best years of our lives", "answer": ["William Wyler"], "scores": [[0.99072265625, 0.99951171875, 1.0]], "normalized_score": [0.9967356324195862], "tokens": [["\u2581William", "\u2581Wy", "ler"]], "entropy": [[0.07012939453125, 0.0026702880859375, 1.0251998901367188e-05]], "avg_entropy": [0.024269978205362957], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "William Wyler", "score_of_biggest_cluster": 0.9967356324195862, "score_of_first_answer": 0.9967356324195862, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.99072265625, "avg_score": 0.9967356324195862, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.004262956007066665, "std_of_first_answer": 0.004262956007066665, "avg_entropy_of_first_answer": 0.024269978205362957, "lex_sim": 1.0}
{"question": "what is the source of information for account receivables", "answer": ["debtor or customer records"], "scores": [[0.00492095947265625, 0.8115234375, 0.0328369140625, 0.311279296875, 0.449462890625]], "normalized_score": [0.11290455609560013], "tokens": [["\u2581deb", "tor", "\u2581or", "\u2581customer", "\u2581records"]], "entropy": [[2.853515625, 0.5498046875, 1.8408203125, 1.728515625, 1.4560546875]], "avg_entropy": [1.6857421875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "invoices", "score_of_biggest_cluster": 0.11290455609560013, "score_of_first_answer": 0.11290455609560013, "max_score_of_first_answer": 0.8115234375, "min_score_of_first_answer": 0.00492095947265625, "avg_score": 0.11290455609560013, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.29669827297239, "std_of_first_answer": 0.29669827297239, "avg_entropy_of_first_answer": 1.6857421875, "lex_sim": 1.0}
{"question": "where are they playing the superbowl at this year", "answer": ["Hard Rock Stadium, Miami Gardens, Florida #BlogTour: #TheMissingPieceofCherryByRajaniLaRocca #RBRT"], "scores": [[0.6904296875, 0.998046875, 0.99951171875, 0.77294921875, 0.9951171875, 0.8388671875, 1.0, 0.9931640625, 0.9853515625, 4.172325134277344e-07, 7.015466690063477e-05, 1.5497207641601562e-05, 0.007625579833984375, 0.01157379150390625, 0.0024394989013671875, 0.05316162109375, 0.0982666015625, 0.0009975433349609375, 0.9921875, 0.026214599609375, 0.9658203125, 0.68603515625, 0.0894775390625, 0.05157470703125, 0.177490234375, 0.9990234375, 0.001552581787109375, 0.1993408203125, 0.007289886474609375, 0.01078033447265625, 0.232177734375, 0.951171875, 0.9931640625, 0.96044921875, 0.488525390625, 0.00330352783203125, 0.023193359375, 0.10443115234375]], "normalized_score": [0.060828205198049545], "tokens": [["\u2581Hard", "\u2581Rock", "\u2581Stadium", ",", "\u2581Miami", "\u2581Gard", "ens", ",", "\u2581Florida", "\u2581#", "B", "log", "T", "our", ":", "\u2581#", "The", "Miss", "ing", "P", "ie", "ce", "of", "Ch", "er", "ry", "By", "R", "aj", "ani", "La", "R", "oc", "ca", "\u2581#", "R", "B", "RT"]], "entropy": [[1.412109375, 0.01520538330078125, 0.003986358642578125, 0.7333984375, 0.039642333984375, 0.48193359375, 2.276897430419922e-05, 0.04510498046875, 0.07928466796875, 1.2412109375, 0.8603515625, 3.044921875, 4.67578125, 2.705078125, 3.234375, 5.1875, 4.89453125, 5.17578125, 0.0751953125, 3.341796875, 0.248291015625, 0.623046875, 3.302734375, 2.658203125, 2.681640625, 0.00885009765625, 2.857421875, 3.369140625, 3.41015625, 2.1171875, 2.599609375, 0.312744140625, 0.0537109375, 0.18212890625, 2.435546875, 4.4765625, 3.994140625, 1.3349609375]], "avg_entropy": [1.9450865262433101], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Minneapolis, Minnesota", "score_of_biggest_cluster": 0.060828205198049545, "score_of_first_answer": 0.060828205198049545, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.060828205198049545, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4362600656909426, "std_of_first_answer": 0.4362600656909426, "avg_entropy_of_first_answer": 1.9450865262433101, "lex_sim": 1.0}
{"question": "who was the viceroy when the simon commission visited india", "answer": ["Lord Irwin Tags: Trump | Climate | Summit | Paris | Agreement"], "scores": [[0.36669921875, 0.8798828125, 0.99267578125, 0.0, 0.94873046875, 3.5762786865234375e-07, 0.0013074874877929688, 0.0155792236328125, 0.84912109375, 0.1307373046875, 0.0017299652099609375, 0.96142578125, 0.93701171875, 0.037078857421875, 0.8427734375, 0.267333984375, 0.99853515625, 0.9990234375]], "normalized_score": [0.0], "tokens": [["\u2581Lord", "\u2581Ir", "win", "\u2581Tags", ":", "\u2581Trump", "\u2581|", "\u2581Cl", "imate", "\u2581|", "\u2581Sum", "mit", "\u2581|", "\u2581Paris", "\u2581|", "\u2581Ag", "re", "ement"]], "entropy": [[2.1484375, 0.54248046875, 0.048553466796875, 0.892578125, 0.43701171875, 3.384765625, 5.49609375, 6.24609375, 0.60693359375, 1.55078125, 4.6796875, 0.2333984375, 0.42333984375, 5.28515625, 0.74951171875, 3.470703125, 0.015777587890625, 0.007373809814453125]], "avg_entropy": [2.0121487511528864], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Lord Irwin", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.43336456871941836, "std_of_first_answer": 0.43336456871941836, "avg_entropy_of_first_answer": 2.0121487511528864, "lex_sim": 1.0}
{"question": "who has scored the most points for wales v france", "answer": ["Dan Biggar #11 - Dylan Larkin and Anthony Mantha each scored power-play goals to help Detro\u2026"], "scores": [[0.0726318359375, 0.8212890625, 1.0, 1.430511474609375e-06, 0.01468658447265625, 0.04913330078125, 0.01471710205078125, 0.00024008750915527344, 0.0009937286376953125, 0.99951171875, 0.014678955078125, 0.0011167526245117188, 0.06744384765625, 0.0028705596923828125, 0.00469970703125, 0.92041015625, 0.99658203125, 0.045257568359375, 0.61962890625, 0.0001741647720336914, 0.93994140625, 1.0, 0.986328125, 0.0258636474609375, 0.326171875, 0.00014209747314453125, 0.341552734375, 0.0009608268737792969]], "normalized_score": [0.0262195635586977], "tokens": [["\u2581Dan", "\u2581Big", "gar", "\u2581#", "1", "1", "\u2581-", "\u2581D", "yl", "an", "\u2581L", "ark", "in", "\u2581and", "\u2581Anthony", "\u2581Man", "tha", "\u2581each", "\u2581scored", "\u2581power", "-", "play", "\u2581goals", "\u2581to", "\u2581help", "\u2581Det", "ro", "\u2026"]], "entropy": [[2.623046875, 0.56591796875, 0.00024819374084472656, 1.404296875, 3.5, 1.8603515625, 3.318359375, 1.7763671875, 3.560546875, 0.00653839111328125, 2.609375, 0.623046875, 0.46142578125, 1.60546875, 5.48828125, 0.58251953125, 0.0299835205078125, 3.220703125, 1.2666015625, 1.9111328125, 0.266357421875, 0.0013751983642578125, 0.09429931640625, 2.0, 2.3125, 0.4794921875, 1.2587890625, 1.0302734375]], "avg_entropy": [1.5663320762770516], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Neil Jenkins", "score_of_biggest_cluster": 0.0262195635586977, "score_of_first_answer": 0.0262195635586977, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.430511474609375e-06, "avg_score": 0.0262195635586977, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4194282383163769, "std_of_first_answer": 0.4194282383163769, "avg_entropy_of_first_answer": 1.5663320762770516, "lex_sim": 1.0}
{"question": "who plays faith on when calls the heart", "answer": ["Danica McKellar #1714: Willa Cather to Charles H. and Anne B. Hoyt, [December 4, 1937]"], "scores": [[0.1026611328125, 0.8994140625, 0.99853515625, 0.99267578125, 1.0, 1.1920928955078125e-07, 0.01435089111328125, 0.0153656005859375, 0.0243682861328125, 0.136962890625, 0.00611114501953125, 0.01995849609375, 0.0186767578125, 0.430419921875, 0.51123046875, 0.0006551742553710938, 0.0126190185546875, 0.0013275146484375, 0.275634765625, 0.001224517822265625, 0.05010986328125, 0.071533203125, 0.89990234375, 0.268798828125, 0.9140625, 0.50537109375, 0.012298583984375, 0.0379638671875, 0.5244140625, 0.9736328125, 0.02044677734375, 0.9599609375, 0.98779296875, 0.99951171875, 0.9609375, 0.693359375, 0.03375244140625, 0.2479248046875]], "normalized_score": [0.07470380514860153], "tokens": [["\u2581Dan", "ica", "\u2581McK", "ell", "ar", "\u2581#", "1", "7", "1", "4", ":", "\u2581W", "illa", "\u2581C", "ather", "\u2581to", "\u2581Charles", "\u2581H", ".", "\u2581and", "\u2581Anne", "\u2581B", ".", "\u2581Ho", "yt", ",", "\u2581[", "Dec", "ember", "\u2581", "4", ",", "\u2581", "1", "9", "3", "7", "]"]], "entropy": [[1.9423828125, 0.61572265625, 0.01325225830078125, 0.0430908203125, 0.00011461973190307617, 0.654296875, 4.203125, 3.876953125, 3.18359375, 2.6796875, 3.033203125, 3.60546875, 3.3515625, 2.482421875, 1.2392578125, 4.484375, 4.828125, 2.48046875, 2.783203125, 4.62890625, 4.734375, 2.673828125, 0.72119140625, 3.826171875, 0.440185546875, 2.169921875, 4.5546875, 3.689453125, 0.90283203125, 0.169921875, 1.513671875, 0.258544921875, 0.0872802734375, 0.00293731689453125, 0.1651611328125, 0.83251953125, 1.8974609375, 1.29296875]], "avg_entropy": [2.106903281651045], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Andrea Brooks", "score_of_biggest_cluster": 0.07470380514860153, "score_of_first_answer": 0.07470380514860153, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.07470380514860153, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4067207540574758, "std_of_first_answer": 0.4067207540574758, "avg_entropy_of_first_answer": 2.106903281651045, "lex_sim": 1.0}
{"question": "what genre is the magic tree house books", "answer": ["Children's Fiction #420693 - 05/06/16 05:24 PM Re: 2016 Eurovision Song Contest [Re: Aqxb"], "scores": [[0.45751953125, 0.9873046875, 1.0, 0.48974609375, 1.0, 1.8477439880371094e-06, 0.00948333740234375, 0.1083984375, 0.06353759765625, 0.04730224609375, 0.03424072265625, 0.04150390625, 0.0011320114135742188, 0.328369140625, 0.048736572265625, 0.064208984375, 0.484375, 0.384765625, 0.07684326171875, 0.4130859375, 0.0777587890625, 0.0269927978515625, 0.13818359375, 0.3251953125, 0.07745361328125, 0.9814453125, 0.19775390625, 0.0902099609375, 0.497314453125, 0.0008854866027832031, 0.712890625, 0.014801025390625, 0.1849365234375, 0.6748046875, 0.112548828125, 0.54638671875, 0.00038361549377441406, 0.36083984375, 0.716796875, 0.98095703125, 0.99853515625, 0.479736328125, 0.9990234375, 0.99755859375, 0.026397705078125, 0.0005397796630859375, 0.0029296875, 0.01091766357421875]], "normalized_score": [0.08691529184579849], "tokens": [["\u2581Children", "'", "s", "\u2581F", "iction", "\u2581#", "4", "2", "0", "6", "9", "3", "\u2581-", "\u2581", "0", "5", "/", "0", "6", "/", "1", "6", "\u2581", "0", "5", ":", "2", "4", "\u2581PM", "\u2581Re", ":", "\u2581", "2", "0", "1", "6", "\u2581Euro", "vision", "\u2581Song", "\u2581Cont", "est", "\u2581[", "Re", ":", "\u2581A", "q", "x", "b"]], "entropy": [[1.0439453125, 0.09747314453125, 0.0002186298370361328, 1.3984375, 0.0014886856079101562, 0.86669921875, 3.685546875, 2.85546875, 2.751953125, 3.00390625, 2.70703125, 3.275390625, 2.01953125, 3.671875, 1.27734375, 3.009765625, 2.193359375, 1.2578125, 2.05859375, 1.482421875, 0.658203125, 0.95703125, 2.166015625, 1.265625, 2.30859375, 0.11981201171875, 1.8095703125, 2.302734375, 1.9384765625, 2.330078125, 1.34765625, 4.37109375, 2.75, 1.921875, 2.232421875, 1.4111328125, 6.05078125, 2.73046875, 1.6083984375, 0.1474609375, 0.0160675048828125, 2.91015625, 0.012420654296875, 0.0234527587890625, 5.0234375, 2.6640625, 2.578125, 3.876953125]], "avg_entropy": [2.003965978821119], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Children's historical fantasy", "score_of_biggest_cluster": 0.08691529184579849, "score_of_first_answer": 0.08691529184579849, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.8477439880371094e-06, "avg_score": 0.08691529184579849, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.35743728263329905, "std_of_first_answer": 0.35743728263329905, "avg_entropy_of_first_answer": 2.003965978821119, "lex_sim": 1.0}
{"question": "where is the inscription on the statue of liberty", "answer": ["On the pedestal of the Statue of Liberty."], "scores": [[0.041778564453125, 0.98779296875, 0.5283203125, 1.0, 1.0, 0.93017578125, 0.99853515625, 0.93994140625, 0.99951171875, 0.9990234375, 0.9970703125, 1.0, 0.3916015625, 0.173583984375, 0.91796875, 0.9990234375, 0.033843994140625, 0.984375, 0.56640625, 1.0, 1.0, 0.00955963134765625, 0.67724609375, 0.6611328125, 0.67333984375, 0.40576171875, 1.0, 0.83935546875, 0.6201171875, 0.01439666748046875, 0.1064453125, 0.62451171875, 0.9111328125, 0.95458984375, 0.97119140625, 0.88037109375, 0.552734375, 0.159912109375, 0.9365234375, 0.006633758544921875, 0.57666015625, 1.0, 0.99462890625, 0.99755859375, 1.0, 0.99951171875, 0.98828125, 0.99853515625, 0.345947265625, 0.5517578125]], "normalized_score": [0.495606392621994], "tokens": [["\u2581On", "\u2581the", "\u2581ped", "est", "al", "\u2581of", "\u2581the", "\u2581Stat", "ue", "\u2581of", "\u2581Liber", "ty", ".", "\u2581The", "\u2581ins", "cription", "\u2581on", "\u2581the", "\u2581ped", "est", "al", "\u2581includes", "\u2581the", "\u2581date", "\u2581of", "\u2581dedic", "ation", ",", "\u2581the", "\u2581French", "\u2581name", "\u2581of", "\u2581the", "\u2581statue", ",", "\u2581and", "\u2581the", "\u2581words", "\u2581\"", "J", "UL", "Y", "\u2581IV", "\u2581MD", "CC", "L", "XX", "VI", "\"", "\u2581which"]], "entropy": [[0.888671875, 0.09552001953125, 1.4560546875, 3.272294998168945e-05, 0.0007257461547851562, 0.40771484375, 0.014312744140625, 0.2314453125, 0.003253936767578125, 0.0073394775390625, 0.022491455078125, 0.001834869384765625, 1.51171875, 1.0791015625, 0.552734375, 0.00713348388671875, 0.806640625, 0.09039306640625, 1.2275390625, 0.0002009868621826172, 0.001506805419921875, 1.0576171875, 1.4560546875, 1.505859375, 0.7314453125, 0.9638671875, 0.0005092620849609375, 0.5888671875, 0.92529296875, 2.919921875, 1.3359375, 0.68017578125, 0.470947265625, 0.216064453125, 0.17578125, 0.5166015625, 1.2744140625, 2.796875, 0.355224609375, 1.4931640625, 0.6904296875, 0.000347137451171875, 0.0347900390625, 0.0220947265625, 0.00021922588348388672, 0.00339508056640625, 0.076171875, 0.01073455810546875, 1.078125, 1.6396484375]], "avg_entropy": [0.6285388553142548], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The New Colossus", "score_of_biggest_cluster": 0.495606392621994, "score_of_first_answer": 0.495606392621994, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.006633758544921875, "avg_score": 0.495606392621994, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3420983943865041, "std_of_first_answer": 0.3420983943865041, "avg_entropy_of_first_answer": 0.6285388553142548, "lex_sim": 1.0}
{"question": "when does closure of the ductus arteriosus occur", "answer": ["Prenatal development"], "scores": [[0.006076812744140625, 0.65478515625, 0.11114501953125, 0.3125]], "normalized_score": [0.10842481255531311], "tokens": [["\u2581P", "ren", "atal", "\u2581development"]], "entropy": [[3.09375, 1.0791015625, 0.360107421875, 1.90234375]], "avg_entropy": [1.60882568359375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "at birth", "score_of_biggest_cluster": 0.10842481255531311, "score_of_first_answer": 0.10842481255531311, "max_score_of_first_answer": 0.65478515625, "min_score_of_first_answer": 0.006076812744140625, "avg_score": 0.10842481255531311, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2473616491217683, "std_of_first_answer": 0.2473616491217683, "avg_entropy_of_first_answer": 1.60882568359375, "lex_sim": 1.0}
{"question": "when was the last god of war made", "answer": ["God of War in 2018 #TheSpark: Creating a Culture of Innovation and Employee Empowerment"], "scores": [[0.73583984375, 1.0, 1.0, 0.04925537109375, 0.97998046875, 1.0, 1.0, 0.9990234375, 1.0, 1.7881393432617188e-07, 0.0016584396362304688, 0.0005164146423339844, 0.058319091796875, 7.194280624389648e-05, 2.5928020477294922e-05, 0.82373046875, 0.0009465217590332031, 0.9453125, 0.521484375, 0.994140625, 0.9990234375, 0.0682373046875, 0.01361083984375, 0.85986328125, 1.0, 0.99951171875]], "normalized_score": [0.06569347530603409], "tokens": [["\u2581God", "\u2581of", "\u2581War", "\u2581in", "\u2581", "2", "0", "1", "8", "\u2581#", "The", "S", "park", ":", "\u2581Creating", "\u2581a", "\u2581Culture", "\u2581of", "\u2581In", "nov", "ation", "\u2581and", "\u2581Employee", "\u2581Emp", "ower", "ment"]], "entropy": [[1.134765625, 0.0009131431579589844, 0.0007710456848144531, 0.5615234375, 0.11431884765625, 0.00026226043701171875, 0.0004973411560058594, 0.00669097900390625, 0.0011882781982421875, 1.3388671875, 4.13671875, 1.19140625, 1.087890625, 2.29296875, 4.07421875, 0.9482421875, 2.79296875, 0.38037109375, 2.375, 0.044219970703125, 0.009368896484375, 2.66796875, 4.13671875, 0.78076171875, 0.0006394386291503906, 0.0032367706298828125]], "avg_entropy": [1.1570191383361816], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2018", "score_of_biggest_cluster": 0.06569347530603409, "score_of_first_answer": 0.06569347530603409, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.06569347530603409, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.45434289630880026, "std_of_first_answer": 0.45434289630880026, "avg_entropy_of_first_answer": 1.1570191383361816, "lex_sim": 1.0}
{"question": "who won game 4 of the 2000 nba finals", "answer": ["The Los Angeles Lakers."], "scores": [[0.6103515625, 0.9384765625, 0.99951171875, 0.9970703125, 1.0, 0.359619140625, 2.562999725341797e-06, 0.00446319580078125, 4.172325134277344e-07, 0.00018167495727539062, 0.0137481689453125, 0.00628662109375, 0.037567138671875, 0.2314453125, 0.921875, 0.1690673828125, 0.943359375, 0.056884765625, 0.0010995864868164062, 0.0005125999450683594, 0.98388671875, 1.0, 8.225440979003906e-06, 0.0163726806640625, 0.88427734375, 0.9052734375, 0.98193359375, 0.86669921875, 1.0, 0.01386260986328125, 0.00154876708984375, 7.987022399902344e-06, 0.994140625, 0.99951171875]], "normalized_score": [0.03380820155143738], "tokens": [["\u2581The", "\u2581Los", "\u2581Angeles", "\u2581L", "akers", ".", "\u2581#", "N", "HS", "7", "0", ":", "\u2581", "7", "0", "\u2581Years", "\u2581of", "\u2581the", "\u2581Most", "\u2581Rem", "ark", "able", "\u2581Institution", "\u2581the", "\u2581World", "\u2581Has", "\u2581Ever", "\u2581Se", "en", "\u2581|", "\u2581James", "\u2581Mack", "en", "zie"]], "entropy": [[1.09765625, 0.391357421875, 0.003452301025390625, 0.0211334228515625, 0.00010436773300170898, 1.416015625, 0.763671875, 3.95703125, 0.244384765625, 1.0546875, 1.58203125, 2.439453125, 4.74609375, 2.287109375, 0.6513671875, 2.142578125, 0.381591796875, 3.017578125, 1.2685546875, 3.248046875, 0.08251953125, 0.0015687942504882812, 3.173828125, 2.09765625, 0.740234375, 0.33203125, 0.1236572265625, 0.440673828125, 0.0016813278198242188, 2.03515625, 3.640625, 4.125, 0.0513916015625, 0.004695892333984375]], "avg_entropy": [1.398959368467331], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Los Angeles Lakers", "score_of_biggest_cluster": 0.03380820155143738, "score_of_first_answer": 0.03380820155143738, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.03380820155143738, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4538432053982597, "std_of_first_answer": 0.4538432053982597, "avg_entropy_of_first_answer": 1.398959368467331, "lex_sim": 1.0}
{"question": "when did the nba add the three point line", "answer": ["1979-1980 season."], "scores": [[0.96240234375, 1.0, 1.0, 1.0, 0.99951171875, 0.912109375, 0.82421875, 1.0, 1.0, 1.0, 0.9697265625, 0.19970703125, 2.980232238769531e-07, 3.6776065826416016e-05, 0.0050506591796875, 8.285045623779297e-05, 0.079345703125, 0.00014543533325195312, 0.04864501953125, 0.94482421875, 0.0008497238159179688, 7.045269012451172e-05, 0.049896240234375, 0.03900146484375, 0.0017900466918945312, 0.06744384765625, 4.1425228118896484e-05, 0.2069091796875, 0.096923828125, 0.0001627206802368164, 0.50341796875]], "normalized_score": [0.027284301817417145], "tokens": [["\u2581", "1", "9", "7", "9", "-", "1", "9", "8", "0", "\u2581season", ".", "\u2581#", "Ind", "ia", "\u2581\u2013", "\u2581The", "\u2581other", "\u2581side", "\u2581of", "\u2581India", "\u2581Sh", "ining", ":", "\u2581Human", "\u2581development", "al", "\u2581indices", "\u2581#", "must", "read"]], "entropy": [[0.234130859375, 0.0005159378051757812, 0.0006785392761230469, 0.0010271072387695312, 0.0025806427001953125, 0.402587890625, 0.46630859375, 0.0007185935974121094, 0.0022449493408203125, 0.0015268325805664062, 0.17041015625, 1.0712890625, 0.580078125, 3.265625, 1.1982421875, 2.876953125, 2.80078125, 4.125, 4.28515625, 0.396484375, 2.837890625, 3.052734375, 2.146484375, 2.71484375, 4.51953125, 0.37548828125, 2.703125, 1.349609375, 3.57421875, 4.2265625, 1.359375]], "avg_entropy": [1.6368452502835182], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1979\u201380", "score_of_biggest_cluster": 0.027284301817417145, "score_of_first_answer": 0.027284301817417145, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.027284301817417145, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.44915821153273644, "std_of_first_answer": 0.44915821153273644, "avg_entropy_of_first_answer": 1.6368452502835182, "lex_sim": 1.0}
{"question": "who is the founder of google and when was it founded", "answer": ["Larry Page and Sergey Brin founded Google on September 4, 1998."], "scores": [[0.34033203125, 0.99951171875, 0.90185546875, 0.9970703125, 1.0, 1.0, 1.0, 0.10955810546875, 0.99951171875, 0.377197265625, 0.99267578125, 0.99951171875, 0.99951171875, 0.95361328125, 0.99951171875, 1.0, 1.0, 1.0, 1.0, 0.94873046875, 5.364418029785156e-07, 8.422136306762695e-05, 0.0015192031860351562, 0.01180267333984375, 0.0010728836059570312, 0.00045228004455566406, 0.025390625, 0.142333984375, 0.12261962890625, 0.0100860595703125, 0.023040771484375, 0.343017578125, 0.818359375, 0.0877685546875, 0.1968994140625, 0.005218505859375, 0.71240234375, 0.000553131103515625, 0.841796875, 0.01137542724609375, 0.0212249755859375, 0.02020263671875, 0.2744140625, 0.96630859375]], "normalized_score": [0.0984288901090622], "tokens": [["\u2581Larry", "\u2581Page", "\u2581and", "\u2581Serge", "y", "\u2581Br", "in", "\u2581founded", "\u2581Google", "\u2581on", "\u2581September", "\u2581", "4", ",", "\u2581", "1", "9", "9", "8", ".", "\u2581#", "Re", "view", ":", "\u2581W", "AL", "K", "ING", "\u2581ON", "\u2581TR", "AP", "DO", "ORS", "\u2581by", "\u2581@", "mat", "ty", "oll", "ie", "\u2581\u2013", "\u2581#", "M", "ust", "Read"]], "entropy": [[0.78857421875, 0.00432586669921875, 0.455322265625, 0.025238037109375, 0.0002582073211669922, 0.0005588531494140625, 0.0003821849822998047, 1.4306640625, 0.00537872314453125, 0.67236328125, 0.04644775390625, 0.0034236907958984375, 0.004665374755859375, 0.1905517578125, 0.005405426025390625, 4.851818084716797e-05, 2.6464462280273438e-05, 7.891654968261719e-05, 0.0008082389831542969, 0.2161865234375, 0.11419677734375, 3.080078125, 2.724609375, 3.853515625, 4.8359375, 3.490234375, 2.50390625, 3.416015625, 2.080078125, 1.80859375, 1.8095703125, 1.8427734375, 0.499267578125, 3.365234375, 4.61328125, 6.30859375, 1.728515625, 3.755859375, 1.0810546875, 4.265625, 5.19140625, 5.58984375, 2.888671875, 0.2279052734375]], "avg_entropy": [1.7028517370874232], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1998", "score_of_biggest_cluster": 0.0984288901090622, "score_of_first_answer": 0.0984288901090622, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.364418029785156e-07, "avg_score": 0.0984288901090622, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44482708183952874, "std_of_first_answer": 0.44482708183952874, "avg_entropy_of_first_answer": 1.7028517370874232, "lex_sim": 1.0}
{"question": "when did the battles of lexington and concord happen", "answer": ["1775"], "scores": [[0.171630859375, 0.99951171875, 0.99267578125, 0.99951171875, 0.99951171875]], "normalized_score": [0.7017029523849487], "tokens": [["\u2581", "1", "7", "7", "5"]], "entropy": [[0.69189453125, 0.0049591064453125, 0.04595947265625, 0.006805419921875, 0.003940582275390625]], "avg_entropy": [0.15071182250976561], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "April 19, 1775", "score_of_biggest_cluster": 0.7017029523849487, "score_of_first_answer": 0.7017029523849487, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.171630859375, "avg_score": 0.7017029523849487, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.33047935522932154, "std_of_first_answer": 0.33047935522932154, "avg_entropy_of_first_answer": 0.15071182250976561, "lex_sim": 1.0}
{"question": "what is the name of the skin between your nostrils", "answer": ["philtrum ### What is the difference between the words \"station\", \"stop\", and \"halt\"?"], "scores": [[0.73193359375, 1.0, 1.0, 0.0, 0.00043964385986328125, 0.7333984375, 0.73486328125, 0.022674560546875, 0.98583984375, 0.033782958984375, 0.08038330078125, 0.50537109375, 0.006496429443359375, 0.0004718303680419922, 0.98779296875, 0.026397705078125, 0.95751953125, 0.9091796875, 0.99853515625, 0.69140625, 0.88720703125]], "normalized_score": [0.0], "tokens": [["\u2581phil", "tr", "um", "\u2581###", "\u2581What", "\u2581is", "\u2581the", "\u2581difference", "\u2581between", "\u2581the", "\u2581words", "\u2581\"", "station", "\",", "\u2581\"", "stop", "\",", "\u2581and", "\u2581\"", "halt", "\"?"]], "entropy": [[1.3720703125, 9.250640869140625e-05, 0.0008325576782226562, 0.54443359375, 3.5859375, 1.7490234375, 1.357421875, 3.158203125, 0.102294921875, 3.861328125, 5.55859375, 2.197265625, 4.30859375, 0.666015625, 0.083251953125, 2.990234375, 0.2216796875, 0.336669921875, 0.0135040283203125, 1.1552734375, 0.493896484375]], "avg_entropy": [1.6074579329717726], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the nasal septum", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42299990982504915, "std_of_first_answer": 0.42299990982504915, "avg_entropy_of_first_answer": 1.6074579329717726, "lex_sim": 1.0}
{"question": "when did the second it movie come out", "answer": ["September 18, 2019 ### What is Tarsia?"], "scores": [[0.1822509765625, 0.99365234375, 0.496337890625, 0.74462890625, 0.904296875, 0.9990234375, 0.962890625, 1.0, 0.85498046875, 0.99755859375, 0.0, 0.0021915435791015625, 0.466064453125, 0.00035119056701660156, 0.0004906654357910156, 0.00043487548828125, 0.61181640625]], "normalized_score": [0.0], "tokens": [["\u2581September", "\u2581", "1", "8", ",", "\u2581", "2", "0", "1", "9", "\u2581###", "\u2581What", "\u2581is", "\u2581T", "ars", "ia", "?"]], "entropy": [[1.810546875, 0.043548583984375, 1.359375, 1.033203125, 0.351318359375, 0.00995635986328125, 0.1593017578125, 4.357099533081055e-05, 0.41943359375, 0.0219268798828125, 0.779296875, 3.453125, 3.01171875, 1.6796875, 4.0546875, 1.6875, 2.3359375]], "avg_entropy": [1.3065063076860763], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "September 6, 2019", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4119388331898796, "std_of_first_answer": 0.4119388331898796, "avg_entropy_of_first_answer": 1.3065063076860763, "lex_sim": 1.0}
{"question": "who has the oldest team in the nba", "answer": ["Boston Celtics #1 New York Times bestselling author Daniel Silva delivers another stunning thriller in which Gabriel Allon confronts a terrorist network that is setting its sights on the Vatican."], "scores": [[0.96044921875, 0.99951171875, 1.0, 1.0, 4.76837158203125e-07, 0.062408447265625, 0.00013339519500732422, 0.58349609375, 0.0006694793701171875, 0.07818603515625, 0.61572265625, 0.9306640625, 0.912109375, 0.0115966796875, 0.227294921875, 0.09881591796875, 0.76904296875, 0.94482421875, 0.705078125, 0.99951171875, 0.9794921875, 0.99951171875, 0.88037109375, 0.472900390625, 0.061279296875, 0.99853515625, 1.0, 0.1663818359375, 0.99853515625, 0.99658203125, 0.051849365234375, 0.96875, 0.59033203125, 0.712890625, 0.80224609375, 0.021820068359375, 0.99853515625, 0.98876953125, 0.9990234375, 0.994140625, 0.888671875, 0.97412109375, 1.0, 1.0, 0.9814453125]], "normalized_score": [0.26456624269485474], "tokens": [["\u2581Boston", "\u2581C", "elt", "ics", "\u2581#", "1", "\u2581New", "\u2581York", "\u2581Times", "\u2581best", "s", "elling", "\u2581author", "\u2581Daniel", "\u2581Silva", "\u2581del", "ivers", "\u2581another", "\u2581st", "unning", "\u2581thr", "iller", "\u2581in", "\u2581which", "\u2581Gabriel", "\u2581All", "on", "\u2581confront", "s", "\u2581a", "\u2581terror", "ist", "\u2581network", "\u2581that", "\u2581is", "\u2581setting", "\u2581its", "\u2581s", "ights", "\u2581on", "\u2581the", "\u2581V", "at", "ican", "."]], "entropy": [[0.2349853515625, 0.0024166107177734375, 0.00013875961303710938, 0.0006976127624511719, 0.9873046875, 3.990234375, 3.087890625, 1.6572265625, 1.4482421875, 0.380126953125, 0.9765625, 0.282470703125, 0.578125, 4.51171875, 2.697265625, 2.427734375, 0.54150390625, 0.2666015625, 1.537109375, 0.003875732421875, 0.1702880859375, 0.004108428955078125, 0.59033203125, 1.462890625, 1.8251953125, 0.01238250732421875, 0.0002918243408203125, 1.34765625, 0.015045166015625, 0.03106689453125, 0.95703125, 0.1995849609375, 1.1494140625, 0.69873046875, 1.2275390625, 3.5390625, 0.01413726806640625, 0.0726318359375, 0.0083160400390625, 0.0408935546875, 0.433837890625, 0.2193603515625, 0.0002319812774658203, 0.0008654594421386719, 0.1357421875]], "avg_entropy": [0.88375260565016], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Sacramento Kings", "score_of_biggest_cluster": 0.26456624269485474, "score_of_first_answer": 0.26456624269485474, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.76837158203125e-07, "avg_score": 0.26456624269485474, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39158299391428525, "std_of_first_answer": 0.39158299391428525, "avg_entropy_of_first_answer": 0.88375260565016, "lex_sim": 1.0}
{"question": "what's the dog's name on tom and jerry", "answer": ["Spike"], "scores": [[0.57177734375, 0.99853515625, 1.0]], "normalized_score": [0.82958984375], "tokens": [["\u2581S", "pi", "ke"]], "entropy": [[2.044921875, 0.015045166015625, 1.3053417205810547e-05]], "avg_entropy": [0.6866600314776102], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Spike", "score_of_biggest_cluster": 0.82958984375, "score_of_first_answer": 0.82958984375, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.57177734375, "avg_score": 0.82958984375, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.20152171639878272, "std_of_first_answer": 0.20152171639878272, "avg_entropy_of_first_answer": 0.6866600314776102, "lex_sim": 1.0}
{"question": "when is last time the astros won the world series", "answer": ["2017 #384798 - 05/13/12 12:05 PM How to get rid of unhealthy habits?"], "scores": [[0.8466796875, 1.0, 1.0, 0.99853515625, 0.97607421875, 1.1920928955078125e-07, 0.001171112060546875, 0.018646240234375, 0.039215087890625, 0.0875244140625, 0.036529541015625, 0.042083740234375, 0.0006279945373535156, 0.331298828125, 0.048492431640625, 0.0552978515625, 0.60546875, 0.306396484375, 0.080078125, 0.97998046875, 0.02581787109375, 0.0028209686279296875, 0.396240234375, 0.336181640625, 0.3408203125, 0.9931640625, 0.2705078125, 0.052764892578125, 0.49462890625, 0.000530242919921875, 0.0203704833984375, 0.022735595703125, 0.07080078125, 0.9951171875, 0.00136566162109375, 0.1875, 0.998046875, 0.998046875, 0.21240234375, 0.9990234375, 0.377685546875]], "normalized_score": [0.07933419942855835], "tokens": [["\u2581", "2", "0", "1", "7", "\u2581#", "3", "8", "4", "7", "9", "8", "\u2581-", "\u2581", "0", "5", "/", "1", "3", "/", "1", "2", "\u2581", "1", "2", ":", "0", "5", "\u2581PM", "\u2581How", "\u2581to", "\u2581get", "\u2581rid", "\u2581of", "\u2581un", "he", "alth", "y", "\u2581hab", "its", "?"]], "entropy": [[0.654296875, 0.0012416839599609375, 0.0004611015319824219, 0.01023101806640625, 0.1158447265625, 1.1142578125, 4.375, 3.451171875, 3.732421875, 2.833984375, 2.767578125, 3.24609375, 2.765625, 4.125, 1.0751953125, 2.67578125, 0.9267578125, 1.20703125, 2.27734375, 0.1497802734375, 0.237060546875, 1.056640625, 1.7841796875, 0.9072265625, 1.421875, 0.0623779296875, 1.7529296875, 1.8623046875, 1.2646484375, 2.328125, 1.634765625, 5.74609375, 4.53125, 0.044891357421875, 4.80078125, 3.498046875, 0.0171966552734375, 0.019134521484375, 3.9453125, 0.0099334716796875, 2.603515625]], "avg_entropy": [1.8788631136824445], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2017", "score_of_biggest_cluster": 0.07933419942855835, "score_of_first_answer": 0.07933419942855835, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.07933419942855835, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3966993318423509, "std_of_first_answer": 0.3966993318423509, "avg_entropy_of_first_answer": 1.8788631136824445, "lex_sim": 1.0}
{"question": "when was the first australian prime minister elected", "answer": ["January 1, 1901 (Australian federation date)"], "scores": [[0.1065673828125, 0.99853515625, 0.99365234375, 0.9775390625, 0.99951171875, 0.99951171875, 1.0, 0.99951171875, 1.0, 0.04876708984375, 0.0274200439453125, 0.0226287841796875, 0.50439453125, 1.0, 0.00872039794921875, 0.94677734375]], "normalized_score": [0.32146456837654114], "tokens": [["\u2581January", "\u2581", "1", ",", "\u2581", "1", "9", "0", "1", "\u2581(", "Austral", "ian", "\u2581feder", "ation", "\u2581date", ")"]], "entropy": [[2.33984375, 0.01392364501953125, 0.04058837890625, 0.136962890625, 0.006237030029296875, 0.004741668701171875, 0.0005245208740234375, 0.0031681060791015625, 0.0010089874267578125, 1.1064453125, 2.29296875, 0.10968017578125, 0.92919921875, 0.000316619873046875, 1.310546875, 0.28515625]], "avg_entropy": [0.5363320112228394], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Sir Edmund Barton", "score_of_biggest_cluster": 0.32146456837654114, "score_of_first_answer": 0.32146456837654114, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.00872039794921875, "avg_score": 0.32146456837654114, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.435598715814922, "std_of_first_answer": 0.435598715814922, "avg_entropy_of_first_answer": 0.5363320112228394, "lex_sim": 1.0}
{"question": "when was the problem of cfc's discovered", "answer": ["The problem of CFCs, or chlorofluorocarbons, was discovered in the 1970s."], "scores": [[0.321533203125, 0.92529296875, 0.97607421875, 0.765625, 1.0, 0.9501953125, 0.19775390625, 0.9892578125, 0.99951171875, 1.0, 1.0, 0.99951171875, 0.99951171875, 1.0, 1.0, 0.9990234375, 1.0, 0.99951171875, 0.943359375, 0.79296875, 0.9990234375, 0.9970703125, 0.1943359375, 0.998046875, 1.0, 0.99560546875, 1.0, 0.99951171875, 0.91943359375, 1.1920928955078125e-07, 0.01013946533203125, 0.06634521484375, 0.07342529296875, 0.00023233890533447266, 0.005828857421875, 0.0016326904296875, 0.416015625, 0.0223236083984375, 0.26318359375, 1.8596649169921875e-05, 0.00891876220703125, 0.4853515625, 0.0172119140625, 0.0411376953125]], "normalized_score": [0.16011403501033783], "tokens": [["\u2581The", "\u2581problem", "\u2581of", "\u2581C", "FC", "s", ",", "\u2581or", "\u2581ch", "lor", "of", "lu", "or", "oc", "ar", "b", "ons", ",", "\u2581was", "\u2581discovered", "\u2581in", "\u2581the", "\u2581", "1", "9", "7", "0", "s", ".", "\u2581#", "2", "2", "0", "\u2581--", "\u2581The", "\u2581R", "ise", "\u2581Of", "\u2581The", "\u2581Trans", "human", "ists", "\u2581", "0"]], "entropy": [[1.34375, 0.47265625, 0.1173095703125, 0.63134765625, 0.00011211633682250977, 0.2010498046875, 0.9091796875, 0.079833984375, 0.004871368408203125, 0.0002384185791015625, 2.3424625396728516e-05, 0.004909515380859375, 0.0023746490478515625, 0.0003516674041748047, 0.0019474029541015625, 0.00849151611328125, 0.002201080322265625, 0.00298309326171875, 0.273681640625, 0.53125, 0.01140594482421875, 0.0205230712890625, 0.82763671875, 0.01342010498046875, 2.4974346160888672e-05, 0.031585693359375, 0.00037670135498046875, 0.0053253173828125, 0.39013671875, 1.451171875, 3.783203125, 2.546875, 2.765625, 3.07421875, 5.12890625, 5.1171875, 2.25, 0.56396484375, 3.166015625, 3.798828125, 2.142578125, 2.48828125, 2.931640625, 1.8544921875]], "avg_entropy": [1.112545144828883], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "late 1970s", "score_of_biggest_cluster": 0.16011403501033783, "score_of_first_answer": 0.16011403501033783, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.16011403501033783, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4331107860612061, "std_of_first_answer": 0.4331107860612061, "avg_entropy_of_first_answer": 1.112545144828883, "lex_sim": 1.0}
{"question": "who has the most followers in the world on instagram", "answer": ["Cristiano Ronaldo"], "scores": [[0.70556640625, 0.9990234375, 0.99951171875, 1.0, 1.0]], "normalized_score": [0.9323528409004211], "tokens": [["\u2581Crist", "iano", "\u2581R", "onal", "do"]], "entropy": [[1.365234375, 0.007312774658203125, 0.002986907958984375, 0.0008249282836914062, 0.0008220672607421875]], "avg_entropy": [0.2754362106323242], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Instagram's own account", "score_of_biggest_cluster": 0.9323528409004211, "score_of_first_answer": 0.9323528409004211, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.70556640625, "avg_score": 0.9323528409004211, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.11762751052236654, "std_of_first_answer": 0.11762751052236654, "avg_entropy_of_first_answer": 0.2754362106323242, "lex_sim": 1.0}
{"question": "what is cost of first class mail stamp", "answer": ["The cost of a first-class mail stamp can vary depending on the type of stamp and current postal rates."], "scores": [[0.236083984375, 0.9765625, 0.99609375, 0.99755859375, 0.80908203125, 0.91455078125, 1.0, 0.984375, 0.9990234375, 0.1351318359375, 0.98779296875, 0.79052734375, 0.9990234375, 0.87255859375, 0.014495849609375, 0.94482421875, 0.6083984375, 0.58154296875, 0.025909423828125, 0.64306640625, 0.9931640625, 0.96240234375, 0.59228515625, 0.8642578125, 0.5263671875, 0.436767578125, 0.99951171875, 1.0, 0.9990234375, 0.99951171875, 0.95703125, 0.97314453125, 0.91455078125, 0.91650390625, 0.84765625, 0.99853515625, 1.0, 1.0, 1.0, 0.96923828125, 0.83642578125, 8.940696716308594e-07, 1.1920928955078125e-06, 0.16162109375, 0.99951171875, 0.003101348876953125, 0.000598907470703125, 0.0006809234619140625]], "normalized_score": [0.2513071894645691], "tokens": [["\u2581The", "\u2581cost", "\u2581of", "\u2581a", "\u2581first", "-", "class", "\u2581mail", "\u2581stamp", "\u2581can", "\u2581vary", "\u2581depending", "\u2581on", "\u2581the", "\u2581type", "\u2581of", "\u2581stamp", "\u2581and", "\u2581current", "\u2581postal", "\u2581rates", ".", "\u2581Please", "\u2581check", "\u2581the", "\u2581United", "\u2581States", "\u2581Post", "al", "\u2581Service", "\u2581website", "\u2581for", "\u2581the", "\u2581most", "\u2581up", "-", "to", "-", "date", "\u2581information", ".", "\u2581#", "Me", "To", "o", ":", "\u2581N", "ana"]], "entropy": [[2.36328125, 0.141357421875, 0.033416748046875, 0.01812744140625, 0.5205078125, 0.293212890625, 0.00015270709991455078, 0.092529296875, 0.00682830810546875, 1.4140625, 0.07733154296875, 0.8349609375, 0.0086669921875, 0.5498046875, 1.2783203125, 0.222900390625, 1.1416015625, 1.34375, 1.189453125, 1.24609375, 0.050689697265625, 0.1953125, 1.634765625, 0.603515625, 0.70751953125, 1.404296875, 0.00347900390625, 0.002239227294921875, 0.00655364990234375, 0.006496429443359375, 0.21923828125, 0.13330078125, 0.36376953125, 0.3408203125, 0.54248046875, 0.01202392578125, 0.0007920265197753906, 0.0010824203491210938, 0.00013637542724609375, 0.161376953125, 0.470703125, 0.6767578125, 2.939453125, 2.763671875, 0.0064239501953125, 1.9912109375, 5.015625, 2.8984375]], "avg_entropy": [0.7485110883911451], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "49 cents", "score_of_biggest_cluster": 0.2513071894645691, "score_of_first_answer": 0.2513071894645691, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 8.940696716308594e-07, "avg_score": 0.2513071894645691, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3677157668201814, "std_of_first_answer": 0.3677157668201814, "avg_entropy_of_first_answer": 0.7485110883911451, "lex_sim": 1.0}
{"question": "who came first second and third on the grand national", "answer": ["1. Red Rum (1973, 1974, 1977)"], "scores": [[0.242431640625, 0.998046875, 0.80810546875, 0.043212890625, 0.285400390625, 0.1771240234375, 0.94677734375, 0.9990234375, 1.0, 0.921875, 0.8818359375, 0.99755859375, 1.0, 1.0, 1.0, 1.0, 0.9658203125, 0.9658203125, 1.0, 1.0, 1.0, 1.0, 0.94287109375]], "normalized_score": [0.7015690803527832], "tokens": [["\u2581", "1", ".", "\u2581Red", "\u2581Rum", "\u2581(", "1", "9", "7", "3", ",", "\u2581", "1", "9", "7", "4", ",", "\u2581", "1", "9", "7", "7", ")"]], "entropy": [[3.015625, 0.019287109375, 0.67626953125, 2.419921875, 1.470703125, 1.4150390625, 0.3896484375, 0.01068115234375, 0.00031280517578125, 0.280029296875, 0.58154296875, 0.0183563232421875, 0.0012054443359375, 2.7894973754882812e-05, 1.2218952178955078e-05, 0.0014553070068359375, 0.178955078125, 0.1663818359375, 4.857778549194336e-05, 0.000339508056640625, 2.2172927856445312e-05, 0.0016880035400390625, 0.2421875]], "avg_entropy": [0.47346696646317193], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Pleasant Company", "score_of_biggest_cluster": 0.7015690803527832, "score_of_first_answer": 0.7015690803527832, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.043212890625, "avg_score": 0.7015690803527832, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3026440382181913, "std_of_first_answer": 0.3026440382181913, "avg_entropy_of_first_answer": 0.47346696646317193, "lex_sim": 1.0}
{"question": "what is a dropped pin on google maps for", "answer": ["A dropped pin on Google Maps is a location marker that can be placed on the map to indicate a point of interest, a favorite spot, or a spot saved for later use."], "scores": [[0.63134765625, 0.96142578125, 1.0, 0.9560546875, 0.9990234375, 0.9990234375, 0.96630859375, 0.68310546875, 0.423583984375, 0.916015625, 0.90478515625, 0.78857421875, 0.99951171875, 0.6748046875, 0.86474609375, 0.65087890625, 0.9990234375, 0.87548828125, 0.65234375, 0.953125, 0.06597900390625, 0.9892578125, 0.9990234375, 0.2261962890625, 0.65673828125, 0.1002197265625, 0.2152099609375, 0.98681640625, 0.8623046875, 0.51708984375, 0.0007834434509277344, 0.1116943359375, 0.9091796875, 0.07635498046875, 0.76416015625, 0.9951171875, 0.19873046875, 0.20361328125, 0.1224365234375, 0.7001953125, 0.80126953125, 0.8720703125, 0.5595703125, 0.92919921875, 0.609375, 0.5302734375, 0.99658203125, 0.0227813720703125, 0.241943359375, 0.990234375]], "normalized_score": [0.4637225866317749], "tokens": [["\u2581A", "\u2581dropped", "\u2581pin", "\u2581on", "\u2581Google", "\u2581Maps", "\u2581is", "\u2581a", "\u2581location", "\u2581marker", "\u2581that", "\u2581can", "\u2581be", "\u2581placed", "\u2581on", "\u2581the", "\u2581map", "\u2581to", "\u2581indicate", "\u2581a", "\u2581point", "\u2581of", "\u2581interest", ",", "\u2581a", "\u2581favorite", "\u2581spot", ",", "\u2581or", "\u2581a", "\u2581spot", "\u2581saved", "\u2581for", "\u2581later", "\u2581use", ".", "\u2581It", "\u2581is", "\u2581a", "\u2581way", "\u2581to", "\u2581save", "\u2581a", "\u2581location", "\u2581on", "\u2581the", "\u2581map", ",", "\u2581which", "\u2581can"]], "entropy": [[1.5595703125, 0.2354736328125, 0.002437591552734375, 0.1910400390625, 0.007427215576171875, 0.00952911376953125, 0.2039794921875, 0.7607421875, 1.3125, 0.47900390625, 0.455078125, 0.80517578125, 0.007030487060546875, 0.8642578125, 0.55419921875, 0.65087890625, 0.0115814208984375, 0.51416015625, 1.2333984375, 0.19580078125, 0.3984375, 0.06256103515625, 0.0088653564453125, 0.81298828125, 0.8369140625, 2.7421875, 0.77294921875, 0.070068359375, 0.412109375, 1.02734375, 1.802734375, 1.419921875, 0.42333984375, 0.61376953125, 0.69189453125, 0.038787841796875, 0.9853515625, 0.744140625, 1.5224609375, 1.3896484375, 0.5439453125, 0.62744140625, 1.076171875, 0.336181640625, 1.2099609375, 0.86572265625, 0.0292816162109375, 1.244140625, 1.98046875, 0.06982421875]], "avg_entropy": [0.6962575531005859], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "marks locations in Google Maps", "score_of_biggest_cluster": 0.4637225866317749, "score_of_first_answer": 0.4637225866317749, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0007834434509277344, "avg_score": 0.4637225866317749, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.3349015867001353, "std_of_first_answer": 0.3349015867001353, "avg_entropy_of_first_answer": 0.6962575531005859, "lex_sim": 1.0}
{"question": "when did disney art of animation resort open", "answer": ["July 14, 2012"], "scores": [[0.00222015380859375, 0.9931640625, 0.9375, 0.7724609375, 0.92333984375, 0.9951171875, 0.99951171875, 1.0, 0.71630859375, 0.99853515625]], "normalized_score": [0.5035862922668457], "tokens": [["\u2581July", "\u2581", "1", "4", ",", "\u2581", "2", "0", "1", "2"]], "entropy": [[1.37890625, 0.045806884765625, 0.2880859375, 0.9794921875, 0.307373046875, 0.03436279296875, 0.004093170166015625, 0.0001723766326904297, 0.6123046875, 0.0147552490234375]], "avg_entropy": [0.36653525829315187], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "May 31, 2012", "score_of_biggest_cluster": 0.5035862922668457, "score_of_first_answer": 0.5035862922668457, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.00222015380859375, "avg_score": 0.5035862922668457, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.29351378974269876, "std_of_first_answer": 0.29351378974269876, "avg_entropy_of_first_answer": 0.36653525829315187, "lex_sim": 1.0}
{"question": "who starred in the pirates of the caribbean", "answer": ["Johnny Depp ## Overview"], "scores": [[0.99365234375, 0.99951171875, 1.0, 0.0, 4.374980926513672e-05, 0.004215240478515625]], "normalized_score": [0.0], "tokens": [["\u2581Johnny", "\u2581De", "pp", "\u2581##", "\u2581Over", "view"]], "entropy": [[0.057373046875, 0.003932952880859375, 0.00047588348388671875, 1.130859375, 5.9765625, 2.26171875]], "avg_entropy": [1.5718204180399578], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Johnny Depp", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.49815698107471573, "std_of_first_answer": 0.49815698107471573, "avg_entropy_of_first_answer": 1.5718204180399578, "lex_sim": 1.0}
{"question": "when was the death penalty reinstated in oregon", "answer": ["1978"], "scores": [[0.319091796875, 0.998046875, 0.99853515625, 0.356689453125, 0.9814453125]], "normalized_score": [0.6446400284767151], "tokens": [["\u2581", "1", "9", "7", "8"]], "entropy": [[1.947265625, 0.01666259765625, 0.01291656494140625, 0.8916015625, 0.12103271484375]], "avg_entropy": [0.5978958129882812], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1984", "score_of_biggest_cluster": 0.6446400284767151, "score_of_first_answer": 0.6446400284767151, "max_score_of_first_answer": 0.99853515625, "min_score_of_first_answer": 0.319091796875, "avg_score": 0.6446400284767151, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3210571342437223, "std_of_first_answer": 0.3210571342437223, "avg_entropy_of_first_answer": 0.5978958129882812, "lex_sim": 1.0}
{"question": "who wrote the song would i lie to you", "answer": ["Charles Norman Hayward and Colin Charles Greenwood > Evaluaci\u00f3n y m\u00e9tricas > Evaluaci\u00f3n de contenido > Evaluaci\u00f3n de usuarios"], "scores": [[0.362060546875, 0.0024547576904296875, 0.50244140625, 0.99072265625, 0.195556640625, 0.0220489501953125, 1.0, 0.2230224609375, 0.4716796875, 0.41259765625, 1.1920928955078125e-07, 0.0009560585021972656, 3.2901763916015625e-05, 0.00010842084884643555, 0.01340484619140625, 0.0005517005920410156, 0.9423828125, 0.4013671875, 0.3212890625, 0.062255859375, 0.9140625, 0.9189453125, 0.388916015625, 0.159912109375, 0.951171875, 0.50830078125, 0.1361083984375, 0.92333984375, 0.9638671875, 0.371826171875, 0.0195465087890625, 0.19189453125, 0.998046875]], "normalized_score": [0.07007811963558197], "tokens": [["\u2581Charles", "\u2581Norman", "\u2581Hay", "ward", "\u2581and", "\u2581Col", "in", "\u2581Charles", "\u2581Green", "wood", "\u2581>", "\u2581E", "valu", "aci\u00f3n", "\u2581y", "\u2581m\u00e9", "tr", "icas", "\u2581>", "\u2581E", "valu", "aci\u00f3n", "\u2581de", "\u2581conten", "ido", "\u2581>", "\u2581E", "valu", "aci\u00f3n", "\u2581de", "\u2581us", "u", "arios"]], "entropy": [[1.7548828125, 4.6484375, 2.0, 0.07012939453125, 1.68359375, 2.486328125, 0.001552581787109375, 3.00390625, 1.8271484375, 1.498046875, 1.8974609375, 4.51953125, 4.453125, 0.9482421875, 3.19921875, 4.84765625, 0.2529296875, 0.71337890625, 1.955078125, 4.71484375, 0.64892578125, 0.3759765625, 2.73046875, 4.23046875, 0.1968994140625, 2.13671875, 4.50390625, 0.51904296875, 0.216064453125, 1.7021484375, 4.6328125, 0.491455078125, 0.0188446044921875]], "avg_entropy": [2.087249177874941], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Peter Vale", "score_of_biggest_cluster": 0.07007811963558197, "score_of_first_answer": 0.07007811963558197, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.07007811963558197, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37240888807851197, "std_of_first_answer": 0.37240888807851197, "avg_entropy_of_first_answer": 2.087249177874941, "lex_sim": 1.0}
{"question": "cast of the have and have nots play", "answer": ["* Lauren London as Whitney"], "scores": [[0.01291656494140625, 0.002162933349609375, 0.828125, 0.7998046875, 0.81201171875, 0.07470703125, 0.9970703125]], "normalized_score": [0.14120355248451233], "tokens": [["\u2581*", "\u2581La", "uren", "\u2581London", "\u2581as", "\u2581Whit", "ney"]], "entropy": [[3.4375, 3.833984375, 0.9951171875, 1.501953125, 0.67529296875, 3.513671875, 0.0212554931640625]], "avg_entropy": [1.9969678606305803], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Tony Hightower as Frank", "score_of_biggest_cluster": 0.14120355248451233, "score_of_first_answer": 0.14120355248451233, "max_score_of_first_answer": 0.9970703125, "min_score_of_first_answer": 0.002162933349609375, "avg_score": 0.14120355248451233, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41539011080536337, "std_of_first_answer": 0.41539011080536337, "avg_entropy_of_first_answer": 1.9969678606305803, "lex_sim": 1.0}
{"question": "who was elected senator of illinois in 1858", "answer": ["Abraham Lincoln"], "scores": [[0.85693359375, 0.9990234375]], "normalized_score": [0.9252549409866333], "tokens": [["\u2581Abraham", "\u2581Lincoln"]], "entropy": [[0.451416015625, 0.007068634033203125]], "avg_entropy": [0.22924232482910156], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Stephen A. Douglas", "score_of_biggest_cluster": 0.9252549409866333, "score_of_first_answer": 0.9252549409866333, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 0.85693359375, "avg_score": 0.9252549409866333, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.071044921875, "std_of_first_answer": 0.071044921875, "avg_entropy_of_first_answer": 0.22924232482910156, "lex_sim": 1.0}
{"question": "when does the champions league quarter finals start", "answer": ["The UEFA Champions League quarter-finals typically start in mid-April."], "scores": [[0.1907958984375, 0.332275390625, 0.998046875, 0.9990234375, 0.9013671875, 0.99462890625, 1.0, 0.9853515625, 0.45361328125, 0.1474609375, 0.92138671875, 0.65966796875, 0.962890625, 0.98486328125, 0.99951171875, 0.83447265625, 0.45068359375, 0.070556640625, 0.01100921630859375, 0.03021240234375, 0.99951171875, 0.9931640625, 0.0860595703125, 0.90869140625, 0.56689453125, 0.69775390625, 0.05584716796875, 0.9150390625, 0.23876953125, 0.7587890625, 0.9970703125, 0.5302734375, 0.76416015625, 0.99755859375, 0.96142578125, 1.0, 1.0, 0.98779296875, 0.9990234375, 0.96875, 0.99462890625, 1.8477439880371094e-06, 0.0218505859375, 0.051239013671875, 0.08056640625, 0.07110595703125, 0.0012483596801757812, 0.072021484375]], "normalized_score": [0.27816206216812134], "tokens": [["\u2581The", "\u2581UEFA", "\u2581Champions", "\u2581League", "\u2581quarter", "-", "final", "s", "\u2581typically", "\u2581start", "\u2581in", "\u2581mid", "-", "A", "pril", ".", "\u2581The", "\u2581specific", "\u2581schedule", "\u2581depends", "\u2581on", "\u2581the", "\u2581calendar", "\u2581year", "\u2581and", "\u2581the", "\u2581exact", "\u2581dates", "\u2581are", "\u2581determined", "\u2581by", "\u2581UEFA", ",", "\u2581the", "\u2581gover", "ning", "\u2581body", "\u2581of", "\u2581European", "\u2581football", ".", "\u2581#", "1", "7", "9", "8", ":", "\u2581The"]], "entropy": [[2.591796875, 1.8642578125, 0.0179901123046875, 0.006511688232421875, 0.40625, 0.037750244140625, 0.0002505779266357422, 0.1068115234375, 1.966796875, 0.87060546875, 0.329345703125, 0.9375, 0.1895751953125, 0.10284423828125, 0.002819061279296875, 0.68896484375, 1.52734375, 0.35693359375, 0.83447265625, 1.673828125, 0.0025005340576171875, 0.04998779296875, 1.3115234375, 0.396240234375, 0.74951171875, 1.2451171875, 3.19921875, 0.4609375, 1.412109375, 1.033203125, 0.0257415771484375, 0.7060546875, 0.62451171875, 0.0225677490234375, 0.221923828125, 1.5556812286376953e-05, 0.0002899169921875, 0.07244873046875, 0.01103973388671875, 0.1697998046875, 0.042205810546875, 0.8046875, 4.32421875, 2.755859375, 2.900390625, 2.59765625, 2.515625, 5.40234375]], "avg_entropy": [0.9910495492319266], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "16 March 2018", "score_of_biggest_cluster": 0.27816206216812134, "score_of_first_answer": 0.27816206216812134, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.8477439880371094e-06, "avg_score": 0.27816206216812134, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40092373070160203, "std_of_first_answer": 0.40092373070160203, "avg_entropy_of_first_answer": 0.9910495492319266, "lex_sim": 1.0}
{"question": "actor who plays dr avery on grey's anatomy", "answer": ["Jesse Williams #MentorMondays: How to Build Your Mentorship Toolkit"], "scores": [[0.431884765625, 0.302001953125, 0.99755859375, 2.0265579223632812e-06, 0.0030384063720703125, 0.00017595291137695312, 0.1986083984375, 0.0758056640625, 0.3525390625, 0.036712646484375, 0.0032596588134765625, 0.01751708984375, 0.445556640625, 0.0977783203125, 0.11474609375, 0.0018148422241210938, 0.459228515625, 0.97314453125, 0.9296875, 0.18408203125, 0.8154296875]], "normalized_score": [0.05150103569030762], "tokens": [["\u2581J", "esse", "\u2581Williams", "\u2581#", "M", "ent", "or", "M", "ond", "ays", ":", "\u2581How", "\u2581to", "\u2581Build", "\u2581Your", "\u2581M", "ent", "or", "ship", "\u2581Tool", "kit"]], "entropy": [[2.13671875, 0.6640625, 0.0189666748046875, 0.7783203125, 3.861328125, 3.099609375, 0.96826171875, 2.24609375, 2.2109375, 0.171875, 2.70703125, 4.515625, 2.673828125, 4.88671875, 2.4375, 0.88916015625, 1.099609375, 0.1492919921875, 0.38037109375, 2.109375, 0.59423828125]], "avg_entropy": [1.838043939499628], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Jesse Wesley Williams", "score_of_biggest_cluster": 0.05150103569030762, "score_of_first_answer": 0.05150103569030762, "max_score_of_first_answer": 0.99755859375, "min_score_of_first_answer": 2.0265579223632812e-06, "avg_score": 0.05150103569030762, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.33883564736868704, "std_of_first_answer": 0.33883564736868704, "avg_entropy_of_first_answer": 1.838043939499628, "lex_sim": 1.0}
{"question": "what is the breakdown product formed when one phosphate group is removed from atp", "answer": ["ADP (Adenosine Diphosphate) ### What is the purpose of the LambdaCalculator class?"], "scores": [[0.162841796875, 1.0, 0.3349609375, 0.78857421875, 1.0, 1.0, 1.0, 0.72509765625, 0.92138671875, 0.9990234375, 1.0, 0.97998046875, 0.0, 0.0008220672607421875, 0.73388671875, 0.8125, 0.0084381103515625, 0.986328125, 0.392333984375, 0.0003063678741455078, 0.01482391357421875, 0.0011911392211914062, 0.07659912109375, 0.12841796875, 0.11614990234375]], "normalized_score": [0.0], "tokens": [["\u2581AD", "P", "\u2581(", "A", "den", "os", "ine", "\u2581Di", "ph", "osph", "ate", ")", "\u2581###", "\u2581What", "\u2581is", "\u2581the", "\u2581purpose", "\u2581of", "\u2581the", "\u2581L", "ambda", "Calcul", "ator", "\u2581class", "?"]], "entropy": [[1.0654296875, 0.0016193389892578125, 1.2138671875, 0.53271484375, 0.0002090930938720703, 0.0008382797241210938, 0.0003714561462402344, 0.638671875, 0.3134765625, 0.009124755859375, 0.00037789344787597656, 0.10614013671875, 0.297607421875, 4.4296875, 1.6455078125, 1.1708984375, 3.185546875, 0.10223388671875, 2.650390625, 4.61328125, 4.37109375, 4.828125, 0.77392578125, 3.037109375, 1.2724609375]], "avg_entropy": [1.4504283905029296], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "adenosine diphosphate (ADP)", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4244052033286982, "std_of_first_answer": 0.4244052033286982, "avg_entropy_of_first_answer": 1.4504283905029296, "lex_sim": 1.0}
{"question": "when was the last time oklahoma won a national championship in football", "answer": ["2000"], "scores": [[0.86474609375, 0.9951171875, 1.0, 0.98193359375, 0.99951171875]], "normalized_score": [0.9667775630950928], "tokens": [["\u2581", "2", "0", "0", "0"]], "entropy": [[0.6640625, 0.0313720703125, 0.0011692047119140625, 0.09283447265625, 0.006237030029296875]], "avg_entropy": [0.1591350555419922], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2003", "score_of_biggest_cluster": 0.9667775630950928, "score_of_first_answer": 0.9667775630950928, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.86474609375, "avg_score": 0.9667775630950928, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.05216800165550254, "std_of_first_answer": 0.05216800165550254, "avg_entropy_of_first_answer": 0.1591350555419922, "lex_sim": 1.0}
{"question": "when was the last time michigan basketball won the championship", "answer": ["April 3, 2018 #0221: Batman \u2013 The Animated Series The Legion of Doom Set"], "scores": [[0.033660888671875, 0.986328125, 0.056182861328125, 0.92626953125, 0.99658203125, 0.9384765625, 1.0, 0.921875, 0.79345703125, 4.887580871582031e-06, 0.008026123046875, 0.03662109375, 0.0313720703125, 0.07415771484375, 0.0011548995971679688, 4.291534423828125e-06, 0.2149658203125, 0.0062255859375, 0.444091796875, 0.368408203125, 0.99951171875, 0.99658203125, 0.0015716552734375, 0.00879669189453125, 0.004047393798828125, 0.99755859375, 0.974609375, 0.9990234375, 2.5033950805664062e-06]], "normalized_score": [0.044365040957927704], "tokens": [["\u2581April", "\u2581", "3", ",", "\u2581", "2", "0", "1", "8", "\u2581#", "0", "2", "2", "1", ":", "\u2581Bat", "man", "\u2581\u2013", "\u2581The", "\u2581Anim", "ated", "\u2581Series", "\u2581The", "\u2581Leg", "ion", "\u2581of", "\u2581Do", "om", "\u2581Set"]], "entropy": [[0.66650390625, 0.09490966796875, 0.67578125, 0.33154296875, 0.024749755859375, 0.23486328125, 6.765127182006836e-05, 0.323974609375, 0.69775390625, 1.5810546875, 4.54296875, 3.66796875, 2.142578125, 3.1328125, 3.076171875, 4.12890625, 2.1640625, 3.728515625, 3.63671875, 2.2890625, 0.00290679931640625, 0.030731201171875, 2.826171875, 3.90625, 0.4208984375, 0.0200653076171875, 0.182861328125, 0.007785797119140625, 2.421875]], "avg_entropy": [1.6193280363905018], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1989", "score_of_biggest_cluster": 0.044365040957927704, "score_of_first_answer": 0.044365040957927704, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.5033950805664062e-06, "avg_score": 0.044365040957927704, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44890361163578374, "std_of_first_answer": 0.44890361163578374, "avg_entropy_of_first_answer": 1.6193280363905018, "lex_sim": 1.0}
{"question": "when was you'll never walk alone first released", "answer": ["U2"], "scores": [[3.8564205169677734e-05, 0.30322265625]], "normalized_score": [0.0034195820335298777], "tokens": [["\u2581U", "2"]], "entropy": [[1.029296875, 3.458984375]], "avg_entropy": [2.244140625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1945", "score_of_biggest_cluster": 0.0034195820335298777, "score_of_first_answer": 0.0034195820335298777, "max_score_of_first_answer": 0.30322265625, "min_score_of_first_answer": 3.8564205169677734e-05, "avg_score": 0.0034195820335298777, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.15159204602241516, "std_of_first_answer": 0.15159204602241516, "avg_entropy_of_first_answer": 2.244140625, "lex_sim": 1.0}
{"question": "do you cut cards to the left or right", "answer": ["It depends on the game and the cultural context in which it is played."], "scores": [[0.2783203125, 0.671875, 0.998046875, 0.95556640625, 0.254150390625, 0.69921875, 0.91552734375, 0.00681304931640625, 0.06884765625, 0.136962890625, 0.99853515625, 0.63232421875, 0.99365234375, 0.278076171875, 0.89599609375, 0.55615234375, 0.84912109375, 0.8193359375, 0.99072265625, 0.65478515625, 0.84130859375, 0.9951171875, 0.998046875, 0.99951171875, 0.78515625, 0.91650390625, 0.79248046875, 1.0, 0.9912109375, 0.334228515625, 0.96728515625, 0.99072265625, 1.0, 1.0, 0.9990234375, 1.0, 0.99755859375, 1.7881393432617188e-07, 0.0003273487091064453, 0.7470703125, 0.01044464111328125, 0.0013723373413085938, 6.473064422607422e-05, 0.004459381103515625, 0.194580078125, 0.0972900390625, 0.005924224853515625, 0.1531982421875]], "normalized_score": [0.19141440093517303], "tokens": [["\u2581It", "\u2581depends", "\u2581on", "\u2581the", "\u2581game", "\u2581and", "\u2581the", "\u2581cultural", "\u2581context", "\u2581in", "\u2581which", "\u2581it", "\u2581is", "\u2581played", ".", "\u2581In", "\u2581some", "\u2581games", ",", "\u2581cards", "\u2581are", "\u2581cut", "\u2581to", "\u2581the", "\u2581left", ",", "\u2581while", "\u2581in", "\u2581others", ",", "\u2581they", "\u2581are", "\u2581cut", "\u2581to", "\u2581the", "\u2581right", ".", "\u2581#", "TB", "T", ":", "\u2581Sh", "op", "\u2581T", "alk", "\u2581with", "\u2581S", "eth"]], "entropy": [[2.845703125, 0.78466796875, 0.01556396484375, 0.2568359375, 1.3173828125, 0.95166015625, 0.56787109375, 3.19140625, 2.251953125, 0.84814453125, 0.0121612548828125, 0.67431640625, 0.0411376953125, 0.59814453125, 0.356201171875, 1.44921875, 0.66259765625, 0.5439453125, 0.07000732421875, 0.9677734375, 0.4658203125, 0.039947509765625, 0.0185699462890625, 0.0024318695068359375, 0.5244140625, 0.33447265625, 0.58251953125, 0.00186920166015625, 0.051422119140625, 0.64404296875, 0.1529541015625, 0.055328369140625, 0.0018777847290039062, 0.0012760162353515625, 0.006317138671875, 0.00024175643920898438, 0.0208740234375, 1.595703125, 4.37109375, 1.2158203125, 2.650390625, 4.515625, 0.219482421875, 4.33203125, 3.591796875, 3.396484375, 5.14453125, 2.8984375]], "avg_entropy": [1.1508847574392955], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "right", "score_of_biggest_cluster": 0.19141440093517303, "score_of_first_answer": 0.19141440093517303, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.19141440093517303, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39631216573333355, "std_of_first_answer": 0.39631216573333355, "avg_entropy_of_first_answer": 1.1508847574392955, "lex_sim": 1.0}
{"question": "when did the wave hill walk off end", "answer": ["The Wave, an area of sandstone formations located in Arizona, USA has been closed to the public since 2009."], "scores": [[0.2001953125, 0.56005859375, 0.99951171875, 0.00016927719116210938, 0.045806884765625, 1.990795135498047e-05, 0.97216796875, 0.032257080078125, 0.03045654296875, 0.477294921875, 1.0, 0.8154296875, 0.68017578125, 0.03515625, 0.62646484375, 0.7958984375, 0.002338409423828125, 0.33203125, 0.0163116455078125, 0.931640625, 0.29736328125, 0.998046875, 0.9287109375, 0.87158203125, 0.845703125, 1.0, 0.104736328125, 0.70458984375, 0.327880859375, 0.1651611328125, 0.61376953125, 0.63671875, 0.328857421875, 0.75439453125, 0.80078125, 0.99609375, 0.833984375, 0.7509765625, 0.63037109375, 0.708984375, 0.599609375, 1.0, 0.64794921875, 0.98779296875, 0.9853515625, 0.007335662841796875, 0.53466796875, 0.89697265625, 0.60546875, 0.348388671875]], "normalized_score": [0.2588152289390564], "tokens": [["\u2581The", "\u2581W", "ave", ",", "\u2581an", "\u2581area", "\u2581of", "\u2581sand", "stone", "\u2581form", "ations", "\u2581located", "\u2581in", "\u2581Arizona", ",", "\u2581USA", "\u2581has", "\u2581been", "\u2581closed", "\u2581to", "\u2581the", "\u2581public", "\u2581since", "\u2581", "2", "0", "0", "9", ".", "\u2581It", "\u2581is", "\u2581not", "\u2581possible", "\u2581to", "\u2581walk", "\u2581off", "\u2581the", "\u2581end", "\u2581of", "\u2581the", "\u2581W", "ave", "\u2581as", "\u2581it", "\u2581is", "\u2581situated", "\u2581in", "\u2581a", "\u2581remote", "\u2581area"]], "entropy": [[2.216796875, 2.228515625, 0.00725555419921875, 0.037628173828125, 1.548828125, 1.8984375, 0.2108154296875, 3.478515625, 0.296630859375, 1.35546875, 0.00014090538024902344, 0.8056640625, 0.95947265625, 0.9052734375, 0.79638671875, 0.931640625, 0.267578125, 1.2978515625, 3.294921875, 0.333251953125, 1.4951171875, 0.01568603515625, 0.360595703125, 0.66650390625, 0.4306640625, 0.0009226799011230469, 0.58740234375, 1.1865234375, 1.6123046875, 2.125, 1.0439453125, 1.328125, 1.3125, 0.56298828125, 0.8564453125, 0.036590576171875, 0.66796875, 0.74755859375, 0.931640625, 0.89404296875, 1.1845703125, 0.00032520294189453125, 1.0048828125, 0.0909423828125, 0.09564208984375, 1.8837890625, 1.0927734375, 0.4169921875, 1.0380859375, 1.2373046875]], "avg_entropy": [0.9555781602859497], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "16 August 1975", "score_of_biggest_cluster": 0.2588152289390564, "score_of_first_answer": 0.2588152289390564, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.990795135498047e-05, "avg_score": 0.2588152289390564, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.34865529702140957, "std_of_first_answer": 0.34865529702140957, "avg_entropy_of_first_answer": 0.9555781602859497, "lex_sim": 1.0}
{"question": "when was the last time.michigan beat ohio state", "answer": ["2016 #1 Post by jajaborola4 \u00bb Wed Sep 06, 2017 1:35 am"], "scores": [[0.61376953125, 1.0, 1.0, 0.99951171875, 0.6572265625, 6.020069122314453e-06, 0.01178741455078125, 1.6689300537109375e-06, 0.2047119140625, 0.018585205078125, 0.0018777847290039062, 0.06976318359375, 5.8591365814208984e-05, 0.01007843017578125, 0.071533203125, 0.14501953125, 0.102294921875, 0.9990234375, 0.373779296875, 0.90771484375, 0.99755859375, 0.99072265625, 0.9990234375, 1.0, 0.99609375, 0.99951171875, 0.998046875, 0.34423828125, 0.22705078125, 0.1763916015625, 0.11407470703125, 0.51416015625]], "normalized_score": [0.09718488901853561], "tokens": [["\u2581", "2", "0", "1", "6", "\u2581#", "1", "\u2581Post", "\u2581by", "\u2581j", "aj", "abor", "ola", "4", "\u2581\u00bb", "\u2581Wed", "\u2581Sep", "\u2581", "0", "6", ",", "\u2581", "2", "0", "1", "7", "\u2581", "1", ":", "3", "5", "\u2581am"]], "entropy": [[1.4541015625, 0.0021305084228515625, 0.0016689300537109375, 0.00618743896484375, 1.048828125, 0.98193359375, 4.93359375, 2.3828125, 3.134765625, 6.3203125, 3.892578125, 4.75390625, 3.849609375, 3.57421875, 3.423828125, 2.525390625, 2.119140625, 0.008087158203125, 1.1767578125, 0.482666015625, 0.0186920166015625, 0.06719970703125, 0.007541656494140625, 6.729364395141602e-05, 0.028411865234375, 0.004734039306640625, 0.019744873046875, 2.0078125, 1.3916015625, 1.7919921875, 2.302734375, 0.71435546875]], "avg_entropy": [1.7008564043790102], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2011", "score_of_biggest_cluster": 0.09718488901853561, "score_of_first_answer": 0.09718488901853561, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.6689300537109375e-06, "avg_score": 0.09718488901853561, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4236672145490579, "std_of_first_answer": 0.4236672145490579, "avg_entropy_of_first_answer": 1.7008564043790102, "lex_sim": 1.0}
{"question": "who sang the theme song for the man with the golden gun", "answer": ["Lulu ### What is \"Minecraft\"?"], "scores": [[0.9990234375, 1.0, 0.0, 0.00031065940856933594, 0.50439453125, 0.0014276504516601562, 0.01132965087890625, 8.225440979003906e-06, 0.306396484375, 0.8408203125]], "normalized_score": [0.0], "tokens": [["\u2581L", "ulu", "\u2581###", "\u2581What", "\u2581is", "\u2581\"", "M", "ine", "craft", "\"?"]], "entropy": [[0.00809478759765625, 0.0016384124755859375, 0.814453125, 4.4140625, 2.455078125, 1.376953125, 1.7197265625, 1.7548828125, 2.607421875, 0.73193359375]], "avg_entropy": [1.5884244918823243], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Lulu", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4136631452393702, "std_of_first_answer": 0.4136631452393702, "avg_entropy_of_first_answer": 1.5884244918823243, "lex_sim": 1.0}
{"question": "who sings the pokemon theme song season 1", "answer": ["Jason Paige #1 New York Times bestselling author Sandra Brown delivers a heart-pounding story of suspense and twisted passion as a woman is drawn to the edge of danger in the company of a madman."], "scores": [[0.95556640625, 0.978515625, 0.96630859375, 7.152557373046875e-07, 0.0260467529296875, 0.0003261566162109375, 0.83935546875, 0.73876953125, 0.1351318359375, 0.44873046875, 0.9462890625, 0.81787109375, 9.357929229736328e-05, 0.94873046875, 0.96044921875, 0.004734039306640625, 0.9755859375, 0.6865234375, 0.352783203125, 0.99755859375, 0.7041015625, 0.96630859375, 0.53759765625, 0.99609375, 0.95947265625, 0.99951171875, 0.98388671875, 0.004131317138671875, 0.98974609375, 0.76025390625, 0.401611328125, 0.93310546875, 0.931640625, 0.62353515625, 0.93896484375, 0.703125, 0.93115234375, 0.87109375, 0.99951171875, 0.275390625, 0.69873046875, 0.278076171875, 0.05194091796875, 0.9990234375, 0.98193359375, 0.0097503662109375, 0.94287109375, 0.93310546875]], "normalized_score": [0.2566223442554474], "tokens": [["\u2581Jason", "\u2581Pa", "ige", "\u2581#", "1", "\u2581New", "\u2581York", "\u2581Times", "\u2581best", "s", "elling", "\u2581author", "\u2581Sand", "ra", "\u2581Brown", "\u2581del", "ivers", "\u2581a", "\u2581heart", "-", "p", "ounding", "\u2581story", "\u2581of", "\u2581susp", "ense", "\u2581and", "\u2581tw", "isted", "\u2581passion", "\u2581as", "\u2581a", "\u2581woman", "\u2581is", "\u2581drawn", "\u2581to", "\u2581the", "\u2581edge", "\u2581of", "\u2581danger", "\u2581in", "\u2581the", "\u2581company", "\u2581of", "\u2581a", "\u2581mad", "man", "."]], "entropy": [[0.321044921875, 0.1473388671875, 0.20849609375, 0.859375, 4.26171875, 3.291015625, 1.12109375, 1.48828125, 0.58203125, 0.94140625, 0.2171630859375, 1.1298828125, 2.6015625, 0.320068359375, 0.351318359375, 4.56640625, 0.1339111328125, 1.06640625, 2.068359375, 0.0230865478515625, 0.955078125, 0.1689453125, 1.2001953125, 0.03399658203125, 0.281005859375, 0.00395965576171875, 0.11651611328125, 3.669921875, 0.079833984375, 0.58349609375, 1.6337890625, 0.564453125, 0.48876953125, 1.7646484375, 0.330810546875, 0.8740234375, 0.27685546875, 1.076171875, 0.004863739013671875, 0.98583984375, 1.3447265625, 2.171875, 4.40234375, 0.0100555419921875, 0.12066650390625, 2.912109375, 0.303955078125, 0.483154296875]], "avg_entropy": [1.0946255524953206], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Jason Paige", "score_of_biggest_cluster": 0.2566223442554474, "score_of_first_answer": 0.2566223442554474, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 7.152557373046875e-07, "avg_score": 0.2566223442554474, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3661604230496208, "std_of_first_answer": 0.3661604230496208, "avg_entropy_of_first_answer": 1.0946255524953206, "lex_sim": 1.0}
{"question": "atlantic ocean's shape is similar to which english alphabet", "answer": ["\"S\" #SpoonieStory: Amanda\u2019s Chronic Illness Inspires Her Art"], "scores": [[0.2066650390625, 0.23388671875, 0.99169921875, 5.960464477539062e-07, 0.052337646484375, 0.0035247802734375, 0.0004630088806152344, 0.000732421875, 0.00037980079650878906, 1.9252300262451172e-05, 0.263916015625, 0.00508880615234375, 1.0, 0.01702880859375, 0.99072265625, 0.2261962890625, 0.99951171875, 0.0013275146484375, 0.88671875, 0.68212890625, 0.6669921875, 0.09375]], "normalized_score": [0.024410147219896317], "tokens": [["\u2581\"", "S", "\"", "\u2581#", "S", "po", "onie", "Story", ":", "\u2581Am", "anda", "\u2019", "s", "\u2581Chron", "ic", "\u2581Ill", "ness", "\u2581In", "sp", "ires", "\u2581Her", "\u2581Art"]], "entropy": [[2.95703125, 1.9580078125, 0.0560302734375, 0.74072265625, 5.96875, 3.6953125, 0.234619140625, 2.8828125, 1.1376953125, 3.72265625, 3.111328125, 3.666015625, 0.001018524169921875, 3.787109375, 0.059906005859375, 1.4921875, 0.00444793701171875, 0.4873046875, 0.58447265625, 0.7861328125, 2.072265625, 2.14453125]], "avg_entropy": [1.8886526281183416], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "S", "score_of_biggest_cluster": 0.024410147219896317, "score_of_first_answer": 0.024410147219896317, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539062e-07, "avg_score": 0.024410147219896317, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3961714308067078, "std_of_first_answer": 0.3961714308067078, "avg_entropy_of_first_answer": 1.8886526281183416, "lex_sim": 1.0}
{"question": "which is the site of the light dependent reactions of photosynthesis", "answer": ["chlorophyll in the chloroplasts of plant leaves #50."], "scores": [[0.53515625, 0.99951171875, 0.595703125, 0.998046875, 0.059417724609375, 0.7607421875, 0.56298828125, 1.0, 0.9609375, 1.0, 0.89453125, 0.5068359375, 0.4150390625, 0.04705810546875, 1.1920928955078125e-07, 0.0123291015625, 0.06072998046875, 0.00582122802734375, 0.023345947265625, 9.322166442871094e-05, 0.09375, 0.00588226318359375, 0.99951171875, 6.002187728881836e-05, 7.152557373046875e-06, 0.406494140625, 0.001956939697265625, 0.295654296875]], "normalized_score": [0.04264694079756737], "tokens": [["\u2581ch", "lor", "oph", "yll", "\u2581in", "\u2581the", "\u2581ch", "lor", "op", "last", "s", "\u2581of", "\u2581plant", "\u2581leaves", "\u2581#", "5", "0", ".", "\u2581The", "\u2581World", "\u2581Is", "\u2581Fl", "at", "\u2581###", "What", "\u2581is", "\u2581it", "?"]], "entropy": [[1.4912109375, 0.006092071533203125, 0.681640625, 0.0146026611328125, 1.8935546875, 0.8720703125, 0.8115234375, 0.0006175041198730469, 0.1669921875, 0.00030493736267089844, 0.46484375, 1.0712890625, 1.2021484375, 0.2476806640625, 1.208984375, 4.53125, 2.693359375, 2.8125, 3.884765625, 3.771484375, 3.09375, 1.3125, 0.0062103271484375, 2.06640625, 1.888671875, 3.46484375, 1.462890625, 2.955078125]], "avg_entropy": [1.5741880706378393], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "thylakoid membranes", "score_of_biggest_cluster": 0.04264694079756737, "score_of_first_answer": 0.04264694079756737, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.04264694079756737, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39830472251687526, "std_of_first_answer": 0.39830472251687526, "avg_entropy_of_first_answer": 1.5741880706378393, "lex_sim": 1.0}
{"question": "who played the mother in the black stallion", "answer": ["Teri Garr"], "scores": [[0.7861328125, 0.9892578125, 0.998046875, 1.0]], "normalized_score": [0.9386184811592102], "tokens": [["\u2581Ter", "i", "\u2581G", "arr"]], "entropy": [[0.6142578125, 0.059478759765625, 0.016571044921875, 0.0006318092346191406]], "avg_entropy": [0.17273485660552979], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Teri Garr", "score_of_biggest_cluster": 0.9386184811592102, "score_of_first_answer": 0.9386184811592102, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.7861328125, "avg_score": 0.9386184811592102, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.09086492939680914, "std_of_first_answer": 0.09086492939680914, "avg_entropy_of_first_answer": 0.17273485660552979, "lex_sim": 1.0}
{"question": "new anime from the creators of attack on titan", "answer": ["\"Attack on Titan\" #41: The Sermon on the Mount - Part 1"], "scores": [[0.48095703125, 0.309326171875, 1.0, 0.99951171875, 0.9990234375, 1.0, 0.75537109375, 2.294778823852539e-05, 0.00048232078552246094, 0.08123779296875, 0.0439453125, 0.054473876953125, 0.006885528564453125, 0.00021255016326904297, 0.97998046875, 0.0025310516357421875, 0.9208984375, 0.5517578125, 0.07403564453125, 0.37841796875, 0.8759765625, 0.59814453125]], "normalized_score": [0.08834100514650345], "tokens": [["\u2581\"", "Att", "ack", "\u2581on", "\u2581T", "itan", "\"", "\u2581#", "4", "1", ":", "\u2581The", "\u2581S", "erm", "on", "\u2581on", "\u2581the", "\u2581Mount", "\u2581-", "\u2581Part", "\u2581", "1"]], "entropy": [[3.19921875, 2.9140625, 0.0007424354553222656, 0.002899169921875, 0.00751495361328125, 9.191036224365234e-05, 0.66796875, 2.17578125, 3.900390625, 2.927734375, 3.19140625, 1.6357421875, 5.05078125, 4.10546875, 0.09796142578125, 0.138916015625, 0.669921875, 2.384765625, 2.783203125, 3.740234375, 0.6806640625, 1.1240234375]], "avg_entropy": [1.8817951408299534], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Vinland Saga", "score_of_biggest_cluster": 0.08834100514650345, "score_of_first_answer": 0.08834100514650345, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.294778823852539e-05, "avg_score": 0.08834100514650345, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40697990854959615, "std_of_first_answer": 0.40697990854959615, "avg_entropy_of_first_answer": 1.8817951408299534, "lex_sim": 1.0}
{"question": "who sang the original song send in the clowns", "answer": ["Judy Collins"], "scores": [[0.99853515625, 1.0, 0.9951171875]], "normalized_score": [0.9978820085525513], "tokens": [["\u2581Jud", "y", "\u2581Collins"]], "entropy": [[0.0145111083984375, 0.001110076904296875, 0.034515380859375]], "avg_entropy": [0.016712188720703125], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Glynis Johns", "score_of_biggest_cluster": 0.9978820085525513, "score_of_first_answer": 0.9978820085525513, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.9951171875, "avg_score": 0.9978820085525513, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.002045866713863368, "std_of_first_answer": 0.002045866713863368, "avg_entropy_of_first_answer": 0.016712188720703125, "lex_sim": 1.0}
{"question": "who plays bongos on sympathy for the devil", "answer": ["Keith Richards"], "scores": [[0.328369140625, 0.99658203125, 1.0]], "normalized_score": [0.6891151666641235], "tokens": [["\u2581Keith", "\u2581Rich", "ards"]], "entropy": [[1.1328125, 0.024169921875, 5.125999450683594e-05]], "avg_entropy": [0.38567789395650226], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Rocky Dzidzornu", "score_of_biggest_cluster": 0.6891151666641235, "score_of_first_answer": 0.6891151666641235, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.328369140625, "avg_score": 0.6891151666641235, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3158072831776781, "std_of_first_answer": 0.3158072831776781, "avg_entropy_of_first_answer": 0.38567789395650226, "lex_sim": 1.0}
{"question": "when did last podcast on the left start", "answer": ["2009 #006: Tucker Hibbert \u2013 The King of Snowmobiling"], "scores": [[0.43310546875, 0.9990234375, 0.9990234375, 0.07574462890625, 0.421875, 1.1920928955078125e-07, 0.0021724700927734375, 0.2442626953125, 0.007564544677734375, 0.06439208984375, 0.009857177734375, 0.00528717041015625, 0.0006666183471679688, 0.09246826171875, 0.9892578125, 0.01486968994140625, 0.187255859375, 0.05645751953125, 0.8564453125, 0.158203125, 0.65625, 0.9501953125, 0.320068359375]], "normalized_score": [0.05354038625955582], "tokens": [["\u2581", "2", "0", "0", "9", "\u2581#", "0", "0", "6", ":", "\u2581T", "ucker", "\u2581H", "ib", "bert", "\u2581\u2013", "\u2581The", "\u2581King", "\u2581of", "\u2581Snow", "m", "ob", "iling"]], "entropy": [[2.302734375, 0.008880615234375, 0.00899505615234375, 0.27734375, 1.1494140625, 0.83251953125, 5.8125, 2.541015625, 1.25, 3.740234375, 5.73828125, 4.0546875, 1.1748046875, 0.916015625, 0.09088134765625, 4.6640625, 5.03125, 4.69921875, 0.5595703125, 3.630859375, 1.1337890625, 0.2369384765625, 0.64501953125]], "avg_entropy": [2.1956093829611074], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2011", "score_of_biggest_cluster": 0.05354038625955582, "score_of_first_answer": 0.05354038625955582, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.05354038625955582, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37164883423841427, "std_of_first_answer": 0.37164883423841427, "avg_entropy_of_first_answer": 2.1956093829611074, "lex_sim": 1.0}
{"question": "who sang what i like about you originally", "answer": ["The Romantics #IrishFilm: Watch the trailer for Irish indie film The Belly of the Whale"], "scores": [[0.9921875, 0.9990234375, 0.9892578125, 7.152557373046875e-07, 0.0010242462158203125, 0.0004892349243164062, 0.33935546875, 0.0003783702850341797, 0.9521484375, 8.845329284667969e-05, 0.0040283203125, 0.20166015625, 0.1981201171875, 0.9892578125, 0.96337890625, 0.060791015625, 0.03594970703125, 0.95654296875, 0.3134765625, 0.01406097412109375, 0.00531005859375, 0.92138671875, 0.96923828125, 0.98779296875, 0.99853515625, 1.0]], "normalized_score": [0.0609002523124218], "tokens": [["\u2581The", "\u2581Rom", "antics", "\u2581#", "I", "r", "ish", "Fil", "m", ":", "\u2581Watch", "\u2581the", "\u2581tra", "iler", "\u2581for", "\u2581Irish", "\u2581ind", "ie", "\u2581film", "\u2581The", "\u2581Bel", "ly", "\u2581of", "\u2581the", "\u2581Wh", "ale"]], "entropy": [[0.0716552734375, 0.0091400146484375, 0.07763671875, 0.76708984375, 4.59375, 4.1953125, 1.8515625, 4.04296875, 0.2314453125, 2.212890625, 4.7265625, 4.4609375, 3.890625, 0.07489013671875, 0.277587890625, 3.9375, 3.740234375, 0.2484130859375, 2.71484375, 2.859375, 4.05078125, 0.43603515625, 0.170654296875, 0.0791015625, 0.01611328125, 0.000682830810546875]], "avg_entropy": [1.9129918905404897], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The Romantics.", "score_of_biggest_cluster": 0.0609002523124218, "score_of_first_answer": 0.0609002523124218, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 7.152557373046875e-07, "avg_score": 0.0609002523124218, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.45384042741563174, "std_of_first_answer": 0.45384042741563174, "avg_entropy_of_first_answer": 1.9129918905404897, "lex_sim": 1.0}
{"question": "who did the united states win its independence from", "answer": ["Great Britain."], "scores": [[0.9892578125, 0.99951171875, 0.2939453125, 7.152557373046875e-07, 0.0113983154296875, 0.015594482421875, 0.0034885406494140625, 0.11444091796875, 0.373779296875, 0.027435302734375, 0.2176513671875, 0.00012505054473876953, 0.0004830360412597656, 0.12939453125, 0.66064453125, 0.348388671875]], "normalized_score": [0.026502396911382675], "tokens": [["\u2581Great", "\u2581Britain", ".", "\u2581#", "1", ".", "\u2581", "2", "0", "1", "9", "\u2581B", "MW", "\u2581", "3", "\u2581Series"]], "entropy": [[0.07635498046875, 0.003711700439453125, 0.947265625, 0.201904296875, 3.31640625, 3.20703125, 2.0078125, 2.724609375, 2.35546875, 0.8701171875, 2.224609375, 1.359375, 4.35546875, 2.4921875, 0.94384765625, 1.3134765625]], "avg_entropy": [1.7749779224395752], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the British Empire", "score_of_biggest_cluster": 0.026502396911382675, "score_of_first_answer": 0.026502396911382675, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 7.152557373046875e-07, "avg_score": 0.026502396911382675, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.3302483930693087, "std_of_first_answer": 0.3302483930693087, "avg_entropy_of_first_answer": 1.7749779224395752, "lex_sim": 1.0}
{"question": "when did the new day win the tag team titles", "answer": ["July 23, 2018 #IamSafe: What the Panama Papers Tell Us About Corruption and Accountability"], "scores": [[0.00363922119140625, 0.99755859375, 0.603515625, 0.5283203125, 0.93798828125, 0.998046875, 0.99853515625, 1.0, 0.99853515625, 0.042724609375, 4.172325134277344e-07, 0.002635955810546875, 0.135498046875, 0.00022161006927490234, 0.053741455078125, 0.00039839744567871094, 0.001010894775390625, 0.0202789306640625, 0.0009059906005859375, 0.26708984375, 0.88427734375, 0.99951171875, 0.01824951171875, 0.97998046875, 0.63330078125, 0.0259246826171875, 0.9970703125, 0.3515625, 0.0052642822265625, 0.9990234375]], "normalized_score": [0.057938843965530396], "tokens": [["\u2581July", "\u2581", "2", "3", ",", "\u2581", "2", "0", "1", "8", "\u2581#", "I", "am", "Sa", "fe", ":", "\u2581What", "\u2581the", "\u2581Pan", "ama", "\u2581Pap", "ers", "\u2581Tell", "\u2581Us", "\u2581About", "\u2581Cor", "ruption", "\u2581and", "\u2581Account", "ability"]], "entropy": [[1.8544921875, 0.0194549560546875, 0.71630859375, 1.1650390625, 0.27978515625, 0.01490020751953125, 0.011962890625, 6.264448165893555e-05, 0.0113677978515625, 0.72314453125, 1.529296875, 3.970703125, 2.79296875, 2.515625, 3.123046875, 1.8330078125, 4.5, 4.55859375, 5.0546875, 1.1689453125, 0.56689453125, 0.00432586669921875, 2.833984375, 0.11285400390625, 1.0283203125, 3.0390625, 0.0214385986328125, 2.32421875, 2.935546875, 0.010345458984375]], "avg_entropy": [1.6240128099918365], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2016", "score_of_biggest_cluster": 0.057938843965530396, "score_of_first_answer": 0.057938843965530396, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.057938843965530396, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4397452116446792, "std_of_first_answer": 0.4397452116446792, "avg_entropy_of_first_answer": 1.6240128099918365, "lex_sim": 1.0}
{"question": "who played mrs warboys in one foot in the grave", "answer": ["Jenny Agutter #017: How to Overcome Fear and Take Action with Jessica Lorimer"], "scores": [[0.01137542724609375, 0.99462890625, 0.56494140625, 0.99560546875, 1.7881393432617188e-07, 0.006954193115234375, 0.08148193359375, 0.01317596435546875, 0.0021800994873046875, 0.0012178421020507812, 0.190185546875, 0.00019216537475585938, 0.86865234375, 0.203369140625, 0.98876953125, 0.287841796875, 0.10723876953125, 0.7412109375, 0.0220947265625, 0.00655364990234375, 0.9765625, 0.0980224609375, 0.41943359375]], "normalized_score": [0.041779957711696625], "tokens": [["\u2581Jen", "ny", "\u2581Ag", "utter", "\u2581#", "0", "1", "7", ":", "\u2581How", "\u2581to", "\u2581Over", "come", "\u2581F", "ear", "\u2581and", "\u2581Take", "\u2581Action", "\u2581with", "\u2581Jess", "ica", "\u2581Lor", "imer"]], "entropy": [[3.81640625, 0.041412353515625, 1.6865234375, 0.02947998046875, 0.6728515625, 5.98046875, 3.044921875, 2.244140625, 2.962890625, 5.34765625, 3.30078125, 5.4375, 0.60498046875, 3.845703125, 0.08343505859375, 1.7255859375, 2.6640625, 1.0986328125, 3.0625, 5.26953125, 0.2216796875, 4.62109375, 2.33984375]], "avg_entropy": [2.613133969514266], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Doreen Mantle", "score_of_biggest_cluster": 0.041779957711696625, "score_of_first_answer": 0.041779957711696625, "max_score_of_first_answer": 0.99560546875, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.041779957711696625, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38452070131229804, "std_of_first_answer": 0.38452070131229804, "avg_entropy_of_first_answer": 2.613133969514266, "lex_sim": 1.0}
{"question": "where was the world economic forum held this year", "answer": ["Davos, Switzerland #656 - The Shrine Auditorium, Los Angeles - 5th March 2017"], "scores": [[0.94140625, 1.0, 0.955078125, 0.9990234375, 2.384185791015625e-07, 9.226799011230469e-05, 0.060821533203125, 0.057586669921875, 0.0001838207244873047, 0.007015228271484375, 0.0002275705337524414, 0.0013484954833984375, 0.20703125, 0.8466796875, 1.0, 0.99951171875, 0.232421875, 0.92578125, 0.990234375, 0.0037689208984375, 0.1934814453125, 0.0302886962890625, 0.0020503997802734375, 0.0672607421875, 0.81884765625, 0.6240234375, 0.99853515625, 0.01212310791015625, 0.08197021484375]], "normalized_score": [0.04592129588127136], "tokens": [["\u2581Dav", "os", ",", "\u2581Switzerland", "\u2581#", "6", "5", "6", "\u2581-", "\u2581The", "\u2581S", "hr", "ine", "\u2581Aud", "itor", "ium", ",", "\u2581Los", "\u2581Angeles", "\u2581-", "\u2581", "5", "th", "\u2581March", "\u2581", "2", "0", "1", "7"]], "entropy": [[0.358642578125, 0.0020122528076171875, 0.2279052734375, 0.007965087890625, 1.0654296875, 1.1806640625, 2.7578125, 2.865234375, 2.66796875, 4.6171875, 1.3212890625, 1.525390625, 0.7666015625, 0.70703125, 0.0012359619140625, 0.00417327880859375, 2.763671875, 0.42529296875, 0.07415771484375, 0.6201171875, 4.15234375, 1.841796875, 0.955078125, 3.533203125, 0.7392578125, 0.68798828125, 0.01302337646484375, 0.08154296875, 1.7724609375]], "avg_entropy": [1.3012578898462757], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Davos", "score_of_biggest_cluster": 0.04592129588127136, "score_of_first_answer": 0.04592129588127136, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.04592129588127136, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4373928083418935, "std_of_first_answer": 0.4373928083418935, "avg_entropy_of_first_answer": 1.3012578898462757, "lex_sim": 1.0}
{"question": "dogs name in the grinch who stole christmas", "answer": ["Max #3 \u2013 I\u2019m a Celebrity, Get Me Out of Here!"], "scores": [[0.99560546875, 1.7881393432617188e-07, 0.01537322998046875, 0.00015926361083984375, 0.0188751220703125, 0.11907958984375, 0.560546875, 0.071533203125, 0.0007295608520507812, 0.257080078125, 0.986328125, 0.99755859375, 0.05615234375, 0.9873046875, 0.994140625, 0.97998046875, 0.98974609375, 0.9990234375, 0.91064453125]], "normalized_score": [0.07428605109453201], "tokens": [["\u2581Max", "\u2581#", "3", "\u2581\u2013", "\u2581I", "\u2019", "m", "\u2581a", "\u2581C", "ele", "br", "ity", ",", "\u2581Get", "\u2581Me", "\u2581Out", "\u2581of", "\u2581Here", "!"]], "entropy": [[0.032470703125, 0.81396484375, 5.109375, 3.294921875, 5.51171875, 3.732421875, 0.943359375, 2.8203125, 3.615234375, 3.072265625, 0.0865478515625, 0.01837158203125, 1.857421875, 0.12890625, 0.03955078125, 0.11834716796875, 0.068359375, 0.00890350341796875, 0.544921875]], "avg_entropy": [1.6745986938476562], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Max", "score_of_biggest_cluster": 0.07428605109453201, "score_of_first_answer": 0.07428605109453201, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.07428605109453201, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.45264513019826347, "std_of_first_answer": 0.45264513019826347, "avg_entropy_of_first_answer": 1.6745986938476562, "lex_sim": 1.0}
{"question": "when did they stop making pull tabs on beer cans", "answer": ["I'm sorry, but there is no factual basis for the statement that pull tabs were ever made on beer cans."], "scores": [[0.292724609375, 0.50146484375, 1.0, 0.71435546875, 0.98681640625, 0.40673828125, 0.049224853515625, 0.732421875, 0.99169921875, 0.1705322265625, 0.998046875, 0.70556640625, 0.9033203125, 0.61669921875, 0.8779296875, 0.697265625, 0.78662109375, 0.94580078125, 0.99755859375, 0.99169921875, 0.63232421875, 0.99951171875, 0.99853515625, 1.0, 0.99951171875, 1.0, 0.9931640625]], "normalized_score": [0.6785982251167297], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581but", "\u2581there", "\u2581is", "\u2581no", "\u2581fact", "ual", "\u2581basis", "\u2581for", "\u2581the", "\u2581statement", "\u2581that", "\u2581pull", "\u2581tabs", "\u2581were", "\u2581ever", "\u2581made", "\u2581on", "\u2581be", "er", "\u2581can", "s", "."]], "entropy": [[2.365234375, 1.3076171875, 0.0017108917236328125, 0.697265625, 0.07794189453125, 1.0947265625, 1.3818359375, 1.044921875, 0.0626220703125, 2.328125, 0.017303466796875, 0.70654296875, 0.3388671875, 0.990234375, 0.5283203125, 0.6357421875, 0.64404296875, 0.2425537109375, 0.0208740234375, 0.06298828125, 1.2060546875, 0.00260162353515625, 0.010955810546875, 0.00015473365783691406, 0.00439453125, 0.0002732276916503906, 0.05096435546875]], "avg_entropy": [0.5861062915236862], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1990", "score_of_biggest_cluster": 0.6785982251167297, "score_of_first_answer": 0.6785982251167297, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.049224853515625, "avg_score": 0.6785982251167297, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2749719061044656, "std_of_first_answer": 0.2749719061044656, "avg_entropy_of_first_answer": 0.5861062915236862, "lex_sim": 1.0}
{"question": "when did the red guards start and end", "answer": ["The Red Guards were a Chinese paramilitary group that existed from 1964 to 1967 during the Cultural Revolution."], "scores": [[0.8740234375, 0.99365234375, 0.84521484375, 0.99951171875, 0.6474609375, 0.77294921875, 0.3056640625, 0.01314544677734375, 1.0, 0.99951171875, 1.0, 0.9130859375, 0.381103515625, 0.892578125, 0.81982421875, 0.9775390625, 1.0, 1.0, 1.0, 0.0224761962890625, 0.98681640625, 0.994140625, 1.0, 1.0, 0.9931640625, 0.12493896484375, 0.38232421875, 0.998046875, 0.94580078125, 1.0, 0.8369140625, 5.364418029785156e-07, 2.6941299438476562e-05, 0.038482666015625, 0.039794921875, 0.00010526180267333984, 0.2122802734375, 6.73532485961914e-05, 0.453369140625, 0.08917236328125, 0.00237274169921875, 0.99658203125, 0.78173828125, 0.1575927734375, 0.1795654296875]], "normalized_score": [0.1696486622095108], "tokens": [["\u2581The", "\u2581Red", "\u2581Gu", "ards", "\u2581were", "\u2581a", "\u2581Chinese", "\u2581par", "amil", "it", "ary", "\u2581group", "\u2581that", "\u2581existed", "\u2581from", "\u2581", "1", "9", "6", "4", "\u2581to", "\u2581", "1", "9", "6", "7", "\u2581during", "\u2581the", "\u2581Cultural", "\u2581Revolution", ".", "\u2581#", "Book", "Re", "view", "\u2581\u2013", "\u2581The", "\u2581House", "\u2581on", "\u2581the", "\u2581Cl", "iff", "\u2581by", "\u2581Charlotte", "\u2581Williams"]], "entropy": [[0.6875, 0.054443359375, 0.435546875, 0.0026798248291015625, 1.212890625, 0.81201171875, 2.130859375, 2.3046875, 0.0006403923034667969, 0.002490997314453125, 3.403425216674805e-05, 0.3955078125, 0.88037109375, 0.491943359375, 0.60693359375, 0.1290283203125, 9.894371032714844e-06, 5.125999450683594e-06, 0.0003185272216796875, 0.417236328125, 0.08135986328125, 0.039337158203125, 1.8835067749023438e-05, 0.0003807544708251953, 0.041015625, 1.0634765625, 1.2099609375, 0.01520538330078125, 0.28515625, 0.0020046234130859375, 0.6767578125, 0.80517578125, 4.15625, 3.599609375, 0.25244140625, 2.208984375, 4.00390625, 2.130859375, 0.85400390625, 1.099609375, 2.744140625, 0.0271453857421875, 0.9541015625, 4.57421875, 0.7060546875]], "avg_entropy": [0.9354736314879524], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1966 and 1967", "score_of_biggest_cluster": 0.1696486622095108, "score_of_first_answer": 0.1696486622095108, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.364418029785156e-07, "avg_score": 0.1696486622095108, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41060673468601533, "std_of_first_answer": 0.41060673468601533, "avg_entropy_of_first_answer": 0.9354736314879524, "lex_sim": 1.0}
{"question": "when did lionel messi play his first game for barcelona", "answer": ["May 15, 2004 ##### SECTION I: QUESTIONS"], "scores": [[0.407958984375, 0.99853515625, 0.99853515625, 0.007282257080078125, 0.93505859375, 0.9990234375, 1.0, 1.0, 1.0, 0.99853515625, 0.0, 0.00011092424392700195, 0.015777587890625, 0.0002758502960205078, 0.136474609375, 0.017913818359375, 0.87548828125, 0.99951171875, 0.6259765625]], "normalized_score": [0.0], "tokens": [["\u2581May", "\u2581", "1", "5", ",", "\u2581", "2", "0", "0", "4", "\u2581#####", "\u2581SE", "CTION", "\u2581I", ":", "\u2581Q", "UE", "ST", "IONS"]], "entropy": [[1.1083984375, 0.0112762451171875, 0.01035308837890625, 1.076171875, 0.25439453125, 0.0102081298828125, 0.0002579689025878906, 9.715557098388672e-06, 0.0006251335144042969, 0.01239776611328125, 0.94287109375, 1.75, 2.09765625, 2.123046875, 2.419921875, 5.3984375, 0.58447265625, 0.003726959228515625, 0.80859375]], "avg_entropy": [0.9796220973918313], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2002", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4483382534055533, "std_of_first_answer": 0.4483382534055533, "avg_entropy_of_first_answer": 0.9796220973918313, "lex_sim": 1.0}
{"question": "when's the last time philly won the superbowl", "answer": ["I'm sorry, I don't know the answer to that question."], "scores": [[0.08319091796875, 0.79736328125, 0.99951171875, 0.9892578125, 0.99072265625, 0.6396484375, 0.33837890625, 0.99658203125, 1.0, 0.16552734375, 0.75927734375, 0.84619140625, 0.9853515625, 0.970703125, 0.7880859375, 0.7646484375, 0.255126953125, 0.92626953125, 0.366455078125, 0.81298828125, 0.90966796875, 0.82958984375, 0.323974609375, 0.3056640625, 0.88037109375, 0.9970703125, 2.980232238769531e-07, 0.000995635986328125, 0.00539398193359375, 0.007297515869140625, 0.83203125, 4.5299530029296875e-06, 0.0350341796875, 0.00011914968490600586]], "normalized_score": [0.12990111112594604], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581I", "\u2581don", "'", "t", "\u2581know", "\u2581the", "\u2581answer", "\u2581to", "\u2581that", "\u2581question", ".", "\u2581Can", "\u2581you", "\u2581provide", "\u2581more", "\u2581context", "\u2581or", "\u2581clarify", "\u2581your", "\u2581question", "?", "\u2581#", "W", "ater", "Is", "Life", "\u2581at", "\u2581The", "\u2581Broad"]], "entropy": [[2.02734375, 0.6865234375, 0.002971649169921875, 0.0692138671875, 0.061798095703125, 1.1962890625, 1.58984375, 0.0247650146484375, 0.00032639503479003906, 0.499267578125, 0.8623046875, 0.736328125, 0.09259033203125, 0.1590576171875, 0.6162109375, 0.69482421875, 2.009765625, 0.26904296875, 1.0869140625, 0.63623046875, 0.325927734375, 0.51904296875, 1.16796875, 1.466796875, 0.5048828125, 0.024871826171875, 0.313232421875, 5.34765625, 4.25390625, 4.2265625, 1.0966796875, 1.541015625, 4.90625, 5.32421875]], "avg_entropy": [1.3041360027649824], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2017", "score_of_biggest_cluster": 0.12990111112594604, "score_of_first_answer": 0.12990111112594604, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.12990111112594604, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3892341477764124, "std_of_first_answer": 0.3892341477764124, "avg_entropy_of_first_answer": 1.3041360027649824, "lex_sim": 1.0}
{"question": "when is the fourth movie of the divergent series coming out", "answer": ["As far as my knowledge cutoff in 2021, the fourth movie of the Divergent Series was never made."], "scores": [[0.0711669921875, 0.10552978515625, 0.99853515625, 0.544921875, 0.90869140625, 0.96826171875, 0.6064453125, 0.38427734375, 0.9169921875, 1.0, 1.0, 1.0, 0.99951171875, 0.986328125, 0.95166015625, 0.88330078125, 0.9716796875, 0.662109375, 0.99609375, 0.9833984375, 1.0, 1.0, 0.09942626953125, 0.267333984375, 0.1949462890625, 0.076171875, 0.81396484375]], "normalized_score": [0.5556822419166565], "tokens": [["\u2581As", "\u2581far", "\u2581as", "\u2581my", "\u2581knowledge", "\u2581cut", "off", "\u2581in", "\u2581", "2", "0", "2", "1", ",", "\u2581the", "\u2581fourth", "\u2581movie", "\u2581of", "\u2581the", "\u2581D", "iver", "gent", "\u2581Series", "\u2581was", "\u2581never", "\u2581made", "."]], "entropy": [[1.8203125, 1.2939453125, 0.012725830078125, 0.71435546875, 0.46337890625, 0.1944580078125, 0.9482421875, 1.5732421875, 0.30859375, 0.0003962516784667969, 0.0005979537963867188, 0.0020732879638671875, 0.004604339599609375, 0.09332275390625, 0.268310546875, 0.55615234375, 0.15185546875, 0.7685546875, 0.030975341796875, 0.10113525390625, 2.0265579223632812e-06, 0.00019800662994384766, 0.330322265625, 1.0205078125, 2.21875, 0.342041015625, 0.73876953125]], "avg_entropy": [0.5169564088185629], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "never made", "score_of_biggest_cluster": 0.5556822419166565, "score_of_first_answer": 0.5556822419166565, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0711669921875, "avg_score": 0.5556822419166565, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.34913046082906113, "std_of_first_answer": 0.34913046082906113, "avg_entropy_of_first_answer": 0.5169564088185629, "lex_sim": 1.0}
{"question": "what are the importance of rigor mortis in meat processing", "answer": ["Rigor mortis is important in meat processing because it helps to retain the shape and structure of the meat, making it easier to slice and package."], "scores": [[0.78857421875, 1.0, 1.0, 0.99609375, 1.0, 0.92626953125, 0.334228515625, 0.96533203125, 0.9931640625, 0.998046875, 0.58642578125, 0.99853515625, 0.8017578125, 0.96337890625, 0.10491943359375, 0.99951171875, 0.1361083984375, 0.828125, 0.088623046875, 0.99951171875, 0.9951171875, 0.95947265625, 0.60791015625, 0.67236328125, 1.0, 0.97021484375, 0.99951171875, 0.22705078125, 0.96826171875, 0.708984375, 0.99462890625, 0.71435546875, 0.9873046875, 0.76513671875, 0.9970703125, 0.876953125, 0.74951171875, 0.93505859375, 1.0, 0.45703125, 0.9990234375, 0.343017578125, 0.994140625, 0.80615234375, 0.59765625, 1.0, 0.7138671875, 0.0284271240234375, 0.91796875, 0.99951171875]], "normalized_score": [0.6753085255622864], "tokens": [["\u2581R", "ig", "or", "\u2581mort", "is", "\u2581is", "\u2581important", "\u2581in", "\u2581meat", "\u2581processing", "\u2581because", "\u2581it", "\u2581helps", "\u2581to", "\u2581retain", "\u2581the", "\u2581shape", "\u2581and", "\u2581structure", "\u2581of", "\u2581the", "\u2581meat", ",", "\u2581making", "\u2581it", "\u2581easier", "\u2581to", "\u2581slice", "\u2581and", "\u2581package", ".", "\u2581It", "\u2581also", "\u2581helps", "\u2581to", "\u2581prevent", "\u2581the", "\u2581meat", "\u2581from", "\u2581spo", "iling", "\u2581as", "\u2581quickly", ".", "\u2581Additionally", ",", "\u2581the", "\u2581extent", "\u2581of", "\u2581rig"]], "entropy": [[1.0693359375, 0.0004887580871582031, 0.00010293722152709961, 0.0265960693359375, 0.00044846534729003906, 0.377685546875, 1.6259765625, 0.1826171875, 0.04852294921875, 0.01392364501953125, 1.0458984375, 0.01255035400390625, 0.94482421875, 0.216796875, 2.345703125, 0.00673675537109375, 1.6806640625, 0.48779296875, 0.5703125, 0.00319671630859375, 0.034210205078125, 0.1839599609375, 1.095703125, 1.1630859375, 0.0019626617431640625, 0.1456298828125, 0.006153106689453125, 1.341796875, 0.1583251953125, 1.224609375, 0.0390625, 0.78369140625, 0.07080078125, 1.033203125, 0.022979736328125, 0.60693359375, 0.95458984375, 0.3740234375, 0.0013217926025390625, 1.6630859375, 0.00669097900390625, 2.005859375, 0.039215087890625, 0.6875, 1.298828125, 0.002201080322265625, 0.78173828125, 2.509765625, 0.2880859375, 0.00315093994140625]], "avg_entropy": [0.5837667596340179], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "tenderness of meat", "score_of_biggest_cluster": 0.6753085255622864, "score_of_first_answer": 0.6753085255622864, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0284271240234375, "avg_score": 0.6753085255622864, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.283933256382613, "std_of_first_answer": 0.283933256382613, "avg_entropy_of_first_answer": 0.5837667596340179, "lex_sim": 1.0}
{"question": "when did it become law to stand for the national anthem", "answer": ["It is not the law to stand for the national anthem."], "scores": [[0.6455078125, 0.96484375, 0.99853515625, 0.037200927734375, 1.0, 0.96728515625, 0.9990234375, 0.99951171875, 1.0, 0.9755859375, 1.0, 1.0, 0.6103515625, 0.075927734375, 0.364501953125, 0.2420654296875, 0.10235595703125, 1.0, 0.487548828125, 0.99755859375, 1.0, 0.465087890625, 1.0, 0.99755859375, 0.44091796875, 0.98876953125, 0.60302734375, 0.7568359375, 0.953125, 0.146240234375, 0.9765625, 0.76171875, 0.9853515625, 0.83154296875, 0.0, 0.00010663270950317383]], "normalized_score": [0.0], "tokens": [["\u2581It", "\u2581is", "\u2581not", "\u2581the", "\u2581law", "\u2581to", "\u2581stand", "\u2581for", "\u2581the", "\u2581national", "\u2581anth", "em", ".", "\u2581The", "\u2581law", "\u2581requires", "\u2581individuals", "\u2581to", "\u2581rise", "\u2581for", "\u2581the", "\u2581national", "\u2581anth", "em", ",", "\u2581but", "\u2581it", "\u2581is", "\u2581not", "\u2581mand", "atory", "\u2581to", "\u2581stand", ".", "\u2581###", "\u2581Introduction"]], "entropy": [[1.23828125, 0.1947021484375, 0.015777587890625, 0.7666015625, 0.0011768341064453125, 0.1639404296875, 0.009002685546875, 0.005401611328125, 0.0016307830810546875, 0.115478515625, 0.0005006790161132812, 0.00011998414993286133, 0.978515625, 1.7529296875, 2.166015625, 1.8037109375, 1.392578125, 0.0015573501586914062, 0.86328125, 0.02001953125, 0.0007009506225585938, 1.1533203125, 0.00244903564453125, 0.0169525146484375, 1.6494140625, 0.0841064453125, 1.40234375, 0.63037109375, 0.321044921875, 2.224609375, 0.11309814453125, 0.6298828125, 0.1031494140625, 0.76123046875, 1.51953125, 5.796875]], "avg_entropy": [0.77500838206874], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "June 22, 1942", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3576268470923029, "std_of_first_answer": 0.3576268470923029, "avg_entropy_of_first_answer": 0.77500838206874, "lex_sim": 1.0}
{"question": "who plays jill bigelow in line of duty", "answer": ["Jessica Gunning"], "scores": [[0.2783203125, 1.0, 0.97314453125, 0.9853515625]], "normalized_score": [0.7187508344650269], "tokens": [["\u2581Jess", "ica", "\u2581Gun", "ning"]], "entropy": [[3.3515625, 0.0025177001953125, 0.1861572265625, 0.103271484375]], "avg_entropy": [0.9108772277832031], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Polly Walker", "score_of_biggest_cluster": 0.7187508344650269, "score_of_first_answer": 0.7187508344650269, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.2783203125, "avg_score": 0.7187508344650269, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.30665333229510977, "std_of_first_answer": 0.30665333229510977, "avg_entropy_of_first_answer": 0.9108772277832031, "lex_sim": 1.0}
{"question": "when does the new season of lost in space come out", "answer": ["The second season of \"Lost in Space\" premiered on December 24, 2019."], "scores": [[0.20263671875, 0.50390625, 0.99951171875, 0.912109375, 0.2005615234375, 0.9990234375, 0.99951171875, 0.99755859375, 1.0, 0.99951171875, 0.66845703125, 0.998046875, 0.9833984375, 0.97119140625, 0.9990234375, 0.99658203125, 0.99951171875, 0.89453125, 0.9990234375, 0.99755859375, 1.0, 0.916015625, 0.9990234375, 0.607421875, 2.86102294921875e-06, 0.0006160736083984375, 0.07147216796875, 0.106689453125, 0.0902099609375, 0.058685302734375, 0.00026798248291015625, 0.2342529296875, 0.131591796875, 0.061431884765625, 0.64013671875, 0.304931640625, 0.09576416015625, 0.98291015625, 0.99462890625, 0.9619140625, 0.032562255859375, 0.455810546875, 0.1785888671875, 0.99560546875, 0.1363525390625, 0.0947265625, 0.020904541015625, 0.0001462697982788086]], "normalized_score": [0.20132435858249664], "tokens": [["\u2581The", "\u2581second", "\u2581season", "\u2581of", "\u2581\"", "L", "ost", "\u2581in", "\u2581Space", "\"", "\u2581premier", "ed", "\u2581on", "\u2581December", "\u2581", "2", "4", ",", "\u2581", "2", "0", "1", "9", ".", "\u2581#", "8", "4", "3", "5", "0", "\u2581-", "\u2581", "0", "1", "/", "2", "2", "/", "2", "0", "\u2581", "1", "2", ":", "5", "4", "\u2581AM", "\u2581T"]], "entropy": [[2.4140625, 1.90234375, 0.006999969482421875, 0.456298828125, 1.2529296875, 0.007556915283203125, 0.0025386810302734375, 0.018798828125, 0.0020599365234375, 0.002834320068359375, 1.32421875, 0.01413726806640625, 0.097412109375, 0.1622314453125, 0.0100555419921875, 0.0222625732421875, 0.004871368408203125, 0.340576171875, 0.00684356689453125, 0.0173187255859375, 4.851818084716797e-05, 0.288330078125, 0.008880615234375, 1.0458984375, 2.2109375, 4.47265625, 3.083984375, 2.619140625, 2.658203125, 2.798828125, 2.5859375, 5.44921875, 2.08984375, 2.52734375, 1.75, 1.3583984375, 2.283203125, 0.1148681640625, 0.039947509765625, 0.214111328125, 0.6279296875, 1.0693359375, 2.16796875, 0.034576416015625, 1.7900390625, 2.3046875, 1.65234375, 1.9052734375]], "avg_entropy": [1.1920476133624713], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "April 13, 2018", "score_of_biggest_cluster": 0.20132435858249664, "score_of_first_answer": 0.20132435858249664, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.86102294921875e-06, "avg_score": 0.20132435858249664, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4210157382868952, "std_of_first_answer": 0.4210157382868952, "avg_entropy_of_first_answer": 1.1920476133624713, "lex_sim": 1.0}
{"question": "where does the last name galvez come from", "answer": ["The last name Galvez is of Spanish origin."], "scores": [[0.03302001953125, 0.646484375, 1.0, 0.92822265625, 0.94775390625, 0.4501953125, 0.9111328125, 0.9990234375, 0.99755859375, 0.6806640625, 0.541015625, 0.73974609375, 0.30810546875, 0.9892578125, 0.8720703125, 0.393798828125, 1.0, 0.247314453125, 0.8291015625, 0.71142578125, 1.0, 0.99169921875, 1.0, 0.7822265625, 0.1536865234375, 0.8447265625, 1.7881393432617188e-07, 0.00011730194091796875, 0.001979827880859375, 0.006622314453125, 0.1329345703125, 0.02587890625, 0.00351715087890625, 0.0196380615234375, 0.958984375, 0.57470703125, 0.388916015625, 1.0, 0.9990234375, 0.99951171875, 0.99951171875, 1.0, 0.0650634765625, 0.00010114908218383789, 0.2088623046875, 0.98828125, 0.449951171875, 0.84716796875]], "normalized_score": [0.18987952172756195], "tokens": [["\u2581The", "\u2581last", "\u2581name", "\u2581Gal", "vez", "\u2581is", "\u2581of", "\u2581Spanish", "\u2581origin", ".", "\u2581It", "\u2581is", "\u2581believed", "\u2581to", "\u2581have", "\u2581origin", "ated", "\u2581in", "\u2581the", "\u2581region", "\u2581of", "\u2581Gal", "icia", "\u2581in", "\u2581Spain", ".", "\u2581#", "Re", "view", ":", "\u2581The", "\u2581Last", "\u2581W", "id", "ow", "\u2581by", "\u2581Kar", "in", "\u2581S", "la", "ugh", "ter", "\u2581-", "\u2581Q", "&", "A", "\u2581with", "\u2581the"]], "entropy": [[1.783203125, 1.0498046875, 0.000789642333984375, 0.265869140625, 0.26611328125, 1.5078125, 0.446533203125, 0.00905609130859375, 0.020111083984375, 0.82958984375, 1.072265625, 1.0546875, 1.7607421875, 0.059844970703125, 0.438232421875, 1.38671875, 0.0002872943878173828, 0.580078125, 0.491943359375, 1.2255859375, 0.0014257431030273438, 0.06494140625, 0.0010728836059570312, 0.5283203125, 1.060546875, 0.5244140625, 0.626953125, 4.01171875, 2.75, 4.3984375, 4.9921875, 4.8984375, 2.49609375, 2.015625, 0.1849365234375, 1.787109375, 2.517578125, 0.0007066726684570312, 0.01023101806640625, 0.0063934326171875, 0.005611419677734375, 0.001178741455078125, 2.478515625, 4.10546875, 2.705078125, 0.10308837890625, 2.396484375, 1.1396484375]], "avg_entropy": [1.2512806703646977], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Spanish surname", "score_of_biggest_cluster": 0.18987952172756195, "score_of_first_answer": 0.18987952172756195, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.18987952172756195, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.39056853631996163, "std_of_first_answer": 0.39056853631996163, "avg_entropy_of_first_answer": 1.2512806703646977, "lex_sim": 1.0}
{"question": "who played the beast in the movie beauty and the beast", "answer": ["Ian McKellen #WaterWars: Can We Solve The Global Water Crisis?"], "scores": [[0.1378173828125, 0.98291015625, 0.99951171875, 5.0067901611328125e-06, 0.0001773834228515625, 0.005672454833984375, 0.007236480712890625, 0.007297515869140625, 0.004116058349609375, 0.009033203125, 0.1151123046875, 0.1448974609375, 1.0, 0.021575927734375, 0.39697265625, 0.58154296875, 0.9970703125, 1.0, 0.9208984375]], "normalized_score": [0.04838383570313454], "tokens": [["\u2581Ian", "\u2581McK", "ellen", "\u2581#", "W", "ater", "W", "ars", ":", "\u2581Can", "\u2581We", "\u2581Sol", "ve", "\u2581The", "\u2581Global", "\u2581Water", "\u2581Cris", "is", "?"]], "entropy": [[1.5185546875, 0.097412109375, 0.003993988037109375, 0.90185546875, 3.404296875, 3.484375, 3.7109375, 3.12109375, 2.65234375, 5.28125, 3.77734375, 2.830078125, 0.0018987655639648438, 0.2401123046875, 1.9697265625, 0.81103515625, 0.02252197265625, 0.0008292198181152344, 0.5224609375]], "avg_entropy": [1.8080063117177863], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Dan Stevens", "score_of_biggest_cluster": 0.04838383570313454, "score_of_first_answer": 0.04838383570313454, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.0067901611328125e-06, "avg_score": 0.04838383570313454, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4308985644671084, "std_of_first_answer": 0.4308985644671084, "avg_entropy_of_first_answer": 1.8080063117177863, "lex_sim": 1.0}
{"question": "what are the 5 pillars of faith of islam", "answer": ["Shahaadat ( declaring monotheism ), Salat ( prayer five times a day ), Sawm ( fasting during Ramadan ), Zakat ( giving to charity ), and Hajj ( pilgrimage to Mecca once"], "scores": [[0.09051513671875, 0.59765625, 0.386474609375, 0.10076904296875, 0.385498046875, 0.0003173351287841797, 0.2034912109375, 0.9970703125, 0.994140625, 0.273193359375, 0.9814453125, 0.95947265625, 0.9951171875, 0.31005859375, 0.1424560546875, 0.99853515625, 0.98193359375, 1.0, 0.99658203125, 0.04144287109375, 0.994140625, 1.0, 0.99853515625, 0.99267578125, 0.99658203125, 0.86083984375, 0.448486328125, 0.9873046875, 0.97314453125, 0.99462890625, 0.9912109375, 0.98828125, 0.9990234375, 0.19775390625, 0.4091796875, 0.364013671875, 0.99951171875, 0.9443359375, 0.103515625, 0.998046875, 1.0, 0.9921875, 0.99853515625, 0.9921875, 0.9990234375, 0.99462890625, 0.9990234375, 0.99072265625, 1.0, 0.0877685546875]], "normalized_score": [0.5084697008132935], "tokens": [["\u2581Sh", "aha", "ad", "at", "\u2581(", "\u2581declaring", "\u2581mon", "othe", "ism", "\u2581),", "\u2581Sal", "at", "\u2581(", "\u2581prayer", "\u2581five", "\u2581times", "\u2581a", "\u2581day", "\u2581),", "\u2581S", "aw", "m", "\u2581(", "\u2581fast", "ing", "\u2581during", "\u2581Ram", "ad", "an", "\u2581),", "\u2581Zak", "at", "\u2581(", "\u2581giving", "\u2581to", "\u2581char", "ity", "\u2581),", "\u2581and", "\u2581H", "aj", "j", "\u2581(", "\u2581pil", "gr", "image", "\u2581to", "\u2581Me", "cca", "\u2581once"]], "entropy": [[1.9697265625, 0.8876953125, 0.7783203125, 0.33544921875, 1.1630859375, 1.583984375, 1.8203125, 0.0204010009765625, 0.037353515625, 1.58984375, 0.1400146484375, 0.173095703125, 0.03515625, 1.8525390625, 0.8232421875, 0.0115203857421875, 0.0986328125, 0.0015516281127929688, 0.0316162109375, 0.51806640625, 0.04229736328125, 0.0015249252319335938, 0.0148773193359375, 0.050262451171875, 0.027862548828125, 0.5810546875, 0.78466796875, 0.091796875, 0.1287841796875, 0.04315185546875, 0.0572509765625, 0.0869140625, 0.00899505615234375, 1.2392578125, 1.5791015625, 0.69580078125, 0.002498626708984375, 0.307373046875, 0.357177734375, 0.01849365234375, 0.0003190040588378906, 0.049652099609375, 0.01287841796875, 0.0596923828125, 0.00931549072265625, 0.040130615234375, 0.007389068603515625, 0.06011962890625, 0.00171661376953125, 1.451171875]], "avg_entropy": [0.4336627292633057], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "concern for the needy", "score_of_biggest_cluster": 0.5084697008132935, "score_of_first_answer": 0.5084697008132935, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0003173351287841797, "avg_score": 0.5084697008132935, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3656875309386684, "std_of_first_answer": 0.3656875309386684, "avg_entropy_of_first_answer": 0.4336627292633057, "lex_sim": 1.0}
{"question": "which nfl coach has the most superbowl rings", "answer": ["Bill Belichick with 6 Super Bowl rings as of 2021."], "scores": [[0.96923828125, 1.0, 0.99951171875, 0.99951171875, 0.1915283203125, 0.97216796875, 0.99169921875, 0.5341796875, 0.98779296875, 0.80224609375, 0.19384765625, 0.61083984375, 0.5517578125, 1.0, 1.0, 0.99951171875, 0.958984375, 0.68408203125, 0.0, 0.0011196136474609375, 0.79150390625]], "normalized_score": [0.0], "tokens": [["\u2581Bill", "\u2581Bel", "ich", "ick", "\u2581with", "\u2581", "6", "\u2581Super", "\u2581Bowl", "\u2581rings", "\u2581as", "\u2581of", "\u2581", "2", "0", "2", "1", ".", "\u2581CHAPTER", "\u2581ON", "E"]], "entropy": [[0.1787109375, 0.0018186569213867188, 0.003387451171875, 0.002559661865234375, 1.7099609375, 0.15478515625, 0.052886962890625, 1.4951171875, 0.07586669921875, 0.56396484375, 1.3134765625, 1.0849609375, 1.1298828125, 0.0025653839111328125, 0.0017852783203125, 0.0048675537109375, 0.2044677734375, 1.0693359375, 0.181396484375, 1.35546875, 0.57177734375]], "avg_entropy": [0.5313830148606074], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Bill Belichick", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.343405987139817, "std_of_first_answer": 0.343405987139817, "avg_entropy_of_first_answer": 0.5313830148606074, "lex_sim": 1.0}
{"question": "where does the white witch live in narnia", "answer": ["Cair Paravel"], "scores": [[0.83349609375, 1.0, 0.99365234375, 0.998046875]], "normalized_score": [0.9535033702850342], "tokens": [["\u2581C", "air", "\u2581Par", "avel"]], "entropy": [[1.072265625, 0.0015325546264648438, 0.046112060546875, 0.01430511474609375]], "avg_entropy": [0.2835538387298584], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "her castle", "score_of_biggest_cluster": 0.9535033702850342, "score_of_first_answer": 0.9535033702850342, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.83349609375, "avg_score": 0.9535033702850342, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.07093745227425605, "std_of_first_answer": 0.07093745227425605, "avg_entropy_of_first_answer": 0.2835538387298584, "lex_sim": 1.0}
{"question": "what is final season of game of thrones", "answer": ["eighth season #MeToo strikes South African sport"], "scores": [[0.09222412109375, 1.0, 0.398681640625, 4.76837158203125e-07, 1.8477439880371094e-06, 0.460693359375, 1.0, 2.2470951080322266e-05, 0.99853515625, 3.4570693969726562e-06, 0.0017566680908203125, 0.00482177734375]], "normalized_score": [0.003824933897703886], "tokens": [["\u2581e", "ighth", "\u2581season", "\u2581#", "Me", "To", "o", "\u2581strik", "es", "\u2581South", "\u2581African", "\u2581sport"]], "entropy": [[1.8408203125, 0.0008029937744140625, 1.140625, 1.080078125, 1.951171875, 2.947265625, 0.001483917236328125, 2.40625, 0.0124053955078125, 1.0576171875, 1.927734375, 5.1328125]], "avg_entropy": [1.624922275543213], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The eighth", "score_of_biggest_cluster": 0.003824933897703886, "score_of_first_answer": 0.003824933897703886, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.76837158203125e-07, "avg_score": 0.003824933897703886, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4155457832586203, "std_of_first_answer": 0.4155457832586203, "avg_entropy_of_first_answer": 1.624922275543213, "lex_sim": 1.0}
{"question": "who won season 2 of great british baking show", "answer": ["Frances Quinn"], "scores": [[0.10302734375, 0.91455078125, 0.984375]], "normalized_score": [0.4526616036891937], "tokens": [["\u2581Frances", "\u2581Qu", "inn"]], "entropy": [[2.009765625, 0.494873046875, 0.11944580078125]], "avg_entropy": [0.87469482421875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Joanne Wheatley", "score_of_biggest_cluster": 0.4526616036891937, "score_of_first_answer": 0.4526616036891937, "max_score_of_first_answer": 0.984375, "min_score_of_first_answer": 0.10302734375, "avg_score": 0.4526616036891937, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.400030471382873, "std_of_first_answer": 0.400030471382873, "avg_entropy_of_first_answer": 0.87469482421875, "lex_sim": 1.0}
{"question": "who plays the dad in the new beauty and the beast", "answer": ["Kevin Kline #ThesisThursday: How I Spent My Summer Vacation"], "scores": [[0.94091796875, 0.99658203125, 0.99609375, 4.76837158203125e-07, 0.0013256072998046875, 0.0002586841583251953, 0.00035834312438964844, 0.564453125, 0.98291015625, 0.006275177001953125, 0.033538818359375, 0.01702880859375, 0.007366180419921875, 0.95751953125, 0.88671875, 0.7421875, 0.939453125, 0.99267578125, 0.9970703125]], "normalized_score": [0.05242874100804329], "tokens": [["\u2581Kevin", "\u2581K", "line", "\u2581#", "Th", "esis", "Th", "urs", "day", ":", "\u2581How", "\u2581I", "\u2581Sp", "ent", "\u2581My", "\u2581Summer", "\u2581V", "ac", "ation"]], "entropy": [[0.32177734375, 0.0296630859375, 0.0347900390625, 0.81787109375, 5.109375, 3.53515625, 4.4453125, 1.6025390625, 0.095947265625, 2.326171875, 5.09765625, 3.55078125, 5.2109375, 0.22900390625, 0.71728515625, 1.3349609375, 0.413818359375, 0.056915283203125, 0.02642822265625]], "avg_entropy": [1.8398100200452303], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Kevin Kline", "score_of_biggest_cluster": 0.05242874100804329, "score_of_first_answer": 0.05242874100804329, "max_score_of_first_answer": 0.9970703125, "min_score_of_first_answer": 4.76837158203125e-07, "avg_score": 0.05242874100804329, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.45558620260300464, "std_of_first_answer": 0.45558620260300464, "avg_entropy_of_first_answer": 1.8398100200452303, "lex_sim": 1.0}
{"question": "only player to play for manchester united manchester city liverpool and everton", "answer": ["Steve Staunton #BREAKING | \ud83d\udce2 PRESS RELEASE / EVENT ALERT \ud83d\udca5"], "scores": [[0.00850677490234375, 0.1881103515625, 0.98583984375, 1.0, 2.3245811462402344e-06, 0.007904052734375, 0.1739501953125, 0.58837890625, 0.9052734375, 9.1552734375e-05, 0.048614501953125, 0.256103515625, 0.98974609375, 0.09844970703125, 0.23876953125, 0.0030040740966796875, 0.2470703125, 0.70703125, 0.99951171875, 0.00013005733489990234, 0.0018444061279296875, 0.03692626953125, 0.4404296875, 0.0222320556640625, 0.97607421875, 0.307861328125, 0.98486328125, 1.0, 0.0010223388671875, 0.83984375]], "normalized_score": [0.06268811225891113], "tokens": [["\u2581Steve", "\u2581Sta", "un", "ton", "\u2581#", "B", "RE", "AK", "ING", "\u2581|", "\u2581", "<0xF0>", "<0x9F>", "<0x93>", "<0xA2>", "\u2581P", "RESS", "\u2581RE", "LEASE", "\u2581/", "\u2581E", "V", "ENT", "\u2581AL", "ERT", "\u2581", "<0xF0>", "<0x9F>", "<0x92>", "<0xA5>"]], "entropy": [[2.294921875, 2.619140625, 0.0826416015625, 0.0011234283447265625, 0.95458984375, 5.43359375, 4.12890625, 0.8701171875, 0.4521484375, 0.61669921875, 3.662109375, 2.89453125, 0.05731201171875, 1.8388671875, 1.96484375, 4.01953125, 3.708984375, 0.91552734375, 0.006591796875, 1.9150390625, 4.8046875, 4.68359375, 2.01171875, 2.9140625, 0.1181640625, 2.34375, 0.09881591796875, 4.8100948333740234e-05, 0.277587890625, 0.58642578125]], "avg_entropy": [1.8758691291014353], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Peter Andrew Beardsley", "score_of_biggest_cluster": 0.06268811225891113, "score_of_first_answer": 0.06268811225891113, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.3245811462402344e-06, "avg_score": 0.06268811225891113, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4062038007561518, "std_of_first_answer": 0.4062038007561518, "avg_entropy_of_first_answer": 1.8758691291014353, "lex_sim": 1.0}
{"question": "when did bihar bifurcate from bengal and some parts of chota nagpur merged into bengal", "answer": ["October 22, 1956 ### Connections"], "scores": [[0.1156005859375, 0.994140625, 0.79248046875, 0.0064697265625, 0.96484375, 0.99169921875, 0.9970703125, 0.9814453125, 0.94677734375, 0.99755859375, 0.0, 0.00018107891082763672, 0.0163421630859375, 0.689453125]], "normalized_score": [0.0], "tokens": [["\u2581October", "\u2581", "2", "2", ",", "\u2581", "1", "9", "5", "6", "\u2581###", "\u2581Con", "ne", "ctions"]], "entropy": [[1.5791015625, 0.037353515625, 0.51904296875, 0.90185546875, 0.1790771484375, 0.04998779296875, 0.0205535888671875, 0.09686279296875, 0.282470703125, 0.022064208984375, 1.1630859375, 3.7734375, 1.232421875, 0.8369140625]], "avg_entropy": [0.7638735089983258], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1912", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.99755859375, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4403843769453013, "std_of_first_answer": 0.4403843769453013, "avg_entropy_of_first_answer": 0.7638735089983258, "lex_sim": 1.0}
{"question": "who are considered to be the founding fathers", "answer": ["The \"founding fathers\" term typically refers to the key individuals who played a significant role in the establishment and development of the United States of America."], "scores": [[0.70703125, 0.0019283294677734375, 0.462158203125, 0.99951171875, 0.998046875, 1.0, 0.99267578125, 0.0008029937744140625, 0.1690673828125, 0.99609375, 0.99951171875, 0.98291015625, 0.08935546875, 0.324462890625, 0.97265625, 0.65576171875, 0.96044921875, 0.297607421875, 0.99951171875, 0.99951171875, 0.92333984375, 0.67529296875, 0.55322265625, 0.7685546875, 1.0, 0.9912109375, 0.99658203125, 0.99951171875, 0.72900390625, 1.0, 0.65185546875, 0.71484375, 0.55224609375, 0.76953125, 0.80615234375, 1.0, 1.0, 0.1669921875, 1.0, 0.99951171875, 0.95458984375, 0.99951171875, 0.9990234375, 0.859375, 1.0, 1.0, 0.99560546875, 0.1439208984375, 1.0, 0.96728515625]], "normalized_score": [0.5598244667053223], "tokens": [["\u2581The", "\u2581\"", "found", "ing", "\u2581f", "athers", "\"", "\u2581term", "\u2581typically", "\u2581refers", "\u2581to", "\u2581the", "\u2581key", "\u2581individuals", "\u2581who", "\u2581played", "\u2581a", "\u2581significant", "\u2581role", "\u2581in", "\u2581the", "\u2581establishment", "\u2581and", "\u2581development", "\u2581of", "\u2581the", "\u2581United", "\u2581States", "\u2581of", "\u2581America", ".", "\u2581These", "\u2581individuals", "\u2581include", "\u2581George", "\u2581Washington", ",", "\u2581John", "\u2581Adams", ",", "\u2581Thomas", "\u2581Jefferson", ",", "\u2581James", "\u2581Mad", "ison", ",", "\u2581Benjamin", "\u2581Franklin", ","]], "entropy": [[1.2626953125, 0.76708984375, 0.7333984375, 0.005420684814453125, 0.0178680419921875, 0.00011557340621948242, 0.0467529296875, 0.21630859375, 1.5322265625, 0.02996826171875, 0.0055389404296875, 0.1129150390625, 2.365234375, 1.697265625, 0.143798828125, 1.2021484375, 0.219482421875, 1.810546875, 0.00516510009765625, 0.0036602020263671875, 0.337158203125, 1.1416015625, 0.7373046875, 0.8896484375, 0.0006051063537597656, 0.054046630859375, 0.031341552734375, 0.0034313201904296875, 0.833984375, 0.0009050369262695312, 0.755859375, 0.984375, 1.3330078125, 0.884765625, 0.68310546875, 0.0007724761962890625, 0.0018768310546875, 1.0537109375, 0.0002903938293457031, 0.0034942626953125, 0.2276611328125, 0.0023937225341796875, 0.006900787353515625, 0.488037109375, 0.0018548965454101562, 0.0003085136413574219, 0.0313720703125, 0.66796875, 0.0014238357543945312, 0.1466064453125]], "avg_entropy": [0.46966824889183045], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "George Washington", "score_of_biggest_cluster": 0.5598244667053223, "score_of_first_answer": 0.5598244667053223, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0008029937744140625, "avg_score": 0.5598244667053223, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.31127470792141315, "std_of_first_answer": 0.31127470792141315, "avg_entropy_of_first_answer": 0.46966824889183045, "lex_sim": 1.0}
{"question": "where did students for a democratic society start", "answer": ["Student Nonviolent Coordinating Committee (SNCC), a civil rights organization in the United States, played a significant role in organizing and publicizing the ideas of Students for a Democratic Society (SDS) in the early 1"], "scores": [[0.0159454345703125, 0.85400390625, 0.99560546875, 1.0, 1.0, 0.99951171875, 0.9990234375, 1.0, 1.0, 0.79150390625, 0.99755859375, 1.0, 0.0037746429443359375, 0.153076171875, 0.79541015625, 0.9990234375, 0.96337890625, 0.2880859375, 0.9931640625, 0.87060546875, 0.99951171875, 0.18603515625, 0.089599609375, 0.88671875, 0.50830078125, 0.99853515625, 0.9951171875, 0.234619140625, 1.0, 0.11517333984375, 0.048583984375, 1.0, 0.82373046875, 0.0241546630859375, 0.81640625, 0.36376953125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9560546875, 1.0, 1.0, 0.114990234375, 0.37109375, 0.98828125, 0.85009765625, 0.9833984375, 1.0]], "normalized_score": [0.5095963478088379], "tokens": [["\u2581Student", "\u2581Non", "vi", "ol", "ent", "\u2581Co", "ordin", "ating", "\u2581Committee", "\u2581(", "SN", "CC", "),", "\u2581a", "\u2581civil", "\u2581rights", "\u2581organization", "\u2581in", "\u2581the", "\u2581United", "\u2581States", ",", "\u2581played", "\u2581a", "\u2581significant", "\u2581role", "\u2581in", "\u2581organ", "izing", "\u2581and", "\u2581public", "izing", "\u2581the", "\u2581ideas", "\u2581of", "\u2581Stud", "ents", "\u2581for", "\u2581a", "\u2581Democratic", "\u2581Society", "\u2581(", "SD", "S", ")", "\u2581in", "\u2581the", "\u2581early", "\u2581", "1"]], "entropy": [[2.708984375, 0.533203125, 0.0293426513671875, 0.0010862350463867188, 9.077787399291992e-05, 0.005859375, 0.007678985595703125, 1.537799835205078e-05, 0.0010442733764648438, 0.78759765625, 0.0205535888671875, 2.4020671844482422e-05, 0.101806640625, 3.849609375, 1.0234375, 0.00937652587890625, 0.18017578125, 2.306640625, 0.051971435546875, 0.59521484375, 0.006145477294921875, 1.75, 3.0859375, 0.358154296875, 1.4970703125, 0.01340484619140625, 0.044158935546875, 1.0478515625, 0.0007452964782714844, 1.8427734375, 2.341796875, 0.001262664794921875, 0.8388671875, 3.36328125, 0.607421875, 0.88134765625, 0.00011676549911499023, 0.0007333755493164062, 0.0009918212890625, 0.00206756591796875, 0.0003769397735595703, 0.2083740234375, 0.0021686553955078125, 0.0003256797790527344, 0.62451171875, 1.97265625, 0.07061767578125, 0.60546875, 0.10284423828125, 0.0009551048278808594]], "avg_entropy": [0.6697228181362153], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ann Arbor, Michigan", "score_of_biggest_cluster": 0.5095963478088379, "score_of_first_answer": 0.5095963478088379, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0037746429443359375, "avg_score": 0.5095963478088379, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3636854197048429, "std_of_first_answer": 0.3636854197048429, "avg_entropy_of_first_answer": 0.6697228181362153, "lex_sim": 1.0}
{"question": "where was the outlaw of josey wales filmed", "answer": ["Mexico"], "scores": [[0.003482818603515625]], "normalized_score": [0.003482817905023694], "tokens": [["\u2581Mexico"]], "entropy": [[2.7265625]], "avg_entropy": [2.7265625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Kanab, Utah", "score_of_biggest_cluster": 0.003482817905023694, "score_of_first_answer": 0.003482817905023694, "max_score_of_first_answer": 0.003482818603515625, "min_score_of_first_answer": 0.003482818603515625, "avg_score": 0.003482817905023694, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.0, "std_of_first_answer": 0.0, "avg_entropy_of_first_answer": 2.7265625, "lex_sim": 1.0}
{"question": "who heads the executive department of west virginia government", "answer": ["Jim Justice #8."], "scores": [[0.64990234375, 0.9990234375, 5.960464477539063e-08, 0.0009760856628417969, 0.004627227783203125, 7.277727127075195e-05, 0.0019330978393554688, 0.040771484375, 0.99755859375, 0.127685546875, 0.9990234375, 0.001911163330078125, 0.357177734375, 0.01763916015625, 0.0010023117065429688, 0.247802734375, 0.0106353759765625, 0.36279296875, 0.09405517578125, 0.493408203125, 0.9833984375, 0.0129547119140625, 0.0104217529296875, 0.76416015625, 0.1563720703125, 0.990234375, 0.9326171875, 1.0, 0.8955078125, 1.0, 0.0007371902465820312, 0.98193359375, 0.99755859375, 0.91796875, 1.0, 0.87451171875, 0.1640625, 0.0221099853515625, 0.74462890625, 0.99951171875, 0.6953125, 0.93701171875, 0.00067901611328125, 0.861328125, 0.99072265625, 0.99560546875, 0.78759765625, 0.0012359619140625]], "normalized_score": [0.08540146797895432], "tokens": [["\u2581Jim", "\u2581Justice", "\u2581#", "8", ".", "\u2581New", "\u2581Year", "\u2019", "s", "\u2581E", "ve", "\u2581B", "ingo", "\u2581\u2013", "\u2581Set", "\u2581up", "\u2581stations", "\u2581for", "\u2581the", "\u2581k", "ids", "\u2581with", "\u2581print", "able", "\u2581New", "\u2581Year", "\u2019", "s", "\u2581E", "ve", "-", "th", "emed", "\u2581b", "ingo", "\u2581cards", ",", "\u2581c", "ray", "ons", ",", "\u2581and", "\u2581pom", "-", "p", "oms", ".", "\u2581After"]], "entropy": [[1.533203125, 0.008056640625, 1.0927734375, 2.685546875, 2.841796875, 3.53125, 4.51953125, 2.71484375, 0.0245513916015625, 2.02734375, 0.0081787109375, 3.9453125, 2.6875, 4.359375, 5.2578125, 2.662109375, 1.892578125, 1.876953125, 2.830078125, 2.560546875, 0.09307861328125, 0.22900390625, 3.109375, 0.6181640625, 1.2890625, 0.06756591796875, 0.342529296875, 0.00063323974609375, 0.467041015625, 0.0003943443298339844, 0.9599609375, 0.1260986328125, 0.019073486328125, 0.436279296875, 0.00015282630920410156, 0.66064453125, 2.009765625, 4.34765625, 1.0029296875, 0.004787445068359375, 0.9423828125, 0.44970703125, 2.34765625, 0.56005859375, 0.057708740234375, 0.03179931640625, 0.814453125, 4.62109375]], "avg_entropy": [1.5555916180213292], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the Governor of West Virginia", "score_of_biggest_cluster": 0.08540146797895432, "score_of_first_answer": 0.08540146797895432, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.08540146797895432, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.43181978585169445, "std_of_first_answer": 0.43181978585169445, "avg_entropy_of_first_answer": 1.5555916180213292, "lex_sim": 1.0}
{"question": "who owns the four seasons hotel in las vegas", "answer": ["Steve Wynn"], "scores": [[0.0079193115234375, 0.9404296875, 1.0, 1.0]], "normalized_score": [0.2937673032283783], "tokens": [["\u2581Steve", "\u2581W", "yn", "n"]], "entropy": [[3.916015625, 0.2293701171875, 1.4007091522216797e-05, 0.0007076263427734375]], "avg_entropy": [1.036526843905449], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "MGM Resorts International", "score_of_biggest_cluster": 0.2937673032283783, "score_of_first_answer": 0.2937673032283783, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0079193115234375, "avg_score": 0.2937673032283783, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42168716414414564, "std_of_first_answer": 0.42168716414414564, "avg_entropy_of_first_answer": 1.036526843905449, "lex_sim": 1.0}
{"question": "when does the miz and maryse show start", "answer": ["I'm sorry, I do not have information about the show \"the miz and maryse show\" as my knowledge is up to 2021."], "scores": [[0.482421875, 0.67041015625, 1.0, 0.92724609375, 0.9912109375, 0.89990234375, 0.39990234375, 0.9990234375, 0.9677734375, 0.6982421875, 0.50830078125, 0.421630859375, 0.132080078125, 0.611328125, 0.167236328125, 0.9921875, 1.0, 0.99853515625, 0.99853515625, 1.0, 1.0, 0.9814453125, 0.529296875, 0.423583984375, 0.66552734375, 0.480712890625, 0.037078857421875, 0.146240234375, 0.9404296875, 0.51171875, 1.0, 1.0, 0.99951171875, 0.998046875, 0.25537109375, 0.0, 0.7236328125, 6.556510925292969e-07, 0.00012600421905517578, 0.01229095458984375, 0.87255859375, 0.0009188652038574219, 0.98779296875]], "normalized_score": [0.0], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581I", "\u2581do", "\u2581not", "\u2581have", "\u2581information", "\u2581about", "\u2581the", "\u2581show", "\u2581\"", "the", "\u2581m", "iz", "\u2581and", "\u2581m", "ary", "se", "\u2581show", "\"", "\u2581as", "\u2581my", "\u2581knowledge", "\u2581is", "\u2581up", "\u2581to", "\u2581", "2", "0", "2", "1", ".", "\u2581Tags", ":", "\u2581Russia", "\u2581|", "\u2581Ukraine", "\u2581|", "\u2581san", "ctions"]], "entropy": [[2.32421875, 1.1162109375, 0.0015478134155273438, 0.276123046875, 0.058929443359375, 0.43896484375, 1.357421875, 0.0082855224609375, 0.150634765625, 1.072265625, 0.83740234375, 1.3857421875, 2.009765625, 1.4443359375, 0.89013671875, 0.0474853515625, 0.0004477500915527344, 0.01053619384765625, 0.01180267333984375, 0.0008153915405273438, 0.00021195411682128906, 0.11737060546875, 1.05859375, 1.7119140625, 0.76513671875, 0.79345703125, 0.290283203125, 1.806640625, 0.268310546875, 0.7490234375, 0.0016040802001953125, 0.0019817352294921875, 0.004398345947265625, 0.017242431640625, 1.099609375, 1.7021484375, 1.44140625, 3.9140625, 1.4033203125, 5.69140625, 0.6943359375, 4.3125, 0.07708740234375]], "avg_entropy": [0.9619794834491818], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2018", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3684240455230233, "std_of_first_answer": 0.3684240455230233, "avg_entropy_of_first_answer": 0.9619794834491818, "lex_sim": 1.0}
{"question": "who sang i ran all the way home", "answer": ["Todd Rundgren"], "scores": [[0.1007080078125, 0.99951171875, 0.98291015625, 0.9990234375]], "normalized_score": [0.5607061982154846], "tokens": [["\u2581Tod", "d", "\u2581Rund", "gren"]], "entropy": [[3.21875, 0.004001617431640625, 0.1187744140625, 0.01021575927734375]], "avg_entropy": [0.8379354476928711], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The Impalas", "score_of_biggest_cluster": 0.5607061982154846, "score_of_first_answer": 0.5607061982154846, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.1007080078125, "avg_score": 0.5607061982154846, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38678440707050077, "std_of_first_answer": 0.38678440707050077, "avg_entropy_of_first_answer": 0.8379354476928711, "lex_sim": 1.0}
{"question": "what is the zebras name in peppa pig", "answer": ["Zebra"], "scores": [[0.57373046875, 0.99609375, 0.859375]], "normalized_score": [0.7889756560325623], "tokens": [["\u2581Z", "eb", "ra"]], "entropy": [[2.201171875, 0.038116455078125, 0.5712890625]], "avg_entropy": [0.936859130859375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Zuzu", "score_of_biggest_cluster": 0.7889756560325623, "score_of_first_answer": 0.7889756560325623, "max_score_of_first_answer": 0.99609375, "min_score_of_first_answer": 0.57373046875, "avg_score": 0.7889756560325623, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.17596576566759964, "std_of_first_answer": 0.17596576566759964, "avg_entropy_of_first_answer": 0.936859130859375, "lex_sim": 1.0}
{"question": "what is the salary of us secretary of state", "answer": ["The current salary for the Secretary of State of the United States is $205,700."], "scores": [[0.297607421875, 0.31201171875, 0.857421875, 1.0, 0.7109375, 0.99609375, 0.2861328125, 0.99853515625, 0.99755859375, 0.12249755859375, 0.99853515625, 0.998046875, 0.99853515625, 0.98583984375, 0.96923828125, 0.99267578125, 0.8818359375, 0.10711669921875, 1.0, 0.96728515625, 1.0, 1.0, 0.2423095703125, 0.11328125, 0.99609375, 0.5556640625, 0.360595703125, 0.947265625, 0.9990234375, 0.9990234375, 0.0960693359375, 0.99951171875, 0.13427734375, 0.1549072265625, 0.60009765625, 0.99853515625, 0.9921875, 0.99853515625, 0.9296875, 1.6689300537109375e-06, 0.014404296875, 0.167236328125, 0.07293701171875, 0.0909423828125, 0.078125, 0.042999267578125, 4.380941390991211e-05]], "normalized_score": [0.274080365896225], "tokens": [["\u2581The", "\u2581current", "\u2581sal", "ary", "\u2581for", "\u2581the", "\u2581Secretary", "\u2581of", "\u2581State", "\u2581of", "\u2581the", "\u2581United", "\u2581States", "\u2581is", "\u2581$", "2", "0", "5", ",", "7", "0", "0", ".", "\u2581However", ",", "\u2581this", "\u2581is", "\u2581subject", "\u2581to", "\u2581change", "\u2581based", "\u2581on", "\u2581annual", "\u2581cost", "\u2581of", "\u2581living", "\u2581adjust", "ments", ".", "\u2581#", "1", "0", "8", "6", "0", "9", "\u2581-"]], "entropy": [[2.50390625, 0.97119140625, 0.6171875, 3.4749507904052734e-05, 0.61572265625, 0.03277587890625, 1.3291015625, 0.0099945068359375, 0.0177764892578125, 0.6630859375, 0.0120849609375, 0.014892578125, 0.0101776123046875, 0.09503173828125, 0.20068359375, 0.045440673828125, 0.392822265625, 1.3046875, 0.00026679039001464844, 0.1678466796875, 7.581710815429688e-05, 4.690885543823242e-05, 1.044921875, 1.6064453125, 0.0299530029296875, 1.421875, 1.6005859375, 0.292236328125, 0.006866455078125, 0.00925445556640625, 1.8056640625, 0.003208160400390625, 2.046875, 0.88525390625, 0.67626953125, 0.010772705078125, 0.04766845703125, 0.0127105712890625, 0.308349609375, 0.7470703125, 4.03515625, 2.599609375, 2.421875, 2.60546875, 2.556640625, 2.376953125, 2.294921875]], "avg_entropy": [0.8606689306015664], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "$205,700", "score_of_biggest_cluster": 0.274080365896225, "score_of_first_answer": 0.274080365896225, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.6689300537109375e-06, "avg_score": 0.274080365896225, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.40864790303699516, "std_of_first_answer": 0.40864790303699516, "avg_entropy_of_first_answer": 0.8606689306015664, "lex_sim": 1.0}
{"question": "who was an early advocate for using scientific methods based on inductive reasoning", "answer": ["Francis Bacon #99."], "scores": [[0.9931640625, 0.99853515625, 1.0, 2.980232238769531e-07, 0.0048980712890625, 0.08380126953125, 0.00905609130859375, 0.0001283884048461914, 0.00013685226440429688, 0.0298919677734375, 0.99658203125, 0.98828125]], "normalized_score": [0.016964765265583992], "tokens": [["\u2581Francis", "\u2581Ba", "con", "\u2581#", "9", "9", ".", "\u2581G", "ross", "\u2581Dom", "estic", "\u2581Product"]], "entropy": [[0.057281494140625, 0.01172637939453125, 0.0006642341613769531, 0.796875, 5.55859375, 3.203125, 2.771484375, 2.796875, 1.57421875, 4.53515625, 0.0220794677734375, 0.09771728515625]], "avg_entropy": [1.7854830821355183], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Aristotle", "score_of_biggest_cluster": 0.016964765265583992, "score_of_first_answer": 0.016964765265583992, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.016964765265583992, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4821859355323606, "std_of_first_answer": 0.4821859355323606, "avg_entropy_of_first_answer": 1.7854830821355183, "lex_sim": 1.0}
{"question": "how did leo dalton die in silent witness", "answer": ["He was killed with a metal bar by a criminal he was trying to apprehend."], "scores": [[0.44580078125, 0.83154296875, 0.26220703125, 0.0222015380859375, 0.927734375, 0.0292205810546875, 0.328125, 0.339599609375, 0.537109375, 0.015533447265625, 0.72216796875, 0.994140625, 0.43701171875, 1.0, 0.9365234375, 1.0, 1.0, 0.98388671875, 5.960464477539063e-08, 0.0005807876586914062, 0.452880859375, 0.003757476806640625, 0.000698089599609375, 0.09002685546875, 0.2318115234375]], "normalized_score": [0.09230085462331772], "tokens": [["\u2581He", "\u2581was", "\u2581killed", "\u2581with", "\u2581a", "\u2581metal", "\u2581bar", "\u2581by", "\u2581a", "\u2581criminal", "\u2581he", "\u2581was", "\u2581trying", "\u2581to", "\u2581app", "reh", "end", ".", "\u2581###", "\u2581What", "\u2581is", "\u2581an", "\u2581O", "CR", "?"]], "entropy": [[2.787109375, 0.6923828125, 1.71875, 0.77294921875, 0.3388671875, 3.494140625, 1.392578125, 1.6630859375, 1.2578125, 2.15234375, 1.01171875, 0.04345703125, 1.9677734375, 0.0018568038940429688, 0.284912109375, 2.0563602447509766e-05, 6.383657455444336e-05, 0.11126708984375, 0.447998046875, 4.8359375, 3.0078125, 1.7978515625, 2.853515625, 3.357421875, 3.56640625]], "avg_entropy": [1.5823213005065917], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "in an explosion", "score_of_biggest_cluster": 0.09230085462331772, "score_of_first_answer": 0.09230085462331772, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.09230085462331772, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38833508563009556, "std_of_first_answer": 0.38833508563009556, "avg_entropy_of_first_answer": 1.5823213005065917, "lex_sim": 1.0}
{"question": "when did starbucks become a publicly traded company", "answer": ["1992 #1 Song This Week 50 Years Ago: July 9, 1971 (Part 1)"], "scores": [[0.779296875, 1.0, 1.0, 1.0, 0.99951171875, 5.960464477539063e-08, 0.02447509765625, 1.4901161193847656e-05, 0.0005283355712890625, 0.5390625, 0.045501708984375, 0.01441192626953125, 0.76171875, 0.91162109375, 0.99853515625, 1.0, 0.315673828125, 0.0016660690307617188, 0.998046875, 0.0236358642578125, 0.97314453125, 0.99609375, 0.99951171875, 1.0, 0.8173828125, 0.4306640625, 0.023406982421875, 0.1171875, 0.904296875, 0.44921875, 0.87353515625]], "normalized_score": [0.11563476920127869], "tokens": [["\u2581", "1", "9", "9", "2", "\u2581#", "1", "\u2581Song", "\u2581This", "\u2581Week", "\u2581", "5", "0", "\u2581Years", "\u2581A", "go", ":", "\u2581July", "\u2581", "9", ",", "\u2581", "1", "9", "7", "1", "\u2581(", "Part", "\u2581", "1", ")"]], "entropy": [[0.65966796875, 0.0019702911376953125, 0.0011701583862304688, 0.0014476776123046875, 0.0030364990234375, 0.87353515625, 5.05859375, 3.08984375, 2.716796875, 1.55078125, 2.537109375, 0.57470703125, 1.125, 0.421142578125, 0.01435089111328125, 1.52587890625e-05, 2.6015625, 3.087890625, 0.018768310546875, 1.4736328125, 0.16796875, 0.02716064453125, 0.005062103271484375, 1.0132789611816406e-05, 0.4775390625, 1.166015625, 2.3515625, 4.61328125, 0.52490234375, 0.9423828125, 0.68017578125]], "avg_entropy": [1.1860349601314915], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "June 1992", "score_of_biggest_cluster": 0.11563476920127869, "score_of_first_answer": 0.11563476920127869, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.11563476920127869, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42288198248285397, "std_of_first_answer": 0.42288198248285397, "avg_entropy_of_first_answer": 1.1860349601314915, "lex_sim": 1.0}
{"question": "who is directly elected according to the constitution", "answer": ["President of India #FridayPuzzle: In a game of golf\u2026"], "scores": [[0.67724609375, 0.716796875, 0.611328125, 8.940696716308594e-07, 0.002101898193359375, 0.002002716064453125, 1.0, 0.0029144287109375, 0.39990234375, 0.9765625, 0.0017290115356445312, 0.00846099853515625, 0.056640625, 0.0201873779296875, 0.7841796875, 0.003635406494140625, 9.113550186157227e-05]], "normalized_score": [0.019008999690413475], "tokens": [["\u2581President", "\u2581of", "\u2581India", "\u2581#", "F", "rid", "ay", "P", "uzz", "le", ":", "\u2581In", "\u2581a", "\u2581game", "\u2581of", "\u2581golf", "\u2026"]], "entropy": [[1.01953125, 1.0, 0.80224609375, 1.265625, 5.50390625, 2.986328125, 0.0009489059448242188, 2.927734375, 2.810546875, 0.13037109375, 1.8095703125, 3.640625, 1.7705078125, 4.0703125, 0.7939453125, 4.44921875, 0.12274169921875]], "avg_entropy": [2.0649505503037395], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "senators", "score_of_biggest_cluster": 0.019008999690413475, "score_of_first_answer": 0.019008999690413475, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 8.940696716308594e-07, "avg_score": 0.019008999690413475, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37951908878025786, "std_of_first_answer": 0.37951908878025786, "avg_entropy_of_first_answer": 2.0649505503037395, "lex_sim": 1.0}
{"question": "real name of daya in taarak mehta ka ooltah chashmah", "answer": ["Disha Vakhani #10 Catchy Hook: \"Feeding the Fiber Frenzy: Delicious Recipes for Gut Health and Weight Loss\""], "scores": [[0.98291015625, 0.232666015625, 0.99951171875, 0.97705078125, 0.0533447265625, 0.82080078125, 1.1920928955078125e-07, 0.00543212890625, 0.054046630859375, 0.0003795623779296875, 4.112720489501953e-06, 0.03668212890625, 0.0014505386352539062, 0.258056640625, 0.262451171875, 0.00010728836059570312, 0.0009374618530273438, 0.30615234375, 0.00038433074951171875, 0.0009713172912597656, 0.29638671875, 0.90576171875, 0.99951171875, 0.07763671875, 0.00943756103515625, 0.1318359375, 0.0931396484375, 0.9892578125, 1.0, 0.486572265625, 0.06903076171875, 0.9150390625, 0.1522216796875, 0.20751953125, 1.0, 0.95751953125, 1.0, 0.494873046875]], "normalized_score": [0.049472641199827194], "tokens": [["\u2581D", "ish", "a", "\u2581V", "akh", "ani", "\u2581#", "1", "0", "\u2581C", "atch", "y", "\u2581Hook", ":", "\u2581\"", "Fe", "eding", "\u2581the", "\u2581F", "iber", "\u2581F", "ren", "zy", ":", "\u2581Del", "icious", "\u2581Re", "ci", "pes", "\u2581for", "\u2581Gut", "\u2581Health", "\u2581and", "\u2581We", "ight", "\u2581L", "oss", "\""]], "entropy": [[0.132080078125, 0.58740234375, 0.0042724609375, 0.1815185546875, 0.2203369140625, 0.56494140625, 1.0322265625, 4.1484375, 4.08203125, 3.712890625, 3.185546875, 3.70703125, 3.267578125, 2.685546875, 3.19140625, 3.265625, 0.1739501953125, 3.0078125, 3.701171875, 2.0546875, 2.9921875, 0.451904296875, 0.0034580230712890625, 1.783203125, 3.91015625, 1.5654296875, 3.037109375, 0.08062744140625, 0.0016841888427734375, 1.9345703125, 2.3359375, 0.4501953125, 1.7177734375, 3.17578125, 0.0012712478637695312, 0.19970703125, 0.00016510486602783203, 1.8193359375]], "avg_entropy": [1.7991313463763188], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Disha Vakani", "score_of_biggest_cluster": 0.049472641199827194, "score_of_first_answer": 0.049472641199827194, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.049472641199827194, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.40913583097108003, "std_of_first_answer": 0.40913583097108003, "avg_entropy_of_first_answer": 1.7991313463763188, "lex_sim": 1.0}
{"question": "panda is a national animal of which country", "answer": ["China #300: \u201cAlien Invasion\u201d (2001)"], "scores": [[0.9814453125, 2.384185791015625e-07, 0.00855255126953125, 0.10272216796875, 0.0521240234375, 0.0015707015991210938, 0.0019216537475585938, 0.021636962890625, 0.00044989585876464844, 0.51318359375, 0.00815582275390625, 0.9384765625, 0.99462890625, 0.62646484375, 0.018768310546875, 0.1549072265625, 0.8759765625, 0.362548828125, 0.1771240234375, 0.87353515625]], "normalized_score": [0.040002383291721344], "tokens": [["\u2581China", "\u2581#", "3", "0", "0", ":", "\u2581\u201c", "A", "li", "en", "\u2581In", "vas", "ion", "\u201d", "\u2581(", "2", "0", "0", "1", ")"]], "entropy": [[0.1312255859375, 0.56689453125, 4.75, 2.802734375, 3.0078125, 2.97265625, 5.15234375, 4.3671875, 4.4921875, 2.1640625, 4.6953125, 0.390625, 0.03704833984375, 2.189453125, 2.6171875, 5.26953125, 0.76318359375, 1.013671875, 1.9189453125, 0.76220703125]], "avg_entropy": [2.5032135009765626], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "China", "score_of_biggest_cluster": 0.040002383291721344, "score_of_first_answer": 0.040002383291721344, "max_score_of_first_answer": 0.99462890625, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.040002383291721344, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3851298760693266, "std_of_first_answer": 0.3851298760693266, "avg_entropy_of_first_answer": 2.5032135009765626, "lex_sim": 1.0}
{"question": "where does the great outdoors movie take place", "answer": ["Montana #DontGetBravoed"], "scores": [[0.40478515625, 0.99951171875, 3.5762786865234375e-07, 0.00185394287109375, 0.29296875, 0.04339599609375, 5.78761100769043e-05, 0.137451171875, 0.32080078125]], "normalized_score": [0.012717756442725658], "tokens": [["\u2581Mont", "ana", "\u2581#", "D", "ont", "Get", "Bra", "vo", "ed"]], "entropy": [[2.53515625, 0.0040435791015625, 1.0390625, 5.5078125, 3.576171875, 3.568359375, 3.25, 2.19140625, 2.3359375]], "avg_entropy": [2.667549981011285], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "in Pechoggin, Wisconsin", "score_of_biggest_cluster": 0.012717756442725658, "score_of_first_answer": 0.012717756442725658, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 3.5762786865234375e-07, "avg_score": 0.012717756442725658, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.30445150170276536, "std_of_first_answer": 0.30445150170276536, "avg_entropy_of_first_answer": 2.667549981011285, "lex_sim": 1.0}
{"question": "what ethnic group celebrates its contribution to america in october", "answer": ["Italian American"], "scores": [[0.64013671875, 0.3076171875]], "normalized_score": [0.44375336170196533], "tokens": [["\u2581Italian", "\u2581American"]], "entropy": [[1.4873046875, 1.0234375]], "avg_entropy": [1.25537109375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Filipino Americans", "score_of_biggest_cluster": 0.44375336170196533, "score_of_first_answer": 0.44375336170196533, "max_score_of_first_answer": 0.64013671875, "min_score_of_first_answer": 0.3076171875, "avg_score": 0.44375336170196533, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.166259765625, "std_of_first_answer": 0.166259765625, "avg_entropy_of_first_answer": 1.25537109375, "lex_sim": 1.0}
{"question": "who has the most all star mvp awards", "answer": ["LeBron James (with 4 MVP awards) as of my knowledge cut off in 2021 #3 Pineapple Express"], "scores": [[0.75, 1.0, 1.0, 0.99951171875, 0.0960693359375, 0.09173583984375, 0.9697265625, 0.9853515625, 0.5263671875, 1.0, 0.966796875, 0.91748046875, 0.25, 1.0, 0.65478515625, 0.951171875, 0.99853515625, 0.21826171875, 0.6748046875, 0.99609375, 1.0, 1.0, 1.0, 0.99951171875, 5.960464477539063e-08, 0.004634857177734375, 3.4689903259277344e-05, 1.710653305053711e-05, 0.160400390625, 0.07452392578125]], "normalized_score": [0.14813263714313507], "tokens": [["\u2581Le", "B", "ron", "\u2581James", "\u2581(", "with", "\u2581", "4", "\u2581M", "VP", "\u2581awards", ")", "\u2581as", "\u2581of", "\u2581my", "\u2581knowledge", "\u2581cut", "\u2581off", "\u2581in", "\u2581", "2", "0", "2", "1", "\u2581#", "3", "\u2581P", "ine", "apple", "\u2581Express"]], "entropy": [[1.1552734375, 0.0019741058349609375, 0.0002046823501586914, 0.0031890869140625, 1.5595703125, 2.287109375, 0.187744140625, 0.08538818359375, 1.326171875, 6.461143493652344e-05, 0.171142578125, 0.44970703125, 1.423828125, 0.0022830963134765625, 0.80224609375, 0.2291259765625, 0.013702392578125, 0.9248046875, 1.267578125, 0.0302581787109375, 0.0001798868179321289, 0.0001430511474609375, 0.0022563934326171875, 0.0055694580078125, 1.1826171875, 5.03125, 3.26171875, 2.947265625, 3.787109375, 4.625]], "avg_entropy": [1.0921491940816244], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Bob Pettit", "score_of_biggest_cluster": 0.14813263714313507, "score_of_first_answer": 0.14813263714313507, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.14813263714313507, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4108718426588056, "std_of_first_answer": 0.4108718426588056, "avg_entropy_of_first_answer": 1.0921491940816244, "lex_sim": 1.0}
{"question": "what are the top five wine producing states", "answer": ["California, Washington, Oregon, New York, and Florida ##### THE REVEREND HENRY VILLARD #######"], "scores": [[0.90625, 0.99658203125, 0.986328125, 1.0, 0.9921875, 0.99951171875, 0.984375, 1.0, 0.9931640625, 0.99169921875, 0.12139892578125, 0.0, 4.655122756958008e-05, 0.006359100341796875, 0.0010776519775390625, 0.0069580078125, 0.056488037109375, 0.39599609375, 0.990234375, 0.0012416839599609375, 0.430908203125, 0.87451171875, 0.062469482421875, 0.080810546875]], "normalized_score": [0.0], "tokens": [["\u2581California", ",", "\u2581Washington", ",", "\u2581Oregon", ",", "\u2581New", "\u2581York", ",", "\u2581and", "\u2581Florida", "\u2581#####", "\u2581THE", "\u2581RE", "VER", "END", "\u2581H", "EN", "RY", "\u2581VI", "LL", "ARD", "\u2581###", "####"]], "entropy": [[0.4404296875, 0.027130126953125, 0.1043701171875, 0.0020427703857421875, 0.0535888671875, 0.0054931640625, 0.1258544921875, 0.00014066696166992188, 0.04205322265625, 0.0621337890625, 1.3125, 0.9345703125, 2.359375, 2.8125, 1.470703125, 0.26806640625, 1.732421875, 2.19921875, 0.0679931640625, 2.5390625, 1.7158203125, 0.595703125, 3.546875, 1.4443359375]], "avg_entropy": [0.9942659338315328], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Washington", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4525448705998727, "std_of_first_answer": 0.4525448705998727, "avg_entropy_of_first_answer": 0.9942659338315328, "lex_sim": 1.0}
{"question": "who said beware of the ides of march", "answer": ["Julius Caesar"], "scores": [[0.845703125, 0.99267578125, 1.0]], "normalized_score": [0.9433549046516418], "tokens": [["\u2581Julius", "\u2581Ca", "esar"]], "entropy": [[0.658203125, 0.05133056640625, 0.00019037723541259766]], "avg_entropy": [0.23657468954722086], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the soothsayer", "score_of_biggest_cluster": 0.9433549046516418, "score_of_first_answer": 0.9433549046516418, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.845703125, "avg_score": 0.9433549046516418, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.07107283548917667, "std_of_first_answer": 0.07107283548917667, "avg_entropy_of_first_answer": 0.23657468954722086, "lex_sim": 1.0}
{"question": "who played the king in the ten commandments", "answer": ["Charlton Heston #26 Post by TP349 \u00bb Sat Jan 04, 2020 8:25 pm"], "scores": [[0.408203125, 0.99951171875, 1.0, 1.0, 0.99951171875, 1.7881393432617188e-07, 0.04998779296875, 0.036834716796875, 2.8014183044433594e-06, 0.004459381103515625, 0.01068115234375, 0.00653839111328125, 0.008636474609375, 0.06671142578125, 0.5751953125, 0.1483154296875, 0.047027587890625, 0.1292724609375, 0.9990234375, 0.1875, 0.2359619140625, 0.99853515625, 0.99267578125, 0.99951171875, 1.0, 0.9990234375, 0.99853515625, 0.99560546875, 0.088623046875, 0.99951171875, 0.2059326171875, 0.10211181640625, 0.6611328125]], "normalized_score": [0.10192271322011948], "tokens": [["\u2581Char", "l", "ton", "\u2581H", "eston", "\u2581#", "2", "6", "\u2581Post", "\u2581by", "\u2581T", "P", "3", "4", "9", "\u2581\u00bb", "\u2581Sat", "\u2581Jan", "\u2581", "0", "4", ",", "\u2581", "2", "0", "2", "0", "\u2581", "8", ":", "2", "5", "\u2581pm"]], "entropy": [[1.375, 0.0031299591064453125, 0.0022258758544921875, 0.001049041748046875, 0.0026874542236328125, 0.763671875, 5.015625, 2.69921875, 2.9296875, 2.884765625, 6.28515625, 5.484375, 2.421875, 2.97265625, 1.76171875, 2.69140625, 1.994140625, 2.46875, 0.00921630859375, 1.1083984375, 1.5107421875, 0.01140594482421875, 0.05255126953125, 0.003376007080078125, 1.424551010131836e-05, 0.00919342041015625, 0.01349639892578125, 0.036285400390625, 1.94140625, 0.00511932373046875, 1.79296875, 2.3046875, 0.650390625]], "avg_entropy": [1.5517088265130015], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Yul Brynner", "score_of_biggest_cluster": 0.10192271322011948, "score_of_first_answer": 0.10192271322011948, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.10192271322011948, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4398677243669844, "std_of_first_answer": 0.4398677243669844, "avg_entropy_of_first_answer": 1.5517088265130015, "lex_sim": 1.0}
{"question": "how long did the menendez brothers get in prison for killing their parents", "answer": ["Life without parole"], "scores": [[0.04449462890625, 0.317626953125, 0.93603515625, 1.0]], "normalized_score": [0.3391402065753937], "tokens": [["\u2581Life", "\u2581without", "\u2581par", "ole"]], "entropy": [[1.7109375, 1.5234375, 0.25244140625, 0.0004661083221435547]], "avg_entropy": [0.8718206286430359], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "life imprisonment", "score_of_biggest_cluster": 0.3391402065753937, "score_of_first_answer": 0.3391402065753937, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.04449462890625, "avg_score": 0.3391402065753937, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4057854632259697, "std_of_first_answer": 0.4057854632259697, "avg_entropy_of_first_answer": 0.8718206286430359, "lex_sim": 1.0}
{"question": "what was the immediate catalyst to the civil war", "answer": ["The immediate catalyst to the Civil War was the election of Abraham Lincoln as President of the United States in 1860 and the subsequent secession of several southern states in protest."], "scores": [[0.71923828125, 0.023712158203125, 0.7041015625, 1.0, 0.257080078125, 0.998046875, 0.42333984375, 0.998046875, 0.9921875, 0.99658203125, 0.97998046875, 0.998046875, 0.865234375, 0.998046875, 0.845703125, 0.451416015625, 0.88916015625, 0.9970703125, 0.99853515625, 0.99951171875, 0.4541015625, 0.67822265625, 1.0, 1.0, 1.0, 0.98974609375, 0.412841796875, 0.94140625, 0.56689453125, 0.99951171875, 1.0, 1.0, 0.9951171875, 0.79296875, 0.6953125, 0.9970703125, 0.1966552734375, 0.322021484375, 0.67333984375, 5.960464477539063e-08, 1.728534698486328e-05]], "normalized_score": [0.35927823185920715], "tokens": [["\u2581The", "\u2581immediate", "\u2581catal", "yst", "\u2581to", "\u2581the", "\u2581Civil", "\u2581War", "\u2581was", "\u2581the", "\u2581election", "\u2581of", "\u2581Abraham", "\u2581Lincoln", "\u2581as", "\u2581President", "\u2581of", "\u2581the", "\u2581United", "\u2581States", "\u2581in", "\u2581", "1", "8", "6", "0", "\u2581and", "\u2581the", "\u2581subsequent", "\u2581se", "cess", "ion", "\u2581of", "\u2581several", "\u2581southern", "\u2581states", "\u2581in", "\u2581protest", ".", "\u2581##", "\u2581Introduction"]], "entropy": [[1.5234375, 1.501953125, 0.673828125, 0.0003504753112792969, 1.0498046875, 0.0161895751953125, 0.98876953125, 0.0157318115234375, 0.060882568359375, 0.03289794921875, 0.159423828125, 0.0157318115234375, 0.50439453125, 0.0157470703125, 0.6005859375, 0.9599609375, 0.457763671875, 0.0205230712890625, 0.015228271484375, 0.00450897216796875, 1.275390625, 0.642578125, 5.513429641723633e-05, 0.0002105236053466797, 0.0005273818969726562, 0.057342529296875, 1.1640625, 0.2529296875, 1.1103515625, 0.00499725341796875, 0.0002841949462890625, 5.21540641784668e-05, 0.03436279296875, 0.7626953125, 0.64501953125, 0.024627685546875, 1.44140625, 1.5830078125, 0.7265625, 1.4541015625, 6.375]], "avg_entropy": [0.6383726480530529], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "slavery", "score_of_biggest_cluster": 0.35927823185920715, "score_of_first_answer": 0.35927823185920715, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.35927823185920715, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3174561036827774, "std_of_first_answer": 0.3174561036827774, "avg_entropy_of_first_answer": 0.6383726480530529, "lex_sim": 1.0}
{"question": "what does the m number mean on a pint glass", "answer": ["The \"M\" number is not a widely recognized symbol or label on pint glasses."], "scores": [[0.224853515625, 0.8291015625, 0.87890625, 0.99072265625, 0.92529296875, 0.1697998046875, 0.050811767578125, 0.365966796875, 0.01021575927734375, 0.421875, 0.14892578125, 0.499755859375, 0.0164337158203125, 0.87353515625, 0.77685546875, 1.0, 0.99951171875, 0.86767578125, 0.301513671875, 0.99755859375, 0.423828125, 0.9765625, 0.974609375, 0.88330078125, 0.0256805419921875, 1.2993812561035156e-05, 8.046627044677734e-06, 5.513429641723633e-05, 8.33272933959961e-05, 0.9755859375, 0.030609130859375]], "normalized_score": [0.09826279431581497], "tokens": [["\u2581The", "\u2581\"", "M", "\"", "\u2581number", "\u2581is", "\u2581not", "\u2581a", "\u2581widely", "\u2581recognized", "\u2581symbol", "\u2581or", "\u2581label", "\u2581on", "\u2581pint", "\u2581glass", "es", ".", "\u2581Can", "\u2581you", "\u2581please", "\u2581provide", "\u2581more", "\u2581context", "?", "\u2581P", "RESS", "\u2581SP", "OK", "ES", "MAN"]], "entropy": [[3.7421875, 0.63720703125, 0.374267578125, 0.060272216796875, 0.431884765625, 1.4033203125, 1.978515625, 1.517578125, 0.849609375, 0.82861328125, 2.134765625, 1.1806640625, 1.689453125, 0.57421875, 0.5537109375, 0.0016660690307617188, 0.0035877227783203125, 0.465576171875, 1.3759765625, 0.02044677734375, 0.7275390625, 0.1441650390625, 0.1466064453125, 0.38232421875, 0.196044921875, 0.38623046875, 0.409423828125, 3.994140625, 0.0206756591796875, 0.171630859375, 2.482421875]], "avg_entropy": [0.9317653102259482], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "imperial fluid ounces", "score_of_biggest_cluster": 0.09826279431581497, "score_of_first_answer": 0.09826279431581497, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 8.046627044677734e-06, "avg_score": 0.09826279431581497, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40539661679725025, "std_of_first_answer": 0.40539661679725025, "avg_entropy_of_first_answer": 0.9317653102259482, "lex_sim": 1.0}
{"question": "where is the boy who played charlie in willy wonka", "answer": ["UPI can't find the name of the actor who played Charlie in Willy Wonka."], "scores": [[0.0002982616424560547, 0.057586669921875, 0.002361297607421875, 0.51513671875, 1.0, 0.448486328125, 0.1466064453125, 0.13232421875, 0.64208984375, 0.97900390625, 0.57470703125, 0.77490234375, 0.99365234375, 0.9384765625, 0.2509765625, 0.79736328125, 1.0, 1.0, 0.99951171875, 1.0, 0.67578125, 1.8477439880371094e-06, 0.0013952255249023438, 0.055755615234375, 0.07061767578125, 0.004070281982421875, 4.26173210144043e-05, 0.069580078125, 0.00022101402282714844, 0.8837890625, 0.75634765625, 1.0, 0.7529296875, 0.04034423828125, 0.97314453125, 0.9892578125, 0.97607421875, 0.99853515625, 0.99072265625, 0.998046875]], "normalized_score": [0.12967908382415771], "tokens": [["\u2581U", "PI", "\u2581can", "'", "t", "\u2581find", "\u2581the", "\u2581name", "\u2581of", "\u2581the", "\u2581actor", "\u2581who", "\u2581played", "\u2581Charlie", "\u2581in", "\u2581Wil", "ly", "\u2581W", "on", "ka", ".", "\u2581#", "3", "9", "6", ":", "\u2581\u201c", "The", "\u2581Great", "\u2581G", "ats", "by", "\u201d", "\u2581by", "\u2581F", ".", "\u2581Scott", "\u2581Fitz", "ger", "ald"]], "entropy": [[3.837890625, 3.685546875, 4.0234375, 1.3427734375, 0.00012636184692382812, 2.25, 2.21875, 2.287109375, 1.50390625, 0.149658203125, 0.96630859375, 0.95263671875, 0.0433349609375, 0.3173828125, 0.63671875, 0.65673828125, 3.4749507904052734e-05, 0.00218963623046875, 0.0041351318359375, 5.841255187988281e-05, 1.291015625, 1.3408203125, 4.61328125, 2.640625, 2.552734375, 2.6796875, 5.2890625, 4.60546875, 4.53515625, 0.80908203125, 1.158203125, 0.0018100738525390625, 1.3408203125, 3.876953125, 0.216796875, 0.07635498046875, 0.1612548828125, 0.01456451416015625, 0.063232421875, 0.0173797607421875]], "avg_entropy": [1.5540760084986687], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Peter Gardner[4] Ostrum", "score_of_biggest_cluster": 0.12967908382415771, "score_of_first_answer": 0.12967908382415771, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.8477439880371094e-06, "avg_score": 0.12967908382415771, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4175948690290785, "std_of_first_answer": 0.4175948690290785, "avg_entropy_of_first_answer": 1.5540760084986687, "lex_sim": 1.0}
{"question": "why the hole in the ozone layer over antarctica", "answer": ["The hole in the ozone layer over Antarctica is caused by the presence of man-made chemicals, specifically chlorofluorocarbons (CFCs), which break down in the atmosphere and release chlorine atoms"], "scores": [[0.6357421875, 0.9345703125, 0.9970703125, 0.99951171875, 0.9990234375, 1.0, 0.99951171875, 0.99560546875, 0.99951171875, 0.9990234375, 0.99951171875, 0.80126953125, 0.95849609375, 0.99755859375, 0.76318359375, 0.07733154296875, 1.0, 0.08416748046875, 0.99560546875, 0.99951171875, 0.974609375, 0.99951171875, 0.6669921875, 0.6591796875, 0.994140625, 1.0, 0.99267578125, 1.0, 1.0, 1.0, 0.9990234375, 0.99853515625, 0.99951171875, 0.99462890625, 0.99951171875, 1.0, 1.0, 0.9033203125, 0.984375, 0.400634765625, 0.99951171875, 0.64404296875, 0.9990234375, 0.5947265625, 0.98095703125, 0.81689453125, 0.99658203125, 1.0, 1.0, 0.1402587890625]], "normalized_score": [0.799948513507843], "tokens": [["\u2581The", "\u2581hole", "\u2581in", "\u2581the", "\u2581o", "zone", "\u2581layer", "\u2581over", "\u2581Ant", "arct", "ica", "\u2581is", "\u2581caused", "\u2581by", "\u2581the", "\u2581presence", "\u2581of", "\u2581man", "-", "made", "\u2581chemical", "s", ",", "\u2581specifically", "\u2581ch", "lor", "of", "lu", "or", "oc", "ar", "b", "ons", "\u2581(", "C", "FC", "s", "),", "\u2581which", "\u2581break", "\u2581down", "\u2581in", "\u2581the", "\u2581atmosphere", "\u2581and", "\u2581release", "\u2581ch", "lor", "ine", "\u2581atoms"]], "entropy": [[1.7724609375, 0.311767578125, 0.0232696533203125, 0.005641937255859375, 0.01026153564453125, 0.00025153160095214844, 0.006046295166015625, 0.035552978515625, 0.0031585693359375, 0.0072784423828125, 0.003940582275390625, 0.74658203125, 0.2410888671875, 0.0186004638671875, 0.72802734375, 1.4609375, 0.001049041748046875, 1.150390625, 0.030303955078125, 0.0044097900390625, 0.1510009765625, 0.00311279296875, 1.095703125, 1.056640625, 0.04705810546875, 3.415346145629883e-05, 0.04339599609375, 0.0020999908447265625, 0.0009264945983886719, 0.00033926963806152344, 0.01010894775390625, 0.012420654296875, 0.00531005859375, 0.039398193359375, 0.00423431396484375, 0.0013561248779296875, 0.0002892017364501953, 0.388427734375, 0.0849609375, 1.8525390625, 0.005558013916015625, 0.86865234375, 0.00675201416015625, 0.99658203125, 0.10186767578125, 0.93994140625, 0.0308074951171875, 1.9729137420654297e-05, 3.343820571899414e-05, 1.0888671875]], "avg_entropy": [0.3079891550540924], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "bromine", "score_of_biggest_cluster": 0.799948513507843, "score_of_first_answer": 0.799948513507843, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.07733154296875, "avg_score": 0.799948513507843, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.23912322215652215, "std_of_first_answer": 0.23912322215652215, "avg_entropy_of_first_answer": 0.3079891550540924, "lex_sim": 1.0}
{"question": "who sings gone gone gone she been gone so long", "answer": ["Lonnie Mack"], "scores": [[0.006404876708984375, 0.08502197265625, 0.951171875, 0.865234375]], "normalized_score": [0.14549855887889862], "tokens": [["\u2581L", "on", "nie", "\u2581Mack"]], "entropy": [[4.35546875, 3.052734375, 0.250732421875, 0.54833984375]], "avg_entropy": [2.05181884765625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Chilliwack", "score_of_biggest_cluster": 0.14549855887889862, "score_of_first_answer": 0.14549855887889862, "max_score_of_first_answer": 0.951171875, "min_score_of_first_answer": 0.006404876708984375, "avg_score": 0.14549855887889862, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43320648482977625, "std_of_first_answer": 0.43320648482977625, "avg_entropy_of_first_answer": 2.05181884765625, "lex_sim": 1.0}
{"question": "who is the presiding officer of legislative council in india", "answer": ["None, as the Presiding Officer of the Legislative Council is different for each state in India."], "scores": [[0.046630859375, 0.55078125, 0.265869140625, 0.7841796875, 0.353271484375, 0.9990234375, 0.93701171875, 0.71826171875, 0.77587890625, 0.98486328125, 1.0, 0.98583984375, 0.54345703125, 0.267822265625, 0.455322265625, 0.9931640625, 0.927734375, 0.8017578125, 0.99951171875, 0.8466796875, 0.0, 0.0195770263671875, 0.033203125, 0.483154296875, 0.01348114013671875, 0.0016880035400390625, 0.2451171875, 1.0, 0.4130859375]], "normalized_score": [0.0], "tokens": [["\u2581None", ",", "\u2581as", "\u2581the", "\u2581Pres", "iding", "\u2581Officer", "\u2581of", "\u2581the", "\u2581Legisl", "ative", "\u2581Council", "\u2581is", "\u2581different", "\u2581for", "\u2581each", "\u2581state", "\u2581in", "\u2581India", ".", "\u2581CHAPTER", "\u2581", "7", ":", "\u2581A", "CC", "ID", "ENT", "S"]], "entropy": [[1.78125, 1.6240234375, 2.0625, 1.056640625, 2.05078125, 0.0077362060546875, 0.2646484375, 0.759765625, 0.59765625, 0.10308837890625, 0.0001304149627685547, 0.0877685546875, 1.2314453125, 2.580078125, 1.0029296875, 0.0457763671875, 0.298583984375, 0.7333984375, 0.003269195556640625, 0.638671875, 1.208984375, 0.9609375, 1.8955078125, 2.515625, 4.83984375, 2.578125, 1.826171875, 0.0016775131225585938, 1.8369140625]], "avg_entropy": [1.1928941052535484], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Chairman", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37002876322999506, "std_of_first_answer": 0.37002876322999506, "avg_entropy_of_first_answer": 1.1928941052535484, "lex_sim": 1.0}
{"question": "who plays auggie in the movie the wonder", "answer": ["Jacob Tremblay #BREAKING: Reports of Active Shooter at NAS Pensacola in Florida"], "scores": [[0.81982421875, 1.0, 1.0, 1.0, 1.0, 5.364418029785156e-07, 0.006591796875, 0.062286376953125, 0.97900390625, 0.393798828125, 0.1806640625, 0.0009446144104003906, 0.44775390625, 0.1441650390625, 4.839897155761719e-05, 0.97119140625, 0.998046875, 0.52978515625, 0.0013904571533203125, 0.98193359375, 1.0, 1.0, 0.99951171875, 0.1856689453125, 0.99609375]], "normalized_score": [0.11675819009542465], "tokens": [["\u2581Jacob", "\u2581T", "rem", "bl", "ay", "\u2581#", "B", "RE", "AK", "ING", ":", "\u2581Re", "ports", "\u2581of", "\u2581Active", "\u2581Sho", "oter", "\u2581at", "\u2581NAS", "\u2581P", "ens", "ac", "ola", "\u2581in", "\u2581Florida"]], "entropy": [[0.71142578125, 0.0018014907836914062, 0.0005507469177246094, 0.0024471282958984375, 1.0967254638671875e-05, 0.281005859375, 6.08984375, 4.78125, 0.172607421875, 1.4228515625, 2.837890625, 5.078125, 2.794921875, 2.517578125, 3.60546875, 0.1771240234375, 0.0154876708984375, 1.5087890625, 4.0546875, 0.142333984375, 0.002620697021484375, 0.0007529258728027344, 0.0033779144287109375, 1.6533203125, 0.03619384765625]], "avg_entropy": [1.5156986808776856], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Jacob Tremblay", "score_of_biggest_cluster": 0.11675819009542465, "score_of_first_answer": 0.11675819009542465, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.364418029785156e-07, "avg_score": 0.11675819009542465, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4294773811580365, "std_of_first_answer": 0.4294773811580365, "avg_entropy_of_first_answer": 1.5156986808776856, "lex_sim": 1.0}
{"question": "who invented the cornell method of note taking", "answer": ["Sarah Cornell"], "scores": [[0.1109619140625, 0.302490234375, 0.99951171875]], "normalized_score": [0.32252076268196106], "tokens": [["\u2581Sarah", "\u2581Corn", "ell"]], "entropy": [[2.478515625, 2.96875, 0.0063934326171875]], "avg_entropy": [1.8178863525390625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Walter Pauk", "score_of_biggest_cluster": 0.32252076268196106, "score_of_first_answer": 0.32252076268196106, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.1109619140625, "avg_score": 0.32252076268196106, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3818147896809904, "std_of_first_answer": 0.3818147896809904, "avg_entropy_of_first_answer": 1.8178863525390625, "lex_sim": 1.0}
{"question": "who was the successful commanding general of the northern forces in the civil war", "answer": ["Ulysses S. Grant #BookReview: The Death of Lucy Kyte by Nicola Upson"], "scores": [[0.9609375, 1.0, 1.0, 1.0, 0.9970703125, 0.98828125, 0.99951171875, 1.6093254089355469e-06, 3.0159950256347656e-05, 0.00620269775390625, 0.39404296875, 0.17236328125, 0.060302734375, 9.560585021972656e-05, 0.86083984375, 0.00019288063049316406, 0.45703125, 0.6357421875, 0.583984375, 0.55712890625, 0.88916015625, 0.99951171875]], "normalized_score": [0.08276060223579407], "tokens": [["\u2581U", "ly", "ss", "es", "\u2581S", ".", "\u2581Grant", "\u2581#", "Book", "Re", "view", ":", "\u2581The", "\u2581Death", "\u2581of", "\u2581Lucy", "\u2581Ky", "te", "\u2581by", "\u2581Nicola", "\u2581U", "pson"]], "entropy": [[0.240234375, 0.0018987655639648438, 4.184246063232422e-05, 9.763240814208984e-05, 0.022491455078125, 0.06396484375, 0.0027790069580078125, 0.8955078125, 4.34375, 4.4375, 0.7724609375, 2.8671875, 2.7890625, 4.12890625, 0.603515625, 2.9765625, 2.443359375, 1.45703125, 1.9287109375, 2.640625, 0.619140625, 0.00418853759765625]], "avg_entropy": [1.5108643986962058], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "George B. McClellan", "score_of_biggest_cluster": 0.08276060223579407, "score_of_first_answer": 0.08276060223579407, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.6093254089355469e-06, "avg_score": 0.08276060223579407, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4103038708709236, "std_of_first_answer": 0.4103038708709236, "avg_entropy_of_first_answer": 1.5108643986962058, "lex_sim": 1.0}
{"question": "which is the fastest train in india and what is its speed", "answer": ["The fastest train in India is the Gatimaan Express with a maximum speed of 160 km/h, which is approximately 100 miles per hour."], "scores": [[0.90869140625, 0.771484375, 1.0, 0.99755859375, 0.99951171875, 0.9970703125, 0.9853515625, 0.99755859375, 0.685546875, 0.9990234375, 0.9794921875, 1.0, 1.0, 0.447998046875, 0.99658203125, 0.85693359375, 0.99951171875, 1.0, 0.99951171875, 0.9990234375, 0.99951171875, 1.0, 0.98095703125, 0.92236328125, 0.755859375, 0.02252197265625, 0.1383056640625, 0.73388671875, 0.611328125, 0.99072265625, 0.96142578125, 0.9970703125, 0.99609375, 0.5244140625, 0.9931640625, 0.99951171875, 0.99755859375, 8.344650268554688e-07, 0.023406982421875, 0.04638671875, 0.06317138671875, 1.1205673217773438e-05, 0.00022113323211669922, 0.0006284713745117188, 0.0083160400390625, 0.34228515625, 0.040771484375, 0.325439453125]], "normalized_score": [0.23088335990905762], "tokens": [["\u2581The", "\u2581fast", "est", "\u2581train", "\u2581in", "\u2581India", "\u2581is", "\u2581the", "\u2581G", "at", "ima", "an", "\u2581Express", "\u2581with", "\u2581a", "\u2581maximum", "\u2581speed", "\u2581of", "\u2581", "1", "6", "0", "\u2581km", "/", "h", ",", "\u2581which", "\u2581is", "\u2581approximately", "\u2581", "1", "0", "0", "\u2581miles", "\u2581per", "\u2581hour", ".", "\u2581#", "1", "9", "2", "\u2581L", "'", "Aut", "re", "\u2581Monde", "\u2581", "1"]], "entropy": [[0.57470703125, 1.169921875, 0.0002663135528564453, 0.0207366943359375, 0.0064849853515625, 0.02117919921875, 0.09552001953125, 0.0195770263671875, 1.4072265625, 0.01061248779296875, 0.1044921875, 0.001224517822265625, 0.0018901824951171875, 1.0703125, 0.028350830078125, 0.5322265625, 0.00518035888671875, 0.00257110595703125, 0.004741668701171875, 0.006381988525390625, 0.003368377685546875, 0.00020110607147216797, 0.11102294921875, 0.326904296875, 0.72705078125, 0.826171875, 2.341796875, 1.0576171875, 1.4482421875, 0.0638427734375, 0.1748046875, 0.0236968994140625, 0.03277587890625, 0.771484375, 0.04193115234375, 0.003025054931640625, 0.0208892822265625, 0.84716796875, 2.904296875, 2.380859375, 2.875, 2.734375, 2.96875, 4.94140625, 2.068359375, 3.482421875, 2.69140625, 1.802734375]], "avg_entropy": [0.890733482937018], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Gatiman", "score_of_biggest_cluster": 0.23088335990905762, "score_of_first_answer": 0.23088335990905762, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 8.344650268554688e-07, "avg_score": 0.23088335990905762, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39795330654827293, "std_of_first_answer": 0.39795330654827293, "avg_entropy_of_first_answer": 0.890733482937018, "lex_sim": 1.0}
{"question": "who did the chiefs play in the playoffs", "answer": ["Tennessee Titans"], "scores": [[0.61962890625, 0.99853515625, 1.0]], "normalized_score": [0.852115273475647], "tokens": [["\u2581Tennessee", "\u2581Tit", "ans"]], "entropy": [[1.51953125, 0.01204681396484375, 8.779764175415039e-05]], "avg_entropy": [0.5105552872021993], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the Tennessee Titans", "score_of_biggest_cluster": 0.852115273475647, "score_of_first_answer": 0.852115273475647, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.61962890625, "avg_score": 0.852115273475647, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.17896438535109147, "std_of_first_answer": 0.17896438535109147, "avg_entropy_of_first_answer": 0.5105552872021993, "lex_sim": 1.0}
{"question": "when does middle-earth shadow of mordor come out", "answer": ["September 30, 2020"], "scores": [[0.1492919921875, 0.98974609375, 0.98828125, 0.99658203125, 0.826171875, 0.994140625, 1.0, 1.0, 0.44140625, 0.94873046875]], "normalized_score": [0.7412169575691223], "tokens": [["\u2581September", "\u2581", "3", "0", ",", "\u2581", "2", "0", "2", "0"]], "entropy": [[2.6796875, 0.06939697265625, 0.0733642578125, 0.02801513671875, 0.5302734375, 0.0390625, 0.00122833251953125, 7.43865966796875e-05, 0.689453125, 0.2381591796875]], "avg_entropy": [0.4348714828491211], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "September 2014", "score_of_biggest_cluster": 0.7412169575691223, "score_of_first_answer": 0.7412169575691223, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.1492919921875, "avg_score": 0.7412169575691223, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.28132286849721677, "std_of_first_answer": 0.28132286849721677, "avg_entropy_of_first_answer": 0.4348714828491211, "lex_sim": 1.0}
{"question": "how long were the pyramids the tallest structure", "answer": ["The Great Pyramid of Giza held the title of the tallest structure in the world for over 4,000 years, from its construction ca."], "scores": [[0.05169677734375, 0.317138671875, 0.98974609375, 1.0, 0.98486328125, 0.99609375, 0.994140625, 1.0, 0.1370849609375, 0.92626953125, 0.6298828125, 0.84619140625, 0.4169921875, 0.9677734375, 1.0, 0.73681640625, 0.90283203125, 1.0, 1.0, 0.99853515625, 0.8720703125, 1.0, 0.861328125, 0.9970703125, 0.99951171875, 1.0, 1.0, 1.0, 0.54296875, 0.9384765625, 0.10247802734375, 0.418212890625, 0.08843994140625, 0.99951171875, 0.9990234375, 1.0, 0.99951171875, 0.017974853515625, 1.0, 0.70849609375, 0.916015625, 0.9912109375, 0.98291015625, 0.49169921875, 0.99951171875, 0.529296875, 1.0, 0.99951171875, 0.60693359375]], "normalized_score": [0.65116947889328], "tokens": [["\u2581The", "\u2581Great", "\u2581Py", "ram", "id", "\u2581of", "\u2581G", "iza", "\u2581held", "\u2581the", "\u2581title", "\u2581of", "\u2581the", "\u2581tall", "est", "\u2581structure", "\u2581in", "\u2581the", "\u2581world", "\u2581for", "\u2581over", "\u2581", "4", ",", "0", "0", "0", "\u2581years", ",", "\u2581from", "\u2581its", "\u2581construction", "\u2581ca", ".", "\u2581", "2", "5", "6", "0", "\u2581B", "CE", "\u2581until", "\u2581the", "\u2581", "1", "9", "th", "\u2581century", "."]], "entropy": [[2.333984375, 1.2841796875, 0.0634765625, 0.0012521743774414062, 0.081298828125, 0.032012939453125, 0.041290283203125, 0.0023288726806640625, 0.9892578125, 0.3134765625, 0.7724609375, 0.55419921875, 0.86328125, 0.14892578125, 1.0728836059570312e-06, 0.68115234375, 0.33740234375, 0.00018978118896484375, 0.0012836456298828125, 0.01287078857421875, 0.40869140625, 0.0018377304077148438, 0.40234375, 0.0213165283203125, 0.004184722900390625, 5.662441253662109e-06, 3.349781036376953e-05, 0.0006899833679199219, 1.236328125, 0.252197265625, 0.560546875, 0.69140625, 0.759765625, 0.004451751708984375, 0.01025390625, 0.0002942085266113281, 0.004306793212890625, 0.09765625, 0.00010895729064941406, 0.669921875, 0.289794921875, 0.057159423828125, 0.11602783203125, 1.2685546875, 0.00414276123046875, 0.7158203125, 0.000812530517578125, 0.006328582763671875, 0.8671875]], "avg_entropy": [0.34625499954029004], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "over 3,800", "score_of_biggest_cluster": 0.65116947889328, "score_of_first_answer": 0.65116947889328, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.017974853515625, "avg_score": 0.65116947889328, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.30481986392558447, "std_of_first_answer": 0.30481986392558447, "avg_entropy_of_first_answer": 0.34625499954029004, "lex_sim": 1.0}
{"question": "who was one of the first to chart the course of forgetting over time", "answer": ["William James Morrissey #WPLongform, Articles, Food for Thought, Post A Day 2013, This is Life, Travel, tvaraj"], "scores": [[0.0041961669921875, 0.98974609375, 1.621246337890625e-05, 0.1474609375, 2.086162567138672e-06, 0.00749969482421875, 2.1576881408691406e-05, 0.99755859375, 0.98828125, 0.0015468597412109375, 1.3709068298339844e-05, 0.415771484375, 0.0005064010620117188, 0.443603515625, 0.8916015625, 1.0, 0.828125, 0.1290283203125, 0.95654296875, 0.99951171875, 0.98486328125, 1.0, 1.0, 0.99951171875, 0.311279296875, 0.9814453125, 0.30810546875, 0.99951171875, 0.99755859375, 0.8740234375, 0.035491943359375, 1.0, 0.9365234375, 0.398681640625, 0.984375, 1.0]], "normalized_score": [0.09871577471494675], "tokens": [["\u2581William", "\u2581James", "\u2581Morris", "sey", "\u2581#", "W", "PL", "ong", "form", ",", "\u2581Articles", ",", "\u2581Food", "\u2581for", "\u2581Th", "ought", ",", "\u2581Post", "\u2581A", "\u2581Day", "\u2581", "2", "0", "1", "3", ",", "\u2581This", "\u2581is", "\u2581Life", ",", "\u2581Tra", "vel", ",", "\u2581t", "var", "aj"]], "entropy": [[0.88671875, 0.09014892578125, 0.98583984375, 1.4697265625, 1.1181640625, 5.26171875, 1.2470703125, 0.024566650390625, 0.066650390625, 1.173828125, 5.5, 3.037109375, 5.64453125, 1.79296875, 0.48828125, 0.0011053085327148438, 0.94970703125, 4.37109375, 0.2325439453125, 0.00563812255859375, 0.0863037109375, 0.0006103515625, 0.0014553070068359375, 0.004528045654296875, 0.92041015625, 0.126220703125, 1.9296875, 0.00376129150390625, 0.0258026123046875, 0.473876953125, 1.109375, 0.0014257431030273438, 0.3740234375, 1.4013671875, 0.0989990234375, 0.002635955810546875]], "avg_entropy": [1.1363303926255968], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Hermann Ebbinghaus", "score_of_biggest_cluster": 0.09871577471494675, "score_of_first_answer": 0.09871577471494675, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.086162567138672e-06, "avg_score": 0.09871577471494675, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4303671209357904, "std_of_first_answer": 0.4303671209357904, "avg_entropy_of_first_answer": 1.1363303926255968, "lex_sim": 1.0}
{"question": "who won the ncaa women's championship last year 2017", "answer": ["South Carolina Gamecocks Women's Basketball"], "scores": [[0.98291015625, 0.99951171875, 0.982421875, 1.0, 1.0, 0.107666015625, 0.99853515625, 1.0, 0.982421875]], "normalized_score": [0.7759174108505249], "tokens": [["\u2581South", "\u2581Carolina", "\u2581Game", "co", "cks", "\u2581Women", "'", "s", "\u2581Basketball"]], "entropy": [[0.11700439453125, 0.00553131103515625, 0.1090087890625, 0.00034427642822265625, 4.649162292480469e-05, 1.2880859375, 0.01190185546875, 0.00012171268463134766, 0.1025390625]], "avg_entropy": [0.18162042564815944], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "South Carolina Gamecocks", "score_of_biggest_cluster": 0.7759174108505249, "score_of_first_answer": 0.7759174108505249, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.107666015625, "avg_score": 0.7759174108505249, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.27841318888905064, "std_of_first_answer": 0.27841318888905064, "avg_entropy_of_first_answer": 0.18162042564815944, "lex_sim": 1.0}
{"question": "what level is a city and guilds qualification", "answer": ["Level 2"], "scores": [[0.669921875, 0.9794921875, 0.91650390625]], "normalized_score": [0.8440855741500854], "tokens": [["\u2581Level", "\u2581", "2"]], "entropy": [[1.494140625, 0.1331787109375, 0.312744140625]], "avg_entropy": [0.6466878255208334], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "entry level to level 7", "score_of_biggest_cluster": 0.8440855741500854, "score_of_first_answer": 0.8440855741500854, "max_score_of_first_answer": 0.9794921875, "min_score_of_first_answer": 0.669921875, "avg_score": 0.8440855741500854, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.1335847629749045, "std_of_first_answer": 0.1335847629749045, "avg_entropy_of_first_answer": 0.6466878255208334, "lex_sim": 1.0}
{"question": "krypton-85 decays by emission of a beta particle. the product of this decay is", "answer": ["Rubidium-85 #IrishAbroad: Irish films The Levelling and Michael Inside selected for 2017 BFI London Film Festival"], "scores": [[0.1666259765625, 1.0, 1.0, 0.998046875, 1.0, 1.0, 0.0, 0.0004794597625732422, 0.0021209716796875, 0.0018777847290039062, 0.0001958608627319336, 0.98046875, 0.01580810546875, 0.004161834716796875, 0.0033550262451171875, 0.0002906322479248047, 0.00356292724609375, 0.99951171875, 0.8193359375, 0.1278076171875, 0.96533203125, 0.04541015625, 0.9873046875, 0.1253662109375, 0.88916015625, 0.97216796875, 0.9990234375, 0.94384765625, 0.51123046875, 0.994140625, 0.97802734375, 0.9853515625, 0.9580078125]], "normalized_score": [0.0], "tokens": [["\u2581Rub", "id", "ium", "-", "8", "5", "\u2581#", "I", "r", "ish", "Ab", "road", ":", "\u2581Irish", "\u2581films", "\u2581The", "\u2581Lev", "elling", "\u2581and", "\u2581Michael", "\u2581Inside", "\u2581selected", "\u2581for", "\u2581", "2", "0", "1", "7", "\u2581B", "FI", "\u2581London", "\u2581Film", "\u2581Festival"]], "entropy": [[2.0703125, 0.00026106834411621094, 0.0001366138458251953, 0.017486572265625, 0.000576019287109375, 0.000370025634765625, 0.61376953125, 3.47265625, 4.22265625, 2.353515625, 3.107421875, 0.1785888671875, 1.369140625, 4.765625, 5.3828125, 2.4453125, 2.7265625, 0.002765655517578125, 0.5927734375, 2.99609375, 0.155029296875, 3.28125, 0.08612060546875, 3.630859375, 0.51123046875, 0.195556640625, 0.01035308837890625, 0.2607421875, 2.37890625, 0.04608154296875, 0.1500244140625, 0.10321044921875, 0.245849609375]], "avg_entropy": [1.43557730588046], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "rubidium-85", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.45956178788191865, "std_of_first_answer": 0.45956178788191865, "avg_entropy_of_first_answer": 1.43557730588046, "lex_sim": 1.0}
{"question": "when did fender start making amps in mexico", "answer": ["late 1990s #MeToo is an opportunity, not just for apologies"], "scores": [[0.00794219970703125, 0.994140625, 0.96142578125, 1.0, 0.08392333984375, 0.99853515625, 0.95361328125, 0.0, 7.814168930053711e-05, 0.7412109375, 0.9990234375, 0.0178680419921875, 0.146240234375, 2.4318695068359375e-05, 0.003391265869140625, 0.6650390625, 0.31787109375, 0.050201416015625, 0.0010814666748046875, 0.96728515625]], "normalized_score": [0.0], "tokens": [["\u2581late", "\u2581", "1", "9", "9", "0", "s", "\u2581#", "Me", "To", "o", "\u2581is", "\u2581an", "\u2581opportunity", ",", "\u2581not", "\u2581just", "\u2581for", "\u2581ap", "ologies"]], "entropy": [[1.67578125, 0.046173095703125, 0.2177734375, 1.9073486328125e-05, 1.0771484375, 0.014068603515625, 0.2052001953125, 0.8857421875, 5.19921875, 1.6826171875, 0.0103607177734375, 3.7890625, 1.7841796875, 1.5439453125, 0.84228515625, 2.005859375, 0.962890625, 0.92626953125, 1.962890625, 0.150390625]], "avg_entropy": [1.2490938186645508], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1996", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4420650957303039, "std_of_first_answer": 0.4420650957303039, "avg_entropy_of_first_answer": 1.2490938186645508, "lex_sim": 1.0}
{"question": "what is the first line of an http request to the server", "answer": ["GET / HTTP/1.1 #1: The New Era?"], "scores": [[0.9130859375, 0.66162109375, 0.57568359375, 0.994140625, 0.99072265625, 0.998046875, 0.99560546875, 0.0, 0.0006017684936523438, 0.017669677734375, 0.00689697265625, 7.033348083496094e-06, 5.906820297241211e-05, 0.00012993812561035156, 0.0004911422729492188, 0.0011644363403320312, 0.52294921875, 0.99951171875, 0.99072265625, 0.135498046875, 0.400390625, 0.010345458984375, 0.91748046875, 0.6962890625, 0.0101776123046875, 0.081298828125, 0.1922607421875, 0.4169921875, 0.03936767578125, 0.99609375, 0.01042938232421875, 0.0005469322204589844, 0.0148162841796875, 0.90625, 0.0023937225341796875, 0.07940673828125, 0.037200927734375, 0.346435546875, 0.99658203125, 0.99267578125, 0.99755859375, 0.8076171875, 0.64208984375, 0.470703125]], "normalized_score": [0.0], "tokens": [["\u2581GET", "\u2581/", "\u2581HTTP", "/", "1", ".", "1", "\u2581#", "1", ":", "\u2581The", "\u2581New", "\u2581Era", "?", "\u2581Why", "\u2581T", "ik", "T", "ok", "\u2581is", "\u2581the", "\u2581Social", "\u2581Media", "\u2581Platform", "\u2581that", "\u2581Every", "one", "\u2581is", "\u2581Watch", "ing", "\u2581|", "\u2581Why", "\u2581Social", "\u2581Media", "\u2581St", "ats", "\u2581Say", "\u2581T", "ik", "T", "ok", "\u2581is", "\u2581the", "\u2581Future"]], "entropy": [[0.5283203125, 0.98583984375, 1.2763671875, 0.04345703125, 0.055694580078125, 0.015716552734375, 0.03167724609375, 0.59326171875, 3.498046875, 2.673828125, 3.072265625, 0.650390625, 0.1732177734375, 1.880859375, 2.42578125, 4.94921875, 2.703125, 0.006237030029296875, 0.06317138671875, 3.35546875, 3.630859375, 3.658203125, 0.457275390625, 2.029296875, 1.9697265625, 4.1796875, 2.009765625, 2.138671875, 1.1884765625, 0.034515380859375, 2.302734375, 5.72265625, 2.462890625, 0.69677734375, 3.091796875, 1.8916015625, 3.57421875, 3.103515625, 0.0265350341796875, 0.05511474609375, 0.0213165283203125, 1.1552734375, 2.017578125, 1.8056640625]], "avg_entropy": [1.7774112874811345], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "A request line", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4169037128916961, "std_of_first_answer": 0.4169037128916961, "avg_entropy_of_first_answer": 1.7774112874811345, "lex_sim": 1.0}
{"question": "what information is displayed in clear text from the ftp header", "answer": ["Source port, Destination port, Service name, Date, Time, and Ident ### What is NPM?"], "scores": [[0.01554107666015625, 0.004261016845703125, 0.5732421875, 0.85400390625, 1.0, 0.98046875, 0.9619140625, 0.1279296875, 0.2822265625, 0.92333984375, 0.0762939453125, 0.70458984375, 0.97021484375, 0.94921875, 0.06402587890625, 0.014373779296875, 0.0, 5.602836608886719e-06, 0.5146484375, 4.506111145019531e-05, 0.0012178421020507812, 0.4833984375]], "normalized_score": [0.0], "tokens": [["\u2581Source", "\u2581port", ",", "\u2581Dest", "ination", "\u2581port", ",", "\u2581Service", "\u2581name", ",", "\u2581Date", ",", "\u2581Time", ",", "\u2581and", "\u2581Ident", "\u2581###", "\u2581What", "\u2581is", "\u2581N", "PM", "?"]], "entropy": [[4.2421875, 0.65234375, 1.33984375, 0.44677734375, 0.0016431808471679688, 0.1324462890625, 0.20361328125, 1.6767578125, 1.4287109375, 0.382080078125, 2.53515625, 0.947265625, 0.2222900390625, 0.259033203125, 4.0859375, 3.90234375, 0.05230712890625, 1.9189453125, 1.9111328125, 2.060546875, 3.271484375, 2.81640625]], "avg_entropy": [1.5676933201876553], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "all transmissions", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4066327701614977, "std_of_first_answer": 0.4066327701614977, "avg_entropy_of_first_answer": 1.5676933201876553, "lex_sim": 1.0}
{"question": "what was the first video game for nintendo", "answer": ["Nintendo's first video game system was the Color TV-Game series, which was released in 1977 in Japan."], "scores": [[0.0223541259765625, 0.81298828125, 0.5625, 1.0, 0.99755859375, 0.681640625, 0.9990234375, 0.0172576904296875, 0.91455078125, 0.8505859375, 0.95654296875, 0.9248046875, 0.994140625, 0.998046875, 0.3681640625, 0.91796875, 0.8583984375, 0.9208984375, 0.99072265625, 0.99853515625, 0.72119140625, 1.0, 1.0, 1.0, 1.0, 0.5078125, 0.99951171875, 0.93359375, 0.0, 0.00910186767578125, 0.18505859375, 0.0146331787109375, 0.001079559326171875, 0.580078125, 0.40625]], "normalized_score": [0.0], "tokens": [["\u2581N", "intendo", "'", "s", "\u2581first", "\u2581video", "\u2581game", "\u2581system", "\u2581was", "\u2581the", "\u2581Color", "\u2581TV", "-", "Game", "\u2581series", ",", "\u2581which", "\u2581was", "\u2581released", "\u2581in", "\u2581", "1", "9", "7", "7", "\u2581in", "\u2581Japan", ".", "\u2581###", "What", "\u2581is", "\u2581a", "\u2581V", "PN", "?"]], "entropy": [[2.8046875, 0.57763671875, 2.29296875, 2.2411346435546875e-05, 0.02587890625, 0.787109375, 0.01012420654296875, 0.265869140625, 0.3837890625, 0.52197265625, 0.250244140625, 0.278564453125, 0.03765869140625, 0.0140228271484375, 1.5732421875, 0.41064453125, 0.47119140625, 0.41259765625, 0.07208251953125, 0.0111541748046875, 0.64306640625, 0.00019669532775878906, 0.0004718303680419922, 0.0001690387725830078, 0.0019207000732421875, 0.85009765625, 0.004764556884765625, 0.3388671875, 1.2607421875, 5.8828125, 2.193359375, 1.2646484375, 5.65625, 2.47265625, 1.9970703125]], "avg_entropy": [0.9648158414023263], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Magnavox Odyssey", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37111114314437504, "std_of_first_answer": 0.37111114314437504, "avg_entropy_of_first_answer": 0.9648158414023263, "lex_sim": 1.0}
{"question": "what is the name of the gap between two front teeth", "answer": ["diastema (Spain) #TheFavourite sweeps the #BAFTAs with seven wins!"], "scores": [[0.416015625, 1.0, 0.9931640625, 0.0026035308837890625, 0.007595062255859375, 0.0794677734375, 0.7958984375, 7.68899917602539e-06, 0.0028438568115234375, 0.0728759765625, 0.00035309791564941406, 0.998046875, 1.0, 8.940696716308594e-07, 0.4345703125, 0.8310546875, 0.7861328125, 0.66259765625, 0.9931640625, 0.95751953125, 0.9921875, 0.19140625, 0.433349609375, 0.53466796875, 0.335205078125, 0.00010347366333007812, 0.81103515625, 0.1722412109375, 0.8486328125, 1.0, 0.99853515625, 1.0, 0.0146942138671875, 0.80126953125, 0.6611328125, 0.376708984375, 0.99951171875, 0.98095703125, 0.34814453125, 0.99951171875, 0.9990234375, 0.99951171875, 0.9990234375, 0.005275726318359375, 0.9912109375, 0.41162109375, 0.62353515625, 0.853515625]], "normalized_score": [0.16141800582408905], "tokens": [["\u2581di", "ast", "ema", "\u2581(", "Sp", "ain", ")", "\u2581#", "The", "F", "av", "our", "ite", "\u2581swe", "eps", "\u2581the", "\u2581#", "B", "AF", "T", "As", "\u2581with", "\u2581seven", "\u2581wins", "!", "\u2581Emma", "\u2581Stone", "\u2581and", "\u2581Rach", "el", "\u2581We", "isz", "\u2581take", "\u2581home", "\u2581Best", "\u2581Act", "ress", "\u2581and", "\u2581Best", "\u2581Support", "ing", "\u2581Act", "ress", "\u2581hon", "ors", ",", "\u2581respectively", "."]], "entropy": [[0.8466796875, 0.0004229545593261719, 0.04852294921875, 0.49853515625, 2.90234375, 2.607421875, 0.912109375, 2.00390625, 5.35546875, 2.798828125, 1.0888671875, 0.0224609375, 0.0016298294067382812, 1.244140625, 1.2529296875, 0.84130859375, 0.951171875, 1.0673828125, 0.04443359375, 0.1802978515625, 0.048675537109375, 0.6875, 1.0791015625, 0.97314453125, 1.2275390625, 2.5625, 1.05078125, 2.794921875, 0.6884765625, 0.0019550323486328125, 0.012939453125, 0.0024623870849609375, 2.017578125, 0.751953125, 1.0576171875, 0.68017578125, 0.00305938720703125, 0.1319580078125, 0.66015625, 0.00640869140625, 0.007328033447265625, 0.003986358642578125, 0.008392333984375, 1.6572265625, 0.051483154296875, 1.3955078125, 0.91064453125, 0.47412109375]], "avg_entropy": [0.9503428240617117], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "diastema (plural diastemata)", "score_of_biggest_cluster": 0.16141800582408905, "score_of_first_answer": 0.16141800582408905, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 8.940696716308594e-07, "avg_score": 0.16141800582408905, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.39256670090498796, "std_of_first_answer": 0.39256670090498796, "avg_entropy_of_first_answer": 0.9503428240617117, "lex_sim": 1.0}
{"question": "where does the story the great gatsby take place", "answer": ["New York City and Long Island, New York."], "scores": [[0.720703125, 1.0, 0.2314453125, 0.74267578125, 0.49853515625, 0.9990234375, 0.0799560546875, 0.63916015625, 1.0, 0.229248046875, 7.748603820800781e-07, 0.01485443115234375, 4.410743713378906e-06, 0.28369140625, 4.291534423828125e-06, 0.7119140625, 0.0029735565185546875, 0.002841949462890625, 0.464111328125, 0.59716796875, 0.03802490234375, 0.0033969879150390625, 0.87890625, 1.0, 0.00933074951171875, 1.0, 0.9951171875]], "normalized_score": [0.05455729737877846], "tokens": [["\u2581New", "\u2581York", "\u2581City", "\u2581and", "\u2581Long", "\u2581Island", ",", "\u2581New", "\u2581York", ".", "\u2581#", "T", "or", "onto", "\u2581Str", "ong", ":", "\u2581One", "\u2581Year", "\u2581Later", "\u2581#", "Dan", "for", "th", "S", "ho", "oting"]], "entropy": [[1.1904296875, 8.368492126464844e-05, 1.58984375, 0.8876953125, 0.97802734375, 0.0082855224609375, 1.0595703125, 1.39453125, 0.0004172325134277344, 1.4677734375, 0.2861328125, 3.443359375, 0.14306640625, 3.017578125, 3.626953125, 1.380859375, 2.205078125, 3.681640625, 2.34375, 1.1123046875, 2.609375, 3.6796875, 0.716796875, 0.0005402565002441406, 2.267578125, 0.0003342628479003906, 0.031280517578125]], "avg_entropy": [1.4489989898822926], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Long Island of 1922", "score_of_biggest_cluster": 0.05455729737877846, "score_of_first_answer": 0.05455729737877846, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 7.748603820800781e-07, "avg_score": 0.05455729737877846, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3991265086769334, "std_of_first_answer": 0.3991265086769334, "avg_entropy_of_first_answer": 1.4489989898822926, "lex_sim": 1.0}
{"question": "who has won the canada open women's doubles", "answer": ["Gabriela Dabrowski and Xu Yifan won the 2019 event."], "scores": [[0.927734375, 0.998046875, 0.9990234375, 0.998046875, 0.99951171875, 1.0, 1.0, 0.9208984375, 0.7431640625, 0.9755859375, 0.9970703125, 0.9990234375, 1.0, 0.005023956298828125, 0.9990234375, 0.328125, 1.0, 1.0, 0.140380859375, 0.8466796875, 0.0003466606140136719, 0.818359375, 6.556510925292969e-07, 0.00615692138671875, 0.0166778564453125, 0.0025043487548828125, 0.0005955696105957031, 0.0703125, 0.07806396484375, 0.46337890625, 0.912109375, 0.9794921875, 0.9990234375, 0.020111083984375, 0.006378173828125, 0.2252197265625, 0.92822265625, 0.7412109375, 1.0, 0.0712890625, 0.93603515625, 0.1744384765625, 0.0304412841796875, 0.27392578125, 0.99755859375, 0.99755859375, 0.87744140625, 1.0]], "normalized_score": [0.18761476874351501], "tokens": [["\u2581Gab", "ri", "ela", "\u2581D", "ab", "row", "ski", "\u2581and", "\u2581X", "u", "\u2581Y", "if", "an", "\u2581won", "\u2581the", "\u2581", "2", "0", "1", "9", "\u2581event", ".", "\u2581#", "1", ".", "\u2581A", "\u2581", "3", "6", "-", "year", "-", "old", "\u2581male", "\u2581presented", "\u2581to", "\u2581the", "\u2581emer", "gency", "\u2581room", "\u2581with", "\u2581severe", "\u2581right", "-", "s", "ided", "\u2581ch", "est"]], "entropy": [[0.55419921875, 0.018218994140625, 0.00849151611328125, 0.021148681640625, 0.007266998291015625, 0.0006656646728515625, 0.0011720657348632812, 0.415771484375, 1.5537109375, 0.1793212890625, 0.0250701904296875, 0.01111602783203125, 8.26120376586914e-05, 0.93115234375, 0.0116729736328125, 1.4541015625, 0.0002593994140625, 0.0004162788391113281, 0.406005859375, 0.470703125, 1.0517578125, 0.6806640625, 1.1181640625, 4.37109375, 3.89453125, 4.10546875, 3.203125, 2.328125, 3.13671875, 1.8125, 0.6337890625, 0.1622314453125, 0.01044464111328125, 4.46875, 3.013671875, 0.640625, 0.406982421875, 1.1689453125, 0.0005049705505371094, 0.291015625, 0.40673828125, 2.802734375, 2.3984375, 2.517578125, 0.022064208984375, 0.0186920166015625, 0.62353515625, 0.0008616447448730469]], "avg_entropy": [1.0700061942140262], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Wakana Nagahara", "score_of_biggest_cluster": 0.18761476874351501, "score_of_first_answer": 0.18761476874351501, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 6.556510925292969e-07, "avg_score": 0.18761476874351501, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4280857338447128, "std_of_first_answer": 0.4280857338447128, "avg_entropy_of_first_answer": 1.0700061942140262, "lex_sim": 1.0}
{"question": "what is best thing i never had song about", "answer": ["relationship with someone who was a really good friend CHAPTER ELEVEN: \u201cThe Only Way To Save Them Is To Join Them\u201d"], "scores": [[0.007251739501953125, 0.42822265625, 0.85595703125, 0.7431640625, 0.22265625, 0.03216552734375, 0.0008587837219238281, 0.146728515625, 0.9853515625, 0.0, 0.0009946823120117188, 0.036529541015625, 0.748046875, 0.99951171875, 0.3525390625, 0.00211334228515625, 0.1312255859375, 0.002582550048828125, 0.0849609375, 0.04150390625, 0.001522064208984375, 0.007293701171875, 0.978515625, 0.79443359375, 0.890625, 0.0180511474609375, 1.0, 0.9208984375, 1.0, 0.90478515625]], "normalized_score": [0.0], "tokens": [["\u2581relationship", "\u2581with", "\u2581someone", "\u2581who", "\u2581was", "\u2581a", "\u2581really", "\u2581good", "\u2581friend", "\u2581CHAPTER", "\u2581E", "LE", "V", "EN", ":", "\u2581\u201c", "The", "\u2581Only", "\u2581Way", "\u2581To", "\u2581Save", "\u2581Th", "em", "\u2581Is", "\u2581To", "\u2581Jo", "in", "\u2581Th", "em", "\u201d"]], "entropy": [[2.255859375, 1.8076171875, 0.66455078125, 1.01953125, 1.1591796875, 2.02734375, 2.7265625, 1.0244140625, 0.09136962890625, 1.45703125, 2.599609375, 2.046875, 0.595703125, 0.0033893585205078125, 2.771484375, 4.2890625, 5.23046875, 6.30859375, 2.3515625, 1.708984375, 3.072265625, 3.0625, 0.130615234375, 1.04296875, 0.6484375, 3.1484375, 0.0013027191162109375, 0.440673828125, 0.0013761520385742188, 0.56494140625]], "avg_entropy": [1.8084237098693847], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "revenge and karma", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41617790070923505, "std_of_first_answer": 0.41617790070923505, "avg_entropy_of_first_answer": 1.8084237098693847, "lex_sim": 1.0}
{"question": "epidemiologists attempt to explain the link between health and variables such as", "answer": ["lifestyle, environment, genetics, and disease exposure."], "scores": [[0.043304443359375, 1.0, 0.99853515625, 0.89013671875, 0.853515625, 0.9990234375, 0.75146484375, 0.9833984375, 1.0, 0.98828125, 0.853515625, 0.1500244140625, 0.2210693359375, 0.998046875, 0.91552734375, 8.940696716308594e-07, 0.0003161430358886719, 0.00021827220916748047, 0.00014770030975341797, 0.2115478515625, 0.99365234375, 9.47713851928711e-05, 0.005657196044921875, 0.0001405477523803711, 0.03277587890625, 0.02435302734375, 0.09576416015625, 1.0, 0.9951171875, 0.837890625, 0.630859375, 0.8984375, 0.99462890625, 0.99951171875]], "normalized_score": [0.09038335829973221], "tokens": [["\u2581l", "ifest", "yle", ",", "\u2581environment", ",", "\u2581gen", "et", "ics", ",", "\u2581and", "\u2581disease", "\u2581expos", "ure", ".", "\u2581#", "C", "over", "Re", "ve", "al", "\u2581\u201c", "S", "cor", "ing", "\u2581The", "\u2581Bill", "ion", "aire", "\u201d", "\u2581by", "\u2581Max", "\u2581Mon", "roe"]], "entropy": [[1.6728515625, 3.838539123535156e-05, 0.0118408203125, 0.521484375, 0.57861328125, 0.00787353515625, 0.89892578125, 0.08447265625, 4.0531158447265625e-06, 0.07574462890625, 0.775390625, 1.9736328125, 1.73828125, 0.01311492919921875, 0.40380859375, 0.72216796875, 2.3125, 3.609375, 2.240234375, 1.4814453125, 0.04443359375, 1.9541015625, 3.296875, 4.03125, 1.1123046875, 3.685546875, 5.0625, 0.0024929046630859375, 0.038909912109375, 0.9501953125, 2.0234375, 0.7294921875, 0.04052734375, 0.0054473876953125]], "avg_entropy": [1.238215123905855], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "biological agents", "score_of_biggest_cluster": 0.09038335829973221, "score_of_first_answer": 0.09038335829973221, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 8.940696716308594e-07, "avg_score": 0.09038335829973221, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4391666312754245, "std_of_first_answer": 0.4391666312754245, "avg_entropy_of_first_answer": 1.238215123905855, "lex_sim": 1.0}
{"question": "when did the apple iphone se come out", "answer": ["March 21, 2016 ##### JEWELRY FOR SALE"], "scores": [[0.63037109375, 0.99169921875, 0.9873046875, 0.99365234375, 0.98828125, 0.99755859375, 1.0, 1.0, 0.99951171875, 1.0, 0.0, 1.9371509552001953e-05, 0.00745391845703125, 0.08135986328125, 0.908203125, 0.037078857421875, 0.0071563720703125, 0.4716796875, 0.9990234375]], "normalized_score": [0.0], "tokens": [["\u2581March", "\u2581", "2", "1", ",", "\u2581", "2", "0", "1", "6", "\u2581#####", "\u2581J", "E", "W", "EL", "RY", "\u2581FOR", "\u2581SA", "LE"]], "entropy": [[0.947265625, 0.052459716796875, 0.06890869140625, 0.042388916015625, 0.0743408203125, 0.0184326171875, 7.224082946777344e-05, 2.0265579223632812e-06, 0.004474639892578125, 0.0012331008911132812, 0.876953125, 1.9248046875, 3.517578125, 3.2890625, 0.68359375, 4.65234375, 4.12109375, 2.326171875, 0.0116424560546875]], "avg_entropy": [1.1901485480760272], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "March 31, 2016", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43895935399225977, "std_of_first_answer": 0.43895935399225977, "avg_entropy_of_first_answer": 1.1901485480760272, "lex_sim": 1.0}
{"question": "which is the default file extension for an audio file in windows media player", "answer": [".wma #Follow Friday, News May 2, 2014"], "scores": [[0.91357421875, 0.15869140625, 0.98388671875, 5.364418029785156e-07, 0.0004825592041015625, 0.0262298583984375, 7.450580596923828e-06, 0.00868988037109375, 1.7583370208740234e-05, 9.864568710327148e-05, 0.943359375, 0.2041015625, 0.0141143798828125, 0.98291015625, 0.92236328125, 0.99951171875, 0.176025390625, 0.52587890625]], "normalized_score": [0.01754406839609146], "tokens": [["\u2581.", "w", "ma", "\u2581#", "F", "ollow", "\u2581Friday", ",", "\u2581News", "\u2581May", "\u2581", "2", ",", "\u2581", "2", "0", "1", "4"]], "entropy": [[0.4775390625, 0.5849609375, 0.08868408203125, 0.70947265625, 4.890625, 4.69921875, 3.47265625, 2.76171875, 2.6640625, 3.052734375, 0.468994140625, 1.845703125, 2.216796875, 0.1656494140625, 0.30615234375, 0.00725555419921875, 0.58349609375, 1.3515625]], "avg_entropy": [1.6859601338704426], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Windows Playlist (WPL)", "score_of_biggest_cluster": 0.01754406839609146, "score_of_first_answer": 0.01754406839609146, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 5.364418029785156e-07, "avg_score": 0.01754406839609146, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42618629264001456, "std_of_first_answer": 0.42618629264001456, "avg_entropy_of_first_answer": 1.6859601338704426, "lex_sim": 1.0}
{"question": "when did the eagles last play in a superbowl", "answer": ["The Eagles have never played in a Super Bowl."], "scores": [[0.03277587890625, 0.465087890625, 1.0, 1.0, 0.3134765625, 0.70361328125, 0.990234375, 1.0, 0.98681640625, 0.99951171875, 0.98974609375, 0.95556640625, 6.556510925292969e-07, 0.0056915283203125, 0.0002999305725097656, 0.00905609130859375, 0.0009307861328125, 0.0848388671875, 0.0282135009765625, 0.01511383056640625, 0.038482666015625, 0.86865234375, 0.9990234375, 0.0004162788391113281, 0.99755859375, 0.003662109375, 0.498779296875, 0.01154327392578125, 0.0002315044403076172, 0.007045745849609375, 0.0279693603515625, 0.00897216796875, 0.206298828125, 0.0146026611328125, 0.458984375, 0.98193359375, 0.006916046142578125, 0.060302734375, 0.0139923095703125, 0.91943359375, 0.97412109375, 1.0, 0.99365234375]], "normalized_score": [0.06498724967241287], "tokens": [["\u2581The", "\u2581E", "ag", "les", "\u2581have", "\u2581never", "\u2581played", "\u2581in", "\u2581a", "\u2581Super", "\u2581Bowl", ".", "\u2581#", "B", "log", "T", "our", "\u2581#", "The", "F", "org", "ot", "ten", "On", "es", "\u2581by", "\u2581@", "L", "ena", "F", "orth", "ale", "\u2581#", "Book", "Re", "view", "\u2581@", "B", "onn", "ier", "Z", "aff", "re"]], "entropy": [[1.3828125, 1.22265625, 0.0005221366882324219, 0.0002052783966064453, 1.384765625, 0.9833984375, 0.06402587890625, 0.0008358955383300781, 0.07318115234375, 0.00537872314453125, 0.06536865234375, 0.2408447265625, 1.166015625, 3.900390625, 1.8232421875, 4.15234375, 2.279296875, 3.96875, 4.4375, 2.5703125, 4.203125, 0.607421875, 0.00811004638671875, 2.302734375, 0.0217132568359375, 1.81640625, 3.060546875, 5.42578125, 2.32421875, 3.494140625, 2.818359375, 3.9921875, 3.71484375, 4.8671875, 2.265625, 0.11468505859375, 1.919921875, 5.30859375, 4.8046875, 0.3525390625, 0.207763671875, 0.0017614364624023438, 0.055145263671875]], "avg_entropy": [1.93975222942441], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2017 season", "score_of_biggest_cluster": 0.06498724967241287, "score_of_first_answer": 0.06498724967241287, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 6.556510925292969e-07, "avg_score": 0.06498724967241287, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4461201801973945, "std_of_first_answer": 0.4461201801973945, "avg_entropy_of_first_answer": 1.93975222942441, "lex_sim": 1.0}
{"question": "who explored waters of cuba the bahamas and hispaniola", "answer": ["Christopher Columbus"], "scores": [[0.91796875, 0.99462890625, 1.0]], "normalized_score": [0.9701293706893921], "tokens": [["\u2581Christopher", "\u2581Columb", "us"]], "entropy": [[0.41650390625, 0.0369873046875, 0.0005097389221191406]], "avg_entropy": [0.1513336499532064], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Christopher Columbus", "score_of_biggest_cluster": 0.9701293706893921, "score_of_first_answer": 0.9701293706893921, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.91796875, "avg_score": 0.9701293706893921, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.037468140808645245, "std_of_first_answer": 0.037468140808645245, "avg_entropy_of_first_answer": 0.1513336499532064, "lex_sim": 1.0}
{"question": "who recorded i can't help falling in love with you", "answer": ["Elvis Presley #39;s ailments."], "scores": [[0.98193359375, 1.0, 0.99853515625, 0.99951171875, 2.384185791015625e-07, 0.01366424560546875, 0.04571533203125, 0.849609375, 0.487548828125, 1.138448715209961e-05, 0.00021338462829589844, 0.0306243896484375, 0.01904296875]], "normalized_score": [0.02006865292787552], "tokens": [["\u2581El", "vis", "\u2581Pres", "ley", "\u2581#", "3", "9", ";", "s", "\u2581a", "il", "ments", "."]], "entropy": [[0.1270751953125, 0.0004718303680419922, 0.0112457275390625, 0.004543304443359375, 0.703125, 5.5234375, 2.970703125, 0.8681640625, 2.576171875, 1.63671875, 4.78125, 0.29248046875, 3.31640625]], "avg_entropy": [1.7547533145317664], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Elvis Presley", "score_of_biggest_cluster": 0.02006865292787552, "score_of_first_answer": 0.02006865292787552, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.02006865292787552, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.45220273688341106, "std_of_first_answer": 0.45220273688341106, "avg_entropy_of_first_answer": 1.7547533145317664, "lex_sim": 1.0}
{"question": "when was the last amendment to the constitution passed", "answer": ["The 27th Amendment to the United States Constitution was passed on March 1, 1992."], "scores": [[0.623046875, 0.90673828125, 0.978515625, 0.99853515625, 0.99951171875, 0.71826171875, 1.0, 1.0, 0.55908203125, 0.99853515625, 0.93603515625, 1.0, 1.0, 0.9326171875, 0.265380859375, 0.221435546875, 0.50634765625, 1.0, 0.9970703125, 1.0, 0.99951171875, 1.0, 0.99951171875, 1.0, 1.0, 0.787109375, 0.0, 0.00020754337310791016, 0.0010499954223632812]], "normalized_score": [0.0], "tokens": [["\u2581The", "\u2581", "2", "7", "th", "\u2581Am", "end", "ment", "\u2581to", "\u2581the", "\u2581United", "\u2581States", "\u2581Constitution", "\u2581was", "\u2581passed", "\u2581on", "\u2581March", "\u2581", "1", ",", "\u2581", "1", "9", "9", "2", ".", "\u2581##", "External", "\u2581links"]], "entropy": [[1.244140625, 0.44677734375, 0.10443115234375, 0.01140594482421875, 0.004291534423828125, 0.59765625, 0.0008440017700195312, 4.744529724121094e-05, 0.8798828125, 0.01068878173828125, 0.29248046875, 0.0010623931884765625, 0.0007147789001464844, 0.26123046875, 0.6708984375, 0.56689453125, 0.88330078125, 0.0009331703186035156, 0.0213470458984375, 0.00241851806640625, 0.0043792724609375, 0.00013315677642822266, 0.00547027587890625, 0.0009717941284179688, 0.0002970695495605469, 0.70556640625, 1.0166015625, 6.36328125, 1.8828125]], "avg_entropy": [0.5510675783815056], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "May 5, 1992", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.34123961304755956, "std_of_first_answer": 0.34123961304755956, "avg_entropy_of_first_answer": 0.5510675783815056, "lex_sim": 1.0}
{"question": "who is the no. 1 ranked tennis player in the world", "answer": ["Ashleigh Barty"], "scores": [[0.2232666015625, 0.98046875, 1.0, 1.0, 1.0]], "normalized_score": [0.7379917502403259], "tokens": [["\u2581Ash", "le", "igh", "\u2581Bart", "y"]], "entropy": [[1.0224609375, 0.0975341796875, 0.0004458427429199219, 0.0009126663208007812, 5.841255187988281e-06]], "avg_entropy": [0.22427189350128174], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Rafael Nadal", "score_of_biggest_cluster": 0.7379917502403259, "score_of_first_answer": 0.7379917502403259, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.2232666015625, "avg_score": 0.7379917502403259, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3088328881141293, "std_of_first_answer": 0.3088328881141293, "avg_entropy_of_first_answer": 0.22427189350128174, "lex_sim": 1.0}
{"question": "who wrote the song to make you feel my love", "answer": ["Adele and Bob Dylan ### Questions 51-100"], "scores": [[0.7470703125, 0.97314453125, 1.0, 0.026123046875, 0.83154296875, 1.0, 1.0, 1.0, 0.0, 0.0008568763732910156, 0.430908203125, 0.0278778076171875, 0.058441162109375, 0.5, 0.72998046875, 0.77392578125, 0.99560546875, 1.0]], "normalized_score": [0.0], "tokens": [["\u2581A", "de", "le", "\u2581and", "\u2581Bob", "\u2581D", "yl", "an", "\u2581###", "\u2581Question", "s", "\u2581", "5", "1", "-", "1", "0", "0"]], "entropy": [[0.65576171875, 0.1585693359375, 4.756450653076172e-05, 1.396484375, 0.92333984375, 0.0008287429809570312, 7.50422477722168e-05, 2.47955322265625e-05, 1.224609375, 2.482421875, 3.259765625, 3.482421875, 1.853515625, 1.740234375, 0.8662109375, 0.79443359375, 0.0323486328125, 0.0018253326416015625]], "avg_entropy": [1.048495481411616], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Bob Dylan", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40282241378915884, "std_of_first_answer": 0.40282241378915884, "avg_entropy_of_first_answer": 1.048495481411616, "lex_sim": 1.0}
{"question": "who sang never gonna let you go", "answer": ["Sergio Mendes #7 What Was Your Favorite Episode Or Movie?"], "scores": [[0.8896484375, 0.94189453125, 0.99365234375, 0.9990234375, 9.5367431640625e-07, 0.0012350082397460938, 5.245208740234375e-06, 0.0013065338134765625, 0.677734375, 0.0023860931396484375, 0.95263671875, 0.998046875, 0.0011348724365234375, 0.93701171875, 0.005992889404296875, 0.07806396484375, 0.1529541015625]], "normalized_score": [0.025444677099585533], "tokens": [["\u2581Ser", "gio", "\u2581M", "endes", "\u2581#", "7", "\u2581What", "\u2581Was", "\u2581Your", "\u2581F", "avor", "ite", "\u2581E", "pisode", "\u2581Or", "\u2581Movie", "?"]], "entropy": [[0.76513671875, 0.288330078125, 0.061492919921875, 0.00890350341796875, 1.416015625, 5.13671875, 2.56640625, 2.8828125, 1.599609375, 1.6005859375, 0.2047119140625, 0.0214996337890625, 3.97265625, 0.4521484375, 3.03515625, 2.861328125, 3.833984375]], "avg_entropy": [1.8063233319450827], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Joe Pizzulo and Leeza Miller", "score_of_biggest_cluster": 0.025444677099585533, "score_of_first_answer": 0.025444677099585533, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 9.5367431640625e-07, "avg_score": 0.025444677099585533, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.45423004124007377, "std_of_first_answer": 0.45423004124007377, "avg_entropy_of_first_answer": 1.8063233319450827, "lex_sim": 1.0}
{"question": "which hormone is released from the ruptured follicle or corpus luteum", "answer": ["progesterone ### The SpongeBob SquarePants Movie (2004)"], "scores": [[0.88427734375, 0.99853515625, 1.0, 1.0, 0.0, 0.00287628173828125, 0.00010913610458374023, 0.0003936290740966797, 0.11395263671875, 0.998046875, 0.94091796875, 0.98779296875, 0.99951171875, 0.44091796875, 0.52294921875, 0.99658203125, 0.99951171875, 1.0, 0.998046875, 0.9111328125]], "normalized_score": [0.0], "tokens": [["\u2581pro", "g", "ester", "one", "\u2581###", "\u2581The", "\u2581S", "pon", "ge", "Bob", "\u2581Square", "P", "ants", "\u2581Movie", "\u2581(", "2", "0", "0", "4", ")"]], "entropy": [[0.465576171875, 0.01222991943359375, 0.0004649162292480469, 0.0004582405090332031, 1.0166015625, 3.728515625, 2.494140625, 4.75, 0.39208984375, 0.0196990966796875, 0.468505859375, 0.08453369140625, 0.0026397705078125, 1.5859375, 1.39453125, 0.032928466796875, 0.002765655517578125, 0.0003223419189453125, 0.0161895751953125, 0.50537109375]], "avg_entropy": [0.8486750602722168], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "estrogen", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4134412828207153, "std_of_first_answer": 0.4134412828207153, "avg_entropy_of_first_answer": 0.8486750602722168, "lex_sim": 1.0}
{"question": "who is the lead singer of depeche mode", "answer": ["Dave Gahan, Martin Gore, and Andy Fletcher #034: A New Start"], "scores": [[0.93359375, 0.99951171875, 1.0, 1.0, 0.006809234619140625, 0.78857421875, 0.9423828125, 1.0, 0.83642578125, 0.59619140625, 0.814453125, 0.99951171875, 1.0, 0.998046875, 2.980232238769531e-07, 0.00940704345703125, 0.03411865234375, 0.01178741455078125, 0.0030994415283203125, 0.0028514862060546875, 0.00031280517578125, 0.009857177734375]], "normalized_score": [0.07130937278270721], "tokens": [["\u2581Dave", "\u2581G", "ah", "an", ",", "\u2581Martin", "\u2581G", "ore", ",", "\u2581and", "\u2581Andy", "\u2581F", "let", "cher", "\u2581#", "0", "3", "4", ":", "\u2581A", "\u2581New", "\u2581Start"]], "entropy": [[0.32568359375, 0.006870269775390625, 0.00026988983154296875, 0.00010949373245239258, 0.93896484375, 1.2275390625, 0.2437744140625, 2.467632293701172e-05, 0.63916015625, 1.150390625, 0.489501953125, 0.007122039794921875, 0.0005621910095214844, 0.01453399658203125, 2.064453125, 4.80859375, 3.306640625, 1.5654296875, 2.455078125, 5.34765625, 2.96484375, 3.9375]], "avg_entropy": [1.4315773871811954], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "David Gahan", "score_of_biggest_cluster": 0.07130937278270721, "score_of_first_answer": 0.07130937278270721, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.07130937278270721, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4554920612684209, "std_of_first_answer": 0.4554920612684209, "avg_entropy_of_first_answer": 1.4315773871811954, "lex_sim": 1.0}
{"question": "who does the head of the fbi report to", "answer": ["The Director of the FBI reports to the Attorney General of the United States."], "scores": [[0.8515625, 0.0085601806640625, 0.998046875, 0.9990234375, 0.765625, 0.99951171875, 0.7236328125, 0.99365234375, 0.99951171875, 0.96630859375, 1.0, 0.99951171875, 0.95166015625, 1.0, 1.0, 1.0, 0.6904296875, 4.76837158203125e-07, 0.017852783203125, 0.069091796875, 0.0875244140625, 0.08404541015625, 0.035064697265625, 0.00015294551849365234, 0.386474609375, 0.03546142578125, 0.051361083984375, 0.80712890625, 0.365234375, 0.185302734375, 0.9921875, 0.0025730133056640625, 0.7685546875, 0.107666015625, 0.467041015625, 0.0863037109375, 0.9921875, 0.1458740234375, 0.09808349609375, 0.040191650390625, 0.0011415481567382812, 0.1463623046875, 0.032257080078125, 0.00047850608825683594, 0.171875, 0.9521484375, 0.76171875, 0.99755859375]], "normalized_score": [0.13689957559108734], "tokens": [["\u2581The", "\u2581Director", "\u2581of", "\u2581the", "\u2581F", "BI", "\u2581reports", "\u2581to", "\u2581the", "\u2581Att", "orney", "\u2581General", "\u2581of", "\u2581the", "\u2581United", "\u2581States", ".", "\u2581#", "3", "8", "8", "9", "6", "\u2581-", "\u2581", "0", "5", "/", "1", "2", "/", "1", "9", "\u2581", "0", "5", ":", "5", "7", "\u2581AM", "\u2581Re", ":", "\u2581What", "\u2581In", "\u2581The", "\u2581World", "\u2581H", "app"]], "entropy": [[0.62646484375, 0.533203125, 0.0169525146484375, 0.00940704345703125, 0.54931640625, 0.00629425048828125, 0.90966796875, 0.04034423828125, 0.0031719207763671875, 0.189697265625, 0.0012063980102539062, 0.0042266845703125, 0.268310546875, 0.000591278076171875, 0.00044226646423339844, 0.0022296905517578125, 0.96630859375, 0.30810546875, 4.50390625, 2.64453125, 2.509765625, 2.490234375, 1.61328125, 2.36328125, 4.3984375, 1.48828125, 2.744140625, 0.91357421875, 1.1103515625, 2.205078125, 0.054168701171875, 0.0633544921875, 1.0048828125, 1.240234375, 1.1142578125, 2.265625, 0.055267333984375, 1.7919921875, 2.306640625, 1.345703125, 2.25390625, 1.1005859375, 4.87109375, 2.216796875, 1.0986328125, 0.375732421875, 1.203125, 0.0222625732421875]], "avg_entropy": [1.2042722056309383], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the Director of National Intelligence", "score_of_biggest_cluster": 0.13689957559108734, "score_of_first_answer": 0.13689957559108734, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.76837158203125e-07, "avg_score": 0.13689957559108734, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42450678004476883, "std_of_first_answer": 0.42450678004476883, "avg_entropy_of_first_answer": 1.2042722056309383, "lex_sim": 1.0}
{"question": "what year did return of the mack come out", "answer": ["1973 #FRAMED: A Narrative and Visual Timeline of the Rikers Island Jail Complex and Its Controversies"], "scores": [[0.97705078125, 0.99853515625, 1.0, 0.943359375, 0.97265625, 2.384185791015625e-07, 0.0018711090087890625, 0.0033397674560546875, 0.61962890625, 0.005733489990234375, 0.00214385986328125, 0.00905609130859375, 0.00023567676544189453, 0.73828125, 0.986328125, 0.0014543533325195312, 0.0013532638549804688, 0.032073974609375, 0.9921875, 0.4912109375, 0.1649169921875, 0.0016202926635742188, 0.00012803077697753906, 1.0, 0.7890625, 0.61669921875, 0.87255859375, 0.302734375, 0.1356201171875, 0.1685791015625, 0.0196685791015625, 0.779296875, 0.99951171875, 0.29638671875]], "normalized_score": [0.05565014109015465], "tokens": [["\u2581", "1", "9", "7", "3", "\u2581#", "F", "RA", "ME", "D", ":", "\u2581A", "\u2581N", "arr", "ative", "\u2581and", "\u2581Visual", "\u2581Tim", "eline", "\u2581of", "\u2581the", "\u2581R", "ik", "ers", "\u2581Island", "\u2581J", "ail", "\u2581Complex", "\u2581and", "\u2581Its", "\u2581Cont", "ro", "vers", "ies"]], "entropy": [[0.1541748046875, 0.0109405517578125, 0.00048828125, 0.256103515625, 0.1431884765625, 0.53759765625, 5.60546875, 3.564453125, 1.681640625, 2.154296875, 0.3408203125, 3.837890625, 5.015625, 0.98486328125, 0.09600830078125, 3.9765625, 4.8828125, 3.96484375, 0.06500244140625, 2.26171875, 2.15234375, 2.9609375, 0.46923828125, 0.0004322528839111328, 1.140625, 2.4609375, 0.455078125, 2.607421875, 2.94921875, 2.21484375, 3.189453125, 0.796875, 0.0028972625732421875, 0.630859375]], "avg_entropy": [1.810754754964043], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "18\u00a0March\u00a01996", "score_of_biggest_cluster": 0.05565014109015465, "score_of_first_answer": 0.05565014109015465, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.05565014109015465, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4197621079543735, "std_of_first_answer": 0.4197621079543735, "avg_entropy_of_first_answer": 1.810754754964043, "lex_sim": 1.0}
{"question": "how many us states currently use capital punishment", "answer": ["29 #311962 - 03/27/08 12:26 PM Re: Male victims of sexual abuse by women [Re: FuzzyLogik]"], "scores": [[0.92626953125, 0.92138671875, 0.9228515625, 5.960464477539063e-08, 0.00351715087890625, 0.05267333984375, 0.0206298828125, 0.0242919921875, 0.06884765625, 0.06640625, 0.00048089027404785156, 0.2435302734375, 0.155517578125, 0.1119384765625, 0.84326171875, 0.258544921875, 0.0975341796875, 0.99609375, 0.0018396377563476562, 0.1524658203125, 0.4189453125, 0.320068359375, 0.355224609375, 0.99658203125, 0.19384765625, 0.103515625, 0.720703125, 0.35546875, 0.99853515625, 6.556510925292969e-06, 3.522634506225586e-05, 0.9990234375, 0.6962890625, 0.039520263671875, 0.31103515625, 0.9990234375, 0.0284423828125, 0.3232421875, 0.66015625, 1.0, 1.0, 0.0027313232421875, 0.0289764404296875, 0.99267578125, 0.84033203125, 0.251953125, 0.990234375]], "normalized_score": [0.08660464733839035], "tokens": [["\u2581", "2", "9", "\u2581#", "3", "1", "1", "9", "6", "2", "\u2581-", "\u2581", "0", "3", "/", "2", "7", "/", "0", "8", "\u2581", "1", "2", ":", "2", "6", "\u2581PM", "\u2581Re", ":", "\u2581Male", "\u2581vict", "ims", "\u2581of", "\u2581sexual", "\u2581ab", "use", "\u2581by", "\u2581women", "\u2581[", "Re", ":", "\u2581F", "uz", "zy", "Log", "ik", "]"]], "entropy": [[0.50830078125, 0.27978515625, 0.350830078125, 0.9423828125, 5.27734375, 2.51171875, 2.5625, 2.064453125, 3.18359375, 2.87890625, 2.728515625, 4.3984375, 1.244140625, 2.4140625, 0.61279296875, 1.2822265625, 2.287109375, 0.03240966796875, 0.060028076171875, 2.216796875, 2.044921875, 0.89404296875, 1.4638671875, 0.033721923828125, 1.7978515625, 2.306640625, 0.88623046875, 2.630859375, 0.01543426513671875, 5.125, 3.236328125, 0.00963592529296875, 1.4580078125, 2.236328125, 1.48828125, 0.010986328125, 1.7333984375, 2.85546875, 1.6328125, 0.0013914108276367188, 0.00255584716796875, 5.66015625, 4.3359375, 0.054962158203125, 1.0361328125, 1.298828125, 0.07623291015625]], "avg_entropy": [1.7481350797287962], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "31 states", "score_of_biggest_cluster": 0.08660464733839035, "score_of_first_answer": 0.08660464733839035, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.08660464733839035, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3949064883105896, "std_of_first_answer": 0.3949064883105896, "avg_entropy_of_first_answer": 1.7481350797287962, "lex_sim": 1.0}
{"question": "what type of joint connects the incus with the malleus", "answer": ["arcuate joint"], "scores": [[0.00933074951171875, 0.10809326171875, 1.0, 0.50732421875]], "normalized_score": [0.1504008024930954], "tokens": [["\u2581ar", "cu", "ate", "\u2581joint"]], "entropy": [[3.21875, 1.3232421875, 0.0023059844970703125, 1.681640625]], "avg_entropy": [1.5564846992492676], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "synovial", "score_of_biggest_cluster": 0.1504008024930954, "score_of_first_answer": 0.1504008024930954, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.00933074951171875, "avg_score": 0.1504008024930954, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3902554856563774, "std_of_first_answer": 0.3902554856563774, "avg_entropy_of_first_answer": 1.5564846992492676, "lex_sim": 1.0}
{"question": "who gets the most punishments on impractical jokers", "answer": ["Q"], "scores": [[0.12298583984375]], "normalized_score": [0.1229858547449112], "tokens": [["\u2581Q"]], "entropy": [[2.6953125]], "avg_entropy": [2.6953125], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Sal", "score_of_biggest_cluster": 0.1229858547449112, "score_of_first_answer": 0.1229858547449112, "max_score_of_first_answer": 0.12298583984375, "min_score_of_first_answer": 0.12298583984375, "avg_score": 0.1229858547449112, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.0, "std_of_first_answer": 0.0, "avg_entropy_of_first_answer": 2.6953125, "lex_sim": 1.0}
{"question": "fast and furious 7 red car abu dhabi", "answer": ["Yes, in the movie Fast and Furious 7, a red Ford GT supercar jumps over a number of skyscrapers in Abu Dhabi, including the Sheikh Zayed Grand Mosque."], "scores": [[0.07891845703125, 0.91357421875, 0.2001953125, 0.86083984375, 0.63232421875, 0.67236328125, 0.464599609375, 0.9990234375, 1.0, 1.0, 1.0, 0.95849609375, 0.439697265625, 0.95849609375, 0.0057373046875, 0.271240234375, 0.80908203125, 0.99853515625, 0.1158447265625, 1.0, 0.3017578125, 0.397216796875, 0.395263671875, 1.0, 0.66357421875, 1.0, 0.99609375, 1.0, 1.0, 0.91650390625, 0.998046875, 1.0, 1.0, 1.0, 1.0, 0.172607421875, 0.0706787109375, 0.99658203125, 0.031585693359375, 0.98291015625, 0.9921875, 1.0, 1.0, 0.9990234375, 0.9921875, 1.0, 0.64501953125, 7.450580596923828e-06]], "normalized_score": [0.439616858959198], "tokens": [["\u2581Yes", ",", "\u2581in", "\u2581the", "\u2581movie", "\u2581Fast", "\u2581and", "\u2581Fur", "ious", "\u2581", "7", ",", "\u2581a", "\u2581red", "\u2581Ford", "\u2581GT", "\u2581super", "car", "\u2581j", "umps", "\u2581over", "\u2581a", "\u2581number", "\u2581of", "\u2581sk", "ys", "c", "rap", "ers", "\u2581in", "\u2581Ab", "u", "\u2581D", "hab", "i", ",", "\u2581including", "\u2581the", "\u2581She", "ikh", "\u2581Z", "ay", "ed", "\u2581Grand", "\u2581Mos", "que", ".", "\u2581#"]], "entropy": [[2.990234375, 0.41162109375, 2.01171875, 0.5400390625, 0.79150390625, 0.8818359375, 0.6943359375, 0.0087127685546875, 7.259845733642578e-05, 0.001972198486328125, 7.009506225585938e-05, 0.2044677734375, 1.1318359375, 0.29296875, 1.8115234375, 1.716796875, 0.8447265625, 0.01214599609375, 1.853515625, 5.781650543212891e-06, 1.427734375, 1.5810546875, 3.267578125, 0.0018939971923828125, 1.669921875, 0.0015773773193359375, 0.025421142578125, 0.0010004043579101562, 4.869699478149414e-05, 0.310302734375, 0.01435089111328125, 4.7326087951660156e-05, 0.0008196830749511719, 0.0002942085266113281, 0.00010693073272705078, 0.75634765625, 3.185546875, 0.031097412109375, 3.03125, 0.08746337890625, 0.05340576171875, 0.000720977783203125, 0.00235748291015625, 0.00948333740234375, 0.044647216796875, 0.0001742839813232422, 1.1357421875, 1.150390625]], "avg_entropy": [0.7081433981657028], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The Lykan Hypersport", "score_of_biggest_cluster": 0.439616858959198, "score_of_first_answer": 0.439616858959198, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 7.450580596923828e-06, "avg_score": 0.439616858959198, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.35618973721290803, "std_of_first_answer": 0.35618973721290803, "avg_entropy_of_first_answer": 0.7081433981657028, "lex_sim": 1.0}
{"question": "how old is baby in dirty dancing movie", "answer": ["17 #1066 \u2013 400 Years of American Capitalism by Adam Smith"], "scores": [[0.70947265625, 0.99462890625, 0.98876953125, 5.960464477539063e-08, 0.0158233642578125, 0.05419921875, 0.0206451416015625, 0.05078125, 5.942583084106445e-05, 0.27001953125, 0.004550933837890625, 0.07501220703125, 0.0943603515625, 0.0011959075927734375, 0.349853515625, 0.0005669593811035156, 0.0005660057067871094, 0.95849609375, 0.000720977783203125, 0.00215911865234375, 0.9990234375]], "normalized_score": [0.014819498173892498], "tokens": [["\u2581", "1", "7", "\u2581#", "1", "0", "6", "6", "\u2581\u2013", "\u2581", "4", "0", "0", "\u2581Years", "\u2581of", "\u2581American", "\u2581Capital", "ism", "\u2581by", "\u2581Adam", "\u2581Smith"]], "entropy": [[1.724609375, 0.041748046875, 0.064697265625, 1.080078125, 6.00390625, 1.970703125, 3.41796875, 3.40625, 2.97265625, 5.06640625, 0.433837890625, 3.197265625, 3.5703125, 2.7890625, 2.896484375, 5.42578125, 3.52734375, 0.251953125, 2.51953125, 2.837890625, 0.01180267333984375]], "avg_entropy": [2.5338232857840404], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "17-year-old", "score_of_biggest_cluster": 0.014819498173892498, "score_of_first_answer": 0.014819498173892498, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.014819498173892498, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.3851183550037392, "std_of_first_answer": 0.3851183550037392, "avg_entropy_of_first_answer": 2.5338232857840404, "lex_sim": 1.0}
{"question": "who plays the bad guy in the good place", "answer": ["Jianyun \"Jason\" Chen"], "scores": [[0.042694091796875, 0.990234375, 1.0, 0.0301361083984375, 0.52294921875, 0.98876953125, 0.052337646484375, 1.0, 0.10723876953125]], "normalized_score": [0.24913503229618073], "tokens": [["\u2581J", "ian", "y", "un", "\u2581\"", "J", "ason", "\"", "\u2581Chen"]], "entropy": [[3.048828125, 0.0750732421875, 2.3543834686279297e-05, 0.7373046875, 1.0859375, 0.07952880859375, 1.7607421875, 0.0010395050048828125, 2.478515625]], "avg_entropy": [1.0296659138467577], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ted Danson", "score_of_biggest_cluster": 0.24913503229618073, "score_of_first_answer": 0.24913503229618073, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0301361083984375, "avg_score": 0.24913503229618073, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44199209143903523, "std_of_first_answer": 0.44199209143903523, "avg_entropy_of_first_answer": 1.0296659138467577, "lex_sim": 1.0}
{"question": "the lowest temperature at which a lubricant will flow is called the", "answer": ["pour point."], "scores": [[0.8251953125, 0.99951171875, 0.381591796875, 4.172325134277344e-07, 0.0058746337890625, 0.04718017578125, 8.940696716308594e-07, 0.0107421875, 0.0012159347534179688, 0.002277374267578125, 0.006988525390625, 0.0233001708984375, 0.060028076171875, 0.9990234375, 0.046234130859375, 0.9970703125, 0.31640625, 0.08819580078125, 0.998046875, 0.98974609375, 0.99951171875, 1.0, 0.98486328125, 0.99853515625, 0.99658203125, 0.08551025390625, 0.99853515625, 0.1651611328125, 0.10467529296875, 0.53369140625]], "normalized_score": [0.06795722246170044], "tokens": [["\u2581pour", "\u2581point", ".", "\u2581#", "3", "1", "\u2581Post", "\u2581by", "\u2581ch", "ij", "im", "\u2581\u00bb", "\u2581Th", "u", "\u2581Aug", "\u2581", "2", "4", ",", "\u2581", "2", "0", "1", "7", "\u2581", "9", ":", "4", "6", "\u2581am"]], "entropy": [[0.97607421875, 0.003070831298828125, 1.0654296875, 0.129638671875, 3.326171875, 3.298828125, 2.904296875, 3.236328125, 5.1171875, 4.6796875, 2.474609375, 3.080078125, 1.58203125, 0.00794219970703125, 2.478515625, 0.021575927734375, 1.3232421875, 1.669921875, 0.01556396484375, 0.0684814453125, 0.005504608154296875, 7.790327072143555e-05, 0.08673095703125, 0.01264190673828125, 0.0302734375, 1.9619140625, 0.01043701171875, 1.7919921875, 2.3046875, 0.712890625]], "avg_entropy": [1.4791941861311595], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "pour point", "score_of_biggest_cluster": 0.06795722246170044, "score_of_first_answer": 0.06795722246170044, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.06795722246170044, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.44615820677721857, "std_of_first_answer": 0.44615820677721857, "avg_entropy_of_first_answer": 1.4791941861311595, "lex_sim": 1.0}
{"question": "who wrote got this feeling in my body", "answer": ["N/A #EUelections19: \u201cA strong and united left is the answer to the far right\u201d"], "scores": [[0.1192626953125, 0.7490234375, 0.99951171875, 6.4373016357421875e-06, 0.0024509429931640625, 0.0008640289306640625, 2.9027462005615234e-05, 0.1895751953125, 0.0011548995971679688, 0.99560546875, 0.005641937255859375, 0.0008640289306640625, 0.006900787353515625, 0.033905029296875, 0.2108154296875, 0.79296875, 0.99609375, 0.0002046823501586914, 0.72314453125, 0.5224609375, 0.275634765625, 0.98388671875, 0.8291015625, 0.422607421875, 0.10345458984375, 0.156005859375]], "normalized_score": [0.03855883702635765], "tokens": [["\u2581N", "/", "A", "\u2581#", "E", "U", "e", "lections", "1", "9", ":", "\u2581\u201c", "A", "\u2581strong", "\u2581and", "\u2581un", "ited", "\u2581left", "\u2581is", "\u2581the", "\u2581answer", "\u2581to", "\u2581the", "\u2581far", "\u2581right", "\u201d"]], "entropy": [[4.83203125, 1.3583984375, 0.0031604766845703125, 1.77734375, 4.91015625, 1.650390625, 4.43359375, 4.09765625, 1.6181640625, 0.033538818359375, 1.4921875, 5.2265625, 4.56640625, 5.1171875, 2.62109375, 1.259765625, 0.0268402099609375, 1.3857421875, 1.49609375, 1.7607421875, 1.669921875, 0.12060546875, 1.12109375, 2.67578125, 0.355224609375, 2.185546875]], "avg_entropy": [2.222893421466534], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Max Martin", "score_of_biggest_cluster": 0.03855883702635765, "score_of_first_answer": 0.03855883702635765, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 6.4373016357421875e-06, "avg_score": 0.03855883702635765, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.382765959465341, "std_of_first_answer": 0.382765959465341, "avg_entropy_of_first_answer": 2.222893421466534, "lex_sim": 1.0}
{"question": "who has the most sacks in college football", "answer": ["I'm sorry, I cannot give you the current information as my training data only goes up to 2021."], "scores": [[0.3408203125, 0.36669921875, 0.9990234375, 0.96337890625, 0.99365234375, 0.8740234375, 0.097412109375, 0.0214080810546875, 0.7529296875, 0.31005859375, 0.361572265625, 0.38330078125, 0.474609375, 0.94091796875, 0.4453125, 0.66552734375, 0.89111328125, 0.98779296875, 0.92724609375, 0.32763671875, 0.97265625, 1.0, 0.99951171875, 0.99951171875, 0.9990234375, 0.29296875, 0.11236572265625, 0.99658203125, 0.58447265625, 0.9794921875, 0.070556640625, 0.8583984375, 0.94970703125, 0.126220703125, 0.5205078125, 0.08795166015625, 0.2183837890625, 0.93701171875, 0.6748046875, 0.724609375, 0.1722412109375, 0.91845703125, 0.8271484375, 4.172325134277344e-07, 0.0845947265625, 3.796815872192383e-05, 0.000881195068359375, 0.00479888916015625]], "normalized_score": [0.22657130658626556], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581I", "\u2581cannot", "\u2581give", "\u2581you", "\u2581the", "\u2581current", "\u2581information", "\u2581as", "\u2581my", "\u2581training", "\u2581data", "\u2581only", "\u2581goes", "\u2581up", "\u2581to", "\u2581", "2", "0", "2", "1", ".", "\u2581However", ",", "\u2581you", "\u2581can", "\u2581look", "\u2581up", "\u2581the", "\u2581statistics", "\u2581on", "\u2581NCAA", ".", "org", "\u2581or", "\u2581other", "\u2581reliable", "\u2581sources", ".", "\u2581#", "E", "U", "refer", "endum"]], "entropy": [[3.84765625, 1.654296875, 0.00868988037109375, 0.176025390625, 0.04461669921875, 0.57958984375, 1.4716796875, 1.328125, 0.8232421875, 1.5234375, 1.3037109375, 1.2431640625, 1.4609375, 0.278564453125, 0.80126953125, 0.8212890625, 0.47607421875, 0.09381103515625, 0.284423828125, 0.6875, 0.1568603515625, 0.000926971435546875, 0.0024871826171875, 0.005374908447265625, 0.0104217529296875, 1.099609375, 2.06640625, 0.0257110595703125, 1.7548828125, 0.11309814453125, 1.4267578125, 0.44970703125, 0.307373046875, 2.01953125, 1.431640625, 2.2734375, 1.4375, 0.250732421875, 0.943359375, 1.2294921875, 1.2138671875, 0.362060546875, 0.62548828125, 0.1851806640625, 5.3046875, 3.23828125, 4.57421875, 1.3173828125]], "avg_entropy": [1.0986371040344238], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Mike Czerwien", "score_of_biggest_cluster": 0.22657130658626556, "score_of_first_answer": 0.22657130658626556, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.22657130658626556, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37236904961035355, "std_of_first_answer": 0.37236904961035355, "avg_entropy_of_first_answer": 1.0986371040344238, "lex_sim": 1.0}
{"question": "when are the opening ceremonies for the 2018 olympic games", "answer": ["February 9, 2018"], "scores": [[0.477294921875, 0.9990234375, 0.9970703125, 0.312744140625, 0.99951171875, 1.0, 1.0, 1.0, 1.0]], "normalized_score": [0.8091094493865967], "tokens": [["\u2581February", "\u2581", "9", ",", "\u2581", "2", "0", "1", "8"]], "entropy": [[1.443359375, 0.007110595703125, 0.0225982666015625, 0.650390625, 0.005611419677734375, 0.0007176399230957031, 7.033348083496094e-06, 7.420778274536133e-05, 0.0010004043579101562]], "avg_entropy": [0.23676328526602852], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "9\u00a0February\u00a02018", "score_of_biggest_cluster": 0.8091094493865967, "score_of_first_answer": 0.8091094493865967, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.312744140625, "avg_score": 0.8091094493865967, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.25423085908160503, "std_of_first_answer": 0.25423085908160503, "avg_entropy_of_first_answer": 0.23676328526602852, "lex_sim": 1.0}
{"question": "where did the california gold rush take place", "answer": ["California #Review: Hers to Protect by Patricia A. Knight - 4 Wine Glasses"], "scores": [[0.98046875, 0.0, 0.0002586841583251953, 0.0149688720703125, 0.002574920654296875, 0.00072479248046875, 0.0003180503845214844, 0.009613037109375, 0.61279296875, 1.0, 0.18701171875, 0.88916015625, 0.9921875, 0.99951171875, 0.230712890625, 0.99072265625, 0.271728515625, 0.0863037109375, 0.04620361328125, 0.28515625, 0.0035305023193359375, 0.89208984375, 0.98828125, 1.0, 0.853515625]], "normalized_score": [0.0], "tokens": [["\u2581California", "\u2581#", "Re", "view", ":", "\u2581H", "ers", "\u2581to", "\u2581Prote", "ct", "\u2581by", "\u2581Pat", "ric", "ia", "\u2581A", ".", "\u2581Knight", "\u2581-", "\u2581", "4", "\u2581W", "ine", "\u2581G", "lass", "es"]], "entropy": [[0.1328125, 1.0126953125, 4.9375, 3.515625, 3.5703125, 4.93359375, 2.99609375, 2.412109375, 1.677734375, 0.0015783309936523438, 1.7958984375, 0.7275390625, 0.05810546875, 0.004230499267578125, 1.66796875, 0.07940673828125, 2.2109375, 2.255859375, 5.0625, 2.0, 1.8955078125, 0.7431640625, 0.081298828125, 0.00022995471954345703, 0.67333984375]], "avg_entropy": [1.777841649055481], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Northern California", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4338135425211994, "std_of_first_answer": 0.4338135425211994, "avg_entropy_of_first_answer": 1.777841649055481, "lex_sim": 1.0}
{"question": "who got the first arjun award in athletics", "answer": ["Anju Bobby George ### Description"], "scores": [[0.2396240234375, 0.98486328125, 0.99755859375, 0.99951171875, 0.0, 8.660554885864258e-05]], "normalized_score": [0.0], "tokens": [["\u2581An", "ju", "\u2581Bobby", "\u2581George", "\u2581###", "\u2581Description"]], "entropy": [[3.15625, 0.1185302734375, 0.0232696533203125, 0.006267547607421875, 1.005859375, 5.41015625]], "avg_entropy": [1.6200555165608723], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Gurbachan Singh Randhawa", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.46398460291109106, "std_of_first_answer": 0.46398460291109106, "avg_entropy_of_first_answer": 1.6200555165608723, "lex_sim": 1.0}
{"question": "how many gold medals did australia win in the 2000 olympics", "answer": ["58, including 16 gold medals."], "scores": [[0.81591796875, 0.85791015625, 0.984375, 0.0227203369140625, 0.9375, 0.98974609375, 0.99560546875, 0.78173828125, 0.92041015625, 0.63037109375, 0.99951171875, 0.5791015625, 8.344650268554688e-07, 0.001209259033203125, 1.0967254638671875e-05, 0.0041351318359375, 0.002338409423828125, 0.01351165771484375, 0.00955963134765625, 0.0007328987121582031, 0.0028667449951171875, 0.99951171875, 0.0677490234375, 0.0217742919921875, 0.9990234375, 0.998046875]], "normalized_score": [0.050162266939878464], "tokens": [["\u2581", "5", "8", ",", "\u2581including", "\u2581", "1", "6", "\u2581gold", "\u2581med", "als", ".", "\u2581#", "4", "\u2581U", "M", "ass", "\u2581C", "lin", "ches", "\u2581Ber", "th", "\u2581with", "\u2581Sh", "ut", "out"]], "entropy": [[0.83642578125, 0.52001953125, 0.10986328125, 0.7470703125, 0.374267578125, 0.0909423828125, 0.03546142578125, 0.90771484375, 0.344970703125, 0.94091796875, 0.00478363037109375, 0.88134765625, 0.274169921875, 3.31640625, 3.080078125, 3.705078125, 2.537109375, 4.4765625, 2.1171875, 0.68017578125, 3.67578125, 0.004528045654296875, 2.291015625, 1.888671875, 0.00899505615234375, 0.0167083740234375]], "avg_entropy": [1.3025481884296124], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "16", "score_of_biggest_cluster": 0.050162266939878464, "score_of_first_answer": 0.050162266939878464, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 8.344650268554688e-07, "avg_score": 0.050162266939878464, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.45017276538993656, "std_of_first_answer": 0.45017276538993656, "avg_entropy_of_first_answer": 1.3025481884296124, "lex_sim": 1.0}
{"question": "what is the spelling of lakh in english", "answer": ["lac generare in format PDF"], "scores": [[0.152099609375, 0.0, 0.00014841556549072266, 0.028289794921875, 7.05718994140625e-05, 0.0026874542236328125]], "normalized_score": [0.0], "tokens": [["\u2581lac", "\u2581gener", "are", "\u2581in", "\u2581format", "\u2581PDF"]], "entropy": [[1.7119140625, 1.17578125, 2.068359375, 4.40234375, 5.37109375, 5.19921875]], "avg_entropy": [3.3214518229166665], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "lakh", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.152099609375, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.05529058372806627, "std_of_first_answer": 0.05529058372806627, "avg_entropy_of_first_answer": 3.3214518229166665, "lex_sim": 1.0}
{"question": "who played sonny in lemony snicket's a series of unfortunate events", "answer": ["Neil Patrick Harris"], "scores": [[0.00988006591796875, 1.0, 1.0]], "normalized_score": [0.21457870304584503], "tokens": [["\u2581Neil", "\u2581Patrick", "\u2581Harris"]], "entropy": [[1.9951171875, 0.00021183490753173828, 0.0005645751953125]], "avg_entropy": [0.6652978658676147], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Presley Smith", "score_of_biggest_cluster": 0.21457870304584503, "score_of_first_answer": 0.21457870304584503, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.00988006591796875, "avg_score": 0.21457870304584503, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.46674701305158783, "std_of_first_answer": 0.46674701305158783, "avg_entropy_of_first_answer": 0.6652978658676147, "lex_sim": 1.0}
{"question": "when did computer become widespread in homes and schools", "answer": ["In the 1980s and 1990s, the widespread use of personal computers in homes and schools began with the introduction of home computers, such as the Apple II and Commodore 64,"], "scores": [[0.1524658203125, 0.9990234375, 0.53369140625, 0.99951171875, 1.0, 0.9951171875, 1.0, 0.994140625, 0.72216796875, 0.9990234375, 0.9970703125, 1.0, 1.0, 1.0, 1.0, 0.1793212890625, 0.0743408203125, 0.947265625, 1.0, 1.0, 1.0, 0.71728515625, 0.998046875, 0.96923828125, 0.99951171875, 0.97509765625, 0.99658203125, 0.99853515625, 0.99951171875, 0.43017578125, 0.142333984375, 0.99951171875, 0.251220703125, 0.99755859375, 0.0253448486328125, 0.77734375, 0.08831787109375, 0.955078125, 1.0, 0.9931640625, 0.497802734375, 0.998046875, 0.87255859375, 0.6630859375, 0.99951171875, 1.0, 0.99560546875, 1.0, 1.0, 0.9755859375]], "normalized_score": [0.6773374676704407], "tokens": [["\u2581In", "\u2581the", "\u2581", "1", "9", "8", "0", "s", "\u2581and", "\u2581", "1", "9", "9", "0", "s", ",", "\u2581the", "\u2581w", "ides", "p", "read", "\u2581use", "\u2581of", "\u2581personal", "\u2581computers", "\u2581in", "\u2581homes", "\u2581and", "\u2581schools", "\u2581began", "\u2581with", "\u2581the", "\u2581introduction", "\u2581of", "\u2581home", "\u2581computers", ",", "\u2581such", "\u2581as", "\u2581the", "\u2581Apple", "\u2581II", "\u2581and", "\u2581Com", "mod", "ore", "\u2581", "6", "4", ","]], "entropy": [[1.9130859375, 0.01015472412109375, 0.8173828125, 0.0060272216796875, 0.00010037422180175781, 0.033935546875, 0.00017321109771728516, 0.0357666015625, 0.9853515625, 0.0085296630859375, 0.02032470703125, 2.9146671295166016e-05, 0.0003371238708496094, 0.0006985664367675781, 0.0020751953125, 1.541015625, 1.173828125, 0.335205078125, 6.645917892456055e-05, 0.0002722740173339844, 8.940696716308594e-06, 0.78955078125, 0.013275146484375, 0.1602783203125, 0.003475189208984375, 0.1771240234375, 0.0261077880859375, 0.01261138916015625, 0.00601959228515625, 1.6474609375, 1.2099609375, 0.0038890838623046875, 1.4287109375, 0.018768310546875, 1.240234375, 0.66845703125, 1.04296875, 0.2626953125, 0.0018224716186523438, 0.046356201171875, 0.87841796875, 0.016998291015625, 0.3916015625, 0.8828125, 0.0027618408203125, 0.0006103515625, 0.0305633544921875, 4.595518112182617e-05, 0.0010442733764648438, 0.1295166015625]], "avg_entropy": [0.35957016348838805], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1980s", "score_of_biggest_cluster": 0.6773374676704407, "score_of_first_answer": 0.6773374676704407, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0253448486328125, "avg_score": 0.6773374676704407, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.31019712897959484, "std_of_first_answer": 0.31019712897959484, "avg_entropy_of_first_answer": 0.35957016348838805, "lex_sim": 1.0}
{"question": "what is a home run with a girl", "answer": ["Sexual intercourse."], "scores": [[0.00543975830078125, 0.92919921875, 0.87060546875, 0.99951171875, 0.3525390625]], "normalized_score": [0.27422118186950684], "tokens": [["\u2581Sex", "ual", "\u2581inter", "course", "."]], "entropy": [[3.271484375, 0.387939453125, 0.49365234375, 0.0027618408203125, 1.501953125]], "avg_entropy": [1.1315582275390625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "\"full\" sexual intercourse", "score_of_biggest_cluster": 0.27422118186950684, "score_of_first_answer": 0.27422118186950684, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.00543975830078125, "avg_score": 0.27422118186950684, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.387556317886528, "std_of_first_answer": 0.387556317886528, "avg_entropy_of_first_answer": 1.1315582275390625, "lex_sim": 1.0}
{"question": "who plays the principal in santa clarita diet", "answer": ["Nathan Fillion"], "scores": [[0.2744140625, 0.5693359375, 1.0, 1.0]], "normalized_score": [0.6287003755569458], "tokens": [["\u2581Nathan", "\u2581F", "ill", "ion"]], "entropy": [[2.609375, 2.146484375, 0.0015306472778320312, 0.0006117820739746094]], "avg_entropy": [1.1895004510879517], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Thomas Lennon", "score_of_biggest_cluster": 0.6287003755569458, "score_of_first_answer": 0.6287003755569458, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.2744140625, "avg_score": 0.6287003755569458, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.30729382185530424, "std_of_first_answer": 0.30729382185530424, "avg_entropy_of_first_answer": 1.1895004510879517, "lex_sim": 1.0}
{"question": "who coined the phrase let them eat cake", "answer": ["Marie Antoinette"], "scores": [[0.94091796875, 0.97265625, 1.0, 1.0]], "normalized_score": [0.9780876636505127], "tokens": [["\u2581Marie", "\u2581Anto", "in", "ette"]], "entropy": [[0.38916015625, 0.15576171875, 0.0003757476806640625, 0.0005283355712890625]], "avg_entropy": [0.13645648956298828], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Jean-Jacques Rousseau", "score_of_biggest_cluster": 0.9780876636505127, "score_of_first_answer": 0.9780876636505127, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.94091796875, "avg_score": 0.9780876636505127, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.024346525237291375, "std_of_first_answer": 0.024346525237291375, "avg_entropy_of_first_answer": 0.13645648956298828, "lex_sim": 1.0}
{"question": "what is the function of a political action committee (pac)", "answer": ["A political action committee (PAC) is a type of organization that raises and spends money to elect federal candidates who align with its goals."], "scores": [[0.81787109375, 0.77294921875, 1.0, 1.0, 0.982421875, 1.0, 1.0, 0.99951171875, 0.998046875, 0.78076171875, 0.79638671875, 0.99951171875, 0.94091796875, 0.99169921875, 0.72900390625, 1.0, 0.99853515625, 0.98974609375, 0.99951171875, 0.99658203125, 0.99853515625, 0.33154296875, 0.796875, 0.99951171875, 0.8603515625, 0.294189453125, 1.0, 0.9814453125, 0.367919921875, 0.71630859375, 0.11651611328125, 0.7119140625, 0.810546875, 0.99951171875, 0.9892578125, 0.99462890625, 1.0, 0.9990234375, 1.0, 0.69873046875, 0.515625, 0.517578125, 0.99951171875, 0.05535888671875, 0.219482421875, 0.80712890625, 0.26171875, 0.9619140625, 0.102294921875, 0.9716796875]], "normalized_score": [0.6959425210952759], "tokens": [["\u2581A", "\u2581political", "\u2581action", "\u2581committee", "\u2581(", "P", "AC", ")", "\u2581is", "\u2581a", "\u2581type", "\u2581of", "\u2581organization", "\u2581that", "\u2581ra", "ises", "\u2581and", "\u2581sp", "ends", "\u2581money", "\u2581to", "\u2581elect", "\u2581federal", "\u2581candidates", "\u2581who", "\u2581align", "\u2581with", "\u2581its", "\u2581goals", ".", "\u2581The", "\u2581primary", "\u2581function", "\u2581of", "\u2581a", "\u2581P", "AC", "\u2581is", "\u2581to", "\u2581support", "\u2581political", "\u2581campaign", "s", ",", "\u2581primarily", "\u2581through", "\u2581financial", "\u2581contributions", "\u2581to", "\u2581candidates"]], "entropy": [[0.76318359375, 0.65478515625, 0.001010894775390625, 0.0001728534698486328, 0.10174560546875, 0.0014514923095703125, 2.199411392211914e-05, 0.005283355712890625, 0.0165557861328125, 0.54296875, 0.720703125, 0.005924224853515625, 0.305419921875, 0.0576171875, 0.74462890625, 8.469820022583008e-05, 0.013275146484375, 0.0667724609375, 0.00304412841796875, 0.0227508544921875, 0.012603759765625, 0.701171875, 0.7490234375, 0.0031337738037109375, 0.5810546875, 1.302734375, 0.0017709732055664062, 0.09844970703125, 1.7587890625, 0.794921875, 1.7744140625, 0.8525390625, 0.71337890625, 0.003971099853515625, 0.0626220703125, 0.037506103515625, 8.857250213623047e-05, 0.009613037109375, 0.0023479461669921875, 1.1953125, 1.37890625, 0.84521484375, 0.003147125244140625, 1.3251953125, 2.619140625, 0.78857421875, 1.6005859375, 0.17724609375, 1.267578125, 0.1781005859375]], "avg_entropy": [0.4973307228088379], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "pools campaign contributions from members", "score_of_biggest_cluster": 0.6959425210952759, "score_of_first_answer": 0.6959425210952759, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.05535888671875, "avg_score": 0.6959425210952759, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2841169688331232, "std_of_first_answer": 0.2841169688331232, "avg_entropy_of_first_answer": 0.4973307228088379, "lex_sim": 1.0}
{"question": "who was the great wall of china built to defend against", "answer": ["Mongol invaders"], "scores": [[0.53564453125, 0.54345703125, 0.324462890625, 1.0]], "normalized_score": [0.5543725490570068], "tokens": [["\u2581Mong", "ol", "\u2581inv", "aders"]], "entropy": [[1.953125, 0.72509765625, 1.7138671875, 0.0017528533935546875]], "avg_entropy": [1.0984606742858887], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "nomads from Inner Asia", "score_of_biggest_cluster": 0.5543725490570068, "score_of_first_answer": 0.5543725490570068, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.324462890625, "avg_score": 0.5543725490570068, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.24660507698763337, "std_of_first_answer": 0.24660507698763337, "avg_entropy_of_first_answer": 1.0984606742858887, "lex_sim": 1.0}
{"question": "who won the 2017 sports personality of the year", "answer": ["Mo Farah #TrudeauMustGo: Hashtag Trends for March 8, 2019"], "scores": [[0.79541015625, 0.998046875, 0.998046875, 2.980232238769531e-07, 0.00501251220703125, 0.00019860267639160156, 0.01015472412109375, 0.947265625, 0.2020263671875, 0.55419921875, 0.97900390625, 0.00027108192443847656, 0.00095367431640625, 0.96044921875, 0.865234375, 0.035919189453125, 0.91845703125, 0.0103302001953125, 0.0389404296875, 0.9912109375, 0.05712890625, 0.4267578125, 0.990234375, 0.99853515625, 1.0, 0.73681640625, 0.105712890625]], "normalized_score": [0.07821594923734665], "tokens": [["\u2581Mo", "\u2581Far", "ah", "\u2581#", "T", "ru", "de", "au", "M", "ust", "Go", ":", "\u2581Has", "ht", "ag", "\u2581Tr", "ends", "\u2581for", "\u2581March", "\u2581", "8", ",", "\u2581", "2", "0", "1", "9"]], "entropy": [[1.1064453125, 0.016998291015625, 0.0151519775390625, 0.6015625, 5.0546875, 4.13671875, 4.7421875, 0.41943359375, 3.236328125, 1.85546875, 0.12042236328125, 0.9267578125, 4.2578125, 0.301025390625, 0.3984375, 4.1796875, 0.389892578125, 3.130859375, 3.361328125, 0.06903076171875, 1.875, 1.669921875, 0.0999755859375, 0.01345062255859375, 0.0011272430419921875, 0.57763671875, 1.1884765625]], "avg_entropy": [1.6202157338460286], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Mo Farah", "score_of_biggest_cluster": 0.07821594923734665, "score_of_first_answer": 0.07821594923734665, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.07821594923734665, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4375424305448017, "std_of_first_answer": 0.4375424305448017, "avg_entropy_of_first_answer": 1.6202157338460286, "lex_sim": 1.0}
{"question": "where are the cones in the eye located", "answer": ["The cones are located in the retina, a layer of light-sensitive cells at the back of the eye."], "scores": [[0.08270263671875, 0.95166015625, 1.0, 0.9453125, 0.99267578125, 0.99755859375, 0.98291015625, 0.12359619140625, 1.0, 0.54736328125, 0.029449462890625, 0.89697265625, 0.79052734375, 0.372802734375, 0.99951171875, 0.99951171875, 0.98388671875, 0.994140625, 0.55126953125, 0.9970703125, 0.99951171875, 0.99853515625, 0.99951171875, 0.99951171875, 0.83642578125, 1.1920928955078125e-07, 5.841255187988281e-06, 0.708984375, 0.1280517578125, 0.0189361572265625, 0.00543975830078125, 0.004230499267578125, 0.58984375, 0.9443359375, 0.373779296875, 0.1187744140625, 0.0114898681640625, 2.1457672119140625e-06, 0.1287841796875, 0.99755859375, 1.0, 0.216064453125, 0.9931640625, 0.0310821533203125, 0.99365234375, 1.0, 0.9990234375, 0.99755859375]], "normalized_score": [0.17267031967639923], "tokens": [["\u2581The", "\u2581con", "es", "\u2581are", "\u2581located", "\u2581in", "\u2581the", "\u2581ret", "ina", ",", "\u2581a", "\u2581layer", "\u2581of", "\u2581light", "-", "sens", "itive", "\u2581cells", "\u2581at", "\u2581the", "\u2581back", "\u2581of", "\u2581the", "\u2581eye", ".", "\u2581#", "OT", "D", "\u2581", "2", "4", "\u2581August", "\u2581", "1", "9", "5", "5", "\u2581When", "\u2581Rosa", "\u2581Park", "s", "\u2581was", "\u2581arrested", "\u2581in", "\u2581Mont", "gom", "ery", ","]], "entropy": [[2.515625, 0.2174072265625, 5.02467155456543e-05, 0.2369384765625, 0.04876708984375, 0.0188446044921875, 0.08856201171875, 1.689453125, 2.1517276763916016e-05, 0.8935546875, 0.9130859375, 0.408447265625, 0.5849609375, 1.4814453125, 0.0068511962890625, 0.00440216064453125, 0.08465576171875, 0.041961669921875, 1.1865234375, 0.0195159912109375, 0.00440216064453125, 0.01294708251953125, 0.005870819091796875, 0.0042877197265625, 0.6015625, 0.6591796875, 1.3037109375, 1.6728515625, 2.5078125, 0.2265625, 0.477294921875, 3.642578125, 1.4326171875, 0.2266845703125, 0.91357421875, 2.09765625, 0.53857421875, 1.34765625, 2.720703125, 0.0226287841796875, 0.0015249252319335938, 0.86181640625, 0.059417724609375, 0.246826171875, 0.043304443359375, 0.0018138885498046875, 0.007518768310546875, 0.020751953125]], "avg_entropy": [0.6688167303800583], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the retina", "score_of_biggest_cluster": 0.17267031967639923, "score_of_first_answer": 0.17267031967639923, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.17267031967639923, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.41717635763964, "std_of_first_answer": 0.41717635763964, "avg_entropy_of_first_answer": 0.6688167303800583, "lex_sim": 1.0}
{"question": "where does the last name hidalgo come from", "answer": ["Hidalgo is a Spanish surname, and its origin is from the province of Hidalgo in central Mexico."], "scores": [[0.0242919921875, 0.99951171875, 1.0, 0.384033203125, 0.9921875, 0.56005859375, 0.66748046875, 0.26708984375, 0.07208251953125, 0.0947265625, 0.81591796875, 0.75439453125, 0.458251953125, 0.876953125, 0.28076171875, 0.99609375, 0.98681640625, 0.85791015625, 1.0, 0.55322265625, 0.0843505859375, 0.923828125, 0.88916015625, 0.1763916015625, 0.6279296875, 0.040313720703125, 0.1322021484375, 0.7744140625, 0.998046875, 0.10797119140625, 0.9931640625, 0.50732421875, 0.5205078125, 0.5654296875, 0.83984375, 0.998046875, 0.2822265625, 0.73974609375, 0.268310546875, 0.99853515625, 0.9990234375, 1.0, 0.673828125, 2.980232238769531e-07, 0.0214691162109375, 0.0001590251922607422, 6.479024887084961e-05, 0.29296875]], "normalized_score": [0.22386878728866577], "tokens": [["\u2581H", "idal", "go", "\u2581is", "\u2581a", "\u2581Spanish", "\u2581surname", ",", "\u2581and", "\u2581its", "\u2581origin", "\u2581is", "\u2581from", "\u2581the", "\u2581province", "\u2581of", "\u2581H", "idal", "go", "\u2581in", "\u2581central", "\u2581Mexico", ".", "\u2581The", "\u2581name", "\u2581was", "\u2581originally", "\u2581given", "\u2581to", "\u2581those", "\u2581who", "\u2581were", "\u2581born", "\u2581or", "\u2581lived", "\u2581in", "\u2581the", "\u2581province", "\u2581of", "\u2581H", "idal", "go", ".", "\u2581#", "1", "\u2581Best", "\u2581City", "\u2581to"]], "entropy": [[2.591796875, 0.0059356689453125, 0.0012216567993164062, 1.3779296875, 0.0633544921875, 0.96142578125, 1.0751953125, 1.994140625, 1.9306640625, 1.0693359375, 0.60791015625, 0.7578125, 2.3203125, 0.5166015625, 2.29296875, 0.0284576416015625, 0.10052490234375, 0.5048828125, 0.00165557861328125, 0.73828125, 0.84423828125, 0.35009765625, 0.406494140625, 1.2021484375, 1.2412109375, 1.9208984375, 1.4189453125, 0.9189453125, 0.01508331298828125, 0.97509765625, 0.054229736328125, 1.0625, 0.9599609375, 0.75390625, 0.63818359375, 0.01641845703125, 1.15234375, 0.94873046875, 1.1748046875, 0.01422882080078125, 0.0102386474609375, 0.0015277862548828125, 0.77099609375, 0.6572265625, 4.6171875, 3.0703125, 2.10546875, 3.056640625]], "avg_entropy": [1.0270515084266663], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Spanish", "score_of_biggest_cluster": 0.22386878728866577, "score_of_first_answer": 0.22386878728866577, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.22386878728866577, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.36667015261167446, "std_of_first_answer": 0.36667015261167446, "avg_entropy_of_first_answer": 1.0270515084266663, "lex_sim": 1.0}
{"question": "what is on top of us capitol building", "answer": ["The Statue of Freedom #68: The Unseen World by Liz Moore"], "scores": [[0.51953125, 0.453369140625, 0.9990234375, 1.0, 0.99951171875, 1.0, 1.1920928955078125e-07, 0.006961822509765625, 0.057586669921875, 0.0047454833984375, 0.11297607421875, 0.0011491775512695312, 0.0022735595703125, 0.001415252685546875, 0.004894256591796875, 0.00045180320739746094, 0.00852203369140625, 0.0003180503845214844]], "normalized_score": [0.013124771416187286], "tokens": [["\u2581The", "\u2581Stat", "ue", "\u2581of", "\u2581Fre", "edom", "\u2581#", "6", "8", ":", "\u2581The", "\u2581Un", "seen", "\u2581World", "\u2581by", "\u2581L", "iz", "\u2581Moore"]], "entropy": [[1.4580078125, 2.087890625, 0.007781982421875, 0.0008630752563476562, 0.0032329559326171875, 0.0004677772521972656, 1.078125, 4.828125, 3.62890625, 3.091796875, 4.171875, 3.271484375, 0.84619140625, 3.443359375, 2.890625, 3.12890625, 3.90625, 4.93359375]], "avg_entropy": [2.376526806089613], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The Statue of Freedom", "score_of_biggest_cluster": 0.013124771416187286, "score_of_first_answer": 0.013124771416187286, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.013124771416187286, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4084031595556605, "std_of_first_answer": 0.4084031595556605, "avg_entropy_of_first_answer": 2.376526806089613, "lex_sim": 1.0}
{"question": "where are most nutrients absorbed in the human digestive tract", "answer": ["Small intestine #216663 - 04/26/06 05:16 PM Re: Why I love being an Amiga User [Re: MacGuy]"], "scores": [[0.2308349609375, 0.89599609375, 1.0, 0.9990234375, 1.1920928955078125e-07, 0.0716552734375, 0.00390625, 0.021881103515625, 0.01560211181640625, 0.35986328125, 0.09173583984375, 0.0003972053527832031, 0.2181396484375, 0.08331298828125, 0.040313720703125, 0.51708984375, 0.24462890625, 0.0821533203125, 0.99267578125, 0.0013675689697265625, 0.090087890625, 0.4931640625, 0.533203125, 0.10247802734375, 0.994140625, 0.1514892578125, 0.1109619140625, 0.53955078125, 0.0012750625610351562, 0.95068359375, 0.0006937980651855469, 0.004467010498046875, 0.0399169921875, 0.0601806640625, 0.13623046875, 0.0013141632080078125, 0.07586669921875, 0.1297607421875, 0.84033203125, 0.99853515625, 0.9990234375, 0.00043272972106933594, 0.5126953125, 0.01039886474609375, 0.982421875]], "normalized_score": [0.060951586812734604], "tokens": [["\u2581Small", "\u2581int", "est", "ine", "\u2581#", "2", "1", "6", "6", "6", "3", "\u2581-", "\u2581", "0", "4", "/", "2", "6", "/", "0", "6", "\u2581", "0", "5", ":", "1", "6", "\u2581PM", "\u2581Re", ":", "\u2581Why", "\u2581I", "\u2581love", "\u2581being", "\u2581an", "\u2581Am", "iga", "\u2581User", "\u2581[", "Re", ":", "\u2581Mac", "G", "uy", "]"]], "entropy": [[1.279296875, 0.337890625, 0.00010466575622558594, 0.00666046142578125, 1.1005859375, 4.9296875, 2.23828125, 3.716796875, 1.3359375, 2.421875, 2.134765625, 1.4072265625, 5.01171875, 2.365234375, 3.033203125, 2.12109375, 1.1669921875, 2.296875, 0.054931640625, 0.058349609375, 2.296875, 1.9208984375, 1.0439453125, 2.228515625, 0.05230712890625, 1.8017578125, 2.306640625, 1.3369140625, 2.154296875, 0.337890625, 5.546875, 3.96875, 4.4375, 4.828125, 1.7158203125, 2.779296875, 1.2900390625, 3.591796875, 1.0048828125, 0.01375579833984375, 0.006977081298828125, 4.62109375, 1.4365234375, 2.296875, 0.10455322265625]], "avg_entropy": [2.003120289908515], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The small intestine", "score_of_biggest_cluster": 0.060951586812734604, "score_of_first_answer": 0.060951586812734604, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.060951586812734604, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37587164124297573, "std_of_first_answer": 0.37587164124297573, "avg_entropy_of_first_answer": 2.003120289908515, "lex_sim": 1.0}
{"question": "when does sloan come into grey's anatomy", "answer": ["Season 9, Episode 8"], "scores": [[0.4033203125, 0.99951171875, 0.11871337890625, 0.039337158203125, 0.86572265625, 1.0, 0.99951171875, 0.06488037109375]], "normalized_score": [0.3184216320514679], "tokens": [["\u2581Season", "\u2581", "9", ",", "\u2581E", "pisode", "\u2581", "8"]], "entropy": [[2.900390625, 0.005382537841796875, 2.052734375, 1.10546875, 0.421142578125, 1.3768672943115234e-05, 0.0030956268310546875, 1.7822265625]], "avg_entropy": [1.0338068529963493], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "season two", "score_of_biggest_cluster": 0.3184216320514679, "score_of_first_answer": 0.3184216320514679, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.039337158203125, "avg_score": 0.3184216320514679, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4196587862409417, "std_of_first_answer": 0.4196587862409417, "avg_entropy_of_first_answer": 1.0338068529963493, "lex_sim": 1.0}
{"question": "how many countries in the world have scouts", "answer": ["estimated 216 countries #1 Post by mtmynd \u00bb December 27th, 2018, 6:18 pm"], "scores": [[0.018463134765625, 0.5205078125, 0.990234375, 0.3623046875, 0.369140625, 0.6015625, 9.5367431640625e-07, 0.0015687942504882812, 1.6689300537109375e-06, 0.0246124267578125, 0.004848480224609375, 0.0041351318359375, 0.00144195556640625, 0.82275390625, 0.235107421875, 0.0295257568359375, 0.998046875, 0.29248046875, 0.091552734375, 0.94287109375, 0.9990234375, 0.9970703125, 0.99951171875, 1.0, 0.2088623046875, 0.177978515625, 0.99560546875, 0.9951171875, 0.07196044921875, 0.99951171875, 0.1611328125, 0.1021728515625, 0.5732421875]], "normalized_score": [0.0851004496216774], "tokens": [["\u2581estimated", "\u2581", "2", "1", "6", "\u2581countries", "\u2581#", "1", "\u2581Post", "\u2581by", "\u2581m", "t", "my", "nd", "\u2581\u00bb", "\u2581December", "\u2581", "2", "7", "th", ",", "\u2581", "2", "0", "1", "8", ",", "\u2581", "6", ":", "1", "8", "\u2581pm"]], "entropy": [[2.306640625, 1.0810546875, 0.057281494140625, 1.240234375, 1.8955078125, 1.1767578125, 1.703125, 1.7607421875, 3.548828125, 2.36328125, 6.375, 5.24609375, 4.5625, 1.3203125, 2.923828125, 3.025390625, 0.01531219482421875, 1.716796875, 2.396484375, 0.229248046875, 0.007488250732421875, 0.0284576416015625, 0.004161834716796875, 4.589557647705078e-05, 0.5341796875, 1.501953125, 0.035247802734375, 0.046295166015625, 1.9072265625, 0.005126953125, 1.7890625, 2.302734375, 0.69189453125]], "avg_entropy": [1.6302513389876394], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "216", "score_of_biggest_cluster": 0.0851004496216774, "score_of_first_answer": 0.0851004496216774, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 9.5367431640625e-07, "avg_score": 0.0851004496216774, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4104168954864557, "std_of_first_answer": 0.4104168954864557, "avg_entropy_of_first_answer": 1.6302513389876394, "lex_sim": 1.0}
{"question": "element named after fictional planet from which superman came", "answer": ["krypton"], "scores": [[0.55810546875, 1.0, 1.0]], "normalized_score": [0.8233264684677124], "tokens": [["\u2581k", "rypt", "on"]], "entropy": [[0.8759765625, 0.0015125274658203125, 7.05718994140625e-05]], "avg_entropy": [0.29251988728841144], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Kryptonite", "score_of_biggest_cluster": 0.8233264684677124, "score_of_first_answer": 0.8233264684677124, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.55810546875, "avg_score": 0.8233264684677124, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2083110797440838, "std_of_first_answer": 0.2083110797440838, "avg_entropy_of_first_answer": 0.29251988728841144, "lex_sim": 1.0}
{"question": "where does the president get authority to issue executive orders", "answer": ["The President of the United States gets the authority to issue executive orders from Article II, Section 1 of the United States Constitution, which grants the President the power to \"take Care that the Laws be faithfully executed.\""], "scores": [[0.552734375, 0.9052734375, 0.189453125, 0.99951171875, 0.99951171875, 0.99951171875, 0.364501953125, 0.42333984375, 0.9990234375, 0.99853515625, 0.99951171875, 0.92529296875, 1.0, 0.96484375, 0.642578125, 0.93310546875, 0.98974609375, 0.9912109375, 0.99951171875, 0.99951171875, 0.9814453125, 0.9990234375, 0.71484375, 0.99951171875, 0.99951171875, 0.422119140625, 0.99755859375, 0.5078125, 1.0, 0.98046875, 0.96630859375, 0.98828125, 0.98046875, 0.99951171875, 0.297607421875, 0.97314453125, 0.4072265625, 0.99951171875, 1.0, 0.99658203125, 1.0, 0.998046875, 1.0, 1.0, 1.0, 0.970703125, 0.609375, 0.99560546875, 0.9228515625, 0.517578125]], "normalized_score": [0.8143054842948914], "tokens": [["\u2581The", "\u2581President", "\u2581of", "\u2581the", "\u2581United", "\u2581States", "\u2581gets", "\u2581the", "\u2581authority", "\u2581to", "\u2581issue", "\u2581executive", "\u2581orders", "\u2581from", "\u2581Article", "\u2581II", ",", "\u2581Section", "\u2581", "1", "\u2581of", "\u2581the", "\u2581United", "\u2581States", "\u2581Constitution", ",", "\u2581which", "\u2581gr", "ants", "\u2581the", "\u2581President", "\u2581the", "\u2581power", "\u2581to", "\u2581\"", "take", "\u2581Care", "\u2581that", "\u2581the", "\u2581La", "ws", "\u2581be", "\u2581faith", "fully", "\u2581executed", ".\"", "\u2581Executive", "\u2581orders", "\u2581are", "\u2581a"]], "entropy": [[1.708984375, 0.4755859375, 1.5615234375, 0.003978729248046875, 0.0034923553466796875, 0.0027866363525390625, 1.3828125, 1.0048828125, 0.0091705322265625, 0.010467529296875, 0.006275177001953125, 0.266357421875, 0.00032019615173339844, 0.1802978515625, 0.67431640625, 0.27294921875, 0.05841064453125, 0.052490234375, 0.004199981689453125, 0.0028324127197265625, 0.09735107421875, 0.0089569091796875, 0.80126953125, 0.0028972625732421875, 0.003978729248046875, 0.9404296875, 0.0217437744140625, 1.146484375, 0.00012791156768798828, 0.1063232421875, 0.16357421875, 0.088623046875, 0.1134033203125, 0.004680633544921875, 0.74462890625, 0.1488037109375, 0.67578125, 0.0039520263671875, 0.0003695487976074219, 0.0215301513671875, 2.3365020751953125e-05, 0.0161285400390625, 0.001129150390625, 6.03795051574707e-05, 0.0023365020751953125, 0.1602783203125, 1.13671875, 0.029754638671875, 0.32568359375, 1.6318359375]], "avg_entropy": [0.3216198575496674], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Constitution", "score_of_biggest_cluster": 0.8143054842948914, "score_of_first_answer": 0.8143054842948914, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.189453125, "avg_score": 0.8143054842948914, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.23183811382760158, "std_of_first_answer": 0.23183811382760158, "avg_entropy_of_first_answer": 0.3216198575496674, "lex_sim": 1.0}
{"question": "when was son of a preacher man released", "answer": ["1998"], "scores": [[0.8251953125, 0.9912109375, 0.99951171875, 0.72314453125, 0.9423828125]], "normalized_score": [0.889595627784729], "tokens": [["\u2581", "1", "9", "9", "8"]], "entropy": [[0.98779296875, 0.052032470703125, 0.003162384033203125, 0.62548828125, 0.250244140625]], "avg_entropy": [0.3837440490722656], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "late 1968", "score_of_biggest_cluster": 0.889595627784729, "score_of_first_answer": 0.889595627784729, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.72314453125, "avg_score": 0.889595627784729, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.10660493693701856, "std_of_first_answer": 0.10660493693701856, "avg_entropy_of_first_answer": 0.3837440490722656, "lex_sim": 1.0}
{"question": "one piece english dubbed episode 564 release date", "answer": ["N/A - it has not been officially released."], "scores": [[0.0009598731994628906, 0.9951171875, 1.0, 0.0626220703125, 0.033660888671875, 0.55126953125, 0.97802734375, 0.951171875, 0.0290679931640625, 0.7705078125, 0.07354736328125, 0.0265350341796875, 0.421142578125, 0.76953125, 0.0158538818359375, 0.7041015625, 0.87158203125, 0.94775390625, 0.9609375, 0.9912109375, 0.962890625, 0.95263671875, 0.98291015625, 0.2021484375, 0.9990234375, 0.237060546875, 0.1368408203125, 0.51123046875, 0.9990234375, 1.0, 1.0, 0.90966796875, 0.12445068359375, 0.95166015625, 6.616115570068359e-06, 0.0015268325805664062, 0.0626220703125, 0.07928466796875, 0.00669097900390625, 0.046600341796875, 0.001644134521484375, 0.00023865699768066406, 8.45789909362793e-05, 0.0006866455078125, 0.662109375, 0.9912109375, 1.0, 0.9853515625]], "normalized_score": [0.12105555087327957], "tokens": [["\u2581N", "/", "A", "\u2581-", "\u2581it", "\u2581has", "\u2581not", "\u2581been", "\u2581officially", "\u2581released", ".", "\u2581The", "\u2581latest", "\u2581episode", ",", "\u2581", "5", "6", "3", ",", "\u2581was", "\u2581released", "\u2581on", "\u2581March", "\u2581", "1", "0", ",", "\u2581", "2", "0", "2", "1", ".", "\u2581#", "3", "5", "3", ":", "\u2581The", "\u2581G", "lass", "\u2581Castle", "\u2581by", "\u2581Je", "ann", "ette", "\u2581W"]], "entropy": [[2.3984375, 0.04132080078125, 0.0014848709106445312, 1.921875, 3.51171875, 1.3232421875, 0.13623046875, 0.2138671875, 0.398681640625, 0.63720703125, 1.142578125, 0.7333984375, 1.970703125, 0.974609375, 2.505859375, 1.2529296875, 0.401123046875, 0.29296875, 0.2283935546875, 0.058502197265625, 0.2205810546875, 0.28173828125, 0.11669921875, 2.482421875, 0.009918212890625, 1.447265625, 2.365234375, 0.6982421875, 0.0079193115234375, 0.0001951456069946289, 1.6748905181884766e-05, 0.302978515625, 0.8017578125, 0.28076171875, 0.5966796875, 3.193359375, 2.6796875, 2.833984375, 2.966796875, 4.8828125, 5.34375, 0.8837890625, 1.3798828125, 3.1796875, 1.3681640625, 0.0672607421875, 0.0025157928466796875, 0.1063232421875]], "avg_entropy": [1.2217823900282383], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "September 16, 2012", "score_of_biggest_cluster": 0.12105555087327957, "score_of_first_answer": 0.12105555087327957, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 6.616115570068359e-06, "avg_score": 0.12105555087327957, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43146729884923807, "std_of_first_answer": 0.43146729884923807, "avg_entropy_of_first_answer": 1.2217823900282383, "lex_sim": 1.0}
{"question": "nearest metro station to gandhi nagar in delhi", "answer": ["Kashmere Gate"], "scores": [[0.08343505859375, 0.1925048828125, 0.98876953125, 1.0, 0.9990234375]], "normalized_score": [0.43660852313041687], "tokens": [["\u2581K", "ash", "m", "ere", "\u2581Gate"]], "entropy": [[4.19921875, 1.478515625, 0.062042236328125, 0.0005812644958496094, 0.00655364990234375]], "avg_entropy": [1.1493823051452636], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Shastri Park metro station", "score_of_biggest_cluster": 0.43660852313041687, "score_of_first_answer": 0.43660852313041687, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.08343505859375, "avg_score": 0.43660852313041687, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4217444846692037, "std_of_first_answer": 0.4217444846692037, "avg_entropy_of_first_answer": 1.1493823051452636, "lex_sim": 1.0}
{"question": "who caused to build qutub minar in delhi", "answer": ["Qutub-ud-Din Aibak #505: How to Overcome Limiting Beliefs and Achieve Your Goals with Hal Elrod"], "scores": [[0.9306640625, 0.9990234375, 0.64453125, 0.97216796875, 0.998046875, 0.9990234375, 0.6650390625, 1.0, 0.99560546875, 0.99951171875, 0.9990234375, 0.0, 0.00348663330078125, 0.07769775390625, 0.06866455078125, 0.0005793571472167969, 0.003631591796875, 0.057037353515625, 0.0001239776611328125, 0.8671875, 0.005649566650390625, 0.273193359375, 0.990234375, 0.998046875, 0.99560546875, 0.5078125, 0.7109375, 0.99462890625, 0.10345458984375, 0.54541015625, 0.9912109375, 0.047210693359375, 0.00035572052001953125, 0.99755859375, 0.9970703125]], "normalized_score": [0.0], "tokens": [["\u2581Q", "ut", "ub", "-", "ud", "-", "D", "in", "\u2581A", "ib", "ak", "\u2581#", "5", "0", "5", ":", "\u2581How", "\u2581to", "\u2581Over", "come", "\u2581Lim", "iting", "\u2581Bel", "ief", "s", "\u2581and", "\u2581Ach", "ieve", "\u2581Your", "\u2581Go", "als", "\u2581with", "\u2581Hal", "\u2581El", "rod"]], "entropy": [[0.44091796875, 0.01116180419921875, 0.912109375, 0.1478271484375, 0.0144805908203125, 0.008209228515625, 0.6416015625, 0.000911712646484375, 0.03155517578125, 0.0033779144287109375, 0.00787353515625, 1.1826171875, 5.06640625, 3.404296875, 2.892578125, 2.701171875, 3.9921875, 3.546875, 5.265625, 0.70458984375, 4.84375, 0.83056640625, 0.09307861328125, 0.017303466796875, 0.0411376953125, 2.392578125, 1.7275390625, 0.041534423828125, 0.8828125, 0.9873046875, 0.06719970703125, 2.974609375, 4.64453125, 0.0181732177734375, 0.0234832763671875]], "avg_entropy": [1.4446278708321707], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Iltutmish", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4328154152531246, "std_of_first_answer": 0.4328154152531246, "avg_entropy_of_first_answer": 1.4446278708321707, "lex_sim": 1.0}
{"question": "what is the main industry in the canadian shield", "answer": ["The Canadian Shield is a vast area of exposed Precambrian bedrock that covers much of northern Canada."], "scores": [[0.1322021484375, 0.6943359375, 0.99462890625, 1.0, 0.6162109375, 0.5263671875, 0.08843994140625, 0.26904296875, 0.9970703125, 0.75537109375, 0.4453125, 1.0, 1.0, 1.0, 0.0013074874877929688, 1.0, 0.9248046875, 0.94482421875, 0.95947265625, 1.0, 0.4248046875, 0.82763671875, 0.8779296875, 0.71435546875, 0.91796875, 0.3037109375, 0.322509765625, 0.9990234375, 0.11566162109375, 0.9423828125, 0.06805419921875, 0.962890625, 1.0, 0.5380859375, 2.980232238769531e-07, 0.0092315673828125, 0.09014892578125, 0.06103515625, 2.3186206817626953e-05, 8.612871170043945e-05, 0.0007309913635253906, 0.381591796875, 0.0037384033203125, 0.052947998046875, 0.01641845703125, 0.0004303455352783203, 0.12109375, 0.075439453125]], "normalized_score": [0.11730533093214035], "tokens": [["\u2581The", "\u2581Canadian", "\u2581Sh", "ield", "\u2581is", "\u2581a", "\u2581vast", "\u2581area", "\u2581of", "\u2581exposed", "\u2581P", "rec", "amb", "rian", "\u2581bed", "rock", "\u2581that", "\u2581covers", "\u2581much", "\u2581of", "\u2581northern", "\u2581Canada", ".", "\u2581It", "\u2581is", "\u2581not", "\u2581known", "\u2581for", "\u2581having", "\u2581a", "\u2581single", "\u2581main", "\u2581industry", ".", "\u2581#", "8", "7", "0", "\u2581The", "\u2581F", "it", "ness", "\u2581Inst", "inct", ",", "\u2581E", "volution", "ary"]], "entropy": [[2.5, 0.71142578125, 0.03399658203125, 1.0728836059570312e-06, 1.1640625, 1.330078125, 0.43603515625, 1.7666015625, 0.0256195068359375, 0.9248046875, 1.6669921875, 1.1324882507324219e-06, 3.820657730102539e-05, 0.0008907318115234375, 0.24658203125, 0.0003705024719238281, 0.404052734375, 0.3212890625, 0.1866455078125, 0.00020766258239746094, 1.4560546875, 0.4873046875, 0.381591796875, 1.0576171875, 0.370849609375, 1.8388671875, 1.8095703125, 0.007152557373046875, 0.876953125, 0.239013671875, 1.236328125, 0.201416015625, 0.0025539398193359375, 0.99462890625, 2.185546875, 5.3046875, 2.859375, 2.47265625, 2.455078125, 1.751953125, 4.44921875, 2.634765625, 4.0546875, 0.264404296875, 1.7958984375, 4.17578125, 2.650390625, 2.5078125]], "avg_entropy": [1.296705258389314], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "mining", "score_of_biggest_cluster": 0.11730533093214035, "score_of_first_answer": 0.11730533093214035, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.980232238769531e-07, "avg_score": 0.11730533093214035, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4073980411072935, "std_of_first_answer": 0.4073980411072935, "avg_entropy_of_first_answer": 1.296705258389314, "lex_sim": 1.0}
{"question": "where does the last name waters come from", "answer": ["it can be of English origin, derived from the Old English word w\u00e6ter, meaning \"water\"."], "scores": [[0.05682373046875, 0.050201416015625, 0.2471923828125, 0.47216796875, 0.494873046875, 0.5537109375, 0.361083984375, 0.5830078125, 0.99951171875, 0.77734375, 0.41259765625, 0.9658203125, 0.35107421875, 0.0509033203125, 0.9345703125, 0.59228515625, 0.8046875, 0.89892578125, 0.98876953125, 0.9970703125, 0.143310546875, 0.301025390625, 0.52392578125, 0.99951171875, 0.859375, 0.88330078125, 0.179443359375, 0.8896484375, 0.9716796875, 0.9365234375, 0.99853515625, 0.97509765625, 0.83544921875, 1.0, 1.0, 0.11724853515625, 0.018646240234375, 0.136474609375, 0.57421875, 0.80615234375, 0.9384765625, 0.9990234375, 0.97119140625, 0.99658203125, 0.9990234375, 0.87353515625, 0.1866455078125, 0.99853515625, 0.7041015625]], "normalized_score": [0.4961819052696228], "tokens": [["\u2581it", "\u2581can", "\u2581be", "\u2581of", "\u2581English", "\u2581origin", ",", "\u2581derived", "\u2581from", "\u2581the", "\u2581Old", "\u2581English", "\u2581word", "\u2581w", "\u00e6", "ter", ",", "\u2581meaning", "\u2581\"", "water", "\".", "\u2581It", "\u2581can", "\u2581also", "\u2581be", "\u2581of", "\u2581Irish", "\u2581origin", ",", "\u2581derived", "\u2581from", "\u2581the", "\u2581G", "ael", "ic", "\u2581\u00d3", "\u2581F", "ath", "arta", ",", "\u2581meaning", "\u2581\"", "desc", "endant", "\u2581of", "\u2581the", "\u2581phys", "ician", "\"."]], "entropy": [[3.369140625, 1.2666015625, 1.130859375, 1.6015625, 1.68359375, 1.0703125, 1.3486328125, 1.7939453125, 0.004390716552734375, 0.810546875, 1.9931640625, 0.1517333984375, 1.482421875, 0.31982421875, 0.438232421875, 0.79833984375, 0.8154296875, 0.3544921875, 0.0712890625, 0.0223388671875, 1.5908203125, 1.4697265625, 1.0703125, 0.00331878662109375, 0.515625, 0.52880859375, 1.03125, 0.463623046875, 0.1629638671875, 0.37109375, 0.0114593505859375, 0.1494140625, 0.62646484375, 0.00023484230041503906, 0.00020813941955566406, 1.8662109375, 2.83203125, 2.888671875, 1.3095703125, 0.6953125, 0.25732421875, 0.00986480712890625, 0.2117919921875, 0.0245513916015625, 0.006591796875, 0.412109375, 4.1953125, 0.01275634765625, 0.6865234375]], "avg_entropy": [0.8965468990559481], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Wales and Yorkshire", "score_of_biggest_cluster": 0.4961819052696228, "score_of_first_answer": 0.4961819052696228, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.018646240234375, "avg_score": 0.4961819052696228, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.34016438231877644, "std_of_first_answer": 0.34016438231877644, "avg_entropy_of_first_answer": 0.8965468990559481, "lex_sim": 1.0}
{"question": "who has won the most superbowls as a player", "answer": ["Tom Brady (6)"], "scores": [[0.69580078125, 1.0, 1.0, 0.14501953125, 0.8486328125, 0.64013671875]], "normalized_score": [0.6163356900215149], "tokens": [["\u2581Tom", "\u2581Br", "ady", "\u2581(", "6", ")"]], "entropy": [[0.94677734375, 0.000415802001953125, 1.4662742614746094e-05, 1.484375, 0.73095703125, 0.97802734375]], "avg_entropy": [0.690094530582428], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Charles Haley", "score_of_biggest_cluster": 0.6163356900215149, "score_of_first_answer": 0.6163356900215149, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.14501953125, "avg_score": 0.6163356900215149, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2918039748011683, "std_of_first_answer": 0.2918039748011683, "avg_entropy_of_first_answer": 0.690094530582428, "lex_sim": 1.0}
{"question": "who is the head of parliament in uk", "answer": ["Speaker of the House of Commons"], "scores": [[0.137939453125, 1.0, 0.99267578125, 0.99951171875, 0.99462890625, 0.98974609375, 0.99658203125]], "normalized_score": [0.7506300806999207], "tokens": [["\u2581Spe", "aker", "\u2581of", "\u2581the", "\u2581House", "\u2581of", "\u2581Commons"]], "entropy": [[1.396484375, 0.0008606910705566406, 0.04901123046875, 0.004474639892578125, 0.039459228515625, 0.06640625, 0.02587890625]], "avg_entropy": [0.22608218874250138], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "The Lord Fowler", "score_of_biggest_cluster": 0.7506300806999207, "score_of_first_answer": 0.7506300806999207, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.137939453125, "avg_score": 0.7506300806999207, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3001109970500812, "std_of_first_answer": 0.3001109970500812, "avg_entropy_of_first_answer": 0.22608218874250138, "lex_sim": 1.0}
{"question": "a legislative act passed by congress is an example of", "answer": ["law #WonderWomenEverywhere: Happy International Women\u2019s Day!"], "scores": [[0.1558837890625, 1.6093254089355469e-06, 0.0007901191711425781, 0.0006947517395019531, 0.027435302734375, 0.2578125, 9.638071060180664e-05, 0.84423828125, 0.0007424354553222656, 0.00014650821685791016, 0.497314453125, 0.9169921875, 0.0567626953125, 1.0, 0.99072265625, 0.87646484375]], "normalized_score": [0.018533460795879364], "tokens": [["\u2581law", "\u2581#", "W", "onder", "W", "omen", "Every", "where", ":", "\u2581Happy", "\u2581International", "\u2581Women", "\u2019", "s", "\u2581Day", "!"]], "entropy": [[2.025390625, 1.060546875, 4.27734375, 4.15234375, 4.13671875, 0.978515625, 1.84765625, 0.5498046875, 0.998046875, 3.8203125, 1.5244140625, 0.410888671875, 0.306640625, 0.0004420280456542969, 0.06396484375, 0.60791015625]], "avg_entropy": [1.672558754682541], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "statutory law", "score_of_biggest_cluster": 0.018533460795879364, "score_of_first_answer": 0.018533460795879364, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.6093254089355469e-06, "avg_score": 0.018533460795879364, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40828058026840863, "std_of_first_answer": 0.40828058026840863, "avg_entropy_of_first_answer": 1.672558754682541, "lex_sim": 1.0}
{"question": "when was the last time it snowed in england on christmas day", "answer": ["2010"], "scores": [[0.7421875, 0.99267578125, 0.99658203125, 0.99365234375, 0.9970703125]], "normalized_score": [0.9383370876312256], "tokens": [["\u2581", "2", "0", "1", "0"]], "entropy": [[1.2041015625, 0.04425048828125, 0.02569580078125, 0.039520263671875, 0.0238494873046875]], "avg_entropy": [0.2674835205078125], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2009", "score_of_biggest_cluster": 0.9383370876312256, "score_of_first_answer": 0.9383370876312256, "max_score_of_first_answer": 0.9970703125, "min_score_of_first_answer": 0.7421875, "avg_score": 0.9383370876312256, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.10113689745878054, "std_of_first_answer": 0.10113689745878054, "avg_entropy_of_first_answer": 0.2674835205078125, "lex_sim": 1.0}
{"question": "who has won the most games in nfl 2017", "answer": ["Tom Brady #MondayBlog 10 WAYS TO SAVE MONEY ON YOUR UTILITY BILLS"], "scores": [[0.85107421875, 0.99951171875, 1.0, 1.615285873413086e-05, 0.0017538070678710938, 0.0024585723876953125, 0.990234375, 1.6868114471435547e-05, 1.1920928955078125e-07, 0.01316070556640625, 0.043914794921875, 0.25341796875, 0.00046062469482421875, 0.004730224609375, 0.99951171875, 0.85791015625, 0.049041748046875, 0.1566162109375, 0.99853515625, 0.7939453125, 0.99853515625, 0.99951171875, 0.289794921875, 0.262451171875, 0.99365234375, 0.0234375, 0.9931640625, 1.0, 0.94873046875, 0.9921875, 0.9990234375, 0.93310546875]], "normalized_score": [0.07224176079034805], "tokens": [["\u2581Tom", "\u2581Br", "ady", "\u2581#", "M", "ond", "ay", "B", "log", "\u2581", "1", "0", "\u2581W", "A", "YS", "\u2581TO", "\u2581S", "AV", "E", "\u2581M", "ONE", "Y", "\u2581ON", "\u2581Y", "OUR", "\u2581U", "T", "IL", "ITY", "\u2581B", "ILL", "S"]], "entropy": [[0.91357421875, 0.005985260009765625, 6.717443466186523e-05, 1.5166015625, 3.103515625, 2.0078125, 0.06353759765625, 0.38720703125, 0.0526123046875, 2.578125, 1.9072265625, 2.673828125, 1.890625, 1.0009765625, 0.003692626953125, 0.99951171875, 3.23046875, 1.361328125, 0.01206207275390625, 1.1826171875, 0.01517486572265625, 0.0045623779296875, 3.41015625, 2.6640625, 0.04638671875, 3.416015625, 0.060302734375, 0.0023441314697265625, 0.21826171875, 0.057098388671875, 0.01052093505859375, 0.51220703125]], "avg_entropy": [1.1033896338194609], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Dallas Cowboys", "score_of_biggest_cluster": 0.07224176079034805, "score_of_first_answer": 0.07224176079034805, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.07224176079034805, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.45140563807966066, "std_of_first_answer": 0.45140563807966066, "avg_entropy_of_first_answer": 1.1033896338194609, "lex_sim": 1.0}
{"question": "where does puerto rico's power come from", "answer": ["a variety of sources including thermal, hydroelectric, wind, and fossil fuels"], "scores": [[0.07562255859375, 0.1273193359375, 0.99951171875, 0.9833984375, 0.5908203125, 0.0777587890625, 0.99072265625, 0.82470703125, 0.214599609375, 1.0, 0.98291015625, 0.75, 0.71142578125, 0.8916015625, 0.032745361328125, 1.0, 0.83447265625, 1.0]], "normalized_score": [0.4634816646575928], "tokens": [["\u2581a", "\u2581variety", "\u2581of", "\u2581sources", "\u2581including", "\u2581thermal", ",", "\u2581hydro", "elect", "ric", ",", "\u2581wind", ",", "\u2581and", "\u2581foss", "il", "\u2581fu", "els"]], "entropy": [[1.896484375, 1.0126953125, 0.006053924560546875, 0.098876953125, 0.85986328125, 1.4521484375, 0.0628662109375, 0.51953125, 0.52490234375, 0.00028586387634277344, 0.092529296875, 0.69091796875, 0.611328125, 0.456298828125, 2.134765625, 0.00028777122497558594, 0.494384765625, 0.00010138750076293945]], "avg_entropy": [0.6063512067000071], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Puerto Rico Electric Power Authority", "score_of_biggest_cluster": 0.4634816646575928, "score_of_first_answer": 0.4634816646575928, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.032745361328125, "avg_score": 0.4634816646575928, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3697392288056766, "std_of_first_answer": 0.3697392288056766, "avg_entropy_of_first_answer": 0.6063512067000071, "lex_sim": 1.0}
{"question": "what's the nba record for most points in a half", "answer": ["81 by Kareem Abdul-Jabbar"], "scores": [[0.85693359375, 0.258544921875, 0.1424560546875, 0.195068359375, 0.8583984375, 0.043121337890625, 0.99951171875, 0.99951171875, 1.0, 0.99658203125, 1.0, 0.99853515625, 0.99951171875]], "normalized_score": [0.5243403315544128], "tokens": [["\u2581", "8", "1", "\u2581by", "\u2581K", "are", "em", "\u2581Abd", "ul", "-", "J", "ab", "bar"]], "entropy": [[0.65283203125, 1.6318359375, 1.1884765625, 1.5380859375, 0.78271484375, 0.214111328125, 0.006229400634765625, 0.00579833984375, 7.075071334838867e-05, 0.0247039794921875, 0.0015869140625, 0.0129547119140625, 0.00310516357421875]], "avg_entropy": [0.46634660775844866], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "59", "score_of_biggest_cluster": 0.5243403315544128, "score_of_first_answer": 0.5243403315544128, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.043121337890625, "avg_score": 0.5243403315544128, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.37859759284076405, "std_of_first_answer": 0.37859759284076405, "avg_entropy_of_first_answer": 0.46634660775844866, "lex_sim": 1.0}
{"question": "who expanded the territory of china during the qing dynasty", "answer": ["Qianlong Emperor CHAPTERS - GENERAL INFORMATION"], "scores": [[0.93994140625, 0.97412109375, 0.998046875, 0.48046875, 0.0, 0.030975341796875, 0.0014047622680664062, 0.0040435791015625, 0.1868896484375, 0.92626953125, 0.8974609375, 0.01403045654296875, 0.9697265625, 0.99658203125]], "normalized_score": [0.0], "tokens": [["\u2581Q", "ian", "long", "\u2581Emperor", "\u2581CHAPTER", "S", "\u2581-", "\u2581G", "EN", "ER", "AL", "\u2581IN", "FORM", "ATION"]], "entropy": [[0.377197265625, 0.12237548828125, 0.0157623291015625, 1.3486328125, 1.275390625, 3.041015625, 1.4501953125, 5.2109375, 3.150390625, 0.43505859375, 0.4697265625, 1.3310546875, 0.1904296875, 0.0252532958984375]], "avg_entropy": [1.3173871721540178], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Qianlong", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.998046875, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4439956581659014, "std_of_first_answer": 0.4439956581659014, "avg_entropy_of_first_answer": 1.3173871721540178, "lex_sim": 1.0}
{"question": "when was the last time stock market crashed", "answer": ["The last major stock market crash occurred in 2008-2009 as a result of the subprime mortgage crisis."], "scores": [[0.34130859375, 0.20361328125, 0.82275390625, 0.99560546875, 1.0, 1.0, 0.353271484375, 0.77392578125, 0.9716796875, 0.99951171875, 1.0, 1.0, 0.9970703125, 0.00879669189453125, 0.99755859375, 1.0, 1.0, 0.99951171875, 0.1475830078125, 0.8134765625, 0.955078125, 0.99951171875, 0.970703125, 0.470703125, 0.986328125, 0.99951171875, 0.9990234375, 1.0, 0.9794921875, 0.6220703125, 0.02313232421875, 0.0015325546264648438, 0.99951171875, 1.0, 0.984375, 0.0, 0.8662109375, 0.876953125, 1.0, 0.9990234375, 0.64892578125, 0.9970703125, 0.0083465576171875, 0.8798828125, 1.0, 0.0889892578125, 0.0175323486328125, 0.99951171875]], "normalized_score": [0.0], "tokens": [["\u2581The", "\u2581last", "\u2581major", "\u2581stock", "\u2581market", "\u2581crash", "\u2581occurred", "\u2581in", "\u2581", "2", "0", "0", "8", "-", "2", "0", "0", "9", "\u2581as", "\u2581a", "\u2581result", "\u2581of", "\u2581the", "\u2581sub", "prime", "\u2581mort", "g", "age", "\u2581crisis", ".", "\u2581The", "\u2581U", ".", "S", ".", "\u2581Court", "\u2581of", "\u2581App", "e", "als", "\u2581for", "\u2581the", "\u2581Federal", "\u2581Circ", "uit", "\u2581has", "\u2581aff", "ir"]], "entropy": [[1.7216796875, 1.046875, 0.69580078125, 0.035247802734375, 0.00040602684020996094, 0.0011415481567382812, 1.0888671875, 0.560546875, 0.1688232421875, 0.0029392242431640625, 4.0531158447265625e-06, 0.00027179718017578125, 0.0206756591796875, 1.5048828125, 0.0185394287109375, 0.0023555755615234375, 0.0006337165832519531, 0.0023708343505859375, 1.4013671875, 0.517578125, 0.1834716796875, 0.0059661865234375, 0.156494140625, 1.3759765625, 0.07342529296875, 0.004726409912109375, 0.006778717041015625, 2.8073787689208984e-05, 0.12548828125, 0.873046875, 0.83544921875, 1.7802734375, 0.0031871795654296875, 0.0016803741455078125, 0.0965576171875, 1.220703125, 0.9658203125, 0.58349609375, 0.0010137557983398438, 0.00921630859375, 1.9150390625, 0.0286102294921875, 1.5283203125, 0.413818359375, 0.00010985136032104492, 3.5859375, 3.201171875, 0.0053863525390625]], "avg_entropy": [0.578587494790554], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "27 Oct 1997", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.36910737698165735, "std_of_first_answer": 0.36910737698165735, "avg_entropy_of_first_answer": 0.578587494790554, "lex_sim": 1.0}
{"question": "who got the first nobel prize in physics", "answer": ["Wilhelm Conrad R\u00f6ntgen **IMPORTANT: Please note, this application is a sample provided by AWS and is not an official AWS application."], "scores": [[0.85302734375, 0.9814453125, 1.0, 0.84716796875, 0.99658203125, 1.0, 5.960464477539062e-07, 0.0010614395141601562, 0.6376953125, 0.96826171875, 0.99658203125, 0.63232421875, 0.2001953125, 0.6806640625, 0.1024169921875, 0.21044921875, 1.3709068298339844e-06, 0.47021484375, 0.08343505859375, 0.0007066726684570312, 0.01198577880859375, 0.472412109375, 0.020294189453125, 0.3173828125, 0.33837890625, 0.73681640625, 0.275634765625, 0.248779296875, 0.73486328125, 0.253173828125, 0.89013671875, 0.089111328125, 0.12420654296875, 0.097900390625, 1.0, 0.81005859375, 0.99755859375, 0.67626953125, 0.0022144317626953125, 0.74609375, 1.0, 0.1693115234375, 0.011444091796875, 0.0149078369140625, 0.99951171875, 0.9814453125, 0.97607421875, 0.7900390625]], "normalized_score": [0.144213005900383], "tokens": [["\u2581Wilhelm", "\u2581Con", "rad", "\u2581R\u00f6", "nt", "gen", "\u2581**", "I", "MP", "ORT", "ANT", ":", "\u2581Please", "\u2581note", ",", "\u2581this", "\u2581application", "\u2581is", "\u2581a", "\u2581sample", "\u2581provided", "\u2581by", "\u2581AWS", "\u2581and", "\u2581is", "\u2581not", "\u2581an", "\u2581official", "\u2581AWS", "\u2581application", ".", "\u2581For", "\u2581a", "\u2581compreh", "ensive", "\u2581list", "\u2581of", "\u2581AWS", "\u2581service", "\u2581offer", "ings", "\u2581and", "\u2581supported", "\u2581functional", "ities", ",", "\u2581please", "\u2581refer"]], "entropy": [[0.791015625, 0.11468505859375, 0.0008683204650878906, 0.45654296875, 0.024932861328125, 0.00084686279296875, 0.916015625, 4.75390625, 2.041015625, 0.176513671875, 0.0296173095703125, 1.138671875, 3.462890625, 1.869140625, 0.5048828125, 1.87109375, 1.779296875, 2.310546875, 2.7109375, 3.7421875, 3.310546875, 1.345703125, 3.0234375, 2.2890625, 2.642578125, 1.2900390625, 2.1640625, 1.88671875, 1.1435546875, 1.3447265625, 0.456787109375, 3.013671875, 2.107421875, 1.689453125, 0.0006914138793945312, 0.9736328125, 0.0200653076171875, 1.4892578125, 2.83984375, 1.869140625, 0.0001806020736694336, 0.72802734375, 3.51171875, 2.17578125, 0.006740570068359375, 0.1326904296875, 0.156494140625, 0.6396484375]], "avg_entropy": [1.4780684486031532], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Wilhelm Conrad R\u00f6ntgen", "score_of_biggest_cluster": 0.144213005900383, "score_of_first_answer": 0.144213005900383, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539062e-07, "avg_score": 0.144213005900383, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.38878497247688426, "std_of_first_answer": 0.38878497247688426, "avg_entropy_of_first_answer": 1.4780684486031532, "lex_sim": 1.0}
{"question": "when did the first battle of ypres end", "answer": ["November 11, 1914"], "scores": [[0.8642578125, 0.99267578125, 0.9814453125, 0.470947265625, 0.798828125, 0.9970703125, 0.99951171875, 1.0, 0.99951171875, 0.99951171875]], "normalized_score": [0.8910112380981445], "tokens": [["\u2581November", "\u2581", "1", "1", ",", "\u2581", "1", "9", "1", "4"]], "entropy": [[0.5, 0.0452880859375, 0.10693359375, 1.32421875, 0.61572265625, 0.019683837890625, 0.00438690185546875, 2.3543834686279297e-05, 0.00457763671875, 0.004932403564453125]], "avg_entropy": [0.2625767409801483], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "22 November 1914", "score_of_biggest_cluster": 0.8910112380981445, "score_of_first_answer": 0.8910112380981445, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.470947265625, "avg_score": 0.8910112380981445, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.16089606075656887, "std_of_first_answer": 0.16089606075656887, "avg_entropy_of_first_answer": 0.2625767409801483, "lex_sim": 1.0}
{"question": "cast of the movie pride of the marines", "answer": ["John Corbett, Rosie Perez, Ralph Waite #009: How to Become a Confident Speaker and Overcome Stage Fright"], "scores": [[0.52392578125, 0.0015668869018554688, 0.99951171875, 1.0, 0.9111328125, 0.1802978515625, 0.900390625, 0.962890625, 0.99951171875, 0.94091796875, 0.01515960693359375, 0.98876953125, 0.99951171875, 5.960464477539063e-08, 0.0015583038330078125, 0.14111328125, 0.07757568359375, 0.00214385986328125, 0.0013561248779296875, 0.112060546875, 0.03924560546875, 0.051727294921875, 0.6494140625, 4.774332046508789e-05, 0.97998046875, 0.55712890625, 0.99951171875, 0.09820556640625, 0.0246429443359375, 0.99658203125, 0.16064453125, 0.99658203125, 0.998046875]], "normalized_score": [0.08612062782049179], "tokens": [["\u2581John", "\u2581Cor", "b", "ett", ",", "\u2581Ros", "ie", "\u2581Pere", "z", ",", "\u2581Ralph", "\u2581Wa", "ite", "\u2581#", "0", "0", "9", ":", "\u2581How", "\u2581to", "\u2581Be", "come", "\u2581a", "\u2581Conf", "ident", "\u2581Spe", "aker", "\u2581and", "\u2581Over", "come", "\u2581Stage", "\u2581F", "right"]], "entropy": [[2.498046875, 1.8837890625, 0.004032135009765625, 0.00017511844635009766, 0.435791015625, 3.490234375, 0.52099609375, 0.2281494140625, 0.00405120849609375, 0.28076171875, 4.59375, 0.09906005859375, 0.0029964447021484375, 0.83154296875, 5.671875, 3.611328125, 2.63671875, 3.244140625, 5.7421875, 3.595703125, 4.046875, 1.8994140625, 1.466796875, 4.29296875, 0.11322021484375, 1.39453125, 0.0026683807373046875, 2.6015625, 3.697265625, 0.024444580078125, 1.443359375, 0.03033447265625, 0.0154571533203125]], "avg_entropy": [1.8304311470551924], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "John Garfield as Al Schmid", "score_of_biggest_cluster": 0.08612062782049179, "score_of_first_answer": 0.08612062782049179, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.08612062782049179, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44127320555714045, "std_of_first_answer": 0.44127320555714045, "avg_entropy_of_first_answer": 1.8304311470551924, "lex_sim": 1.0}
{"question": "who plays the mother of howard on big bang theory", "answer": ["Simon Helberg"], "scores": [[0.0589599609375, 0.994140625, 1.0]], "normalized_score": [0.38844990730285645], "tokens": [["\u2581Simon", "\u2581Hel", "berg"]], "entropy": [[2.142578125, 0.0511474609375, 0.001346588134765625]], "avg_entropy": [0.7316907246907552], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Carol Ann Susi", "score_of_biggest_cluster": 0.38844990730285645, "score_of_first_answer": 0.38844990730285645, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0589599609375, "avg_score": 0.38844990730285645, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.44223593022409313, "std_of_first_answer": 0.44223593022409313, "avg_entropy_of_first_answer": 0.7316907246907552, "lex_sim": 1.0}
{"question": "where is final four being held this year", "answer": ["I'm sorry, my knowledge cutoff is September 2021 and I don't have information on future events."], "scores": [[0.5703125, 0.55908203125, 0.99951171875, 0.9853515625, 0.97998046875, 0.076904296875, 0.72216796875, 0.97216796875, 0.492431640625, 0.9560546875, 0.04095458984375, 0.99658203125, 0.99951171875, 0.9990234375, 1.0, 0.99951171875, 0.399169921875, 0.978515625, 0.47021484375, 0.9970703125, 1.0, 0.9365234375, 0.81298828125, 0.281494140625, 0.54345703125, 0.9990234375, 0.9375, 0.029296875, 0.58056640625, 0.798828125, 0.343505859375, 0.65185546875, 0.93115234375, 0.7841796875, 0.9990234375, 0.0251007080078125, 0.011474609375, 0.442138671875, 0.65625, 0.79541015625, 0.052490234375, 0.9892578125, 0.145751953125, 0.037353515625, 0.99755859375, 1.0, 0.84765625, 0.2861328125]], "normalized_score": [0.45989832282066345], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581my", "\u2581knowledge", "\u2581cut", "off", "\u2581is", "\u2581September", "\u2581", "2", "0", "2", "1", "\u2581and", "\u2581I", "\u2581don", "'", "t", "\u2581have", "\u2581information", "\u2581on", "\u2581future", "\u2581events", ".", "\u2581I", "\u2581suggest", "\u2581checking", "\u2581the", "\u2581official", "\u2581website", "\u2581of", "\u2581the", "\u2581NCAA", ",", "\u2581the", "\u2581organization", "\u2581that", "\u2581runs", "\u2581the", "\u2581NCAA", "\u2581March", "\u2581Mad", "ness", "\u2581tournament", "."]], "entropy": [[2.140625, 1.2509765625, 0.004039764404296875, 0.09344482421875, 0.11224365234375, 1.1201171875, 0.77099609375, 0.1619873046875, 1.07421875, 0.2137451171875, 0.759765625, 0.02734375, 0.00363922119140625, 0.00986480712890625, 0.002288818359375, 0.0031299591064453125, 0.9228515625, 0.1497802734375, 1.0751953125, 0.0224456787109375, 0.00024008750915527344, 0.2406005859375, 0.75927734375, 0.72265625, 1.34375, 0.01114654541015625, 0.3525390625, 1.46484375, 1.11328125, 0.6748046875, 1.921875, 1.060546875, 0.3740234375, 0.60498046875, 0.008270263671875, 1.8857421875, 1.1748046875, 1.384765625, 0.9970703125, 0.64990234375, 0.81298828125, 0.06903076171875, 1.990234375, 0.943359375, 0.0172271728515625, 0.00048613548278808594, 0.6484375, 0.802734375]], "avg_entropy": [0.6655899584293365], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the Alamodome", "score_of_biggest_cluster": 0.45989832282066345, "score_of_first_answer": 0.45989832282066345, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.011474609375, "avg_score": 0.45989832282066345, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3502087375427393, "std_of_first_answer": 0.3502087375427393, "avg_entropy_of_first_answer": 0.6655899584293365, "lex_sim": 1.0}
{"question": "different ways to say bless you in french", "answer": ["1. Que Dieu vous b\u00e9nisse"], "scores": [[0.1610107421875, 0.99365234375, 0.9921875, 0.14453125, 0.96923828125, 0.95947265625, 0.89306640625, 0.99853515625, 1.0]], "normalized_score": [0.6438982486724854], "tokens": [["\u2581", "1", ".", "\u2581Que", "\u2581Dieu", "\u2581vous", "\u2581b", "\u00e9n", "isse"]], "entropy": [[3.3125, 0.054107666015625, 0.054473876953125, 1.6083984375, 0.1937255859375, 0.1871337890625, 0.435791015625, 0.01352691650390625, 0.0014886856079101562]], "avg_entropy": [0.6512384414672852], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "\u00e0 tes / vos souhaits", "score_of_biggest_cluster": 0.6438982486724854, "score_of_first_answer": 0.6438982486724854, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.14453125, "avg_score": 0.6438982486724854, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3421611178536393, "std_of_first_answer": 0.3421611178536393, "avg_entropy_of_first_answer": 0.6512384414672852, "lex_sim": 1.0}
{"question": "when does the eclipse end in the us", "answer": ["The lunar eclipse ended on August 27, 2026."], "scores": [[0.462158203125, 0.0129241943359375, 1.0, 0.99755859375, 0.221923828125, 0.55419921875, 0.042449951171875, 0.9990234375, 0.420654296875, 0.147705078125, 0.74560546875, 0.99560546875, 0.982421875, 0.99951171875, 0.9423828125, 0.274658203125, 0.3486328125, 5.245208740234375e-06, 0.034332275390625, 0.04730224609375, 0.0888671875, 0.091796875, 0.0028514862060546875, 0.0082855224609375, 0.00281524658203125, 0.0008740425109863281, 0.92626953125, 0.042327880859375, 0.65087890625, 0.9951171875, 0.9599609375, 0.08740234375, 0.9951171875, 0.1942138671875, 0.489013671875, 0.63818359375, 0.9970703125, 0.004058837890625, 0.01284027099609375, 0.05181884765625, 0.96337890625, 0.0164337158203125, 0.98779296875, 0.006931304931640625, 0.01137542724609375]], "normalized_score": [0.1127215027809143], "tokens": [["\u2581The", "\u2581lun", "ar", "\u2581eclipse", "\u2581ended", "\u2581on", "\u2581August", "\u2581", "2", "7", ",", "\u2581", "2", "0", "2", "6", ".", "\u2581#", "1", "5", "4", "4", ":", "\u2581How", "\u2581To", "\u2581Over", "come", "\u2581The", "\u2581F", "ear", "\u2581Of", "\u2581Re", "jection", "\u2581And", "\u2581Build", "\u2581Conf", "idence", "\u2581by", "\u2581J", "\u00fcrgen", "\u2581Sch", "mit", "z", "\u2581", "0"]], "entropy": [[2.173828125, 1.8466796875, 0.0001747608184814453, 0.0217742919921875, 2.234375, 0.890625, 1.60546875, 0.007045745849609375, 1.52734375, 0.7587890625, 0.6123046875, 0.032928466796875, 0.08966064453125, 0.0034942626953125, 0.2364501953125, 0.71923828125, 1.3857421875, 0.96728515625, 4.5859375, 2.75390625, 2.59375, 2.421875, 2.5390625, 4.93359375, 2.01953125, 4.94921875, 0.392822265625, 3.8828125, 2.337890625, 0.039459228515625, 0.195556640625, 2.75390625, 0.043792724609375, 2.974609375, 2.232421875, 1.4931640625, 0.023895263671875, 2.849609375, 5.33984375, 3.779296875, 0.264404296875, 3.216796875, 0.07080078125, 2.69140625, 1.3427734375]], "avg_entropy": [1.7296743445926241], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2:44\u00a0p.m. EDT", "score_of_biggest_cluster": 0.1127215027809143, "score_of_first_answer": 0.1127215027809143, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.245208740234375e-06, "avg_score": 0.1127215027809143, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.41493824201007484, "std_of_first_answer": 0.41493824201007484, "avg_entropy_of_first_answer": 1.7296743445926241, "lex_sim": 1.0}
{"question": "to aru kagaku no railgun s episode 3", "answer": ["It seems like you are trying to refer to a specific episode of the anime series \"A Certain Scientific Railgun S.\" However, as an AI research assistant, I cannot provide specific episode numbers or titles as I am not able to"], "scores": [[0.00858306884765625, 0.0806884765625, 0.7958984375, 0.78125, 0.461181640625, 0.3466796875, 0.9990234375, 0.1778564453125, 0.9990234375, 0.08477783203125, 0.8955078125, 0.9833984375, 0.85595703125, 0.42626953125, 0.9892578125, 1.0, 0.164794921875, 0.8720703125, 0.74853515625, 0.99560546875, 1.0, 0.99853515625, 1.0, 0.974609375, 1.0, 1.0, 0.26611328125, 0.607421875, 0.99853515625, 0.24658203125, 0.8798828125, 0.998046875, 1.0, 0.2081298828125, 0.98486328125, 0.99658203125, 0.88037109375, 0.1583251953125, 0.544921875, 0.053558349609375, 0.53271484375, 0.458251953125, 0.677734375, 0.56982421875, 0.5703125, 0.33447265625, 0.4423828125, 0.8095703125, 0.399169921875, 0.998046875]], "normalized_score": [0.5106914639472961], "tokens": [["\u2581It", "\u2581seems", "\u2581like", "\u2581you", "\u2581are", "\u2581trying", "\u2581to", "\u2581refer", "\u2581to", "\u2581a", "\u2581specific", "\u2581episode", "\u2581of", "\u2581the", "\u2581an", "ime", "\u2581series", "\u2581\"", "A", "\u2581C", "ertain", "\u2581Scient", "ific", "\u2581Rail", "gun", "\u2581S", ".\"", "\u2581However", ",", "\u2581as", "\u2581an", "\u2581A", "I", "\u2581research", "\u2581assistant", ",", "\u2581I", "\u2581cannot", "\u2581provide", "\u2581specific", "\u2581episode", "\u2581numbers", "\u2581or", "\u2581titles", "\u2581as", "\u2581I", "\u2581am", "\u2581not", "\u2581able", "\u2581to"]], "entropy": [[1.642578125, 1.8642578125, 0.6689453125, 0.69140625, 1.4580078125, 1.6513671875, 0.007434844970703125, 2.43359375, 0.007579803466796875, 0.49755859375, 0.4306640625, 0.10595703125, 0.52099609375, 1.2197265625, 0.07879638671875, 0.0001544952392578125, 0.6826171875, 0.54638671875, 0.57421875, 0.0411376953125, 0.0014944076538085938, 0.0115509033203125, 0.00055694580078125, 0.1263427734375, 0.0006265640258789062, 0.0026416778564453125, 0.951171875, 1.69921875, 0.01120758056640625, 2.119140625, 0.455322265625, 0.017486572265625, 0.0006513595581054688, 0.7060546875, 0.08355712890625, 0.0284423828125, 0.387451171875, 1.3984375, 2.015625, 2.384765625, 1.216796875, 1.251953125, 1.095703125, 2.0, 1.4521484375, 1.279296875, 1.150390625, 0.8759765625, 1.9638671875, 0.01467132568359375]], "avg_entropy": [0.7965186882019043], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Project Radio Noise", "score_of_biggest_cluster": 0.5106914639472961, "score_of_first_answer": 0.5106914639472961, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.00858306884765625, "avg_score": 0.5106914639472961, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3329802951871265, "std_of_first_answer": 0.3329802951871265, "avg_entropy_of_first_answer": 0.7965186882019043, "lex_sim": 1.0}
{"question": "how old was sasuke when his clan died", "answer": ["13"], "scores": [[0.390625, 0.08819580078125, 0.8232421875]], "normalized_score": [0.3049616515636444], "tokens": [["\u2581", "1", "3"]], "entropy": [[2.54296875, 0.82861328125, 0.69140625]], "avg_entropy": [1.3543294270833333], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "seven", "score_of_biggest_cluster": 0.3049616515636444, "score_of_first_answer": 0.3049616515636444, "max_score_of_first_answer": 0.8232421875, "min_score_of_first_answer": 0.08819580078125, "avg_score": 0.3049616515636444, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.30164626857164906, "std_of_first_answer": 0.30164626857164906, "avg_entropy_of_first_answer": 1.3543294270833333, "lex_sim": 1.0}
{"question": "who is the sixth president of the united states", "answer": ["John Quincy Adams #MeToo movement inspiring men to re-evaluate their behaviour: Shakti Kapoor"], "scores": [[0.9755859375, 0.99951171875, 1.0, 1.0, 0.99853515625, 1.3113021850585938e-06, 0.00020873546600341797, 0.67236328125, 0.99951171875, 0.01445770263671875, 0.00011026859283447266, 0.1529541015625, 0.0249176025390625, 0.77734375, 0.0109710693359375, 0.46337890625, 0.435302734375, 0.99853515625, 0.67529296875, 0.0173187255859375, 0.0027103424072265625, 0.00039076805114746094, 0.00919342041015625, 0.36279296875, 0.367919921875, 0.99365234375]], "normalized_score": [0.061174072325229645], "tokens": [["\u2581John", "\u2581Qu", "in", "cy", "\u2581Adams", "\u2581#", "Me", "To", "o", "\u2581movement", "\u2581insp", "iring", "\u2581men", "\u2581to", "\u2581re", "-", "evalu", "ate", "\u2581their", "\u2581behaviour", ":", "\u2581Sh", "ak", "ti", "\u2581Kap", "oor"]], "entropy": [[0.1455078125, 0.0052337646484375, 8.338689804077148e-05, 1.8775463104248047e-05, 0.01419830322265625, 0.5791015625, 3.560546875, 2.009765625, 0.00434112548828125, 2.314453125, 3.814453125, 1.3095703125, 5.09765625, 1.3291015625, 3.984375, 1.7392578125, 1.115234375, 0.0150146484375, 1.8203125, 2.8125, 2.35546875, 5.2734375, 3.138671875, 2.224609375, 3.421875, 0.04803466796875]], "avg_entropy": [1.8512624272933373], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "John Quincy Adams", "score_of_biggest_cluster": 0.061174072325229645, "score_of_first_answer": 0.061174072325229645, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.3113021850585938e-06, "avg_score": 0.061174072325229645, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42265030633381884, "std_of_first_answer": 0.42265030633381884, "avg_entropy_of_first_answer": 1.8512624272933373, "lex_sim": 1.0}
{"question": "where is fort myers located at in florida", "answer": ["It is located in the Southwest part of Florida."], "scores": [[0.08489990234375, 0.9677734375, 0.689453125, 0.7470703125, 0.11859130859375, 0.07965087890625, 0.57177734375, 0.39990234375, 0.99951171875, 0.54248046875, 0.6103515625, 4.172325134277344e-07, 0.00010907649993896484, 0.002178192138671875, 0.0006422996520996094, 0.403076171875, 0.99609375, 0.6728515625, 0.99951171875, 0.00865936279296875, 0.0171356201171875, 0.004425048828125, 0.60791015625, 0.33349609375, 0.9931640625, 0.83447265625, 1.0, 0.002979278564453125, 0.97265625, 0.1142578125, 0.99951171875, 0.9462890625, 0.56201171875, 0.455322265625, 0.998046875]], "normalized_score": [0.11913765221834183], "tokens": [["\u2581It", "\u2581is", "\u2581located", "\u2581in", "\u2581the", "\u2581South", "west", "\u2581part", "\u2581of", "\u2581Florida", ".", "\u2581#", "W", "omen", "Bo", "yc", "ott", "Tw", "itter", ":", "\u2581How", "\u2581", "2", "8", "0", "\u2581Char", "acters", "\u2581G", "ave", "\u2581R", "ise", "\u2581to", "\u2581a", "\u2581Mov", "ement"]], "entropy": [[1.32421875, 0.1527099609375, 0.71923828125, 0.58740234375, 1.19140625, 0.5537109375, 0.79248046875, 1.4765625, 0.003826141357421875, 0.6962890625, 1.1318359375, 0.459716796875, 2.484375, 3.259765625, 2.755859375, 1.7021484375, 0.0255889892578125, 1.5517578125, 0.003993988037109375, 2.201171875, 4.6015625, 4.1015625, 1.58203125, 1.2255859375, 0.06414794921875, 0.4970703125, 0.0017566680908203125, 2.8984375, 0.1639404296875, 1.8037109375, 0.003505706787109375, 0.274169921875, 2.15625, 2.17578125, 0.017486572265625]], "avg_entropy": [1.2754587990897042], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Lee County", "score_of_biggest_cluster": 0.11913765221834183, "score_of_first_answer": 0.11913765221834183, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.11913765221834183, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.38934702658093123, "std_of_first_answer": 0.38934702658093123, "avg_entropy_of_first_answer": 1.2754587990897042, "lex_sim": 1.0}
{"question": "who plays reggie the robot in justin's house", "answer": ["I'm sorry, I'm unable to find information about \"Justin's House\" with the limited information available to me, and there is no specific information about the character \"Reggie the Robot.\""], "scores": [[0.427734375, 0.84814453125, 1.0, 0.98046875, 0.9912109375, 0.9091796875, 0.1522216796875, 1.0, 0.01540374755859375, 0.99951171875, 0.7431640625, 0.390869140625, 0.658203125, 0.7685546875, 0.427734375, 1.0, 1.0, 1.0, 0.47900390625, 0.90478515625, 0.033782958984375, 0.7294921875, 0.002803802490234375, 0.35791015625, 0.286376953125, 0.89599609375, 0.9990234375, 0.0129547119140625, 0.12451171875, 0.1019287109375, 0.712890625, 0.93359375, 0.1658935546875, 0.7490234375, 0.59912109375, 0.172119140625, 0.91796875, 0.83544921875, 0.9990234375, 1.0, 0.962890625, 0.91455078125, 1.0, 0.1888427734375, 0.46826171875, 0.7890625, 0.8125, 0.66943359375, 0.95703125, 0.9736328125]], "normalized_score": [0.4495210647583008], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581I", "'", "m", "\u2581unable", "\u2581to", "\u2581find", "\u2581information", "\u2581about", "\u2581\"", "Just", "in", "'", "s", "\u2581House", "\"", "\u2581with", "\u2581the", "\u2581limited", "\u2581information", "\u2581available", "\u2581to", "\u2581me", ",", "\u2581and", "\u2581there", "\u2581is", "\u2581no", "\u2581specific", "\u2581information", "\u2581about", "\u2581the", "\u2581character", "\u2581\"", "Reg", "gie", "\u2581the", "\u2581Rob", "ot", ".\"", "\u2581Can", "\u2581you", "\u2581provide", "\u2581more", "\u2581context", "\u2581or"]], "entropy": [[3.576171875, 0.6533203125, 0.001049041748046875, 0.10321044921875, 0.056976318359375, 0.349853515625, 1.767578125, 0.0009493827819824219, 0.1729736328125, 0.005084991455078125, 1.0126953125, 1.41015625, 0.80517578125, 0.896484375, 1.169921875, 0.00025725364685058594, 0.0006937980651855469, 5.662441253662109e-06, 0.7109375, 0.392822265625, 1.212890625, 1.0458984375, 1.8291015625, 1.240234375, 1.341796875, 0.403076171875, 0.00957489013671875, 0.1982421875, 2.484375, 2.0703125, 1.1494140625, 0.29638671875, 1.8818359375, 1.05859375, 1.4267578125, 1.2734375, 0.470703125, 0.703125, 0.01068878173828125, 0.00031685829162597656, 0.1785888671875, 0.29638671875, 0.002063751220703125, 0.9130859375, 1.6728515625, 0.5283203125, 0.5458984375, 0.97021484375, 0.2154541015625, 0.1446533203125]], "avg_entropy": [0.773211954832077], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ben Faulks", "score_of_biggest_cluster": 0.4495210647583008, "score_of_first_answer": 0.4495210647583008, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.002803802490234375, "avg_score": 0.4495210647583008, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.34269999401392925, "std_of_first_answer": 0.34269999401392925, "avg_entropy_of_first_answer": 0.773211954832077, "lex_sim": 1.0}
{"question": "where is the orinoco river located on a map", "answer": ["South America, between Venezuela and Brazil."], "scores": [[0.89013671875, 0.99951171875, 0.008087158203125, 0.009765625, 0.82421875, 0.9931640625, 0.59912109375, 0.5634765625, 5.364418029785156e-07, 0.0767822265625, 0.01007843017578125, 0.04681396484375, 0.07098388671875, 0.0278167724609375, 0.00012612342834472656, 0.310546875, 0.00804901123046875, 0.0218353271484375, 0.57373046875, 0.040130615234375, 0.1971435546875, 0.89208984375, 0.94287109375, 0.0653076171875, 0.006866455078125, 0.78271484375]], "normalized_score": [0.0579385831952095], "tokens": [["\u2581South", "\u2581America", ",", "\u2581between", "\u2581Venezuela", "\u2581and", "\u2581Brazil", ".", "\u2581#", "1", "8", "8", "7", "1", "\u2581(", "1", "1", "/", "1", "9", "/", "2", "0", "1", "2", ")"]], "entropy": [[0.603515625, 0.004116058349609375, 0.841796875, 2.5078125, 0.509765625, 0.0440673828125, 1.2099609375, 0.96826171875, 0.18212890625, 3.515625, 1.8017578125, 2.591796875, 2.388671875, 2.158203125, 2.416015625, 3.681640625, 1.8662109375, 2.833984375, 1.41015625, 2.326171875, 1.6474609375, 0.47412109375, 0.3291015625, 0.367919921875, 1.044921875, 0.8720703125]], "avg_entropy": [1.4845098348764272], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "in South America", "score_of_biggest_cluster": 0.0579385831952095, "score_of_first_answer": 0.0579385831952095, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 5.364418029785156e-07, "avg_score": 0.0579385831952095, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.38367670439940005, "std_of_first_answer": 0.38367670439940005, "avg_entropy_of_first_answer": 1.4845098348764272, "lex_sim": 1.0}
{"question": "where did the river thames start and end", "answer": ["Thames River starts in Gloucestershire, England, and ends in the estuary of the river Thames in London."], "scores": [[0.0655517578125, 0.998046875, 0.8359375, 0.44189453125, 0.87451171875, 0.262939453125, 0.99951171875, 1.0, 1.0, 0.98583984375, 0.9931640625, 0.1458740234375, 0.93994140625, 0.464599609375, 0.98291015625, 0.53369140625, 0.0298309326171875, 1.0, 1.0, 0.9755859375, 0.98779296875, 0.1954345703125, 0.9345703125, 0.9990234375, 0.55078125, 0.9619140625, 0.098876953125, 7.152557373046875e-07, 0.002468109130859375, 0.0703125, 0.06695556640625, 0.08843994140625, 0.07275390625, 0.08404541015625, 1.2516975402832031e-06, 0.1075439453125, 0.007293701171875, 0.0015783309936523438, 0.70751953125, 0.04931640625, 0.00014126300811767578, 0.0482177734375, 0.08148193359375, 0.004673004150390625, 0.9990234375, 0.0303802490234375, 0.0278778076171875, 0.0004138946533203125]], "normalized_score": [0.09103607386350632], "tokens": [["\u2581Th", "ames", "\u2581River", "\u2581starts", "\u2581in", "\u2581Gl", "ouc", "esters", "hire", ",", "\u2581England", ",", "\u2581and", "\u2581ends", "\u2581in", "\u2581the", "\u2581est", "u", "ary", "\u2581of", "\u2581the", "\u2581river", "\u2581Th", "ames", "\u2581in", "\u2581London", ".", "\u2581#", "4", "1", "6", "1", "5", "1", "\u2581Top", "\u2581", "8", "\u2581Re", "asons", "\u2581Why", "\u2581Men", "\u2581Are", "\u2581More", "\u2581Success", "ful", "\u2581At", "\u2581Work", "\u2581in"]], "entropy": [[2.060546875, 0.0206298828125, 0.76025390625, 1.861328125, 0.4423828125, 0.73583984375, 0.00264739990234375, 0.00183868408203125, 1.800060272216797e-05, 0.088623046875, 0.05291748046875, 0.431640625, 0.303955078125, 0.884765625, 0.08990478515625, 0.87744140625, 0.98046875, 9.453296661376953e-05, 0.00064849853515625, 0.1636962890625, 0.09490966796875, 1.2197265625, 0.4326171875, 0.00717926025390625, 0.88037109375, 0.228759765625, 0.36474609375, 0.60302734375, 4.1953125, 3.076171875, 3.015625, 2.716796875, 2.552734375, 2.548828125, 2.603515625, 3.404296875, 1.083984375, 4.68359375, 1.3212890625, 1.3056640625, 2.599609375, 3.646484375, 2.859375, 1.88671875, 0.00823211669921875, 2.33203125, 3.70703125, 3.267578125]], "avg_entropy": [1.3834552367528279], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Thames Estuary, North Sea", "score_of_biggest_cluster": 0.09103607386350632, "score_of_first_answer": 0.09103607386350632, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 7.152557373046875e-07, "avg_score": 0.09103607386350632, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4298404903554626, "std_of_first_answer": 0.4298404903554626, "avg_entropy_of_first_answer": 1.3834552367528279, "lex_sim": 1.0}
{"question": "when does the 14th season of grey's anatomy come out", "answer": ["September 28, 2017 #MondayMusings #WinterSafety"], "scores": [[0.1129150390625, 0.9580078125, 0.99951171875, 0.04931640625, 0.7333984375, 0.99755859375, 1.0, 1.0, 0.105224609375, 0.99951171875, 7.748603820800781e-07, 0.0029850006103515625, 0.1058349609375, 0.9736328125, 0.0012226104736328125, 0.99755859375, 0.53857421875, 0.0011987686157226562, 0.31640625, 0.00025272369384765625, 0.0024776458740234375, 0.338623046875]], "normalized_score": [0.06384725123643875], "tokens": [["\u2581September", "\u2581", "2", "8", ",", "\u2581", "2", "0", "1", "7", "\u2581#", "M", "ond", "ay", "Mus", "ings", "\u2581#", "W", "inter", "S", "af", "ety"]], "entropy": [[2.265625, 0.228515625, 0.0030574798583984375, 1.158203125, 0.61376953125, 0.01678466796875, 0.00011026859283447266, 0.0009565353393554688, 0.3369140625, 0.0033969879150390625, 1.0283203125, 5.63671875, 2.10546875, 0.12286376953125, 1.203125, 0.0241851806640625, 1.8740234375, 2.5078125, 2.697265625, 0.256103515625, 3.55078125, 1.3623046875]], "avg_entropy": [1.227104820988395], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "September 28, 2017", "score_of_biggest_cluster": 0.06384725123643875, "score_of_first_answer": 0.06384725123643875, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 7.748603820800781e-07, "avg_score": 0.06384725123643875, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4355431770220226, "std_of_first_answer": 0.4355431770220226, "avg_entropy_of_first_answer": 1.227104820988395, "lex_sim": 1.0}
{"question": "who is the founder of el pollo loco", "answer": ["Juan Francisco Mart\u00ednez"], "scores": [[0.73779296875, 0.82763671875, 0.12249755859375]], "normalized_score": [0.4213411509990692], "tokens": [["\u2581Juan", "\u2581Francisco", "\u2581Mart\u00ednez"]], "entropy": [[1.630859375, 0.890625, 4.5859375]], "avg_entropy": [2.369140625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Juan Francisco Ochoa", "score_of_biggest_cluster": 0.4213411509990692, "score_of_first_answer": 0.4213411509990692, "max_score_of_first_answer": 0.82763671875, "min_score_of_first_answer": 0.12249755859375, "avg_score": 0.4213411509990692, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3133832542429782, "std_of_first_answer": 0.3133832542429782, "avg_entropy_of_first_answer": 2.369140625, "lex_sim": 1.0}
{"question": "converting stereo signal to mono signal is called", "answer": ["downmixing #WPLongform, 419 Scam, Email spam, Fraud, Postal fraud, Scam, Spam"], "scores": [[0.39794921875, 0.95068359375, 0.990234375, 1.1920928955078125e-07, 0.0010061264038085938, 8.320808410644531e-05, 0.11126708984375, 0.8525390625, 0.001220703125, 0.0135955810546875, 0.0516357421875, 0.0390625, 0.023193359375, 4.0531158447265625e-06, 0.81591796875, 0.533203125, 0.00011521577835083008, 0.032806396484375, 0.99609375, 0.8046875, 0.0038013458251953125, 0.99755859375, 0.71875, 0.0009860992431640625, 0.27734375, 0.0684814453125, 0.99951171875, 0.84423828125, 0.11920166015625, 0.79248046875, 0.81982421875, 0.5791015625, 0.99658203125]], "normalized_score": [0.04467490315437317], "tokens": [["\u2581down", "mix", "ing", "\u2581#", "W", "PL", "ong", "form", ",", "\u2581", "4", "1", "9", "\u2581Sc", "am", ",", "\u2581Email", "\u2581sp", "am", ",", "\u2581Fra", "ud", ",", "\u2581Post", "al", "\u2581fra", "ud", ",", "\u2581Sc", "am", ",", "\u2581Sp", "am"]], "entropy": [[2.361328125, 0.248291015625, 0.06744384765625, 1.3642578125, 4.1328125, 3.0703125, 3.5546875, 0.8017578125, 1.57421875, 2.044921875, 2.37890625, 3.69140625, 2.373046875, 2.537109375, 0.7080078125, 2.041015625, 5.80078125, 1.98828125, 0.032501220703125, 0.83154296875, 4.6015625, 0.0204315185546875, 1.15234375, 3.685546875, 3.65234375, 0.93359375, 0.003406524658203125, 0.625, 2.97265625, 0.58837890625, 0.7734375, 2.591796875, 0.03076171875]], "avg_entropy": [1.9161785010135535], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Panning", "score_of_biggest_cluster": 0.04467490315437317, "score_of_first_answer": 0.04467490315437317, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.04467490315437317, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40924883171694215, "std_of_first_answer": 0.40924883171694215, "avg_entropy_of_first_answer": 1.9161785010135535, "lex_sim": 1.0}
{"question": "who is hosting e live from the red carpet", "answer": ["Ryan Seacrest"], "scores": [[0.943359375, 0.99951171875, 0.99951171875, 1.0]], "normalized_score": [0.9852880835533142], "tokens": [["\u2581Ryan", "\u2581Se", "ac", "rest"]], "entropy": [[0.414306640625, 0.0036106109619140625, 0.0034046173095703125, 0.0005688667297363281]], "avg_entropy": [0.10547268390655518], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Ryan Seacrest", "score_of_biggest_cluster": 0.9852880835533142, "score_of_first_answer": 0.9852880835533142, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.943359375, "avg_score": 0.9852880835533142, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.024385970165734072, "std_of_first_answer": 0.024385970165734072, "avg_entropy_of_first_answer": 0.10547268390655518, "lex_sim": 1.0}
{"question": "who was tammy from basketball wives married to", "answer": ["Glen Rice #MindfulMonday - Meditation and Mindfulness for Beginners"], "scores": [[0.0594482421875, 0.466064453125, 0.9296875, 4.76837158203125e-07, 0.0005431175231933594, 0.0307159423828125, 0.002498626708984375, 0.04302978515625, 0.416015625, 0.9638671875, 0.0009593963623046875, 0.00347137451171875, 0.7666015625, 0.0299224853515625, 0.2215576171875, 0.994140625, 0.9951171875, 0.039154052734375, 0.140380859375, 0.9990234375]], "normalized_score": [0.04420629143714905], "tokens": [["\u2581Glen", "\u2581R", "ice", "\u2581#", "M", "ind", "ful", "M", "ond", "ay", "\u2581-", "\u2581Med", "itation", "\u2581and", "\u2581Mind", "ful", "ness", "\u2581for", "\u2581Begin", "ners"]], "entropy": [[4.125, 3.01953125, 0.30908203125, 1.0126953125, 1.7685546875, 2.029296875, 1.576171875, 3.705078125, 1.326171875, 0.162109375, 2.18359375, 5.37109375, 0.640625, 2.56640625, 3.06640625, 0.04473876953125, 0.045196533203125, 3.38671875, 3.4609375, 0.00998687744140625]], "avg_entropy": [1.990469741821289], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "basketball player Kenny Anderson", "score_of_biggest_cluster": 0.04420629143714905, "score_of_first_answer": 0.04420629143714905, "max_score_of_first_answer": 0.9990234375, "min_score_of_first_answer": 4.76837158203125e-07, "avg_score": 0.04420629143714905, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40641438998842505, "std_of_first_answer": 0.40641438998842505, "avg_entropy_of_first_answer": 1.990469741821289, "lex_sim": 1.0}
{"question": "when does episode 29 of boruto come out", "answer": ["I'm sorry, but as an AI language model, I don't have access to current episode schedules for anime or other television shows."], "scores": [[0.791015625, 0.55517578125, 0.99951171875, 0.98388671875, 0.986328125, 0.1722412109375, 0.2529296875, 0.86083984375, 0.99560546875, 1.0, 0.397216796875, 1.0, 0.98193359375, 0.96240234375, 0.458984375, 0.9951171875, 1.0, 0.98828125, 0.76171875, 0.998046875, 0.20947265625, 0.0082550048828125, 0.50634765625, 0.99462890625, 0.09027099609375, 0.48291015625, 0.99951171875, 0.0784912109375, 0.767578125, 0.376708984375, 0.970703125, 0.97021484375, 0.0780029296875, 0.9990234375, 0.85107421875, 0.85009765625, 0.79248046875, 0.23388671875, 0.1634521484375, 0.3095703125, 0.03375244140625, 0.99267578125, 0.04193115234375, 0.41455078125, 0.7275390625, 0.78515625, 0.98388671875, 0.87548828125, 0.9990234375, 0.51806640625]], "normalized_score": [0.4811718165874481], "tokens": [["\u2581I", "'", "m", "\u2581sorry", ",", "\u2581but", "\u2581as", "\u2581an", "\u2581A", "I", "\u2581language", "\u2581model", ",", "\u2581I", "\u2581don", "'", "t", "\u2581have", "\u2581access", "\u2581to", "\u2581current", "\u2581episode", "\u2581sched", "ules", "\u2581for", "\u2581an", "ime", "\u2581or", "\u2581other", "\u2581television", "\u2581shows", ".", "\u2581However", ",", "\u2581you", "\u2581can", "\u2581check", "\u2581online", "\u2581sources", "\u2581for", "\u2581that", "\u2581information", "\u2581or", "\u2581consult", "\u2581the", "\u2581official", "\u2581website", "\u2581of", "\u2581the", "\u2581an"]], "entropy": [[1.2265625, 1.2412109375, 0.0033588409423828125, 0.10491943359375, 0.08447265625, 0.796875, 0.74560546875, 0.4921875, 0.03350830078125, 6.186962127685547e-05, 0.994140625, 0.0021266937255859375, 0.1021728515625, 0.16455078125, 0.9560546875, 0.03167724609375, 8.046627044677734e-06, 0.071044921875, 0.87841796875, 0.01436614990234375, 1.9892578125, 1.841796875, 1.267578125, 0.03466796875, 1.51953125, 1.9013671875, 0.0056610107421875, 1.0712890625, 0.83251953125, 1.65234375, 0.1619873046875, 0.1697998046875, 1.837890625, 0.00644683837890625, 0.68115234375, 0.474853515625, 0.85107421875, 1.931640625, 1.552734375, 1.3984375, 1.4658203125, 0.05029296875, 0.397705078125, 1.927734375, 0.99462890625, 0.85205078125, 0.12286376953125, 0.47607421875, 0.0079498291015625, 1.4658203125]], "avg_entropy": [0.7377258551120758], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "October 18, 2017", "score_of_biggest_cluster": 0.4811718165874481, "score_of_first_answer": 0.4811718165874481, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0082550048828125, "avg_score": 0.4811718165874481, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3495734579359818, "std_of_first_answer": 0.3495734579359818, "avg_entropy_of_first_answer": 0.7377258551120758, "lex_sim": 1.0}
{"question": "who said have you no sense of decency", "answer": ["Joseph N. Welch"], "scores": [[0.88134765625, 0.78857421875, 0.99560546875, 0.99951171875, 0.99853515625]], "normalized_score": [0.9286363124847412], "tokens": [["\u2581Joseph", "\u2581N", ".", "\u2581Wel", "ch"]], "entropy": [[0.56884765625, 0.6484375, 0.034088134765625, 0.00452423095703125, 0.01215362548828125]], "avg_entropy": [0.2536102294921875], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Joseph Nye Welch", "score_of_biggest_cluster": 0.9286363124847412, "score_of_first_answer": 0.9286363124847412, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.78857421875, "avg_score": 0.9286363124847412, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.08504642789359784, "std_of_first_answer": 0.08504642789359784, "avg_entropy_of_first_answer": 0.2536102294921875, "lex_sim": 1.0}
{"question": "1 the bureau of land management manages over acres of land in the united states", "answer": ["640 million acres."], "scores": [[0.162841796875, 0.0097503662109375, 0.01262664794921875, 0.7880859375, 0.86767578125, 0.39404296875, 0.266357421875, 1.7285346984863281e-06, 0.042144775390625, 0.023712158203125, 0.0784912109375, 9.119510650634766e-06, 0.0005125999450683594, 0.02008056640625, 1.2695789337158203e-05, 0.476318359375]], "normalized_score": [0.011621695011854172], "tokens": [["\u2581", "6", "4", "0", "\u2581million", "\u2581acres", ".", "\u2581#", "2", "2", "4", "\u2581/", "\u2581W", "ise", "\u2581Dec", "isions"]], "entropy": [[2.806640625, 1.162109375, 0.2320556640625, 0.95654296875, 0.5869140625, 1.2109375, 1.310546875, 0.30859375, 3.703125, 3.0859375, 2.810546875, 2.43359375, 3.84765625, 4.08984375, 3.400390625, 1.2099609375]], "avg_entropy": [2.0722122192382812], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "247.3\u00a0million", "score_of_biggest_cluster": 0.011621695011854172, "score_of_first_answer": 0.011621695011854172, "max_score_of_first_answer": 0.86767578125, "min_score_of_first_answer": 1.7285346984863281e-06, "avg_score": 0.011621695011854172, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.27899817095314144, "std_of_first_answer": 0.27899817095314144, "avg_entropy_of_first_answer": 2.0722122192382812, "lex_sim": 1.0}
{"question": "when does south by southwest start in austin texas", "answer": ["Mid-March"], "scores": [[0.0130767822265625, 0.9931640625, 0.99951171875, 1.0]], "normalized_score": [0.33754172921180725], "tokens": [["\u2581Mid", "-", "M", "arch"]], "entropy": [[1.65234375, 0.045745849609375, 0.006160736083984375, 1.8477439880371094e-05]], "avg_entropy": [0.42606720328330994], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "mid-March", "score_of_biggest_cluster": 0.33754172921180725, "score_of_first_answer": 0.33754172921180725, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0130767822265625, "avg_score": 0.33754172921180725, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4263016581547632, "std_of_first_answer": 0.4263016581547632, "avg_entropy_of_first_answer": 0.42606720328330994, "lex_sim": 1.0}
{"question": "who did the 49ers beat in the super bowls", "answer": ["San Francisco 49ers have won 5 Super Bowls: XVI, XIX, XXIII, XXIV, and XXIX."], "scores": [[0.314453125, 1.0, 0.99951171875, 1.0, 1.0, 0.9990234375, 0.1890869140625, 0.98681640625, 0.474853515625, 0.99658203125, 0.93408203125, 0.366455078125, 1.0, 0.215576171875, 0.090087890625, 0.82421875, 0.947265625, 0.9990234375, 0.99853515625, 0.88916015625, 0.9990234375, 0.9990234375, 0.9990234375, 0.99560546875, 0.95703125, 0.9931640625, 0.99951171875, 0.9677734375, 1.7881393432617188e-07, 0.00018012523651123047, 0.0015382766723632812, 0.003326416015625, 0.97802734375, 0.9501953125, 0.00016248226165771484, 0.00045871734619140625, 0.025787353515625, 0.9921875, 0.055877685546875, 0.01342010498046875, 0.0009021759033203125, 0.953125, 0.01180267333984375, 0.8037109375, 0.11920166015625, 0.0032062530517578125, 0.0775146484375, 0.9306640625]], "normalized_score": [0.13829554617404938], "tokens": [["\u2581San", "\u2581Francisco", "\u2581", "4", "9", "ers", "\u2581have", "\u2581won", "\u2581", "5", "\u2581Super", "\u2581Bow", "ls", ":", "\u2581XVI", ",", "\u2581XIX", ",", "\u2581XX", "III", ",", "\u2581XX", "IV", ",", "\u2581and", "\u2581XX", "IX", ".", "\u2581#", "P", "W", "In", "s", "ider", ":", "\u2581Q", "&", "A", "\u2581with", "\u2581P", "ais", "ley", "\u2581Winter", "s", ",", "\u2581Content", "\u2581Cre", "ator"]], "entropy": [[2.134765625, 0.0007305145263671875, 0.007053375244140625, 0.0001277923583984375, 0.0001480579376220703, 0.00931549072265625, 1.94140625, 0.10003662109375, 0.71826171875, 0.0225830078125, 0.249755859375, 0.6630859375, 4.0411949157714844e-05, 1.037109375, 1.6728515625, 0.484375, 0.2296142578125, 0.0092010498046875, 0.0148468017578125, 0.35595703125, 0.00997161865234375, 0.00885772705078125, 0.00847625732421875, 0.027496337890625, 0.18017578125, 0.04840087890625, 0.00235748291015625, 0.1644287109375, 0.728515625, 2.369140625, 4.046875, 3.6484375, 0.20751953125, 0.2454833984375, 1.3076171875, 4.44921875, 2.490234375, 0.07525634765625, 3.85546875, 3.9453125, 2.669921875, 0.292236328125, 3.49609375, 0.83447265625, 3.021484375, 5.30078125, 3.021484375, 0.273193359375]], "avg_entropy": [1.1745870436231296], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "San Diego Chargers", "score_of_biggest_cluster": 0.13829554617404938, "score_of_first_answer": 0.13829554617404938, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.13829554617404938, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4394871971302298, "std_of_first_answer": 0.4394871971302298, "avg_entropy_of_first_answer": 1.1745870436231296, "lex_sim": 1.0}
{"question": "what hangs from the trees in the bayou", "answer": ["Spanish moss (Photo: AP/Jeff Chiu)"], "scores": [[0.97314453125, 0.9453125, 1.0, 0.0017642974853515625, 5.0067901611328125e-06, 0.296142578125, 7.992982864379883e-05, 0.12310791015625, 0.0096588134765625, 0.1436767578125, 0.30078125, 0.998046875, 0.97509765625]], "normalized_score": [0.049091994762420654], "tokens": [["\u2581Spanish", "\u2581m", "oss", "\u2581(", "Photo", ":", "\u2581AP", "/", "J", "eff", "\u2581Ch", "iu", ")"]], "entropy": [[0.17236328125, 0.213623046875, 1.0728836059570312e-06, 0.779296875, 0.90966796875, 2.197265625, 3.25390625, 2.01953125, 2.5546875, 2.7734375, 1.8056640625, 0.0164031982421875, 0.1806640625]], "avg_entropy": [1.2981932071539073], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Spanish moss", "score_of_biggest_cluster": 0.049091994762420654, "score_of_first_answer": 0.049091994762420654, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.0067901611328125e-06, "avg_score": 0.049091994762420654, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.4335395668663142, "std_of_first_answer": 0.4335395668663142, "avg_entropy_of_first_answer": 1.2981932071539073, "lex_sim": 1.0}
{"question": "when does the second half of vikings season 5 air", "answer": ["December 15, 2016 #OscarsSoWhite Creator April Reign Speaks Out On This Year's Nominees"], "scores": [[0.131591796875, 0.9921875, 0.9453125, 0.0809326171875, 0.7607421875, 0.99658203125, 0.9990234375, 1.0, 0.841796875, 0.11602783203125, 7.152557373046875e-07, 0.0005331039428710938, 0.0022106170654296875, 0.9931640625, 0.71875, 0.8740234375, 0.0004649162292480469, 0.81396484375, 3.3020973205566406e-05, 0.95068359375, 1.0, 0.0203399658203125, 0.97998046875, 0.74658203125, 0.03790283203125, 0.0888671875, 0.98779296875, 0.833984375, 1.0, 0.1004638671875, 0.99951171875, 0.94775390625]], "normalized_score": [0.12642548978328705], "tokens": [["\u2581December", "\u2581", "1", "5", ",", "\u2581", "2", "0", "1", "6", "\u2581#", "O", "sc", "ars", "So", "White", "\u2581Cre", "ator", "\u2581April", "\u2581Re", "ign", "\u2581Spe", "aks", "\u2581Out", "\u2581On", "\u2581This", "\u2581Year", "'", "s", "\u2581Nom", "ine", "es"]], "entropy": [[2.763671875, 0.056610107421875, 0.28466796875, 1.99609375, 0.681640625, 0.0262451171875, 0.006603240966796875, 4.404783248901367e-05, 0.437744140625, 1.025390625, 1.228515625, 5.53125, 1.849609375, 0.04669189453125, 1.34765625, 0.90625, 2.505859375, 0.54833984375, 2.392578125, 0.40576171875, 0.002567291259765625, 5.046875, 0.1365966796875, 1.166015625, 2.744140625, 3.8671875, 0.091796875, 0.533203125, 0.0013685226440429688, 1.408203125, 0.005390167236328125, 0.209716796875]], "avg_entropy": [1.2266964074224234], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2018", "score_of_biggest_cluster": 0.12642548978328705, "score_of_first_answer": 0.12642548978328705, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 7.152557373046875e-07, "avg_score": 0.12642548978328705, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.42931914421029294, "std_of_first_answer": 0.42931914421029294, "avg_entropy_of_first_answer": 1.2266964074224234, "lex_sim": 1.0}
{"question": "the actual name of the confederate force at gettysburg was", "answer": ["Army of Northern Virginia"], "scores": [[0.3330078125, 1.0, 0.9990234375, 1.0]], "normalized_score": [0.7594645619392395], "tokens": [["\u2581Army", "\u2581of", "\u2581Northern", "\u2581Virginia"]], "entropy": [[1.1552734375, 0.0016994476318359375, 0.007663726806640625, 0.0008664131164550781]], "avg_entropy": [0.2913757562637329], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Confederate States Army", "score_of_biggest_cluster": 0.7594645619392395, "score_of_first_answer": 0.7594645619392395, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.3330078125, "avg_score": 0.7594645619392395, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.28867540989674323, "std_of_first_answer": 0.28867540989674323, "avg_entropy_of_first_answer": 0.2913757562637329, "lex_sim": 1.0}
{"question": "who has the most wins on around the horn", "answer": ["Bill Simmons"], "scores": [[0.0017242431640625, 0.88232421875, 0.98974609375, 1.0]], "normalized_score": [0.19698703289031982], "tokens": [["\u2581Bill", "\u2581Sim", "m", "ons"]], "entropy": [[3.806640625, 0.79541015625, 0.05792236328125, 0.00011819601058959961]], "avg_entropy": [1.16502283513546], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Woody Paige", "score_of_biggest_cluster": 0.19698703289031982, "score_of_first_answer": 0.19698703289031982, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0017242431640625, "avg_score": 0.19698703289031982, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4163599833856422, "std_of_first_answer": 0.4163599833856422, "avg_entropy_of_first_answer": 1.16502283513546, "lex_sim": 1.0}
{"question": "how many steps does the cn tower have", "answer": ["1,775 ### Why I don't use TDD"], "scores": [[0.9287109375, 0.97314453125, 0.9326171875, 0.99365234375, 0.99951171875, 0.002368927001953125, 0.0, 0.00311279296875, 0.0017061233520507812, 0.004810333251953125, 0.9404296875, 1.0, 0.0166015625, 0.0037364959716796875, 0.006160736083984375]], "normalized_score": [0.0], "tokens": [["\u2581", "1", ",", "7", "7", "5", "\u2581###", "\u2581Why", "\u2581I", "\u2581don", "'", "t", "\u2581use", "\u2581T", "DD"]], "entropy": [[0.451904296875, 0.14013671875, 0.28955078125, 0.045318603515625, 0.0027008056640625, 1.3037109375, 0.96630859375, 5.29296875, 2.486328125, 3.69921875, 0.32568359375, 0.0015726089477539062, 3.427734375, 4.69921875, 1.9462890625]], "avg_entropy": [1.6719096501668294], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "2,579 steps", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.48040360123762477, "std_of_first_answer": 0.48040360123762477, "avg_entropy_of_first_answer": 1.6719096501668294, "lex_sim": 1.0}
{"question": "where was the tv show in the heat of the night filmed", "answer": ["Mississippi #GivingTuesday: A Day of Giving to Support the Schools of Hope"], "scores": [[0.44482421875, 1.1920928955078125e-07, 0.00193023681640625, 0.0011548995971679688, 0.9921875, 1.0, 0.998046875, 0.00484466552734375, 0.01031494140625, 0.299560546875, 0.1583251953125, 0.943359375, 0.9970703125, 0.0303497314453125, 0.7080078125, 0.2117919921875, 0.0016613006591796875, 0.1673583984375, 0.1063232421875, 0.004055023193359375]], "normalized_score": [0.04051998257637024], "tokens": [["\u2581Mississippi", "\u2581#", "G", "iving", "T", "ues", "day", ":", "\u2581A", "\u2581Day", "\u2581of", "\u2581G", "iving", "\u2581to", "\u2581Support", "\u2581the", "\u2581School", "s", "\u2581of", "\u2581Hope"]], "entropy": [[3.474609375, 0.94873046875, 5.18359375, 4.296875, 0.065185546875, 0.0005483627319335938, 0.0155029296875, 2.267578125, 4.3203125, 2.7578125, 0.82861328125, 0.399658203125, 0.0240020751953125, 2.708984375, 1.8427734375, 4.25390625, 4.8515625, 2.96484375, 2.46484375, 3.326171875]], "avg_entropy": [2.349805402755737], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Decatur in Dekalb County", "score_of_biggest_cluster": 0.04051998257637024, "score_of_first_answer": 0.04051998257637024, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1920928955078125e-07, "avg_score": 0.04051998257637024, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.403525428969309, "std_of_first_answer": 0.403525428969309, "avg_entropy_of_first_answer": 2.349805402755737, "lex_sim": 1.0}
{"question": "what is the population of the tri-cities washington", "answer": ["the population of the Tri-Cities region in Washington state includes Richland, Pasco, and Kennewick, with a combined population of approximately 280,000."], "scores": [[0.045196533203125, 0.794921875, 0.96337890625, 0.98388671875, 0.6865234375, 0.998046875, 0.9912109375, 0.99951171875, 0.10748291015625, 0.81298828125, 0.99755859375, 0.66064453125, 0.04644775390625, 0.00566864013671875, 1.0, 0.99365234375, 0.31396484375, 0.99951171875, 0.990234375, 0.99365234375, 1.0, 1.0, 1.0, 0.52001953125, 0.155517578125, 0.974609375, 0.796875, 0.96142578125, 0.9970703125, 0.6337890625, 0.99951171875, 0.86328125, 0.467529296875, 0.98681640625, 1.0, 1.0, 0.99951171875, 1.0, 0.298828125, 2.384185791015625e-07, 0.0001214742660522461, 0.00016832351684570312, 0.1082763671875, 0.9892578125, 0.0009088516235351562, 0.54541015625, 0.08197021484375, 0.0108795166015625]], "normalized_score": [0.2265913188457489], "tokens": [["\u2581the", "\u2581population", "\u2581of", "\u2581the", "\u2581Tri", "-", "C", "ities", "\u2581region", "\u2581in", "\u2581Washington", "\u2581state", "\u2581includes", "\u2581Rich", "land", ",", "\u2581Pas", "co", ",", "\u2581and", "\u2581Ken", "new", "ick", ",", "\u2581with", "\u2581a", "\u2581combined", "\u2581population", "\u2581of", "\u2581approximately", "\u2581", "2", "8", "0", ",", "0", "0", "0", ".", "\u2581#", "K", "re", "ml", "in", "An", "nex", "\u2581#", "B"]], "entropy": [[1.7724609375, 0.97705078125, 0.1978759765625, 0.09423828125, 0.64794921875, 0.01416778564453125, 0.051025390625, 0.0034885406494140625, 0.83251953125, 0.609375, 0.0224761962890625, 1.0380859375, 0.90185546875, 0.373046875, 6.008148193359375e-05, 0.0401611328125, 0.62548828125, 0.00502777099609375, 0.055938720703125, 0.0382080078125, 0.0007905960083007812, 0.00021183490753173828, 0.0008931159973144531, 1.0302734375, 1.203125, 0.1383056640625, 0.650390625, 0.169189453125, 0.0257568359375, 0.9306640625, 0.0027713775634765625, 0.399658203125, 1.177734375, 0.09075927734375, 0.0010528564453125, 0.0016012191772460938, 0.004405975341796875, 0.00017690658569335938, 1.6015625, 0.46435546875, 3.1328125, 1.2236328125, 3.330078125, 0.07806396484375, 3.9609375, 2.013671875, 2.794921875, 4.52734375]], "avg_entropy": [0.7761591896414757], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "283,846", "score_of_biggest_cluster": 0.2265913188457489, "score_of_first_answer": 0.2265913188457489, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 2.384185791015625e-07, "avg_score": 0.2265913188457489, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.3984705790907357, "std_of_first_answer": 0.3984705790907357, "avg_entropy_of_first_answer": 0.7761591896414757, "lex_sim": 1.0}
{"question": "where does the pulmonary trunk receive blood from", "answer": ["Right ventricle of the heart \\nAs a former award-winning journalist with more than a decade of experience in the entertainment industry, I have covered some of the most iconic personalities in Hollywood."], "scores": [[0.0305938720703125, 0.94482421875, 1.0, 1.0, 0.09088134765625, 0.9931640625, 1.0, 5.960464477539063e-08, 0.001018524169921875, 2.8133392333984375e-05, 0.1285400390625, 0.00018548965454101562, 6.198883056640625e-06, 0.8916015625, 0.9541015625, 1.0, 0.005474090576171875, 0.07806396484375, 0.02392578125, 0.9951171875, 0.244873046875, 0.94775390625, 1.0, 0.97509765625, 0.97119140625, 0.275634765625, 0.218017578125, 0.0054779052734375, 0.99951171875, 0.734375, 0.94580078125, 0.8349609375, 0.375732421875, 0.0682373046875, 0.054534912109375, 0.955078125, 0.9755859375, 0.473876953125, 0.034332275390625, 0.99853515625, 0.02105712890625, 0.99853515625, 0.303466796875, 0.515625, 0.6318359375, 0.177734375, 0.130859375, 0.9560546875]], "normalized_score": [0.11203501373529434], "tokens": [["\u2581Right", "\u2581vent", "ric", "le", "\u2581of", "\u2581the", "\u2581heart", "\u2581\\", "n", "As", "\u2581a", "\u2581former", "\u2581award", "-", "win", "ning", "\u2581journalist", "\u2581with", "\u2581more", "\u2581than", "\u2581a", "\u2581de", "cade", "\u2581of", "\u2581experience", "\u2581in", "\u2581the", "\u2581entertain", "ment", "\u2581industry", ",", "\u2581I", "\u2581have", "\u2581covered", "\u2581some", "\u2581of", "\u2581the", "\u2581most", "\u2581icon", "ic", "\u2581personal", "ities", "\u2581in", "\u2581Hollywood", ".", "\u2581My", "\u2581work", "\u2581has"]], "entropy": [[1.7080078125, 0.2734375, 0.0008955001831054688, 0.0022373199462890625, 1.1923828125, 0.041046142578125, 0.0005984306335449219, 0.97509765625, 0.5224609375, 0.69921875, 1.4853515625, 2.88671875, 1.8173828125, 0.412841796875, 0.2010498046875, 0.0002803802490234375, 3.42578125, 1.294921875, 2.3203125, 0.044403076171875, 0.89111328125, 0.26806640625, 0.0004634857177734375, 0.1671142578125, 0.2208251953125, 1.814453125, 3.6953125, 1.4033203125, 0.003726959228515625, 1.1669921875, 0.32763671875, 1.1455078125, 2.51171875, 3.3671875, 3.140625, 0.322265625, 0.1396484375, 0.9208984375, 3.197265625, 0.01139068603515625, 2.55859375, 0.01331329345703125, 1.3876953125, 1.291015625, 1.2099609375, 3.150390625, 3.5859375, 0.31201171875]], "avg_entropy": [1.1985182861487071], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the right ventricle", "score_of_biggest_cluster": 0.11203501373529434, "score_of_first_answer": 0.11203501373529434, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.11203501373529434, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.425373603694193, "std_of_first_answer": 0.425373603694193, "avg_entropy_of_first_answer": 1.1985182861487071, "lex_sim": 1.0}
{"question": "how many ceos of fortune 500 companies are female", "answer": ["32 as of 2021"], "scores": [[0.54345703125, 0.6669921875, 0.260009765625, 0.0308685302734375, 0.99853515625, 0.98095703125, 0.99951171875, 0.99951171875, 0.99951171875, 0.974609375]], "normalized_score": [0.5550088286399841], "tokens": [["\u2581", "3", "2", "\u2581as", "\u2581of", "\u2581", "2", "0", "2", "1"]], "entropy": [[2.228515625, 0.81591796875, 1.5703125, 1.375, 0.01149749755859375, 0.1376953125, 0.0031833648681640625, 0.0032291412353515625, 0.0034160614013671875, 0.134765625]], "avg_entropy": [0.6283533096313476], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "32", "score_of_biggest_cluster": 0.5550088286399841, "score_of_first_answer": 0.5550088286399841, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.0308685302734375, "avg_score": 0.5550088286399841, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.3404272910804958, "std_of_first_answer": 0.3404272910804958, "avg_entropy_of_first_answer": 0.6283533096313476, "lex_sim": 1.0}
{"question": "what is the meaning of veronica in english", "answer": ["\"true image\" or \"veritable image\" #HackingHumanity: Can Machines Be Human, Or, What\u2019s It Mean To Be Alive?"], "scores": [[0.43310546875, 0.68017578125, 0.98583984375, 0.9951171875, 0.52099609375, 0.9990234375, 0.0117950439453125, 0.94482421875, 0.8740234375, 0.93701171875, 5.960464477539063e-08, 0.0010595321655273438, 0.002483367919921875, 0.019256591796875, 0.02996826171875, 0.5908203125, 0.751953125, 0.0139617919921875, 0.0006318092346191406, 0.11041259765625, 0.99951171875, 0.09307861328125, 0.06414794921875, 0.00969696044921875, 0.21923828125, 0.002216339111328125, 0.07122802734375, 0.028106689453125, 0.99951171875, 0.0162506103515625, 0.88330078125, 0.85693359375, 0.97509765625, 0.85400390625, 0.52197265625, 0.86181640625]], "normalized_score": [0.0888078361749649], "tokens": [["\u2581\"", "true", "\u2581image", "\"", "\u2581or", "\u2581\"", "ver", "itable", "\u2581image", "\"", "\u2581#", "H", "ack", "ing", "H", "uman", "ity", ":", "\u2581Can", "\u2581Mach", "ines", "\u2581Be", "\u2581Human", ",", "\u2581Or", ",", "\u2581What", "\u2019", "s", "\u2581It", "\u2581Mean", "\u2581To", "\u2581Be", "\u2581A", "live", "?"]], "entropy": [[2.78125, 0.71142578125, 0.08734130859375, 0.03399658203125, 1.1630859375, 0.009307861328125, 1.5634765625, 0.302001953125, 0.51611328125, 0.322509765625, 1.1455078125, 5.4921875, 3.29296875, 3.5, 4.3125, 2.103515625, 1.693359375, 1.873046875, 5.3203125, 2.451171875, 0.006015777587890625, 3.361328125, 2.322265625, 0.5048828125, 2.265625, 0.7705078125, 1.494140625, 2.494140625, 0.00382232666015625, 2.53515625, 0.5205078125, 0.47705078125, 0.173828125, 0.63623046875, 1.560546875, 0.7578125]], "avg_entropy": [1.6266372468736436], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "she who brings victory", "score_of_biggest_cluster": 0.0888078361749649, "score_of_first_answer": 0.0888078361749649, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.0888078361749649, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4145388513300783, "std_of_first_answer": 0.4145388513300783, "avg_entropy_of_first_answer": 1.6266372468736436, "lex_sim": 1.0}
{"question": "when does bill nye saves the world season 2 come out", "answer": ["October 28, 2017"], "scores": [[0.0035533905029296875, 0.984375, 0.12451171875, 0.047332763671875, 0.7822265625, 0.99560546875, 0.99951171875, 1.0, 0.99169921875, 0.9345703125]], "normalized_score": [0.3290315568447113], "tokens": [["\u2581October", "\u2581", "2", "8", ",", "\u2581", "2", "0", "1", "7"]], "entropy": [[2.42578125, 0.09283447265625, 0.56640625, 1.3623046875, 0.57861328125, 0.03033447265625, 0.003810882568359375, 2.2411346435546875e-05, 0.04864501953125, 0.24609375]], "avg_entropy": [0.5354846477508545], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "December\u00a029,\u00a02017", "score_of_biggest_cluster": 0.3290315568447113, "score_of_first_answer": 0.3290315568447113, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0035533905029296875, "avg_score": 0.3290315568447113, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4165530825212895, "std_of_first_answer": 0.4165530825212895, "avg_entropy_of_first_answer": 0.5354846477508545, "lex_sim": 1.0}
{"question": "who plays artemisia in 300 rise of an empire", "answer": ["Eva Green"], "scores": [[0.97900390625, 0.99951171875]], "normalized_score": [0.9892046451568604], "tokens": [["\u2581Eva", "\u2581Green"]], "entropy": [[0.1334228515625, 0.006755828857421875]], "avg_entropy": [0.07008934020996094], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Caitlin Carmichael", "score_of_biggest_cluster": 0.9892046451568604, "score_of_first_answer": 0.9892046451568604, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.97900390625, "avg_score": 0.9892046451568604, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.01025390625, "std_of_first_answer": 0.01025390625, "avg_entropy_of_first_answer": 0.07008934020996094, "lex_sim": 1.0}
{"question": "who sings the skye boat song on outlander", "answer": ["Dave McKean"], "scores": [[0.06866455078125, 0.0235595703125, 0.0714111328125, 0.994140625]], "normalized_score": [0.10352099686861038], "tokens": [["\u2581Dave", "\u2581Mc", "Ke", "an"]], "entropy": [[3.62109375, 4.49609375, 3.39453125, 0.05078125]], "avg_entropy": [2.890625], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Bear McCreary", "score_of_biggest_cluster": 0.10352099686861038, "score_of_first_answer": 0.10352099686861038, "max_score_of_first_answer": 0.994140625, "min_score_of_first_answer": 0.0235595703125, "avg_score": 0.10352099686861038, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.40730018401909995, "std_of_first_answer": 0.40730018401909995, "avg_entropy_of_first_answer": 2.890625, "lex_sim": 1.0}
{"question": "what does g stand for in baseball stats", "answer": ["games"], "scores": [[0.447265625]], "normalized_score": [0.447265625], "tokens": [["\u2581games"]], "entropy": [[2.193359375]], "avg_entropy": [2.193359375], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Games", "score_of_biggest_cluster": 0.447265625, "score_of_first_answer": 0.447265625, "max_score_of_first_answer": 0.447265625, "min_score_of_first_answer": 0.447265625, "avg_score": 0.447265625, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.0, "std_of_first_answer": 0.0, "avg_entropy_of_first_answer": 2.193359375, "lex_sim": 1.0}
{"question": "where does the optic nerve cross the midline \u200b", "answer": ["The optic nerve does not cross the midline."], "scores": [[0.136962890625, 0.9921875, 1.0, 0.94140625, 0.99169921875, 0.9443359375, 0.9990234375, 0.99755859375, 0.99853515625, 1.0, 1.0, 0.85205078125, 0.64404296875, 0.58837890625, 0.99951171875, 0.65380859375, 0.0289459228515625, 0.1195068359375, 0.9990234375, 0.9892578125, 0.99951171875, 0.79931640625, 0.99072265625, 1.0, 0.298583984375, 0.7607421875, 0.48779296875, 0.9990234375, 0.87841796875, 0.98291015625, 0.35595703125, 0.01300811767578125, 0.9990234375, 0.87890625, 0.034393310546875, 0.78857421875, 0.951171875, 8.165836334228516e-06, 1.1324882507324219e-06, 0.642578125, 0.0008869171142578125, 0.60546875, 0.001285552978515625, 0.0094451904296875, 0.44384765625, 0.87158203125]], "normalized_score": [0.23430290818214417], "tokens": [["\u2581The", "\u2581opt", "ic", "\u2581n", "erve", "\u2581does", "\u2581not", "\u2581cross", "\u2581the", "\u2581mid", "line", ".", "\u2581It", "\u2581enters", "\u2581the", "\u2581brain", "\u2581and", "\u2581connect", "s", "\u2581to", "\u2581the", "\u2581visual", "\u2581cor", "tex", "\u2581on", "\u2581the", "\u2581opposite", "\u2581side", "\u2581of", "\u2581the", "\u2581brain", "\u2581on", "\u2581which", "\u2581it", "\u2581first", "\u2581enters", ".", "\u2581A", "\u2581Guide", "\u2581to", "\u2581Building", "\u2581a", "\u2581P", "itch", "ing", "\u2581Machine"]], "entropy": [[2.845703125, 0.06170654296875, 5.322694778442383e-05, 0.255126953125, 0.04833984375, 0.28466796875, 0.007190704345703125, 0.020172119140625, 0.01129913330078125, 0.0005450248718261719, 0.00110626220703125, 0.6318359375, 1.126953125, 1.6787109375, 0.006195068359375, 1.171875, 0.96728515625, 2.197265625, 0.0098724365234375, 0.06964111328125, 0.007755279541015625, 0.7314453125, 0.06903076171875, 0.00020802021026611328, 1.3193359375, 0.7734375, 0.919921875, 0.007511138916015625, 0.52587890625, 0.090576171875, 0.84814453125, 1.19921875, 0.00881195068359375, 0.37353515625, 2.0, 0.97265625, 0.2257080078125, 0.423095703125, 2.99609375, 1.4287109375, 2.365234375, 2.283203125, 4.3046875, 4.421875, 2.05859375, 0.87060546875]], "avg_entropy": [0.9265395752761675], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "optic chiasm", "score_of_biggest_cluster": 0.23430290818214417, "score_of_first_answer": 0.23430290818214417, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.1324882507324219e-06, "avg_score": 0.23430290818214417, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3797758853351286, "std_of_first_answer": 0.3797758853351286, "avg_entropy_of_first_answer": 0.9265395752761675, "lex_sim": 1.0}
{"question": "who plays dusty in the movie pure country", "answer": ["Gail Morgan Hickman #TellVodafone \u2013 A Call for Customer-Centric Innovation"], "scores": [[0.525390625, 0.050811767578125, 0.09954833984375, 1.0, 0.97021484375, 0.9990234375, 4.172325134277344e-07, 0.002044677734375, 0.0007843971252441406, 0.004161834716796875, 0.00010204315185546875, 0.74853515625, 0.99560546875, 0.00016248226165771484, 0.019378662109375, 0.007099151611328125, 0.356201171875, 0.263916015625, 0.0011739730834960938, 0.19921875, 0.98291015625, 0.0036907196044921875, 0.97705078125, 0.9755859375]], "normalized_score": [0.0315232016146183], "tokens": [["\u2581G", "ail", "\u2581Morgan", "\u2581H", "ick", "man", "\u2581#", "T", "ell", "V", "od", "af", "one", "\u2581\u2013", "\u2581A", "\u2581Call", "\u2581for", "\u2581Customer", "-", "Cent", "ric", "\u2581In", "nov", "ation"]], "entropy": [[2.240234375, 4.29296875, 1.7236328125, 0.0013132095336914062, 0.1605224609375, 0.008697509765625, 0.890625, 4.9609375, 2.134765625, 3.892578125, 2.09375, 1.6083984375, 0.031585693359375, 1.7734375, 5.89453125, 4.9609375, 1.2119140625, 2.8125, 1.240234375, 2.220703125, 0.0894775390625, 2.01953125, 0.14599609375, 0.134521484375]], "avg_entropy": [1.9393247365951538], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "George Strait", "score_of_biggest_cluster": 0.0315232016146183, "score_of_first_answer": 0.0315232016146183, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.0315232016146183, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4269694525767243, "std_of_first_answer": 0.4269694525767243, "avg_entropy_of_first_answer": 1.9393247365951538, "lex_sim": 1.0}
{"question": "who was running as vice president in 1984", "answer": ["Geraldine Ferraro, who ran as the Democratic Vice Presidential candidate alongside Walter Mondale."], "scores": [[0.236328125, 1.0, 0.99951171875, 0.90234375, 1.0, 0.069580078125, 0.3583984375, 0.4443359375, 0.69580078125, 0.86962890625, 0.413818359375, 0.008819580078125, 0.99365234375, 0.96435546875, 0.284423828125, 0.7763671875, 0.97412109375, 1.0, 1.0, 0.6435546875, 4.172325134277344e-07, 0.0059814453125, 0.00015485286712646484, 0.001178741455078125, 0.003932952880859375, 0.04034423828125, 0.00811004638671875, 0.07733154296875, 0.99951171875]], "normalized_score": [0.10401850938796997], "tokens": [["\u2581Ger", "ald", "ine", "\u2581Ferr", "aro", ",", "\u2581who", "\u2581ran", "\u2581as", "\u2581the", "\u2581Democratic", "\u2581Vice", "\u2581President", "ial", "\u2581candidate", "\u2581alongside", "\u2581Walter", "\u2581Mond", "ale", ".", "\u2581#", "2", "\u2581The", "\u2581World", "\u2581Today", ":", "\u2581An", "\u2581Over", "view"]], "entropy": [[1.1171875, 0.0014238357543945312, 0.004222869873046875, 0.384521484375, 0.0011644363403320312, 1.3525390625, 1.166015625, 0.7109375, 0.85205078125, 0.54052734375, 1.33203125, 0.69775390625, 0.04022216796875, 0.1805419921875, 0.7060546875, 0.6650390625, 0.1712646484375, 0.0022296905517578125, 1.990795135498047e-05, 0.892578125, 0.30712890625, 3.849609375, 2.35546875, 6.2890625, 3.046875, 3.005859375, 4.59765625, 2.412109375, 0.002960205078125]], "avg_entropy": [1.265001917707509], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "George H. W. Bush", "score_of_biggest_cluster": 0.10401850938796997, "score_of_first_answer": 0.10401850938796997, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.10401850938796997, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4176372344339708, "std_of_first_answer": 0.4176372344339708, "avg_entropy_of_first_answer": 1.265001917707509, "lex_sim": 1.0}
{"question": "tumhi ho bandhu sakha tumhi cast real name", "answer": ["Rajat Rawail #9: \"An unforgettable family adventure"], "scores": [[0.08282470703125, 0.1448974609375, 0.396240234375, 0.98876953125, 8.940696716308594e-07, 0.00025391578674316406, 0.0005440711975097656, 0.027862548828125, 0.0012531280517578125, 0.0009427070617675781, 0.2462158203125, 0.99609375, 0.99072265625, 0.0027790069580078125, 0.00783538818359375, 0.99951171875]], "normalized_score": [0.017794806510210037], "tokens": [["\u2581Raj", "at", "\u2581Raw", "ail", "\u2581#", "9", ":", "\u2581\"", "An", "\u2581un", "for", "get", "table", "\u2581family", "\u2581advent", "ure"]], "entropy": [[4.14453125, 2.564453125, 2.8984375, 0.08935546875, 1.1640625, 2.943359375, 2.91015625, 4.94921875, 2.689453125, 3.1875, 3.361328125, 0.032379150390625, 0.0743408203125, 5.02734375, 3.123046875, 0.005321502685546875]], "avg_entropy": [2.447767972946167], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Aalika Sheikh", "score_of_biggest_cluster": 0.017794806510210037, "score_of_first_answer": 0.017794806510210037, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 8.940696716308594e-07, "avg_score": 0.017794806510210037, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4111140485745627, "std_of_first_answer": 0.4111140485745627, "avg_entropy_of_first_answer": 2.447767972946167, "lex_sim": 1.0}
{"question": "who played sarah hedley in when the boat comes in", "answer": ["Stephanie Cole #OTD in 1973 \u2013 The British government announced the state of emergency because of industrial unrest and power cuts."], "scores": [[0.1192626953125, 0.99169921875, 0.91650390625, 5.960464477539063e-08, 0.00279998779296875, 0.93505859375, 0.0010175704956054688, 0.95068359375, 0.97998046875, 0.9970703125, 0.2305908203125, 0.06231689453125, 0.0035419464111328125, 0.0197906494140625, 0.12481689453125, 2.6226043701171875e-06, 0.0855712890625, 0.1619873046875, 7.873773574829102e-05, 0.392578125, 0.97705078125, 1.0, 0.00319671630859375, 0.95361328125, 0.0189361572265625, 0.6962890625, 1.0, 0.053009033203125, 0.1788330078125, 0.9140625, 0.99755859375, 0.6318359375, 0.1912841796875, 0.1270751953125, 0.984375, 0.84033203125, 0.98876953125, 0.8857421875, 0.026275634765625, 0.062347412109375, 0.0401611328125, 0.97998046875, 0.035125732421875, 0.08721923828125, 0.056976318359375, 0.99951171875]], "normalized_score": [0.08597951382398605], "tokens": [["\u2581Steph", "anie", "\u2581Cole", "\u2581#", "OT", "D", "\u2581in", "\u2581", "1", "9", "7", "3", "\u2581\u2013", "\u2581The", "\u2581British", "\u2581government", "\u2581announced", "\u2581the", "\u2581state", "\u2581of", "\u2581emer", "gency", "\u2581because", "\u2581of", "\u2581industrial", "\u2581un", "rest", "\u2581and", "\u2581power", "\u2581cut", "s", ".", "\u2581#", "OT", "D", "\u2581in", "\u2581", "1", "8", "4", "5", "\u2581\u2013", "\u2581Sir", "\u2581William", "\u2581Row", "an"]], "entropy": [[3.107421875, 0.07122802734375, 0.51708984375, 0.76904296875, 5.48828125, 0.48095703125, 1.61328125, 0.428466796875, 0.10394287109375, 0.0233154296875, 1.580078125, 2.1640625, 2.3828125, 2.853515625, 3.8046875, 1.5322265625, 2.828125, 1.4775390625, 3.2734375, 2.37890625, 0.1534423828125, 0.00152587890625, 2.533203125, 0.317626953125, 1.21484375, 1.236328125, 0.0015668869018554688, 2.36328125, 3.080078125, 0.436767578125, 0.0224456787109375, 1.8525390625, 3.291015625, 2.259765625, 0.133056640625, 0.865234375, 0.09832763671875, 0.367431640625, 0.1983642578125, 1.900390625, 2.205078125, 0.1234130859375, 3.27734375, 2.337890625, 4.17578125, 0.0032329559326171875]], "avg_entropy": [1.5506172387496284], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Rosalind Bailey", "score_of_biggest_cluster": 0.08597951382398605, "score_of_first_answer": 0.08597951382398605, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.08597951382398605, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43221405716647043, "std_of_first_answer": 0.43221405716647043, "avg_entropy_of_first_answer": 1.5506172387496284, "lex_sim": 1.0}
{"question": "who was the first elected president of pakistan", "answer": ["Iskander Mirza"], "scores": [[0.8310546875, 0.91650390625, 0.98681640625, 0.99951171875, 1.0]], "normalized_score": [0.9444035887718201], "tokens": [["\u2581I", "sk", "ander", "\u2581Mir", "za"]], "entropy": [[0.923828125, 0.371337890625, 0.0723876953125, 0.0033512115478515625, 2.1696090698242188e-05]], "avg_entropy": [0.27418532371521], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Iskander Mirza", "score_of_biggest_cluster": 0.9444035887718201, "score_of_first_answer": 0.9444035887718201, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.8310546875, "avg_score": 0.9444035887718201, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.06561235578524409, "std_of_first_answer": 0.06561235578524409, "avg_entropy_of_first_answer": 0.27418532371521, "lex_sim": 1.0}
{"question": "who is the writer of a walk to remember", "answer": ["Nicholas Sparks #FlyWithMe"], "scores": [[0.99658203125, 0.9912109375, 1.0, 1.0, 5.960464477539063e-08, 0.002742767333984375, 3.445148468017578e-05, 0.0020046234130859375, 0.28759765625]], "normalized_score": [0.011382605880498886], "tokens": [["\u2581Nicholas", "\u2581S", "par", "ks", "\u2581#", "F", "ly", "With", "Me"]], "entropy": [[0.022857666015625, 0.053497314453125, 3.230571746826172e-05, 0.0003178119659423828, 0.5205078125, 5.390625, 4.140625, 1.736328125, 2.8203125]], "avg_entropy": [1.631678170628018], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "American writer Nicholas Sparks", "score_of_biggest_cluster": 0.011382605880498886, "score_of_first_answer": 0.011382605880498886, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.011382605880498886, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.47409058542633514, "std_of_first_answer": 0.47409058542633514, "avg_entropy_of_first_answer": 1.631678170628018, "lex_sim": 1.0}
{"question": "who played cory's older brother on boy meets world", "answer": ["Ben Savage #95: Why do different people have different religious beliefs?"], "scores": [[0.293212890625, 1.0, 1.0, 1.7881393432617188e-07, 0.0004124641418457031, 0.0305938720703125, 0.00978851318359375, 0.00017690658569335938, 0.049957275390625, 9.02414321899414e-05, 0.2340087890625, 0.5546875, 0.9931640625, 0.01458740234375, 0.9619140625, 0.994140625, 0.888671875]], "normalized_score": [0.029220441356301308], "tokens": [["\u2581Ben", "\u2581Sav", "age", "\u2581#", "9", "5", ":", "\u2581Why", "\u2581do", "\u2581different", "\u2581people", "\u2581have", "\u2581different", "\u2581religious", "\u2581belief", "s", "?"]], "entropy": [[2.107421875, 0.0007262229919433594, 9.262561798095703e-05, 0.91845703125, 3.6171875, 3.7578125, 3.6328125, 4.71875, 3.009765625, 1.9443359375, 4.0625, 2.71484375, 0.0692138671875, 3.349609375, 0.220458984375, 0.046630859375, 0.6513671875]], "avg_entropy": [2.0483521082822014], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Will Friedle", "score_of_biggest_cluster": 0.029220441356301308, "score_of_first_answer": 0.029220441356301308, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.7881393432617188e-07, "avg_score": 0.029220441356301308, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4364661179849521, "std_of_first_answer": 0.4364661179849521, "avg_entropy_of_first_answer": 2.0483521082822014, "lex_sim": 1.0}
{"question": "what year does the quiet man take place", "answer": ["The Quiet Man takes place in the early 1930s."], "scores": [[0.42529296875, 0.970703125, 1.0, 0.99951171875, 0.399658203125, 0.99951171875, 0.98193359375, 0.82861328125, 0.27197265625, 0.99755859375, 0.974609375, 1.0, 0.9970703125, 1.0, 0.9921875, 0.83251953125]], "normalized_score": [0.8018490076065063], "tokens": [["\u2581The", "\u2581Qu", "iet", "\u2581Man", "\u2581takes", "\u2581place", "\u2581in", "\u2581the", "\u2581early", "\u2581", "1", "9", "3", "0", "s", "."]], "entropy": [[1.302734375, 0.1947021484375, 2.562999725341797e-05, 0.006343841552734375, 1.6201171875, 0.004398345947265625, 0.125244140625, 0.5068359375, 0.8798828125, 0.02105712890625, 0.1190185546875, 0.0016355514526367188, 0.0221710205078125, 5.537271499633789e-05, 0.04522705078125, 0.6591796875]], "avg_entropy": [0.34428929910063744], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "the 1920s", "score_of_biggest_cluster": 0.8018490076065063, "score_of_first_answer": 0.8018490076065063, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.27197265625, "avg_score": 0.8018490076065063, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.24252284150645892, "std_of_first_answer": 0.24252284150645892, "avg_entropy_of_first_answer": 0.34428929910063744, "lex_sim": 1.0}
{"question": "who played harley in harley davidson and the marlboro man", "answer": ["Mickey Rourke"], "scores": [[0.98974609375, 1.0, 0.98681640625, 1.0, 1.0]], "normalized_score": [0.9952954649925232], "tokens": [["\u2581Mic", "key", "\u2581R", "our", "ke"]], "entropy": [[0.0826416015625, 0.00026988983154296875, 0.0709228515625, 0.00112152099609375, 0.0003190040588378906]], "avg_entropy": [0.031054973602294922], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Mickey Rourke", "score_of_biggest_cluster": 0.9952954649925232, "score_of_first_answer": 0.9952954649925232, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.98681640625, "avg_score": 0.9952954649925232, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.005815263644906018, "std_of_first_answer": 0.005815263644906018, "avg_entropy_of_first_answer": 0.031054973602294922, "lex_sim": 1.0}
{"question": "the joint between a coxal bone of the pelvis and the sacrum", "answer": ["Sacroiliac joint #115: LIVE!"], "scores": [[0.2890625, 0.99755859375, 0.97705078125, 1.0, 0.92333984375, 5.960464477539063e-08, 0.0123291015625, 0.0041046142578125, 0.00875091552734375, 0.0017976760864257812, 0.0007867813110351562, 0.00010985136032104492, 0.10760498046875, 3.2186508178710938e-06, 0.0009918212890625, 0.396240234375, 0.0213623046875, 0.0033016204833984375, 0.68603515625, 0.01537322998046875, 0.9736328125, 0.053924560546875, 0.01093292236328125, 0.5283203125, 0.033905029296875, 0.0005774497985839844, 0.03033447265625, 0.95654296875, 0.994140625, 0.012237548828125, 0.10198974609375, 0.040557861328125, 0.006374359130859375, 0.36865234375, 0.00533294677734375, 0.1710205078125]], "normalized_score": [0.021965371444821358], "tokens": [["\u2581Sac", "ro", "ilia", "c", "\u2581joint", "\u2581#", "1", "1", "5", ":", "\u2581L", "IVE", "!", "\u2581Mark", "\u2581M", "anson", "\u2581on", "\u2581Love", ",", "\u2581D", "ating", "\u2581and", "\u2581M", "ating", "\u2581(", "plus", "\u2581Q", "&", "A", "!", "),", "\u2581with", "\u2581K", "yle", "\u2581T", "oth"]], "entropy": [[1.9560546875, 0.018829345703125, 0.1312255859375, 0.00017774105072021484, 0.282470703125, 0.81787109375, 4.16015625, 1.7890625, 2.400390625, 2.888671875, 5.48046875, 2.548828125, 1.5546875, 1.8544921875, 4.84375, 2.515625, 4.40234375, 5.50390625, 1.458984375, 4.21875, 0.20263671875, 0.52001953125, 2.734375, 1.5380859375, 3.4296875, 5.34375, 5.1875, 0.297119140625, 0.043243408203125, 1.2041015625, 1.8671875, 6.1328125, 5.59375, 2.36328125, 2.791015625, 4.24609375]], "avg_entropy": [2.564483493566513], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "sacroiliac joint", "score_of_biggest_cluster": 0.021965371444821358, "score_of_first_answer": 0.021965371444821358, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 5.960464477539063e-08, "avg_score": 0.021965371444821358, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.38030763983063864, "std_of_first_answer": 0.38030763983063864, "avg_entropy_of_first_answer": 2.564483493566513, "lex_sim": 1.0}
{"question": "what type of database is library literature and information science", "answer": ["Library science databases."], "scores": [[0.70751953125, 0.1435546875, 0.57373046875, 0.040008544921875, 0.0, 0.0034961700439453125, 5.424022674560547e-05, 0.9111328125, 0.67431640625]], "normalized_score": [0.0], "tokens": [["\u2581Library", "\u2581science", "\u2581databases", ".", "\u2581###", "\u2581What", "\u2581it", "\u2581is", ":"]], "entropy": [[1.515625, 1.7255859375, 1.5185546875, 1.587890625, 0.3212890625, 5.01171875, 1.962890625, 0.611328125, 1.728515625]], "avg_entropy": [1.7759331597222223], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "bibliographic database", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 0.9111328125, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3497046395890761, "std_of_first_answer": 0.3497046395890761, "avg_entropy_of_first_answer": 1.7759331597222223, "lex_sim": 1.0}
{"question": "who sang you'll be a woman soon in pulp fiction", "answer": ["Crystal Gayle #86: The Tipping Point, by Malcolm Gladwell"], "scores": [[0.0211334228515625, 0.99951171875, 0.82666015625, 1.0, 1.0728836059570312e-06, 0.0135345458984375, 0.049774169921875, 0.00211334228515625, 0.035400390625, 0.01273345947265625, 0.00013434886932373047, 0.99853515625, 0.0269775390625, 0.0399169921875, 0.98876953125, 0.99658203125, 0.99951171875, 0.9990234375, 1.0]], "normalized_score": [0.05611661076545715], "tokens": [["\u2581Cry", "stal", "\u2581Gay", "le", "\u2581#", "8", "6", ":", "\u2581The", "\u2581T", "ipping", "\u2581Point", ",", "\u2581by", "\u2581Mal", "col", "m", "\u2581Glad", "well"]], "entropy": [[3.05859375, 0.00632476806640625, 0.96923828125, 0.0010099411010742188, 0.72998046875, 4.92578125, 2.90234375, 2.958984375, 4.484375, 4.3203125, 4.41015625, 0.016632080078125, 2.8828125, 5.5078125, 0.10205078125, 0.0231475830078125, 0.00402069091796875, 0.0098876953125, 0.0009255409240722656]], "avg_entropy": [1.9639152476662083], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "rock band Urge Overkill", "score_of_biggest_cluster": 0.05611661076545715, "score_of_first_answer": 0.05611661076545715, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 1.0728836059570312e-06, "avg_score": 0.05611661076545715, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.4802022648718594, "std_of_first_answer": 0.4802022648718594, "avg_entropy_of_first_answer": 1.9639152476662083, "lex_sim": 1.0}
{"question": "new mexico was admitted to the union as the . . . state", "answer": ["47th state #SciFund Challenge 2014: Support Science and Disaster Education in the Field"], "scores": [[0.994140625, 1.0, 1.0, 0.99609375, 0.74169921875, 0.0, 0.0006785392761230469, 0.0008959770202636719, 0.017578125, 0.1585693359375, 0.2275390625, 0.04296875, 0.300537109375, 0.98974609375, 0.9296875, 0.25048828125, 0.029052734375, 0.024658203125, 0.56201171875, 0.032562255859375, 0.0030536651611328125, 0.65283203125, 0.0261688232421875, 0.0667724609375, 0.5830078125, 0.006656646728515625]], "normalized_score": [0.0], "tokens": [["\u2581", "4", "7", "th", "\u2581state", "\u2581#", "S", "ci", "F", "und", "\u2581Challenge", "\u2581", "2", "0", "1", "4", ":", "\u2581Support", "\u2581Science", "\u2581and", "\u2581Dis", "aster", "\u2581Education", "\u2581in", "\u2581the", "\u2581Field"]], "entropy": [[0.05072021484375, 0.0025501251220703125, 0.002490997314453125, 0.031890869140625, 0.708984375, 1.0791015625, 2.375, 4.01953125, 2.9921875, 4.08203125, 1.859375, 3.00390625, 0.876953125, 0.08526611328125, 0.268310546875, 1.7333984375, 2.68359375, 5.0625, 1.353515625, 1.63671875, 3.67578125, 1.6689453125, 1.1650390625, 3.5, 2.197265625, 2.458984375]], "avg_entropy": [1.8682323602529674], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "47th", "score_of_biggest_cluster": 0.0, "score_of_first_answer": 0.0, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.0, "avg_score": 0.0, "D_var": 0.0, "rouge_correct_first_answer": true, "std_of_biggest_cluster": 0.39826844686285834, "std_of_first_answer": 0.39826844686285834, "avg_entropy_of_first_answer": 1.8682323602529674, "lex_sim": 1.0}
{"question": "actor who played caesar in dawn of the planet of the apes", "answer": ["Andy Serkis #RPGaDAY 2019, Day 23: Do you prefer running games in a real, physical location or online?"], "scores": [[0.92236328125, 0.9990234375, 1.0, 1.0, 4.172325134277344e-07, 0.002552032470703125, 0.0002529621124267578, 0.00732421875, 0.210693359375, 0.070556640625, 0.955078125, 0.98291015625, 0.004680633544921875, 0.54541015625, 0.0160064697265625, 0.06121826171875, 0.9931640625, 0.324951171875, 0.134033203125, 0.83349609375, 0.0024242401123046875, 0.98974609375, 0.278076171875, 0.0008664131164550781, 0.36083984375, 0.54541015625, 0.72900390625, 0.06475830078125, 0.00035691261291503906, 0.285888671875, 0.9228515625, 0.81005859375, 0.4482421875, 0.7763671875]], "normalized_score": [0.08450215309858322], "tokens": [["\u2581Andy", "\u2581Ser", "k", "is", "\u2581#", "R", "PG", "a", "DAY", "\u2581", "2", "0", "1", "9", ",", "\u2581Day", "\u2581", "2", "3", ":", "\u2581Do", "\u2581you", "\u2581prefer", "\u2581running", "\u2581games", "\u2581in", "\u2581a", "\u2581real", ",", "\u2581physical", "\u2581location", "\u2581or", "\u2581online", "?"]], "entropy": [[0.41748046875, 0.0076141357421875, 0.0003523826599121094, 4.32133674621582e-05, 0.35009765625, 5.5703125, 1.81640625, 4.921875, 1.8388671875, 1.2890625, 0.289306640625, 0.131591796875, 0.0325927734375, 1.1923828125, 1.8486328125, 3.056640625, 0.058868408203125, 1.5986328125, 2.3984375, 0.91796875, 2.509765625, 0.08135986328125, 2.373046875, 1.619140625, 2.697265625, 1.4267578125, 1.2041015625, 3.265625, 0.4560546875, 2.63671875, 0.372802734375, 0.55029296875, 1.9248046875, 0.9169921875]], "avg_entropy": [1.4638792714651894], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Andy Serkis", "score_of_biggest_cluster": 0.08450215309858322, "score_of_first_answer": 0.08450215309858322, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 4.172325134277344e-07, "avg_score": 0.08450215309858322, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.3996470955842176, "std_of_first_answer": 0.3996470955842176, "avg_entropy_of_first_answer": 1.4638792714651894, "lex_sim": 1.0}
{"question": "spyder from once upon a time in venice", "answer": ["The dog."], "scores": [[0.01678466796875, 0.246826171875, 0.1038818359375, 3.4570693969726562e-06, 0.0005021095275878906, 0.13525390625, 0.1846923828125, 0.0017442703247070312, 0.958984375, 0.99951171875, 0.00991058349609375, 0.22119140625, 0.0021305084228515625, 0.0302276611328125, 0.028533935546875, 0.67431640625, 0.998046875, 0.0994873046875, 0.008758544921875, 0.0010023117065429688, 0.00988006591796875, 0.1981201171875, 0.85888671875]], "normalized_score": [0.03356073796749115], "tokens": [["\u2581The", "\u2581dog", ".", "\u2581#", "1", "0", "0", "Day", "so", "f", "B", "etter", "B", "logging", "\u2581Challenge", "\u2581Day", "\u2581", "6", ":", "\u2581Why", "\u2581B", "log", "?"]], "entropy": [[4.24609375, 4.38671875, 2.28515625, 1.1416015625, 3.080078125, 4.33203125, 3.564453125, 3.908203125, 0.26611328125, 0.0059051513671875, 2.521484375, 3.45703125, 2.2578125, 3.654296875, 2.029296875, 1.326171875, 0.020904541015625, 2.177734375, 2.64453125, 4.52734375, 3.74609375, 0.74169921875, 0.77783203125]], "avg_entropy": [2.482547262440557], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Jason Momoa", "score_of_biggest_cluster": 0.03356073796749115, "score_of_first_answer": 0.03356073796749115, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 3.4570693969726562e-06, "avg_score": 0.03356073796749115, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.35353758895151755, "std_of_first_answer": 0.35353758895151755, "avg_entropy_of_first_answer": 2.482547262440557, "lex_sim": 1.0}
{"question": "when did world war 2 officially start and end", "answer": ["World War II started on September 1, 1939, and ended on September 2, 1945."], "scores": [[0.95751953125, 1.0, 0.9384765625, 0.324462890625, 0.99169921875, 0.9951171875, 0.99951171875, 1.0, 0.99462890625, 0.9990234375, 1.0, 1.0, 1.0, 1.0, 0.2344970703125, 0.9951171875, 0.99169921875, 1.0, 0.9736328125, 1.0, 1.0, 1.0, 0.99951171875, 1.0, 1.0, 1.0, 1.0, 0.9677734375]], "normalized_score": [0.9056106805801392], "tokens": [["\u2581World", "\u2581War", "\u2581II", "\u2581started", "\u2581on", "\u2581September", "\u2581", "1", ",", "\u2581", "1", "9", "3", "9", ",", "\u2581and", "\u2581ended", "\u2581on", "\u2581September", "\u2581", "2", ",", "\u2581", "1", "9", "4", "5", "."]], "entropy": [[0.237548828125, 0.0004715919494628906, 0.2349853515625, 1.1083984375, 0.057403564453125, 0.032257080078125, 0.0025424957275390625, 0.0007748603820800781, 0.036865234375, 0.007251739501953125, 1.9669532775878906e-05, 8.046627044677734e-06, 0.00013685226440429688, 9.608268737792969e-05, 0.599609375, 0.033782958984375, 0.05682373046875, 0.001850128173828125, 0.126708984375, 0.0018568038940429688, 0.0001100301742553711, 0.0004210472106933594, 0.005596160888671875, 3.039836883544922e-06, 7.092952728271484e-06, 0.0001304149627685547, 0.00028204917907714844, 0.166015625]], "avg_entropy": [0.0968556169952665], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "1939", "score_of_biggest_cluster": 0.9056106805801392, "score_of_first_answer": 0.9056106805801392, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.2344970703125, "avg_score": 0.9056106805801392, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.1845980065723166, "std_of_first_answer": 0.1845980065723166, "avg_entropy_of_first_answer": 0.0968556169952665, "lex_sim": 1.0}
{"question": "who played maudie in the movie el dorado", "answer": ["Kevin Costner"], "scores": [[0.00595855712890625, 0.84228515625, 1.0]], "normalized_score": [0.17121170461177826], "tokens": [["\u2581Kevin", "\u2581Cost", "ner"]], "entropy": [[3.154296875, 0.98974609375, 0.0001163482666015625]], "avg_entropy": [1.381386439005534], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "Charlene Holt", "score_of_biggest_cluster": 0.17121170461177826, "score_of_first_answer": 0.17121170461177826, "max_score_of_first_answer": 1.0, "min_score_of_first_answer": 0.00595855712890625, "avg_score": 0.17121170461177826, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.43620007418637446, "std_of_first_answer": 0.43620007418637446, "avg_entropy_of_first_answer": 1.381386439005534, "lex_sim": 1.0}
{"question": "how many pitchers does a major league team have", "answer": ["10-12"], "scores": [[0.343505859375, 0.97607421875, 0.2489013671875, 0.77880859375, 0.99951171875, 0.480224609375]], "normalized_score": [0.5610710978507996], "tokens": [["\u2581", "1", "0", "-", "1", "2"]], "entropy": [[2.537109375, 0.15673828125, 1.48046875, 0.90771484375, 0.002986907958984375, 0.896484375]], "avg_entropy": [0.9969170888264974], "clusters": [[0]], "scores_of_each_cluster": [1.0], "semantic_entropy": -0.0, "num_clusters": 1, "proportion_of_biggest_clusters": 1.0, "rouge_correct_of_biggest_cluster": false, "gold_answer": "five starting pitchers", "score_of_biggest_cluster": 0.5610710978507996, "score_of_first_answer": 0.5610710978507996, "max_score_of_first_answer": 0.99951171875, "min_score_of_first_answer": 0.2489013671875, "avg_score": 0.5610710978507996, "D_var": 0.0, "rouge_correct_first_answer": false, "std_of_biggest_cluster": 0.2966000171564572, "std_of_first_answer": 0.2966000171564572, "avg_entropy_of_first_answer": 0.9969170888264974, "lex_sim": 1.0}
